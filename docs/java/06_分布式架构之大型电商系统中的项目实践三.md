# 06_分布式架构之大型电商系统中的项目实践

## 03_多场景下的企业级分布式事务技术深入底层剖析

### 01_通过项目全程驱动来学习分布式事务技术的思路说明 

如果我们仅仅是讲解一下分布式事务实现的几种技术方案，整合一些技术做一下demo，然后就ok了 

最好的还是说什么呢，搞一个项目出来，有一定模拟仿真的业务，然后在一套模拟仿真的业务中，有一个系统，分析一下这个系统在事务这块有哪些技术难题，面临着哪些技术问题，我们针对这些问题，来学习分布式事务相关的技术，应用到我们的这个项目里来，结合一些业务让大家来好好的体会一下技术 

**01、仿支付宝流量充值中心的案例背景介绍（包含10+个服务的分布式系统）**

**02、基于Spring Boot完成单块架构的仿支付宝流量充值中心**

**03、事务的基础概念以及为流量充值中心加入最基础的事务**

**04、深入剖析Spring事务框架的源码（@Transactional注解底层的秘密）**

**05、并发量和数据量持续增加时将数据库进行拆分**

**06、跨多个数据库的事务问题分析**

**07、XA规范 + 2PC + 3PC的分布式事务知识讲解**

**08、MySQL XA分布式事务原理**

**09、Java与Spring的事务支持：JDBC事务、JTA事务、全局事务以及本地事务**

**10、多数据源支持 + XA分布式事务来重构流量充值中心**

**11、Spring对XA分布式事务支持的相关源码深入剖析**

**12、对流量充值中心进行服务化拆分（基于Spring Cloud拆分为10+个服务）**

**13、服务化系统的分布式事务问题分析**

**14、分布式系统一致性问题、CAP理论与BASE理论**

**15、分布式事务的各种解决方案原理讲解：TCC补偿方案、可靠消息最终一致性方案、最大努力通知方案、Sagas方案**

**16、可靠消息最终一致性方案的技术架构设计**

**17、在流量充值中心系统中落地实践可靠消息最终一致性方案**

**18、对可靠消息最终一致性方案进行多个点的架构优化**

**19、对可靠消息最终一致性方案涉及到的MQ等相关底层原理进行深入剖析**

**20、TCC方案的技术选型以及各种候选框架的压测**

**21、TCC方案的技术架构设计**

**22、在流量充值中心系统中落地实践TCC方案**

**23、站在BAT大型互联网公司的角度对TCC方案进行多个点的架构优化**

**24、对tcc-transaction框架深入阅读源码**

**25、最大努力通知方案的技术架构设计**

**26、在流量充值中心中落地实践最大努力通知方案**

**27、对最大努力通知方案进行多个点的架构优化**

28、**对最大努力通知方案涉及到的MQ等底层原理进行深入剖析**

**29、深入学习saga分布式事务解决方案**

**30、saga方案的技术架构设计**

**31、在流量充值中心项目中落地实践saga方案**

**32、深入研究saga分布式事务框架的源码**

**33、将TCC、可靠消息最终一致性、最大努力通知、saga等几种方案结合业务场景运用在电商平台项目中，与我们复杂电商的各个业务结合来使用**

### 02_先来体验一下真实的支付宝流量充值中心的使用流程的截图

咱们来看一个支付宝的流量充值中心的截图，其实很简单的：

![](C:\Users\zy199005\Desktop\中华石杉\images\java\06\0300201.png) 

![](C:\Users\zy199005\Desktop\中华石杉\images\java\06\0300202.png)

 ![](C:\Users\zy199005\Desktop\中华石杉\images\java\06\0300203.png)



![](C:\Users\zy199005\Desktop\中华石杉\images\java\06\0300204.png)

流量充值，说白了，就是在支付宝的充值中心里选择流量充值，然后选择一个流量套餐，付多少钱买多少个G的流量，进入一个支付宝支付的界面，刷个指纹确认支付就ok了，你的钱从支付宝转出去，然后人家中国移动给你充个1G的流量到你手机里，大体上来说就是这样子 

然后会创建一个对应的订单，或者叫做充值记录也可以 

每个充值记录里面，就是一个详细的账单，里面显示了你的各种东西 

### 03_如果让我们来实现支付宝的流量充值中心你会如何设计整体架构？

01_流量充值中心的整体架构设计

![0300301](C:\Users\zy199005\Desktop\中华石杉\images\java\06\0300301.png)

 但是可别小瞧了这一点东西，里面其实还是有点小复杂的东西的 

首先咱们来看看，如果从一个系统角度，要拆分为多少个服务来完成这个流量充值的过程。接下来的话呢，我们就围绕着这个流量充值中心的业务，结合业务流程，来分析一下，如果底层的系统让我们来设计的话，要包含哪些服务或者是哪些模块呢 

我们绝对不是说完全参照真实的支付宝的流量充值中心来做的，我们就站在一个用户的角度，分析一下使用流程，站在工程师的角度，如果让你来设计的话，需要包含哪些服务呢？我们这个课程里的这个所谓流量充值中心，主要是用一个比较贴近日常生活的项目案例来给大家来讲解和学习，绝对不是说我们做出来的流量充值中心的系统架构就跟真实的是一样的，这里肯定是有一定的差距的 

我觉得我干过类似的流量充值的项目，我感觉好像不应该是这样，较真 

八九不离十，但是肯定跟真实的系统有一定的差距 

（1）商品服务：这里是维护流量产品的，一个流量产品就是一个商品，比如说：100M，5元，就是一个流量产品；300M，10元，也是一个流量产品；那么就需要这么一个服务对流量产品进行增删改查了 

流量商品：售价，流量，类型（全国、省内、全球），说明，创建时间，修改时间 

（2）订单服务：你说要是充值了一个流量，那肯定会有一个流量充值的订单吧，这个就是在充值记录查询里可以看到的，比如下面那样子。 

支付成功之后，一定会给你创建一个流量充值订单 

流量充值订单：用户id（好比是你自己的支付宝账户的id），商户id（好比是中国移动的支付宝账户的id），商户名称（中国移动官方旗舰店），金额，订单标题，订单分类（通讯物流、日常生活），订单状态（交易成功，交易失败），付款方式（信用卡、支付宝余额、余额宝、银行卡、花呗分期），充值说明，充值号码，充值面值，奖励积分，订单的创建时间，订单的修改时间，订单号 

（3）支付服务：这个就是说你要实际付款的时候，肯定得有个支付服务来支持你付款吧，他会把你的支付宝里的钱划拨给中国移动，对吧，中国收到钱之后，才能给你的手机号里充值进去流量 

其实此时就会将指定的这个金额，比如说原价30块的1G流量包，现在优惠价是27块，然后你的账户里之前有一个5块钱的流量券，此时计算出最终价格就是22块，你刷一下指纹，22块钱，会从你的（信用卡、支付宝余额、余额宝、银行卡、花呗分期），将22块钱从你的支付宝的账户里，转账到中国移动的支付宝账户里去 

（4）运营商BOSS系统：这个就是运营商的系统了，一般叫做Business Operation Support System，就是业务操作支持系统，你支付成功之后，肯定得找运营商来完成流量的充值 

如果说你发现你的22块钱，已经从你的支付宝账户转到了中国移动的支付宝账户之后，接着当然是通知中国移动的运营商系统（BOSS系统，Business Operation Support System，业务操作支持系统），哥儿们，我已经付给你22块钱了，要充值1G流量，你得将这个流量给我充值到我的手机号里去 

（5）消息服务：如果运营商系统返回告诉你已经充值成功了，那么就ok了，你可以找消息服务来发送短信之类的消息给用户说充值成功了 

（6）抽奖服务：大家自己去关注一下支付宝，有的时候，你充值一次，就会给你一次抽奖的机会，所以说支付成功之后，会找抽奖服务来给你累加一次抽奖的机会 

如果大家玩儿过支付宝的充值的话，就应该知道这里有一个抽奖的环节，如果你充值成功了一次之火，他就会给你一个抽奖的权利，你就可以进行一次抽奖 

抽奖：用户id，当前抽奖次数，已使用的抽奖次数，创建时间，修改时间 

（7）积分服务：大家自己看看上面那个账单里的信息，是不是你充值以后会按照一定的比例，应该是5%的比例，给你累加对应的积分，充值了200块钱，就会有10个积分 

积分：用户id，当前积分，已兑换积分，创建时间，修改时间 

（8）促销服务：大家自己观察一下，有些流量充值套餐里，是不是有“惠”的标识，就是说，有些流量充值，会根据促销活动来减免你需要支付的金额 

你肯定是可以在这个促销服务中，去创建一个促销优惠活动，你的每个活动都可以跟指定的流量商品进行绑定，绑定了之后，在显示流量套餐列表的时候，如果这个流量套餐是有优惠活动的，此时就会显示这个优惠活动的优惠价 

优惠活动：流量商品id，优惠价格，活动的开始时间（从几月几号几点开始，生效），活动的结束时间（到几月几号节点，结束），状态（未开始，启用，已结束），创建时间，修改时间 

送流量券活动：流量商品id，流量券的金额，活动的开始时间（从几月几号几点开始，生效），活动的结束时间（到几月几号节点，结束），状态（未开始，启用，已结束），创建时间，修改时间 

（9）流量券服务：大家看看有个套餐，是不是说充值之后会送一个5元的流量券，那么下次你支付的时候，就可以用流量券来抵扣 

流量券：用户id，流量券的金额，状态（未使用，已使用，已过期），有效期开始时间（从几月几号开始，这个券是生效的），有效期结束时间（到几月几号，这个券就会失效），创建时间，修改时间 

举例，花费27块钱购买了一个1G的流量套餐包之后，赠送了一张5块钱的流量券，但是这个流量券是在2018-07-01~2018-08-01，有效期只有1个月，你必须在1个月之内再次充值流量，才可以使用这个流量券，如果超过了这个期限，那么流量券作废，以后就不能再用了 

（10）流量服务：这个服务就是核心的负责指挥其余所有服务的一个中枢大脑 

其实都是直接手机app跟流量充值服务进行交互，流量服务负责去全权指挥后面的各种服务完成各种事情，实现各种业务逻辑

### 04_画图分析流量充值中心的10+个服务如何配合运转流程

02_流量充值中心运转流程

![](C:\Users\zy199005\Desktop\中华石杉\images\java\06\0300401.png) 

那么下面我们来梳理一个流量充值的业务流程出来，但是先说明，我们不会说做的完全跟真实的一模一样，我们只是尽可能按照这个场景来还原出来，尽量用贴近生活的场景，以及有一定复杂度的场景来学习分布式事务这个技术： 

（1）进入流量充值页面：显示所有的流量产品，以及每个流量产品对应的促销活动的价格，包括每个流量产品的明细说明，以及流量券。这里会查询商品服务，促销服务，流量券服务，显示出来对应的信息 

（2）选择了一个流量产品，然后选择支付之后，进入支付页面，接着刷个指纹发起支付 

（3）调用订单服务，创建一个订单 

（4）调用支付服务，完成具体的支付交易，也就是在用户的支付宝账户里扣款，同时在运营商账户里入账款项 

（5）调用运营商BOSS系统，完成具体的流量充值，让运营商系统给手机号充值流量 

（6）完事儿了之后，调用消息服务，发个短信给用户，让用户知道 

（7）调用抽奖服务，给用户增加一次抽奖的机会 

（8）调用积分服务，给用户增加对应的积分 

（9）调用流量券服务，给用户赠送一个流量券 

画图来说明一下上面的整套业务流程 

好啦，说简单不简单，说复杂也不复杂，但是有个贴近生活的场景，让我们一步一步来学习分布式事务的技术方案，足够了，接下来，我们会从单机单库事务讲起，一直到分布式事务的各种技术方案

### 05_基于Spring Boot搭建一个单块架构的流量充值系统 

介绍完整个类似支付宝的流量充值中心，站在用户的使用流程（截图），如果让你来设计这个流量充值系统架构会是如何的（会划分为哪些服务，每个服务是干嘛的），梳理了一下基于这套架构的整个流量充值中心运转的流程 

基于Spring Boot快速的搭建一个单块的工程，我们从单块工程起步，给大家一步一步来演示整个事务的问题出现的过程，spring boot做单块系统，spring cloud做分布式系统，每个过程都有对应的事务问题 

**1、创建一个工程：data-refill-center** 

流量充值中心 

纯正的英文来说流量，其实是data，不是flow之类的单词，我今天用了100MB的流量。I have consumed 100MB data today.，是这么说的 

有些人的流量使用的需求很大，Some people have heavy data usage demand。 

比较纯正的充值的说法是top up、refill或者recharge，我们就用refill这个单词好了 

所以工程的意思就是流量充值中心 

**2、pom.xml（主要引入spring boot*相关的依赖）** 

<!-- 继承spring boot的parent工程 -->

​     <parent>

​       <groupId>org.springframework.boot</groupId>

​       <artifactId>spring-boot-starter-parent</artifactId>

​       <version>1.5.9.RELEASE</version>

​     </parent>     

​     <dependencies>

​          <!-- spring boot的核心starter -->

​       <dependency>

​          <groupId>org.springframework.boot</groupId>

​         <artifactId>spring-boot-starter-web</artifactId>

​       </dependency>

​          <dependency>

​            <groupId>org.mybatis.spring.boot</groupId>

​            <artifactId>mybatis-spring-boot-starter</artifactId>

​            <version>1.3.1</version>

​          </dependency>

​          <dependency> 

​            <groupId>org.springframework.boot</groupId> 

​            <artifactId>spring-boot-starter-data-jpa</artifactId> 

​          </dependency>

​          <dependency>

​            <groupId>org.springframework.boot</groupId>

​            <artifactId>spring-boot-starter-jdbc</artifactId>

​          </dependency>       

​          <!-- spring boot提供的辅助开发工具 -->

​          <dependency>

​         <groupId>org.springframework.boot</groupId>

​         <artifactId>spring-boot-devtools</artifactId>

​         <optional>true</optional>

​       </dependency>        

​          <!-- MySQL数据库连接需要的依赖 -->

​          <dependency> 

​            <groupId>mysql</groupId> 

​            <artifactId>mysql-connector-java</artifactId> 

​            <scope>runtime</scope> 

​          </dependency>

​          <dependency> 

​            <groupId>com.alibaba</groupId> 

​            <artifactId>druid</artifactId> 

​            <version>1.1.6</version> 

​          </dependency>          

​          <!-- 测试需要的依赖 -->

​          <dependency>

​            <groupId>org.springframework.boot</groupId>

​            <artifactId>spring-boot-starter-test</artifactId>

​          </dependency>            

​          <!-- json处理相关的依赖 -->

​          <dependency>

​            <groupId>com.alibaba</groupId>

​            <artifactId>fastjson</artifactId>

​            <version>1.2.45</version>

​          </dependency>          

​          <!-- 系统监控相关的依赖 -->

​          <dependency>

​         <groupId>org.springframework.boot</groupId>

​          <artifactId>spring-boot-starter-actuator</artifactId>

​       </dependency>       

​       <!-- cglib的BeanCopier需要的依赖 -->

​       <dependency> 

​      <groupId>asm</groupId> 

​      <artifactId>asm</artifactId> 

​      <version>3.3.1</version> 

​    </dependency> 

​    <dependency> 

​      <groupId>asm</groupId> 

​      <artifactId>asm-commons</artifactId> 

​      <version>3.3.1</version> 

​    </dependency> 

​    <dependency> 

​      <groupId>asm</groupId> 

​      <artifactId>asm-util</artifactId> 

​      <version>3.3.1</version> 

​    </dependency> 

​    <dependency> 

​      <groupId>cglib</groupId> 

​      <artifactId>cglib-nodep</artifactId> 

​      <version>2.2.2</version> 

​    </dependency>    

​    <dependency> 

​            <groupId>commons-fileupload</groupId> 

​            <artifactId>commons-fileupload</artifactId> 

​            <version>1.3.2</version> 

​          </dependency>           

​          <dependency>

​            <groupId>com.fasterxml.jackson.core</groupId>

​            <artifactId>jackson-databind</artifactId>

​          </dependency>

​     </dependencies>     

​     <build>

​       <plugins>

​            <!-- spring boot提供的核心maven插件 -->

​         <plugin>

​           <groupId>org.springframework.boot</groupId>

​           <artifactId>spring-boot-maven-plugin</artifactId>

​         </plugin>

​         <plugin>

​                    <groupId>org.codehaus.mojo</groupId>

​                    <artifactId>cobertura-maven-plugin</artifactId>

​                    <version>2.7</version>

​               </plugin>

​       </plugins>

​     </build> 

**3、Spring Boot的application.yml配置文件（主要是数据源配置）** 

spring:

 datasource:

  type: com.alibaba.druid.pool.DruidDataSource

  url: jdbc:mysql://127.0.0.1:3306/data-refill-center?useUnicode=true&characterEncoding=utf-8

  username: root

  password: root

  driverClassName: com.mysql.jdbc.Driver

  initialSize: 50

  minIdle: 50

  maxActive: 500

  maxWait: 60000 

  timeBetweenEvictionRunsMillis: 60000 

  minEvictableIdleTimeMillis: 300000

  validationQuery: SELECT 1 FROM DUAL

  testWhileIdle: true

  testOnBorrow: false 

  testOnReturn: false 

  poolPreparedStatements: true 

  maxPoolPreparedStatementPerConnectionSize: 20

  filters: stat,wall,log4j

connectionProperties: druid.stat.mergeSql=true;druid.stat.slowSqlMillis=5000 

**4、编写Druid数据源配置类** 

数据库连接池还是使用druid，我们针对这个数据库连接池，要写一个配置bean 

@Configuration 

public class DruidDataSourceConfig {   

  @Value("${spring.datasource.url}") 

  private String dbUrl; 

  @Value("${spring.datasource.username}") 

  private String username; 

  @Value("${spring.datasource.password}") 

  private String password; 

  @Value("${spring.datasource.driverClassName}") 

  private String driverClassName; 

  @Value("${spring.datasource.initialSize}") 

  private int initialSize; 

  @Value("${spring.datasource.minIdle}") 

  private int minIdle; 

  @Value("${spring.datasource.maxActive}") 

  private int maxActive; 

  @Value("${spring.datasource.maxWait}") 

  private int maxWait; 

  @Value("${spring.datasource.timeBetweenEvictionRunsMillis}") 

  private int timeBetweenEvictionRunsMillis; 

  @Value("${spring.datasource.minEvictableIdleTimeMillis}") 

  private int minEvictableIdleTimeMillis; 

  @Value("${spring.datasource.validationQuery}") 

  private String validationQuery; 

  @Value("${spring.datasource.testWhileIdle}") 

  private boolean testWhileIdle; 

  @Value("${spring.datasource.testOnBorrow}") 

  private boolean testOnBorrow; 

  @Value("${spring.datasource.testOnReturn}") 

  private boolean testOnReturn; 

  @Value("${spring.datasource.poolPreparedStatements}") 

  private boolean poolPreparedStatements; 

  @Value("${spring.datasource.maxPoolPreparedStatementPerConnectionSize}") 

  private int maxPoolPreparedStatementPerConnectionSize; 

  @Value("${spring.datasource.filters}") 

  private String filters; 

  @Value("{spring.datasource.connectionProperties}") 

  private String connectionProperties;   

  /**

   \* 创建druid数据库连接池bean

   \* @return

   */

  @Bean   

  @Primary 

  public DataSource dataSource(){ 

​    DruidDataSource datasource = new DruidDataSource(); 

​    datasource.setUrl(this.dbUrl); 

​    datasource.setUsername(username); 

​    datasource.setPassword(password); 

​    datasource.setDriverClassName(driverClassName); 

​    datasource.setInitialSize(initialSize); 

​    datasource.setMinIdle(minIdle); 

​    datasource.setMaxActive(maxActive); 

​    datasource.setMaxWait(maxWait);     

​    datasource.setTimeBetweenEvictionRunsMillis(timeBetweenEvictionRunsMillis); 

​    datasource.setMinEvictableIdleTimeMillis(minEvictableIdleTimeMillis); 

​    datasource.setValidationQuery(validationQuery); 

​    datasource.setTestWhileIdle(testWhileIdle); 

​    datasource.setTestOnBorrow(testOnBorrow); 

​    datasource.setTestOnReturn(testOnReturn); 

​    datasource.setPoolPreparedStatements(poolPreparedStatements); 

​    datasource.setMaxPoolPreparedStatementPerConnectionSize(maxPoolPreparedStatementPerConnectionSize);     

​    try { 

​      datasource.setFilters(filters); 

​    } catch (SQLException e) { 

​      e.printStackTrace();

​    }     

​    datasource.setConnectionProperties(connectionProperties);      

​    return datasource; 

  }  

} 

**5、编写一个Spring Boot启动类** 

@SpringBootApplication

@ServletComponentScan

@Import(DruidDataSourceConfig.class)

public class DataRefillCenterApplication {     

​     public static void main(String[] args) { 

​          SpringApplication.run(DataRefillCenterApplication.class, args);

​     }     

} 

**6、创建一个流量充值中心的数据库：data-refill-center** 

我本地已经安装好了MySQL了，作为windows一个服务已经启动了，所以我用的是SQLyog数据库管理软件，下载的，大家用什么都可以。一般数据库的名字跟系统或者是服务的名字是一样的 

**7、启动一次spring boot单块系统，确认不要报错就可以了**

### 06_完成流量充值中心的显示流量充值商品的功能

![](C:\Users\zy199005\Desktop\中华石杉\images\java\06\0300601.png) 

前置说明：我们刚开始是做一个单块的系统，所以之前规划出来的10多个服务，都是放在一个单块系统里的，也就是我们刚才创建的那个data-refill-center的流量充值中心的系统，比如说流量服务其实刚开始就是在流量充值中心系统里是一个模块 

**1、再来细化一下用户进入流量充值界面的过程** 

（1）打开手机APP，进入流量充值的界面

（2）手机APP会发送一个请求到后端的流量服务（模块）里去

（3）首先，流量服务需要从商品服务（商品模块），获取到所有的流量套餐商品

（4）接着对每个流量套餐商品，都获取到对应的优惠活动，要求是关联当前流量套餐商品的优惠活动，而且状态是处于“进行中”的优惠活动，在创建优惠活动的时候，一个流量套餐最多只能查出来一个优惠活动。如果有优惠活动就跟流量套餐商品绑定在一起，如果没有优惠活动，那么就算了

（5）最后就是对每个流量套餐商品，都获取到对应的送流量券活动，要求是关联当前流量套餐商品的送优惠券活动，而且状态是处于“进行中”的活动。同上，如果有就绑定在一起，如果没有就算了 

**2、创建细化的数据库表结构** 

（1）流量套餐表 

流量套餐包（data_package）：id，售价，流量，类型（全国、省内、境外），说明，创建时间，修改时间 

```
ALTER TABLE data_package MODIFY created_time TIMESTAMP NULL DEFAULT CURRENT_TIMESTAMP 
ALTER TABLE data_package MODIFY modified_time TIMESTAMP NULL DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP 
```

（2）优惠活动表

优惠活动（promotion_activity）：id，流量套餐id，优惠价格，活动的开始时间（从几月几号几点开始，生效），活动的结束时间（到几月几号节点，结束），状态（未开始，进行中，已结束），创建时间，修改时间 

```
ALTER TABLE promotion_activity MODIFY created_time TIMESTAMP NULL DEFAULT CURRENT_TIMESTAMP 
ALTER TABLE promotion_activity MODIFY modified_time TIMESTAMP NULL DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP 
```

（3）送流量券活动表 

送流量券活动（coupon_activity）：id，流量套餐id，流量券的金额，活动的开始时间（从几月几号几点开始，生效），活动的结束时间（到几月几号节点，结束），状态（未开始，进行中，已结束），创建时间，修改时间 

**3、完成代码开发** 

**4、插入几条数据，测试一下** 

做web接口的测试，用chrome浏览器的postman插件，具体如何安装，大家自行百度，这个很简单 

http://localhost:8080/dataRefillCenter/dataPackages 

[

  {

​    "id": 1,

​    "price": 30,

​    "data": 1024,

​    "type": 2,

​    "comment": "月底失效，到账后生效",

​    "createdTime": 1533460448000,

​    "modifiedTime": 1533460448000,

​    "promotionActivity": {

​      "id": 1,

​      "dataPackageId": null,

​      "discountPrice": null,

​      "startTime": 1514736000000,

​      "endTime": 1546272000000,

​      "status": 2,

​      "createdTime": 1533460507000,

​      "modifiedTime": 1533460507000

​    },

​    "couponActivity": {

​      "id": 1,

​      "dataPackageId": null,

​      "couponAmount": null,

​      "startTime": 1514736000000,

​      "endTime": 1546272000000,

​      "status": 2,

​      "createdTime": 1533460618000,

​      "modifiedTime": 1533460618000

​    }

  }

]

### 07_完成流量充值中心的选择流量套餐商品后准备付款的功能

![](C:\Users\zy199005\Desktop\中华石杉\images\java\06\0300701.png)  

进入这个支付界面的时候，会发送一个请求到你的流量充值中心的后台系统去，主要是计算一下这个用户具体要支付多少钱 

手机APP，需要将用户账号id、用户选择的流量套餐的id、这个流量套餐当前的一个优惠价格（如果有的话），将这三个东西发送给后台的接口，后台系统会去查询用户账号id有没有流量券，如果有的话，将面额最高的流量券给查询出来，直接返回给手机APP 

就比如说，某个流量套餐，30元 -> 1GB，优惠价格是27元，用户有一张3元的流量券以及一张2元的流量券 

此时进入支付界面的时候，用户应该支付多少钱呢？后台接口，会查到这个用户账号id对应的流量券最高的面额，是3元钱，此时就会自动使用3元的流量券来抵扣掉这个27元的优惠价格 

计算出这个用户最终需要付款的是27元 - 3元 = 24元，这个时候用户用24元就可以买到1GB的流量 

手机APP获取到了面额最高的一张流量券之后，在手机APP端直接用优惠金额扣减掉流量券金额，显示出来最终的金额，告诉你使用了某张流量券，如果你确认支付了，就会给后台的支付接口，带回来对应的使用的流量券的id 

流量券（coupon）：id，用户账号id，流量券的金额，状态（未使用，已使用，已过期），有效期开始时间（从几月几号开始，这个券是生效的），有效期结束时间（到几月几号，这个券就会失效），创建时间，修改时间

### 08_完成流量充值中心的确认支付进行流量充值的功能（一）

### 09_完成流量充值中心的确认支付进行流量充值的功能（二） 

比如说你购买了一个优惠价为27元的流量套餐，你之前有一张3块钱的流量券，抵扣之后你要支付24元，你刷指纹，一下子支付了这个流量套餐，选择进行充值 

（1）完成支付：将用户的支付宝账号里的金额，转账到中国移动支付宝账号里去 

账号金额表（account_amount）：id，user_account_id，amount，created_time，modified_time 

```
ALTER TABLE data_package MODIFY created_time TIMESTAMP NULL DEFAULT CURRENT_TIMESTAMP 
ALTER TABLE data_package MODIFY modified_time TIMESTAMP NULL DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP 
```

（2）创建流量充值订单：状态为支付成功 

流量充值订单：id，订单号，用户id（好比是你自己的支付宝账户的id），商户id（好比是中国移动的支付宝账户的id），商户名称（中国移动官方旗舰店），金额，订单标题，订单分类（通讯物流、日常生活），订单状态（交易成功，交易失败），付款方式（信用卡、支付宝余额、余额宝、银行卡、花呗分期），充值说明，充值号码，充值流量，奖励积分，订单的创建时间，订单的修改时间 

（3）完成流量充值：找第三方的运营商的BOSS系统，告诉他，谁，什么手机号码，已经给你的支付宝转账了24元，麻烦你给他的手机号充值1GB的流量 

上面4个步骤可以说是核心的几个步骤 

（4）通知用户：找消息服务，发送短信通知用户 

不会说真实的去调用发短信的服务，这种发短信的API接口，第三方厂商，很多很多，百度搜索一下，他们一般来说，第三方厂商，会提供发送短信的API接口，你的系统只要预先在他们那里充值一些钱，然后你调用一次他们的接口，人家就给你发送一条短信，然后扣一条短信的钱 

（5）增加抽奖机会：找抽奖服务，给用户增加一次抽奖的机会 

我这儿没有给大家截图，但是我想说的是什么呢，大家自己去玩儿一下支付宝充值中心里面，充值话费最近有活动，你充值一次话费，就有一次抽奖的机会，然后下次你再进入支付宝，他会提示你有一个抽奖的机会 

抽奖：id，用户id，抽奖次数，创建时间，修改时间 

（6）增加积分：找积分服务，给用户增加5%，24元 * 5% = 1.2积分 

积分：id，用户id，积分，创建时间，修改时间 

（7）修改流量券的状态：如果本次支付用了流量券的话，就会去找流量券服务，去将使用的流量券的状态修改为已使用 

（8）赠送流量券：找流量券服务，给这个用户赠送一张跟流量券活动匹配的流量券。如果说这个流量套餐是有赠送流量券的活动的话，那么此时就会附赠一张流量券

### 10_完成流量充值中心的查看充值记录以及充值订单的功能

### 11_事务的基础知识筑基（一）：ACID以及几种隔离级别

27_01_读未提交

![](C:\Users\zy199005\Desktop\中华石杉\images\java\06\0301101.png)  

27_02_读已提交

![](C:\Users\zy199005\Desktop\中华石杉\images\java\06\0301102.png) 

27_03_可重复读

![](C:\Users\zy199005\Desktop\中华石杉\images\java\06\0301103.png)

27_04_幻读

![](C:\Users\zy199005\Desktop\中华石杉\images\java\06\0301104.png)

27_05_串行化

![](C:\Users\zy199005\Desktop\中华石杉\images\java\06\0301105.png) 

1、面试题 

事务的几个特点是什么？数据库事务有哪些隔离级别？MySQL的默认隔离级别是？ 

2、面试官心里分析 

用mysql开发的三个基本面：存储引擎、索引，然后就是事务，你必须得用事务。因为一个业务系统里，肯定要加事务保证一堆关联操作，要么一起成功要么一起失败，对不对？所以这是聊数据库必问的一个问题。 

最最最最最最基本的用mysql来开发，就3点：存储引擎（了解），索引（能建索引，写的SQL都用上索引），事务（了解事务的隔离级别，基于spring的事务支持在代码里加事务），咱们项目阶段一里的在mysql相关的也就这么几点。 

存储引擎 -> innodb，索引，基本按照你的SQL的需求都建了索引（可能漏了部分索引忘了建），事务（@Transactional注解，对service层统一加了事务） 

3、面试题剖析 

**3.1** **事务的ACID** 

这个先说一下ACID，必须得知道： 

（1）Atomic：原子性，就是一堆SQL，要么一起成功，要么都别执行，不允许某个SQL成功了，某个SQL失败了，这就是扯淡，不是原子性。 

（2）Consistency：一致性，这个是针对数据一致性来说的，就是一组SQL执行之前，数据必须是准确的，执行之后，数据也必须是准确的。别搞了半天，执行完了SQL，结果SQL对应的数据修改没给你执行，那不是坑爹么。 

（3）Isolation：隔离性，这个就是说多个事务在跑的时候不能互相干扰，别事务A操作个数据，弄到一半儿还没弄好呢，结果事务B来改了这个数据，导致事务A的操作出错了，那不就搞笑了。 

（4）Durability：持久性，事务成功了，就必须永久对数据的修改是有效的，别过了一会儿数据自己没了，不见了，那就好玩儿了。 

**3.2** **事务隔离级别** 

总之，面试问你事务，先聊一下ACID，然后聊聊隔离级别 

（1）读未提交，Read Uncommitted：这个很坑爹，就是说某个事务还没提交的时候，修改的数据，就让别的事务给读到了，这就恶心了，很容易导致出错的。这个也叫做脏读。 

（2）读已提交，Read Committed（不可重复读）：这个比上面那个稍微好一点，但是一样比较尴尬，就是说事务A在跑的时候， 先查询了一个数据是值1，然后过了段时间，事务B把那个数据给修改了一下还提交了，此时事务A再次查询这个数据就成了值2了，这是读了人家事务提交的数据啊，所以是读已提交。这个也叫做不可重复读，就是所谓的一个事务内对一个数据两次读，可能会读到不一样的值。 

（3）可重复读，Read Repeatable：这个就是比上面那个再好点儿，就是说事务A在执行过程中，对某个数据的值，无论读多少次都是值1；哪怕这个过程中事务B修改了数据的值还提交了，但是事务A读到的还是自己事务开始时这个数据的值。 

（4）串行化：幻读，不可重复读和可重复读都是针对两个事务同时对某条数据在修改，但是幻读针对的是插入，比如某个事务把所有行的某个字段都修改为了2，结果另外一个事务插入了一条数据，那个字段的值是1，然后就尴尬了。第一个事务会突然发现多出来一条数据，那个数据的字段是1。如果要解决幻读，就需要使用串行化级别的隔离级别，所有事务都串行起来，不允许多个事务并行操作。 

MySQL的默认隔离级别是Read Repeatable，就是可重复读，就是说每个事务都会开启一个自己要操作的某个数据的快照，事务期间，读到的都是这个数据的快照罢了，对一个数据的多次读都是一样的。 

但是另外几个隔离级别都是提供的。 

我们聊下MySQL是如何实现Read Repeatable的吧，因为一般我们都不修改这个隔离级别，但是你得清楚是怎么回事儿，MySQL是通过MVCC机制来实现的，就是多版本并发控制，multi-version concurrency control。 

innodb存储引擎，会在每行数据的最后加两个隐藏列，一个保存行的创建时间，一个保存行的删除时间，但是这儿存放的不是时间，而是事务id，事务id是mysql自己维护的自增的，全局唯一。 

事务id，在mysql内部是全局唯一递增的，事务id=1，事务id=2，事务id=3 

id       name        创建事务id       删除事务id 

1         张三         120              122

2        李四         119              空

2        小李四       122              空 

事务id=121的事务，查询id=1的这一行的时候，一定会找到创建事务id <= 当前事务id的那一行，select * from table where id=1，就可以查到上面那一行 

事务id=122的事务，将id=1的这一行给删除了，此时就会将id=1的行的删除事务id设置成122 

事务id=121的事务，再次查询id=1的那一行，能查到吗？能查到，要求创建事务id <= 当前事务id，当前事务id < 删除事务id 

事务id=121的事务，查询id=2的那一行，查到name=李四 

事务id=122的事务，将id=2的那一行的name修改成name=小李四 

事务id=121的事务，查询id=2的那一行，答案是：李四，创建事务id <= 当前事务id，当前事务id < 删除事务id 

在一个事务内查询的时候，mysql只会查询创建时间的事务id小于等于当前事务id的行，这样可以确保这个行是在当前事务中创建，或者是之前创建的；同时一个行的删除时间的事务id要么没有定义（就是没删除），要么是必当前事务id大（在事务开启之后才被删除）；满足这两个条件的数据都会被查出来。 

那么如果某个事务执行期间，别的事务更新了一条数据呢？这个很关键的一个实现，其实就是在innodb中，是插入了一行记录，然后将新插入的记录的创建时间设置为新的事务的id，同时将这条记录之前的那个版本的删除时间设置为新的事务的id。 

现在get到这个点了吧？这样的话，你的这个事务其实对某行记录的查询，始终都是查找的之前的那个快照，因为之前的那个快照的创建时间小于等于自己事务id，然后删除时间的事务id比自己事务id大，所以这个事务运行期间，会一直读取到这条数据的同一个版本。 

记住，聊到事务隔离级别，必须把这套东西给喷出来，尤其是mvcc，说实话，市面上相当大比重的java程序员，对mvcc是不了解的，这个东西很简单，结构大家居然不知道，真是相当大的差异！

### 12_事务的基础知识筑基（二）：Spring的事务支持以及传播特性 

1、面试题 

spring的事务支持（注解事务、声明事务、编程事务、事务的传播机制）？执行某个操作，前50次成功，第51次失败。a 全部回滚；b 前50次提交，第51次抛异常。ab场景分别如何设置spring事务。 

2、面试官心里分析 

聊完上面那个问题，面试官估计心里对你感觉相当不错了，但是呢，事儿没玩，还得聊聊实际项目中，你的java系统里的事务咋玩儿的啊？这就涉及到了spring对事务的支持，然后重要的事务传播机制！ 

3、面试题剖析 

这个，你一般就聊下，spring支持编程式事务，和声明式事务。编程式事务就是用个事务类TransactionTemplate来管理事务，这个一般现在没人傻到干这个事儿了；声明式事务分成在xml里配置个AOP来声明个切面加事务，一般现在也没人傻到干这个了；大部分情况下，都是用@Transactional注解。 

这个@Transactional注解呢，根据阿里编码规范，一般建议加在方法级别，就是要事务的方法就加事务，不要事务的方法就别加事务，否则很多一个数据库操作的方法，你还加事务，你这不是。。。？可能有同学注意到我们项目阶段一，都是傻乎乎的在类上加了事务对吧？ 

对，其实不是我傻，是我装傻，我当时为了快速开发，所以都给扔类上了，类里所有方法都开启了事务，但是后续我们会慢慢优化这些细节的。 

另外这个注解一般要加rollbackFor，就是指定哪些异常类型才要回滚事务 

还有比较重要的，就是有个isolation属性，你可以自己手动调整事务的隔离级别，但是这个一般不调整，记住，别乱调整事务隔离级别，一般可重复读+mysql mvcc机制跑的很好，你别瞎折腾。 

另外一个重要的事务属性，就是propagation，事务的传播行为，我们就重点先来聊一下事务的传播行为，这个在项目里可能确实是要用到的。其实说白了，这个事务的传播机制，就是说，一个加了@Transactional的事务方法，和嵌套了另外一个@Transactional的事务方法的时候，包括再次嵌入@Transactional事务方法的时候，这个事务怎么玩儿？ 

我们的项目阶段一里是不是有大量这种场景？呵呵，所以啊，真实复杂业务系统的好处就在这里，真好，后面我会慢慢优化这些细节，包括事务的传播机制等等，让你各种技术都在复杂业务系统里看看怎么玩儿的。 

public class ServiceA { 

@Autowired

private ServiceB b; 

@Transactional

public void methodA() {

// 一坨数据库操作

for(int i = 0; i < 51; i++) {

try {

b.methodB();

} catch(Exception e) {

// 打印异常日志

}

​    }

// 一坨数据库操作

} 

} 

public class ServiceB { 

@Transactional(propagation = PROPAGATION_REQUIRES_NEW)

public void methodB() throws Exception {

// 一坨数据库操作

} 

} 

项目阶段一里面，是不是有好多OrderService调用了MembershipService调用了WmsService 

一共有7种事务传播行为： 

（1）PROPAGATION_REQUIRED：这个是最常见的，就是说，如果ServiceA.method调用了ServiceB.method，如果ServiceA.method开启了事务，然后ServiceB.method也声明了事务，那么ServiceB.method不会开启独立事务，而是将自己的操作放在ServiceA.method的事务中来执行，ServiceA和ServiceB任何一个报错都会导致整个事务回滚。这就是默认的行为，其实一般我们都是需要这样子的。 

（2）PROPAGATION_SUPPORTS：如果ServiceA.method开了事务，那么ServiceB就将自己加入ServiceA中来运行，如果ServiceA.method没有开事务，那么ServiceB自己也不开事务 

（3）PROPAGATION_MANDATORY：必须被一个开启了事务的方法来调用自己，否则报错 

（4）PROPAGATION_REQUIRES_NEW：ServiceB.method强制性自己开启一个新的事务，然后ServiceA.method的事务会卡住，等ServiceB事务完了自己再继续。这就是影响的回滚了，如果ServiceA报错了，ServiceB是不会受到影响的，ServiceB报错了，ServiceA可以选择性的回滚或者是提交。 

（5）PROPAGATION_NOT_SUPPORTED：就是ServiceB.method不支持事务，ServiceA的事务执行到ServiceB那儿，就挂起来了，ServiceB用非事务方式运行结束，ServiceA事务再继续运行。这个好处就是ServiceB代码报错不会让ServiceA回滚。 

（6）PROPAGATION_NEVER：不能被一个事务来调用，ServiceA.method开事务了，但是调用了ServiceB会报错 

（7）PROPAGATION_NESTED：开启嵌套事务，ServiceB开启一个子事务，如果回滚的话，那么ServiceB就回滚到开启子事务的这个save point。 

大家回头想想那个面试题，其实就是ServiceA里循环51调用ServiceB，第51次调用ServiceB失败了。第一个选项，就是两个事务都设置为PROPAGATION_REQUIRED就好了，ServiceB的所有操作都加入了ServiceA启动的一个大事务里去，任何一次失败都会导致整个事务的回滚；第二个选项，就是将ServiceB设置为PROPAGATION_REQUIRES_NEW，这样ServiceB的每次调用都在一个独立的事务里执行，这样的话，即使第51次报错，但是仅仅只是回滚第51次的操作，前面50次都在独立的事务里成功了，是不会回滚的。 

其实一般也就PROPAGATION_REQUIRES_NEW比较常用，要的效果就是嵌套的那个事务是独立的事务，自己提交或者回滚，不影响外面的大事务，外面的大事务可以获取抛出的异常，自己决定是继续提交大事务还是回滚大事务。 

一般在单块系统开发，多人协作的时候比较常见，就是小A调用小B的模块，小A不管小B是成功还是不成功，自己都要提交，这个时候可以这么弄，就是说小B的操作不是构成小A的事务的重要组成部分，就是个分支。1627098499

### 13_分析一下流量充值中心在不用事务的情况下可能出现的问题 

刷指纹，直接付款，充值流量，这个过程涉及了很多的步骤 

在这些复杂的步骤里，如果说我们没有使用事务的话，可能会出现什么样的问题呢？ 

（1）完成支付转账：成功，用户的24块钱已经从自己的支付宝账号里转账到了中国移动的官方支付宝账户里去了，哥儿们，账户200，现在24块没了，176块钱 

（2）创建充值订单：成功，你可以看到，充值订单显示的是支付成功 

（3）调用第三方运营商系统完成流量充值：结果，出了一个问题，第三方运营系统调用的时候出错了，也就是中国移动收了24块钱，实际上1GB的流量并没有给你充值到账户里去。移动都有掌上营业厅，你在支付宝充值完了以后，然后你去自己的中国移动掌上营业厅里一看，哥儿们，流量只有10MB了，1GB的流量根本没有充值进去 

（4）发送短信通知用户，流量充值成功：成功，人家还恬不知耻的给你发了一个短信，告诉你说，哥儿们，你的1GB的流量已经充值成功了 

（5）给用户增加一次抽奖的机会：还给你一次抽奖的机会，让你来抽奖 

（6）给用户增加充值面额5%的积分：支付宝的积分里，还增加了1.2积分 

（7）如果使用了流量券的话，要将流量券的状态更新为：已使用，流量券也使用掉了，状态变成已使用，无法再次使用了 

（8）如果充值的流量套餐有赠送流量券的活动，那么需要给用户赠送一张流量券：人家还真的赠送了你一张5块钱的流量券。结果5块钱的流量券你查了半天都没发现流量券到你的账户里去 

如果说不用事务，不进行整个复杂业务逻辑一致性的控制的话 

很可能就会出现一些啼笑皆非的问题，就是说，本来上面的8个步骤必须是同时完成，要么就是同时不完成。7个步骤成功了，其中1个步骤失败了

### 14_使用Spring事务框架以及@Transactional注解为流量充值中心加入事务 

事务的基础知识的筑基，之前都给大家讲解过了 

直接使用spring最最基本的，以及核心的对事务的支持，@Transactional注解，基于这个注解为我们的流量充值中心的核心业务逻辑加入事务的控制 

我们期望的是： 

（1）完成支付转账：成功，用户的24块钱已经从自己的支付宝账号里转账到了中国移动的官方支付宝账户里去了，哥儿们，账户200，现在24块没了，176块钱 

（2）创建充值订单：成功，你可以看到，充值订单显示的是支付成功 

（3）调用第三方运营商系统完成流量充值：结果，出了一个问题，第三方运营系统调用的时候出错了，也就是中国移动收了24块钱，实际上1GB的流量并没有给你充值到账户里去。移动都有掌上营业厅，你在支付宝充值完了以后，然后你去自己的中国移动掌上营业厅里一看，哥儿们，流量只有10MB了，1GB的流量根本没有充值进去 

（4）发送短信通知用户，流量充值成功：成功，人家还恬不知耻的给你发了一个短信，告诉你说，哥儿们，你的1GB的流量已经充值成功了 

（5）给用户增加一次抽奖的机会：还给你一次抽奖的机会，让你来抽奖 

（6）给用户增加充值面额5%的积分：支付宝的积分里，还增加了1.2积分 

（7）如果使用了流量券的话，要将流量券的状态更新为：已使用，流量券也使用掉了，状态变成已使用，无法再次使用了 

（8）如果充值的流量套餐有赠送流量券的活动，那么需要给用户赠送一张流量券：人家还真的赠送了你一张5块钱的流量券。结果5块钱的流量券你查了半天都没发现流量券到你的账户里去 

除了第4步，发送短信是可有可无的，发送短信这个事儿，可以跟另外7个步骤脱离开来，如果发送成功就最好，如果不幸的情况发生了，发送短信，调用第三方的发短信的API接口失败了，也无所谓 

用一个事务就可以了 

### 15_测试加入事务后的流量充值中心能否保证故障场景下的数据一致性 

先把@Transactional注解给去掉，模拟一个故障，看一看如果没有实物控制的话，会导致如何混乱的一种数据的情况，体验一下 

再把@Transactional注解给加上去，我们再次模拟同样的故障，看一看有事务控制了以后，就可以保证放在事务里的复杂的一坨业务逻辑，要么一起成功要么一起失败 

{

 "userAccountId": 1,

 "businessAccountId": 2,

 "businessName": "中国移动官方旗舰店",

 "payAmount": 24,

 "payType": 1,

 "phoneNumber": "15651587652",

 "data": 1024,

 "dataPackage": {

  "id": 1,

  "price": 30,

  "data": 1024,

  "type": 2,

  "comment": "月底失效，到账后生效",

  "promotionActivity": {

   "id": 1,

   "dataPackageId": 1,

   "discountPrice": 27,

   "status": 2

  },

  "couponActivity": {

   "id": 1,

   "dataPackageId": 1,

   "couponAmount": 5,

   "status": 2

  }

 },

 "coupon": {

  "id": 1,

  "userAccountId": 1,

  "couponAmount": 3,

  "status": 1

 }

} 

事务就生效了，没有事务，一个复杂业务逻辑中，任何一个步骤一旦失败了，就会导致复杂的数据处于不一致的状态，这是无法容忍的 

我们现在使用了事务之后，要么一起成功，要么就是一起失败，如果一个复杂业务逻辑中，任何一个步骤失败了，都会导致其他步骤一起回滚

### 16_Spring事务框架源码初探之基于AOP思想与动态代理无缝插入事务支持

03_spring事务的基本原理

![](C:\Users\zy199005\Desktop\中华石杉\images\java\06\0301601.png) 

初步给大家说过一下，咱们对分布式事务这块课程的授课计划 

我的理念，给大家教技术的时候，需要有理论知识、案例项目的实战、深入源码的剖析，对你学会的任何一种技术，如果有可能，最好是对相关的源码看一下，研究一下，做到知其然而知其所以然 

初步的，我们把分布式事务课程目前在第一个小阶段，完成了一个案例项目的开发，初步体验了一下在单块系统的场景下，事务的使用的意义 

我们可以先把spring框架，也就是@Transactional注解背后的秘密给大家来讲解，初步的去看一些spring框架里跟事务相关的一些源码 

我们在这里不是重点看spring的源码，spring源码特别大，特别多，我们在项目阶段三会深入的研究一下spring源码，在这里呢，我们就是初步的对某些主题（事务）相关的源码去看一下 

spring，@Transactional注解之后，为什么就可以莫名其妙的让方法支持事务了 

AOP思想，动态代理的技术 

spring aop和动态代理本身的概念，我默认是java初学者都该懂的一些东西，spring aop是什么都不知道，4个月的j2ee就业培训班儿出来的学生都知道spring aop，动态代理是什么都不知道，java动态代理，cglib动态代理 

AOP，面向一个切面织入一坨额外的逻辑，不去care AOP概念 

spring对我们的service组件创建了一个动态代理，你加了@Transactional注解之后，就对这个动态代理插入了一堆事务管理的增强逻辑，开始执行方法之前先开启事务，方法中有报错就回滚事务，如果没有报错就提提交事务

### 17_在spring-tx-4.3.13.RELEASE.jar中直接定位到spring事务的核心源码 

这块因为我们仅仅是挑选spring事务相关的少量的源码来阅读，并不是从头到尾，从里到外的去阅读spring框架的源码，所以说我们不会给大家按照spring cloud源码剖析课程的那个思路，从0开始慢慢去捋和找源码 

所以这一讲的话呢，我就直接告诉大家spring事务支持相关的核心代码是在哪里，关于很多spring杂七杂八的一些东西，大家不要过于的纠结，直接初步看一看事务相关的最最基础的核心的源码就可以了 

spring-tx-4.3.13.RELEASE.jar，spring-tx这个项目是spring对事务的支持核心的逻辑，都放在这个地方了，明眼人一看就知道，我们其实自己没定义spring的依赖，其实这个spring的依赖都是spring boot给我们搞进来的 

spring boot 1.5.9版本，spring 1.5.9版本依赖的spring版本就是4.3.13.RELEASE版本 

org.springframework.transaction.interceptor，直接看这个包，其他的代码暂时先别看，你看也很麻烦，我们现在还没到深入系统性的剖析spring源码的程度 

你就只要关注一个类就可以了，TransactioanIntercepor，这个类里是事务执行的核心的入口 

TransactionIntercepor其实就是如果我们给我们的service组件加了@Transactional注解之后，就会对我们的这个service组件里的方法在调用的时候，就会先走这个TransactionoIntercepor的拦截 

事务拦截器，拦截我们对@Transactional注解标注的类中的方法的调用，finishRfillData()方法之前，就会先走这个拦截器 

在这个拦截器里，就可以给我们先打开事务，然后再执行我么你的finishRefillData()方法，接着根据方法的执行结果，报错就回滚事务，没报错就提交事务 

TransactionIntercepor.invoke()方法，这个里面调用了invokeWithinTransaction()方法，核心的事务控制的逻辑都在invokeWithinTransaction()方法中，invokeWithinTransaction()方法其实是父类TransactionAspectSupport（Aspect这个名词就可以看出来了，这个东西一定是跟Spring AOP机制是有关系的，Aspect切面的意思，就是spring AOP的核心概念） 

TransactionInfo txInfo = createTransactionIfNecessary(tm, txAttr, joinpointIdentification); 

上面那行代码其实是核心中的核心，这行代码顾名思义，其实就是如果你使用了@Transactional注解之后，意思就是要给这个方法开启事务，此时就会给你开启一个事务，创建事务 

retVal = invocation.proceedWithInvocation(); 

这行代码，其实相当于是去调用你的那个RefillDataCenterService.finishRefillData()方法 

 completeTransactionAfterThrowing(txInfo, ex); 

这行代码是什么意思呢，如果你的RefillDataCenterService.finishRefillData()方法报错了，抛了个异常出来，此时就会回滚事务 

commitTransactionAfterReturning(txInfo); 

如果没有报错的话，就会提交你的事务，完成全部逻辑的执行 

### 18_Spring事务框架源码初探（一）：基于hibernate和jdbc完成事务的开启

04_spring事务的源码初探

![](C:\Users\zy199005\Desktop\中华石杉\images\java\06\0301801.png)  

断点，跑一跑程序，然后来看看事务这块的源码 

事务是如何开启的 

TransactionInfo txInfo = createTransactionIfNecessary(tm, txAttr, joinpointIdentification); 

createTransactionIfNecessary()这个方法其实是开启事务最核心的一个方法 

这里能看到txAttr里有一些事务传播相关的一些东西，具体的不说了，之前都给大家讲解过spring的事务传播这块的机制 

status = tm.getTransaction(txAttr);，这行代码，其实就是开启事务最核心的一行代码，tm是个什么东西呢？tm就是PlatformTransactionManager，这个东西翻译成中文就是平台事务管理器，事务管理器 

tm就是一个事务管理器，通过这个事务管理器的getTransaction()方法，相当于是通过事务管理器来开启一个事务，AbstractPlatformTransactionManager里面去了，不去看里面的源码也无所谓，不知道是否还记得，自己可以回去看看jdbc，如果你自己手写最最原始的jdbc，来开启这个事务，是有最最原始的API 

AbstractPlatformTransactionManager里面，调用了spirng-orm这个项目的一些代码，这个代码里，你用屁股想想都知道了，无非就是利用java底层的一些API和接口针对你使用的那个数据库，直接start transaction，开启一个事务 

然后将事务的信息给你封装成一个类似TransactionStatus的这么一个对象，这个对象里面一定是封装了最最核心的事务相关的信息 

​          if (getDataSource() != null) {

​               ConnectionHolder conHolder = (ConnectionHolder)

​                         TransactionSynchronizationManager.getResource(getDataSource());

​               txObject.setConnectionHolder(conHolder);

​          } 

这块代码，就表明了，在JpaTransactionObject中，其实封装了我们自己定义的那个DruidDataSource（数据库连接池），后续打开事务，会基于这个数据库连接池来打开对应的事务 

doBegin(transaction, definition); 

这个代码，很明显，肯定是在开启事务了，基于之前的druid数据库连接池在开启事务 

我刚才应该是给大家回头看一下，应该是最最底层的事务打开的源码，实在是要跟的太深了，就是可以看到，默认情况下，spring的事务的支持是使用的hibernate这个框架中的一些事务管理相关的一些底层的类库和代码 

​               log.trace( "Preparing to begin transaction via JDBC Connection.setAutoCommit(false)" );

​               getConnectionForTransactionManagement().setAutoCommit( false );

​               status = TransactionStatus.ACTIVE;

​               log.trace( "Transaction begun via JDBC Connection.setAutoCommit(false)" ); 

hibernate底层，说白了，还是依赖于jdbc的API来开启事务，Connection.setAutoCommit(false)，就相当于开启了一个事务 

​               getConnectionForTransactionManagement().setAutoCommit( false ); 

用屁股来猜想一下，getConnectionForTransactionManagement()，一定是从我们之前定义的druid数据库连接池中获取到了一个Connection连接，最原始jdbc的编程里面，都是面向Connection数据库连接来编程的 

基于jdbc的Connection连接执行了setAutoCommit(false)，将自动提交设置为false，相当于是在底层发送了一条指令给mysql说，开启事务

### 19_Spring事务框架源码初探（二）：开启事务之后再执行业务逻辑

04_spring事务的源码初探(1)

![](C:\Users\zy199005\Desktop\中华石杉\images\java\06\0301901.png)  

可以看到，开启完事务之后，就应该去执行我们的目标的方法，业务逻辑，RefillDataCenterService.finishRefillData()方法，这样的话呢，就可以将这个方法所有的数据库操作都纳入一个事务中去了 

retVal = invocation.proceedWithInvocation(); 

其实就是在调用我们的目标方法，RefillDataCenterService.finishRefillData()方法 

很清晰的看到一点，就是说在开启事务之后，然后来执行这个业务逻辑方法，我们通过断点调试可以发现在业务逻辑方法咔嚓咔嚓咔嚓执行的时候，其实数据库里啥都没有，增删改的操作都没有反映到数据库中去呢 

就是因为事务，打开一个事务之后，在事务里面执行的crud操作，其实是不会立即反馈到数据库里让其他人看见的，必须是最后有一个提交事务，或者是回滚事务，提交事务的话呢，别人就可以看到你对数据库做的修改 

如果是回滚事务呢，就全都没有了，你做的那些crud就全都没有了

### 20_Spring事务框架源码初探（三）：如果业务逻辑没报错则提交事务

04_spring事务的源码初探(2)

![](C:\Users\zy199005\Desktop\中华石杉\images\java\06\0302001.png)  

commitTransactionAfterReturning(txInfo); 

​                    prepareForCommit(status);

​                    triggerBeforeCommit(status);

​                    triggerBeforeCompletion(status); 

屁股猜想论，这三行代码是干嘛的，prepareForCommit()这个一看就是在为提交事务做一些准备的工作，triggerBeforeCommit()一看就是在触发提交事务之前要执行的一些操作，triggerBeforeCompletion一看就是在完成事务操作之前触发的一些操作 

trigger猜想一下，很可能是人家spring提供的一个扩展点，如果你实现一个特殊的bean，这里很可能就会把你提供的一些代码，在每个事务提交之前给你来执行一下，可能是spring提供的特殊扩展点 

只是说给大家提供一下在自己阅读源码的时候，你要慢慢学会连蒙带猜，是根据上下文，方法名称，变量名称，来猜想某个方法内部可能是在干什么，当然也可能trigger其实压根儿跟我刚才说的扩展点没关系 

log.trace( "Preparing to commit transaction via JDBC Connection.commit()" ); 

其实说白了，用的就是原始的JDBC的Connection.commit()方法，提交事务，就会发现在数据库中所有的crud操作都反映出来了，就是所谓的事务

### 21_Spring事务框架源码初探（四）：如果业务逻辑报错则进行事务回滚

03_spring事务的基本原理(1)

![](C:\Users\zy199005\Desktop\中华石杉\images\java\06\0302101.png)

04_spring事务的源码初探(3)

![](C:\Users\zy199005\Desktop\中华石杉\images\java\06\0302102.png)

如果说目标的业务逻辑里有报错，那么事务的管控机制和源码会如何走呢 

​               try {

​                    // This is an around advice: Invoke the next interceptor in the chain.

​                    // This will normally result in a target object being invoked.

​                    retVal = invocation.proceedWithInvocation();

​               }

​               catch (Throwable ex) {

​                    // target invocation exception

​                    completeTransactionAfterThrowing(txInfo, ex);

​                    throw ex;

​               } 

就是在目标的业务逻辑里一定是报错了，所以会走到catch逻辑里面去 

completeTransactionAfterThrowing(txInfo, ex);，这个行代码逻辑就会触发事务的回滚 

log.trace( "Preparing to rollback transaction via JDBC Connection.rollback()" );，底层基于jdbc的Connection.rollback()回滚了事务 

TransactionInterceptor，spring-tx项目里的，拦截器，就是在spring给我们的RefillDataCenterService创建的动态代理中，在调用动态代理的目标方法之前，先执行这个事务拦截器 

事务拦截器会给你先开启一个事务，然后执行你的finishRefillData()方法，你的方法里的数据库操作都被纳入到了事务中去了，接着的话呢根据你的finishRefillData()方法里的报错的情况，没报错就提交事务，报错就回滚事务

### 22_分析一下互联网项目中用户量增长以及数据量增长问导致的数据库拆分 

进入分布式事务的下一个阶段，单块的事务给实战演示，源码剖析，都已经讲完了，如果说现在是单块的系统，但是使用了底层多个数据库，协调多个数据库如何进行事务的控制呢？这是一个很大的问题 

互联网公司里，什么情况下会出现一个系统，但是有多个库呢？ 

用户量不断的增长，以及数据量不断的增长，以及访问量不断的增长，会促成数据库的拆分 

类似于支付宝的流量充值的平台，手机APP，支付宝，官方的移动手机营业厅 

假设某个流量充值的手机APP，他有100万的注册用户，100万的注册用户可不是每个人天天都会来用这个APP的，平均每个人每个月充值一次流量，每个月就有100万次流量充值的操作，每天大概是3万次的流量充值的量 

注册用户100万的情况下，流量充值APP的访问量和数据量的情况 

访问量，一天3万次流量充值的操作，每次流量充值的操作，最起码要调用几个接口？3个接口，第一个接口进入流量充值界面，第二个是显示充值的金额，第三个是完成支付。可以认为流量充值中心的系统， 每天大概调用次数是3万次 * 3个接口 = 9万次接口调用，算一下整数，大概系统一天是10万次调用。 

一天10万次调用，高峰期每秒钟的调用次数大概是多少次呢？中午休息2个小时，晚上2个小时，算一天高峰是4个小时，高峰期承载的请求次数是80%，8万次。高峰期每个小时是2万次调用，高峰期每秒钟的请求次数大概也就5~6次，QPS也就是5/s。 

我们再来算一下系统每秒钟高峰是5次调用，对数据库的请求又是多少次呢？平均一下每次系统调用会触发3次数据库的请求，高峰期系统每秒钟对数据库会请求15次。MySQL的高峰期的QPS大概是15/s。 

每天大概是3万次流量充值的操作，一次流量充值操作就会导致多出一个流量充值的订单，流量充值的订单表，一天大概会新增3万条数据，一个月是150万条数据，每个月会新增150万个订单，每年的话是2000万个订单。 

基本上差不太多，会有一些偏差，差的不会太离谱 

大家可以看到一点，就是说，像这种手机流量充值的APP，访问量应该是很低的，但是确实人家是有数据量的，每年新增2000万条数据。 

============================================================= 

如果有1000万的注册用户呢？ 

系统高峰期QPS大概会是50/s，对数据库的高峰期QPS大概会是150/s，所以还是不会构成所谓的高并发，但是每天新增30万订单，每个月新增1500万订单，每年新增2亿订单。主要问题是出在数据量上了。 

2000万注册用户呢？3000注册用户呢？一年就要新增几亿订单 

几亿订单数据，实际的这种系统里，订单表字段，或者订单表可能会拆分成几个表，字段可能多达数十个，甚至上百个字段。还不光是一个订单表，可能还有关联的其他的表，一般来说数据库部署在一台服务器上面，磁盘空间是1TB。 

要承载很多其他的一些东西，还要有日志，还要存各个数据表的数据，可能在2000万注册用户，3000万注册用户，每年几亿订单的规模之下，一年以后这个mysql数据库服务器上的磁盘空间都不够了 

一般在这种情况下，我们会做的第一件事情，就是数据库的拆分，刚开始不会做复杂的分库分表，就会按照业务来拆分库： 

（1）资金：account_amount，每个用户起码对应一条数据，几千万条数据

（2）流量券：coupon，数据量也会随着时间的增长不断的变多，你不断的在给各种用户赠送流量券

（3）促销：promotion_activity，coupon_activity，这个数据量不会特别大

（4）积分：credit，每个用户起码对应一条数据，几千万条数据

（5）流量套餐：data_package，数据不会特别大

（6）抽奖：lottery_draw，每个用户起码对应一条数据，几千万条数据

（7）充值订单：refill_order，这个东西是个大头，几千万用户的时候，一年是10万级别的订单量，数据量很大了，一个订单算1kb，10亿个订单基本上快1TB了，当然实际上可能比1TB小，几百GB，也可能比1TB多 

这个时候，一般来说，如果要解决这个问题，肯定是要做分库分分表，就是肯定会将充值订单的数据均匀分散到多个数据库服务器上去，但是我们这里先不考虑那么复杂，最最起码，你首先要做的一件事情，就是将各个业务的库拆分开来 

资金、流量券、促销、积分、流量套餐、抽奖、充值订单，分别使用独立的数据库服务器，各个表的数据放在自己的服务器上，使用自己的磁盘空间，这样可以初步的先延长一下我们数据库的使用的周期

### 23_动手将流量充值中心的各个不同的业务模块的数据库进行拆分 

正常来说，这种拆分，一般会将库建在不同的数据库服务器上，就是我们得有7台数据库服务器，在各个服务器上安装mysql实例，在mysql中创建对应的库，但是在我们这里，我们就模拟一下 

（1）资金：data-refill-center-finance

（2）流量券：data-refill-center-coupon

（3）活动：data-refill-center-activity

（4）积分：data-refill-center-credit

（5）流量套餐：data-refill-center-package

（6）抽奖：data-refill-center-lottery

（7）充值订单：data-refill-center-order 

我们将原来的1个库拆分为了7个库，如果你就1个库的话，应对数据量的增长可能只能支撑3个月，现在拆分了7个库以后，可能就可以支撑8个月，但是如果要长久的扩展，肯定还是需要分库分表 

事务这块如何来处理呢？ 

需要先来在代码层面重构一下，基于spring boot + mybatis的技术栈，来支持多数据源，一个系统使用多个库的时候，就需要使用多个数据源，那么你的代码的层面就需要让不同的mapper组件来使用不同的数据源 

### 24_基于Spring Boot对多数据源的支持来改造代码支持多个数据库 

**1、在application.yml中配置多个数据源** 

之前不是都是spring.datasource.xxx啥的么 

全部都改造成类似于order.datasource.xxx，就这样子，一共我们不是拆分出了7个库么，那你就在这里配置出来7个数据源，每个数据源都通过这种方式起了个名字就ok了 

**2、为每个数据源编写一个DataSourceConfig bean** 

比如说搞一个OrderDataSourceConfig类 

其实别的没啥，主要加这行东西，将这个数据源配置到对应包下面的mapper组件里去 

@MapperScan(basePackages = “com.zhss.data.refill.center.mapper.order”, sqlSessionFactoryRef = "orderSqlSessionFactory") 

将订单相关的mapper放到那个包下面去，然后指定这个数据源就注入给那个包下面的mapper了，然后那个sqlSessionFactoryRef就是说，会把这个数据源注入到这个指定的名字的SqlSessionFactory里去了 

所以数据源的配置类看起来是下面这样子的： 

@Configuration 

@MapperScan(basePackages = “com.zhss.data.refill.center.mapper.order”, sqlSessionFactoryRef = "orderSqlSessionFactory")

public class DruidDataSourceConfig {   

  @Value("${order.datasource.url}") 

  private String dbUrl; 

  @Value("${order.datasource.username}") 

  private String username; 

  @Value("${order.datasource.password}") 

  private String password; 

  @Value("${order.datasource.driverClassName}") 

  private String driverClassName; 

  @Value("${order.datasource.initialSize}") 

  private int initialSize; 

  @Value("${order.datasource.minIdle}") 

  private int minIdle; 

  @Value("${order.datasource.maxActive}") 

  private int maxActive; 

  @Value("${order.datasource.maxWait}") 

  private int maxWait; 

  @Value("${order.datasource.timeBetweenEvictionRunsMillis}") 

  private int timeBetweenEvictionRunsMillis; 

  @Value("${order.datasource.minEvictableIdleTimeMillis}") 

  private int minEvictableIdleTimeMillis; 

  @Value("${order.datasource.validationQuery}") 

  private String validationQuery; 

  @Value("${order.datasource.testWhileIdle}") 

  private boolean testWhileIdle; 

  @Value("${order.datasource.testOnBorrow}") 

  private boolean testOnBorrow; 

  @Value("${order.datasource.testOnReturn}") 

  private boolean testOnReturn; 

  @Value("${order.datasource.poolPreparedStatements}") 

  private boolean poolPreparedStatements; 

  @Value("${order.datasource.maxPoolPreparedStatementPerConnectionSize}") 

  private int maxPoolPreparedStatementPerConnectionSize; 

  @Value("${order.datasource.filters}") 

  private String filters; 

  @Value("{order.datasource.connectionProperties}") 

  private String connectionProperties;   

  /**

   \* 创建druid数据库连接池bean

   \* @return

   */

  @Bean(name = "orderDataSource")   

  @Primary 

  public DataSource dataSource(){ 

​    DruidDataSource datasource = new DruidDataSource(); 

​    datasource.setUrl(this.dbUrl); 

​    datasource.setUsername(username); 

​    datasource.setPassword(password); 

​    datasource.setDriverClassName(driverClassName); 

​    datasource.setInitialSize(initialSize); 

​    datasource.setMinIdle(minIdle); 

​    datasource.setMaxActive(maxActive); 

​    datasource.setMaxWait(maxWait);     

​    datasource.setTimeBetweenEvictionRunsMillis(timeBetweenEvictionRunsMillis); 

​    datasource.setMinEvictableIdleTimeMillis(minEvictableIdleTimeMillis); 

​    datasource.setValidationQuery(validationQuery); 

​    datasource.setTestWhileIdle(testWhileIdle); 

​    datasource.setTestOnBorrow(testOnBorrow); 

​    datasource.setTestOnReturn(testOnReturn); 

​    datasource.setPoolPreparedStatements(poolPreparedStatements); 

​    datasource.setMaxPoolPreparedStatementPerConnectionSize(maxPoolPreparedStatementPerConnectionSize);     

​    try { 

​      datasource.setFilters(filters); 

​    } catch (SQLException e) { 

​      e.printStackTrace();

​    }     

​    datasource.setConnectionProperties(connectionProperties);      

​    return datasource; 

} 

  @Bean(name = "orderTransactionManager")

  @Primary

  public DataSourceTransactionManager orderTransactionManager() {

​    return new DataSourceTransactionManager(orderDataSource());

  } 

  @Bean(name = "orderSqlSessionFactory")

  @Primary

  public SqlSessionFactory masterSqlSessionFactory(@Qualifier("orderDataSource") DataSource orderDataSource)

​      throws Exception {

​    final SqlSessionFactoryBean sessionFactory = new SqlSessionFactoryBean();

​    sessionFactory.setDataSource(orderDataSource);

​    sessionFactory.setMapperLocations(new PathMatchingResourcePatternResolver()

​        .getResources(“classpath:mapper/order/*.xml”));

​    return sessionFactory.getObject();

  }   

} 

可以在src/main/resources下，建个mapper/order文件夹 

类比上面那样子，再搞几个数据源出来，然后就ok了 

**3、再次运行系统尝试一下，看是不是都ok**

### 25_跨多个数据库的场景下传统的单库事务无法应对的问题分析以及演示 

咱们现在已经拆分为多个数据库了，我们之前做的那个事务，实际上来说是针对的单个数据库的，我们之前加的那个spring的@Transactional注解其实在这里就已经失效了，因为那个注解是没法应对多个库的事务的 

他只是针对单个数据库，可以保证对单个数据库的各种操作包裹在一个事务内，要么一起成功，要么一起失败 

我来给大家演示一下，目前的多库的场景下，事务已经失效的一个问题 

按理来说，如果事务生效的话，就应该说，各个库的数据都不应该变化的，对不对 

资金库的数据变化了，订单库多了一条订单出来，抽奖库数据变化了，我们现在拆分成了多个数据库了，之前加的那个@Transactional注解就失效了，针对单库的，我们现在多数据库了。。 

我们来讲解，分布式事务，第一种最最基础的分布式事务，就是这样子，一个系统横跨多个数据库，此时基于多个库的分布式事务如何来做，XA规范、2PC、3PC、MySQL对XA分布式事务的支持、Spring多数据库 + MySQL分布式事务如何做 

要把多个数据库的操作，给包裹在一个事务中，如果任何一个操作报错，多个数据库中的操作全部回滚，如果没有报错，那么多个数据库中的操作全部提交。积分库的SQL报错，其实订单库、资金库、抽奖库是不会回滚的，各个库之间完全独立

### 26_最基础的分布式事务：XA规范以及2PC分布式事务理论介绍

05_XA规范与2PC协议

![](C:\Users\zy199005\Desktop\中华石杉\images\java\06\0302601.png)   

**1、XA规范** 

上一讲演示的过程中，如果一个系统操作多个数据库，肯定是有跨多个库的分布式事务的一个问题，在很多年之前全世界，老美早就已经发现这个问题了，很早以前就定义了一整套的解决方案来处理分布式事务的问题 

有个叫做X/Open的组织定义了分布式事务的模型，这里面有几个角色，就是AP（Application，应用程序），TM（Transaction Manager，事务管理器），RM（Resource Manager，资源管理器），CRM（Communication Resource Manager，通信资源管理器） 

这么说有点儿抽象，其实Application说白了就是我们的系统，TM的话就是一个在系统里嵌入的一个专门管理横跨多个数据库的事务的一个组件，RM的话说白了就是数据库（比如MySQL），CRM可以是消息中间件（但是也可以不用这个东西） 

然后这里定义了一个很重要的概念，就是全局事务，这个玩意儿说白了就是一个横跨多个数据库的事务，就是一个事务里，涉及了多个数据库的操作，然后要保证多个数据库中，任何一个操作失败了，其他所有库的操作全部回滚，这就是所谓的分布式事务 

上面这套东西就是所谓的X/Open组织搞的一个分布式事务的模型，那么XA是啥呢？说白了，就是定义好的那个TM与RM之间的接口规范，就是管理分布式事务的那个组件跟各个数据库之间通信的一个接口，说白了就是这个意思 

完了比如管理分布式事务的组件，TM就会根据XA定义的接口规范，刷刷刷跟各个数据库通信和交互，告诉大家说，各位数据库同学一起来回滚一下，或者是一起来提交个事务把，大概这个意思 

这个XA仅仅是个规范，具体的实现是数据库产商来提供的，比如说MySQL就会提供XA规范的接口函数和类库实现，等等 

**2、2PC理论** 

X/Open组织定义的一套分布式事务的模型，还是比较虚的，还没办法落地，而且XA接口规范也是一个比较务虚的一个东西，光靠我说的这些东西还是没法落地的 

基本上来说，你搞明白了XA也就明白了2PC了，2PC说白了就是基于XA规范搞的一套分布式事务的理论，也可以叫做一套规范，或者是协议，都ok。Two-Phase-Commitment-Protocol，两阶段提交协议 

2PC，其实就是基于XA规范，来让分布式事务可以落地，定义了很多实现分布式事务过程中的一些细节 

（1）准备阶段 

画个图来玩玩儿，用咱们的那个流量充值的例子来举个例子好了，简单来说，就是TM先发送个prepare消息给各个数据库，让各个库先把分布式事务里要执行的各种操作，先准备执行，其实此时各个库会差不多先执行好，就是不提交罢了 

如果你硬是要理解一下的话，也可以认为是prepare消息一发，各个库先在本地开个事务，然后执行好SQL，万事俱备只欠东风了，而且注意这里各个数据库会准备好随时可以提交或者是回滚，有对应的日志记录的 

然后各个数据库都返回一个响应消息给事务管理器，如果成功了就发送一个成功的消息，如果失败了就发送一个失败的消息  

（2）提交阶段 

第一种情况，要是TM哥儿们发现某个数据库告诉他说，不好意思啊，我这儿失败了，那就尴尬了。或者是TM等了半天，某个数据库楞是死活不返回消息，跟失踪了一样，不知道在干嘛，也就麻烦了 

这个时候TM直接判定这个分布式事务失败，毕竟某个数据库那里报了个错么，对不对，然后TM通知所有的数据库，全部回滚回滚回滚，赶紧的，做了啥操作都回滚，其实这里你可以认为是通知每个数据库，把自己本地的那个事务回滚不就得了，然后各个库都回滚好了以后就通知TM，TM就认为整个分布式事务都回滚了 

但是呢，要是TM接收到所有的数据库返回的消息都是成功，那就happy了，直接发送个消息通知各个数据库说提交，兄弟们，然后各个数据库都在自己本地提交事务呗，就这么回事儿，提交好了通知下TM，TM要是发现所有数据库的事务都提交成功了，就认为整个分布式事务成功了

### 27_画图来剖析一下2PC分布式事务方案的缺陷以及问题

06_2PC的缺陷

![](C:\Users\zy199005\Desktop\中华石杉\images\java\06\0302701.png)   

1、同步阻塞：在阶段一里执行prepare操作会占用资源，一直到整个分布式事务完成，才会释放资源，这个过程中，如果有其他人要访问这个资源，就会被阻塞住 

2、单点故障：TM是个单点，一旦挂掉就完蛋了 

3、事务状态丢失：即使把TM做成一个双机热备的，一个TM挂了自动选举其他的TM出来，但是如果TM挂掉的同时，接收到commit消息的某个库也挂了，此时即使重新选举了其他的TM，压根儿不知道这个分布式事务当前的状态，因为不知道哪个库接收过commit消息，那个接收过commit消息的库也挂了，兄弟 

4、脑裂问题：在阶段二中，如果发生了脑裂问题，那么就会导致某些数据库没有接收到commit消息，那就完蛋了，有些库收到了commit消息，结果有些库没有收到，这咋整呢，那肯定完蛋了

### 28_针对2PC的问题引入3PC分布式事务方案的理论知识讲解

06_2PC的缺陷(1)

![](C:\Users\zy199005\Desktop\中华石杉\images\java\06\0302801.png) 

07_3PC的过程和原理 

![](C:\Users\zy199005\Desktop\中华石杉\images\java\06\0302802.png)  

3PC，说白了，就是three-phase-commitment，三阶段提交协议，这个是针对2PC做的一个改进，主要就是为了解决2PC协议的一些问题 

3PC的话改成了下面的过程： 

（1）CanCommit阶段：这个就是TM发送一个CanCommit消息给各个数据库，然后各个库返回个结果，注意一下，这里的话呢，是不会执行实际的SQL语句的，其实说白了，就是各个库看看自己网络环境啊，各方面是否ready 

（2）PreCommit阶段：如果各个库对CanCommit消息返回的都是成功，那么就进入PreCommit阶段，TM发送PreCommit消息给各个库，这个时候就相当于2PC里的阶段一，其实就会执行各个SQL语句，只是不提交罢了；如果有个库对CanCommit消息返回了失败，那么就尴尬了，TM发送abort消息给各个库，大家别玩儿了，结束这个分布式事务 

（3）DoCommit阶段：如果各个库对PreCommit阶段都返回了成功，那么发送DoCommit消息给各个库，就说提交事务吧，兄弟们，各个库如果都返回提交成功给TM，那么分布式事务成功；如果有个库对PreCommit返回的是失败，或者超时一直没返回，那么TM认为分布式事务失败，直接发abort消息给各个库，说兄弟们回滚吧，各个库回滚成功之后通知TM，分布式事务回滚 

说白了大概就是这样子，但是这里的话，跟2PC相比，主要做了下面两个改进点： 

（1）引入了CanCommit阶段 

（2）在DoCommit阶段，各个库自己也有超时机制，也就是说，如果一个库收到了PreCommit自己还返回成功了，等了一会儿，如果超时时间到了，还没收到TM发送的DoCommit消息或者是abort消息，直接判定为TM可能出故障了，人家库自己颠儿颠儿的就执行DoCommit操作，提交事务了。 

因为这里就是说，如果这个库接收到了PreCommit消息，说明第一阶段各个库对CanCommit都返回成功了啊，这样TM才会发送PreCommit来，那么就默认为基本上各个库的PreCommit都会成功，所以大家没接收到DoCommit，直接自己执行提交操作了 

所以这个超时的机制是基于CanCommit的引入来实现的，有了一个CanCommit多了一个阶段，大家才能自己执行超时commit机制，这不就解决了TM挂掉的单点问题么，大家想想是不是这样子 

另外资源阻塞问题也能减轻一下，因为一个库如果一直接收不到DoCommit消息，不会一直锁着资源，人家自己会提交释放资源的，所有能减轻资源阻塞问题，比2PC稍微好一些吧而已 

3PC的缺陷： 

但是其实这种的话，也不是完全就一定好的，因为还是可能有问题啊，如果人家TM在DoCommit阶段发送了abort消息给各个库，结果因为脑裂问题，某个库没接收到abort消息，自己还颠儿颠儿的执行了commit操作，不是也不对么 

所以啊，其实2PC也好，3PC也好，都没法完全保证分布式事务的ok的，要明白这一点，总有一些特殊情况下会出问题的   

### 29_动手体验一下MySQL对XA分布式事务的支持以及图解基本原理

08_MySQL XA分布式事务的实现

![](C:\Users\zy199005\Desktop\中华石杉\images\java\06\0302901.png) 

XA分布式事务，2PC，3PC，常见的数据库，MySQL（特别是互联网公司，Oracle），MySQL对XA分布式事务的支持，我们来动手实验一下，然后呢，我们画个图简单分析一下MySQL的XA分布式事务的原理 

这个MySQL人家肯定是支持XA分布式事务的，而且支持的是2PC的协议，其实一般这种单系统多库的话，分布式事务用的都是2PC，而不是3PC，所以说呢，啥分布式事务，在严苛的情况下，还是会出现数据问题的 

话说回来，即使用的是3PC不也会出问题么，是不是，各位同学 

咱们就将MySQL作为RM，也就是资源管理器，我们自己手工基于MySQL客户端对XA分布式事务支持的API和接口，来编写代码，自己模拟作为TM事务管理器，来模拟实验一把所谓的分布式事务的操作流程 

是不是很简单，各位同学，MySQL提供了接口和命令支持XA分布式事务的，2PC的协议，那么基于MySQL做分布式事务的时候，TM是谁啊？当然是MySQL客户端咯，我们用哪个MySQL客户端来管理这个分布式事务，会引入第三方的类库，作为我们系统里的一个组件，自行控制分布式事务的Prepare、Commit、Rollback，对吧 

核心的原理，画个图，就跟之前的2PC是一样的

### 30_学习完了基础知识之后提一句啥是JTA事务以及全局事务呢 

JTA事务，全局事务，别慌 

全局事务，概念主要是针对的是X/Open组织定义了一套分布式事务的模型和规范，DTP 

Distributed Transaction Processing Reference Model，分布式事务处理模型，DTP，TM、RM、AP等等角色的这么一套分布式事务的模型 

XA，实际上来说是一种接口规范，就是说TM在跟数据库（RM）进行通信时的接口规范，按照一套什么样的规范来管理和执行一整套的分布式事务呢，XA接口规范中定义的流程是什么样的呢？ 

start -> end

prepare -> commit / rollback 

XA，接口规范 

全局事务，Global Transaction，是DTP模型中的一个概念，全局事务，指的其实就是说跨多个数据库的这么一个分布式事务 

JTA事务，站在另外一个角度，其实是J2EE中的一个概念，Java Transaction API，JTA一套分布式事务的编程API，他呢是按照XA、DTP那套模型和规范来搞的，在J2EE中，单库的事务是通过JDBC事务来支持的 

如果是跨多个库的事务，是通过JTA API来支持的，通过JTA API可以协调和管理横跨多个数据库的分布式事务，一般来说会结合JNDI（J2EE里面老生常谈的一套东西），J2EE里面很多东西定义的很好，但是在业内使用的时候，最近这些年基本没哪个公司用 

现在还有没有哪个公司是用J2EE中的EJB来玩儿的 

X/Open、DTP、XA、2PC、3PC、全局事务、JTA，这些概念，我觉得大家现在就得全都很清楚了吧，都很简单

### 31_基于Druid多数据源与Atomikos分布式事务类库重构流量充值中心 

现在大家学了基础的XA分布式事务的所有概念了，来搞一把，在流量控制中心中引入XA分布式事务，来管理横跨多个数据库的分布式事务吧，就是我们的流程充值的核心逻辑那块东西 

但是有个问题，我们是不可能用原始的MySQL的XA API来搞的，所以要引入客户端的TM第三方库，也就是常用的Atomikos类库，他可以模拟我们上一讲搞的那段程序，来控制横跨多个数据库的分布式事务 

**1、pom.xml中引入依赖** 

<dependency>

​            <groupId>org.springframework.boot</groupId>

​            <artifactId>spring-boot-starter-jta-atomikos</artifactId>

​          </dependency> 

**2、修改application.yml配置文件** 

activity:

 datasource:

type: com.alibaba.druid.pool.xa.DruidXADataSource 

jta:

 log-dir: classpath:tx-logs

 transaction-manager-id: txManager 

**3、重构druid数据源配置类** 

DruidXADataSource datasource = new DruidXADataSource();

AtomikosDataSourceBean atomikosDataSource = new AtomikosDataSourceBean();

atomikosDataSource.setXaDataSource(datasource); 

所有的数据源要搞成这样子 

就在一个Activity的数据源配置类中保留一个JTA事务管理器的配置 

  @Bean(name = "xatx")

  @Primary

  public JtaTransactionManager activityTransactionManager() {

​       UserTransactionManager userTransactionManager = new UserTransactionManager();

​    UserTransaction userTransaction = new UserTransactionImp();

​    return new JtaTransactionManager(userTransaction, userTransactionManager);

  } 

在其他所有数据源配置类中的这个事务管理器的配置全部删除 

**4、修改事务注解** 

@Transactional(transactionManager = "xatx", rollbackFor = Exception.class) 

**5、测试一下** 

此时其实就已经ok了，先试一下正常的逻辑，让系统可以跑通，不会报错 

然后再模拟某个SQL语句是报错的，这样模拟对某个数据库执行的SQL是报错的，比如说对数字的修改弄成一个字符串传入进去，平时看不出来，但是执行就会报错 

这样看看分布式事务是否会回滚和生效

### 32_基于多数据库场景实验流量充值中心的分布式事务如何应对故障 

分布式事务成功，在一个横跨多个数据库的场景中，某个库的SQL报错，会导致其他库的操作全部回滚，采用的是JTA + Druid多数据源 + Atomikos，基于这三者整合而成的分布式事务的管理，底层的思想其实就是2PC的原理 

分布式事务实现的还是很彻底的，包裹在一个分布式事务中的代码，只要有报错，就回滚，分布式事务全部回滚 

如果没有报错，分布式事务成功执行。。。 

最最基础的分布式事务，单系统跨多库的分布式事务，从基础理论知识的讲解，一直到实战开发，都结束了，我们就花费几讲的时间，来研究一下，整合了JTATransactionManager以及Atomikos框架之后，分布式事务的源码，我们来看一下

### 33_JTA + Atomikos分布式事务源码剖析（一）：分布式事务的创建

09_JTA+Atomikos分布式事务源码剖析

![](C:\Users\zy199005\Desktop\中华石杉\images\java\06\0303301.png) 

整合在spring boot + druid生产级环境中的一套单系统跨多库的分布式事务实践，使用的JTA事务管理器，加上Atomikos分布式事务的框架，Atomikos框架主要是提供了支持分布式事务的DataSource数据源的一个支持 

JTA主要是提供了事务管理器，也就是分布式事务流程管控的这么一套机制

我们从这一讲开始，就把JTA + Atomikos这对组合来阅读一下其源码，分析一下XA分布式事务的框架的底层原理是什么样子的 

原来是单库的时候，tm其实PlatformTransactionManager，也就是单库的最基础的事务管理器，现在的话就变成了我们之前配置的那个JtaTransactionManager了，代表事务的一个对象，是JtaTransactionObject 

JtaTransactionManager.doBegin()方法中去，TransactionManagerImpl中的一个方法，这个方法中主要就是获取一个CompositeTransaction的一个对象，根据当前线程，从一个map中获取出来一个Stack数据结构，从栈中弹出来一个对象 

每个线程过来，都可以获取到属于这个线程他自己的代表着分布式事务的一个CompositeTransaction的对象，刚开始这个栈里肯定是没有对象的，栈是空的，所以刚开始从栈中弹出来的这个对象是null，所以会手动创建一个 

创建好了一个CompositeTransaction对象之后，会放入map中thread对应的一个Stack，将这个对象压入栈中 

你觉得为当前线程创建这么一个CompositeTransaction，他的深意在哪儿呢？这个事务对象，代表了一个当前线程要执行的多个数据库的操作关联起来的一个分布式事务，所以讲这个事务对象跟当前线程通过一个map关联起来了，后面这个线程再执行的时候，就可以获取到这个关联多个数据库操作的分布式事务的CompositeTransaction对象了 

createCompositeTransaction ( 10000 ): created new ROOT transaction with id 192.168.56.1.tm0000500005 

这行日志分明表明了，一个代表分布式事务的CompositeTransaction对象被创建了 

下一讲就要来分析一下，atomikos框架提供的DataSource数据源，肯定会在代码中，被调用了，mybatis的mapper组件，会找SqlSessionFactory，SqlSessionFactory一定会去找底层的数据库连接池中的DataSource 

基于DataSource获取一个Connection，基于这个Connection来执行preparedStatement() SQL语句，肯定会干这个事情的 

Atomikos框架，做了一个DataSource，AtomikosDataSourceBean，从这里来获取Connection的时候，一定是会获取一个Atomikos包装过的Connection，只有这样子，Atomikos框架，才可以帮我们来控制分布式事务的执行 

所以下一讲，我们扼要研究的源码，就是Atomikos包装过的Connection，一定会有一些方法被调用，preparedStatement()方法，在这个里面，Atomikos一定会做一些事情的，屁股猜猜，XA START指令，定义好要执行的一些SQL语句，XA END指令 

我们用屁股来猜猜，估计是在提交事务的时候，JtaTransactionManager会去执行两阶段的提交，先是发送XA PREPARE指令，然后根据情况去发送对应的XA COMMIT指令，或者是XA ROLLBACK指令

### 34_JTA + Atomikos分布式事务源码剖析（二）：Atomikos数据源的逻辑

09_JTA+Atomikos分布式事务源码剖析

![](C:\Users\zy199005\Desktop\中华石杉\images\java\06\0303401.png) 

AtomikosDataSourceBean，作为数据库连接池，后面创建的数据库连接都会从这儿来，我们这一讲就是研究一下这里创建的数据库连接是个什么东西 

org.springframework.boot.jta.atomikos，下面的，这个项目是Atomikos为了跟spring boot整合做的一个项目，里面其实没什么东西，他其实真实的一个AtomikosDataSourceBean是在com.atomikos.jdbc包下面 

transactions-jdbc-3.9.3.jar 

​               ConnectionFactory cf = doInit();

​               connectionPool = new ConnectionPool(cf, this); 

数据库连接池最最核心的是啥？其实很简单，就是从ConnectionFactory里面去获取一个Connection，放到一个ConnectionPool里面去，这个池子里面放了数据库连接，在AtomikosDataSourceBean中，我们其实设置了DruidXADataSource 

其实AtomikosDataSourceBean底层还是依赖于人家DruidXADataSource数据库连接池的，他只是对每个连接做了一个包装 

public Connection getConnection ( HeuristicMessage msg ) throws SQLException  

人家mybatis -> mapper -> SqlSessionFactory -> DataSource -> getConnection()，AtomokosDataSOurceBean最核心的地方其实是getConnection()方法 

com.atomikos.datasource.pool.ConnectionFactory cf = new com.atomikos.jdbc.AtomikosXAConnectionFactory(xaDataSource, tr, this);

​               Configuration.addResource ( tr ); 

ConnectionFactory是Atomikos框架自己做的，这个数据库连接池的工厂，其实是基于DruidXADataSource来封装的，从ConnectionFactory里获取连接，你基本可以认为是通过DruidXADataSource来获取连接 

connection = (Connection) connectionPool.borrowConnection ( msg ); 

从connectionPool中获取了一个数据库连接，一看就是基于底层的DruidXADataSource在获取数据库连接，但是获取出来的数据库连接，肯定是经过Atomikos的包装的，在这个里面的源码中，大家可以看到，创建出来的是一个 

AtomikosConnectionProxy，这个东西里面是封装了一个DruidXADataSource实际返回给他的一个数据库连接，创建了一个动态代理，动态代理中，肯定是封装了这个对应的AtomikosConnectionProxy这个东西的 

AtomokosConnectionProxy其实是一个JDK动态代理中的一个InvocationHandler的这么一个概念，这个东西呢，他其实是在动态代理被调用的时候，都会由他来拦截

### 35_JTA + Atomikos分布式事务源码剖析（三）：XA START指令以及SQL准备

09_JTA+Atomikos分布式事务源码剖析(1)

![](C:\Users\zy199005\Desktop\中华石杉\images\java\06\0303501.png)  

AtomikosDataSourceBean -> getConnection() -> mybatis底层肯定是基于这个数据源来获取数据库连接以及执行preparedStatement之类的操作 -> Connection接口的动态代理 -> AtomikosConnectionProxy（InvocationHandler） 

我们这一讲的话呢，就是给AtomikosConnectionProxy打上断点，每一行代码 -> mapper组件 -> SqlSessionFactory -> AtomikosDataSourceBean.getConntion() -> AtomikosConnectionProxy里面去执行一些SQL 

推测，AtomikosConnectionProxy，被mybatis调用preparedStatement()方法的时候，就会执行XA START相关的指令 

AtomikosDataSoureBean 'financeDataSource': getConnection ( null )...

AtomikosDataSoureBean 'financeDataSource': init... 

一看就是去调用了AtomikosDataSourceBean的getConnection()方法，这个AtomikosDataSourceBean，是financeDataSource，底层封装的是这个DruidXADataSource，每个数据库对应的AtomikosDataSourceBean是不一样的，对应着不同的数据库 

atomikos connection proxy for com.alibaba.druid.proxy.jdbc.ConnectionProxyImpl@6773ba4a 

AtomikosDataSourceBean，你去找他的getConnection()方法，一看就是会返回AtomikosConnectionProxy对应的一个动态代理，这里打印出了对应的日志 

Connection.getAutoCommit()，被调用了，直接走了底层的真实的数据库连接，就是去掉用了那个方法，获取到的结果是true：ret = method.invoke(delegate, args); 

下面一步就是找Connection来执行prepareStatement()操作了： 

[UPDATE account_amount SET amount=amount + ? WHERE user_account_id=?, 1003, 1007] 

XAResourceTransaction ret = findOrCreateBranchWithResourceException(ct);

ct.addParticipant(ret); 

大概什么意思呢？就是说分布式事务，涉及到很多子事务，一个数据库就里面会有一个子事务，XAResourceTransaction（是Atomikos框架自己搞的一个类），代表了一个数据库里的这个子事务 

CompositeTransactionImpl，本身也是Atomikos框架里的一个类，代表的就是一个分布式事务，在分布式事务中，加入一个数据库的子事务 

CompositeTransactionImpl，代表的是一个分布式事务，也是一个root事务，root事务id就是：192.168.56.1.tm0001100005。XAResourceTransaction是其中一个数据库的子事务，id：3139322E3136382E35362E312E746D30303031313030303035:3139322E3136382E35362E312E746D3531 

​         if(LOGGER.isInfoEnabled()){

​              LOGGER.logInfo("XAResource.start ( " + xidToHexString + " , " + logFlag

​            \+ " ) on resource " + resourcename_

​            \+ " represented by XAResource instance " + xaresource_);

​         }

​      xaresource_.start ( xid_, flag ); 

在这个XAResourceTransaction里面，会有一个resume()方法，这个方法中，就会去执行底层的XAResource的start指令，就会给数据库发送一个XA START指令 

​                    ret = method.invoke(delegate, args); 

相当于就会去调用原生的Connection，数据库连接，去执行原生Connection的prepareStatement()方法，将原生的PreparedStatement全部放入一个list中，对于资金数据库，其实是会调用两次相对应的一个prepareStatement()，他会执行两条SQL，完成资金的转账 

但是，第二次执行同一个库的SQL的时候，代表那个库的子事务的XAResourceTransaction就不会重新创建了，所以说只有在第一次创建XAResourceTransaction的时候，才会执行XA START指令 

第二次的话，就不会再次来一次了，isEnlistedInGlobalTransaction()，他肯定会判断一下，当前这个库对应的子事务，是否在全局事务中（GlobalTransaction），之前已经将这个库的子事务对象创建好，加入CompositeTransaction中了，也就是全局事务中了，所以以后对同一个库执行SQL语句的时候 

又换了一个了，就是开始往订单库中插入订单了，对于每个库的SQL，都会针对哪个数据库，创建一个代表哪个库的子事务，XAResourceTransaction，加入分布式事务CompositeTransaction中，同时基于XAResource，执行那个库上的XA START指令 

然后对每个库都开启了XA START指令，都在依次通过prepareStatement()定义好每个库要执行的SQL，到这一步为止，其实所有的SQL都执行完了 

对每个库都发送了XA START指令，同时对每个库都使用prepareStatement()方法定义好了每个库要执行哪些SQL语句，下一步就会去执行整个事务的这么一个提交，其实就会走2PC的一套逻辑了 

对每个库都执行XA END指令，然后对每个库都执行XA PREPARE指令，2PC的阶段一，如果说有人的prepare返回消息不是ok，那么就全量回滚，就是发送XA ROLLBACK指令，如果说所有人的返回消息都是ok，那么就对每个库发送XA COMMIT指令

### 36_JTA + Atomikos分布式事务源码剖析（四）：XA END指令

09_JTA+Atomikos分布式事务源码剖析(2)

![](C:\Users\zy199005\Desktop\中华石杉\images\java\06\0303601.png)  

这一讲的话呢，就到了提交整个分布式事务的时候，这里的话呢就会完成各个库的2PC的提交，XAResource.prepare()，根据结果判定是否要执行XAResource.commit()，或者是XAResource.rollback() 

在AbstractPlatformTransactinoManager中，就会有一个方法triggerBeforeCompletion()，在这个方法中，一看就是去触发了对每个之前使用过的数据库连接的close()方法的调用，此时会走到AtomikosConnectionProxy中去，在那个里面，会执行每个XAResource.end()指令 

具体的代码就不去看了，之前有一个注册Synchronization的一个东西，现在这个trigger应跟那个东西是有关系的，一旦触发之后，就会对之前使用过的每个Connection都调用close()方法，相当于是对对应的那个数据库调用XA END指令

### 37_JTA + Atomikos分布式事务源码剖析（五）：2PC分布式事务提交

09_JTA+Atomikos分布式事务源码剖析(3)

![](C:\Users\zy199005\Desktop\中华石杉\images\java\06\0303701.png) 

dd 

while ( enumm.hasMoreElements () ) {

​        Participant p = (Participant) enumm.nextElement (); 

遍历每个participant，这块就是遍历所有的子数据库的子事务 

if ( commit ) {

​                 if ( participants_.size () <= 1 ) {

​                      commit ( true );

​                 } else {

​                      int prepareResult = prepare ();

​                      // make sure to only do commit if NOT read only

​                      if ( prepareResult != Participant.READ_ONLY )

​                           commit ( false );

​                 }

​            } else {

​                 rollback ();

​            } 

这段代码，是核心中的核心，在prepare()里，其实是尝试了所有库的prepare操作，2PC中的第一个阶段，如果成功了以后，就会执行commit() 

这个图基本上已经差不多了，如果是rollback的话，我们可以等下一讲的时候，来看一下，他是如何进行rollback的，我们来模拟一个报错，基于报错来调试一下这个源码

### 38_JTA + Atomikos分布式事务源码剖析（六）：2PC分布式事务的异常回滚

09_JTA+Atomikos分布式事务源码剖析(4)

![](C:\Users\zy199005\Desktop\中华石杉\images\java\06\0303801.png) 

2PC的正常两阶段提交的过程，如果说prepare阶段成功了以后，就会给各个库发送commit指令，让各个库都提交自己本地的那个小事务 

int prepareResult = prepare (); 

这个方法里面，会根据prepare阶段的各个库的结果，来判断是否要回滚 

while ( enumm.hasMoreElements () ) {

​        Participant p = (Participant) enumm.nextElement ();

​        PrepareMessage pm = new PrepareMessage ( p, result );

​        if ( getCascadeList () != null && p.getURI () != null ) { //null for OTS

​          Integer sibnum = (Integer) getCascadeList ().get ( p.getURI () );

​          if ( sibnum != null ) { // null for local participant!

​            p.setGlobalSiblingCount ( sibnum.intValue () );

​          }

​          p.setCascadeList ( getCascadeList () );

​        } 

​        getPropagator ().submitPropagationMessage ( pm );

​      } // while 

这段代码，其实就是对分布式事务中的所有的Participant，子事务（XAResourceTransaction），遍历，对每个子事务都执行prepare操作，getPropagator ().submitPropagationMessage ( pm );这行代码是对每个子事务执行prepare操作 

result = new PrepareResult ( count ); 

count就是字事务的数量，你有多少个数据库就会有多少个子事务，PrepareResult，就代表了整个prepare阶段的结果，你的每个数据库的子事务的prepare消息返回的结果，都会封装在PrepareResult里面 

result_.addReply ( new Reply ( result, exception,

​            getParticipant (), retried ) ); 

就是将当前这个执行了prepare操作的子事务，以及对应的prepare结果，封装成一个Reply对象，将这个Reply对象放到一个Result的对象中去，所以最终其实就是对每个数据库都执行了prepare操作之后，每个数据库的prepare操作对应的结果，都会封装成一个Reply，然后放到Result里面去 

所有库的prepare操作都执行完毕了之后，就会来判断，所有prepare操作的结果是否都是正常的，result.waitForReplies ();。boolean voteOK = result.allYes ();，就是判断所有库的prepare消息的返回结果是否都是YES，然后voteOK就是所有库都投票OK的。 

 if ( !voteOK ) { 

​        int res = result.getResult ();        

​        try {

​          rollbackWithAfterCompletionNotification(new RollbackCallback() { 

如果不是所有的库对prepare消息返回的结果都是YES，那么就会让所有库执行XA ROLLBACK的指令，我们debug调试为什么很容易rollback，因为有timeout机制，分布式事务是有timeout机制的，debug调试的时候，很容易导致我们的分布式事务的执行是超时的，所以在prepare阶段很容易就是失败的 

​      while ( enumm.hasMoreElements () ) {

​        Participant p = (Participant) enumm.nextElement ();

​         if ( !readOnlyTable_.containsKey ( p ) ) {

​          RollbackMessage rm = new RollbackMessage ( p,

​              rollbackresult, indoubt );

​          propagator_.submitPropagationMessage ( rm );

​        }

​      }  

这个方法里面，他会遍历每个Participant，然后对每个库执行XA ROLLBACK指令 

很有意思的一点，就是对这个rollback指令，其实同样会记录rollback指令的结果，如果rollback指令发送出去之后居然有某个库连rollback指令都没执行完成，那么就 

一旦走了XA分布式事务之后，性能极差 

（1）跨4~5个库的分布式事务的操作，750m左右完成

（2）跨4~5个库，你不用分布式事务，任何事务都不用，650ms左右 

简单的性能测试，用了XA分布式事务之后，增加了100ms，耗时增加了15%，性能降低了15%，我可以大家说的一点是，如果在更加复杂的场景里面，XA分布式事务，性能最极端的情况下，会降低10倍 

比如说你要是不用XA分布式事务，可能就是50ms，用了就是500ms

### 39_JTA + Atomikos分布式事务框架的架构设计以及技术特点总结

10_JTA + Atomikos分布式事务框架的架构设计特点

 ![](C:\Users\zy199005\Desktop\中华石杉\images\java\06\0303901.png) 

站在比较高的一个角度，抽象的角度，来思考一下JTA + Atomikos实现XA分布式事务框架的架构设计的一个特点，基于Spring原生transaction事务控制的一个过程 

JTA，其实是负责了Atomikos框架的一个指挥和调度，让他按照事务的基本步骤来走；Atomikos框架相当于是DTP模型里的TM，跟各个MySQL（RM）通信，XA START、XA END、XA COMMIT、XA ROLLBACK等符合XA规范的一套接口，调用 

技术特点： 

（1）Atomikos框架实现XA分布式事务的一些技术特点是什么呢？ 

（2）如果让你来实现一套Atomikos框架，就是第一步，你需要跟JtaTransactionManager整合起来，需要JTA结合起来 

（3）创建分布式事务的时候，创建一个代表了分布式事务的对象；在各个SQL执行的时候，必须从你的DataSource里面获取Connection，对Connection的prepareStatement()方法的调用，你需要进行拦截，去对各个库执行XA START指令，以及定义好SQL；在提交事务的时候，你就需要去对各个库执行XA PREPARE指令，如果都成功，就执行XA COMMIT指令，如果失败，就执行XA ROLLBACK指令 

（4）比较有技术含量的一些点，还是动态代理的灵活的使用，自己去实现DataSource，Connection变成了你的动态代理，Feign源码，大量的也是依赖于动态代理，动态代理这个东西，不难，JDK动态代理，Atomikos、Feign等开源框架用的都是JDK动态代理，CBLIB动态代理

### 40_团队发展到一定规模了流量充值中心系统为什么要服务化呢 

39讲，单块单库的系统，演变为了单块多库的系统，单块多库的系统的分布式事务采用的是经典的XA分布式事务的方案，包括使用什么XA分布式事务框架，以及XA分布式事务框架底层的源码，以及最底层的原理，都讲清楚了 

分布式事务下一块的内容，单块的系统要演变为分布式的系统，称之为微服务系统，也可以叫做分布式系统，架构班课程之前给大家都分析过分布式系统，微服务架构，spring cloud源码 

流量充值中心，spring cloud重构为分布式系统，过一过，流量充值中心的系统，为什么要拆分为多个服务，为什么要变成分布式的系统呢？ 

流量充值中心内，包含了多个模块： 

（1）活动模块

（2）流量券模块

（3）积分模块

（4）资金模块

（5）抽奖模块

（6）充值订单模块

（7）流量套餐模块 

想象一个场景，我们现在做流量充值中心，基本上停留在一个案例的角度去做的，实际的生产系统里面，如果让你做一个类似支付宝的充值中心的这么一个东西，复杂度要比我们这个复杂上百倍，几十倍不止 

充值中心，流量，花费，还有别的一些东西，活动也有很多种，抽奖玩法，券的玩法，套餐包的玩法，流量商城，流量充值中心 => 支付宝充值中心 => 业务是很复杂的 => 整套系统下来，小几十万行代码的规模，是很正常的 

充值中心如果要做好，这个后端开发团队，10~20人非常正常 

怎么可能比如让20个人同时维护和开发一个单块系统的单个工程呢？这个里面效率就非常的低了，超过10个人维护一个单块系统，协调的成本就很高了： 

（1）开发的时候可能会互相修改代码，涉及到大量的代码冲突的合并； 

（2）测试的时候，比如说，多个人同时开发多个版本，一整套系统部署，测试的机器是同一批机器，要么是张三来部署他的版本来测试，要么是让李四部署他的版本来测试，测试环境都有冲突 

（3）大单块系统，涉及很多东西，依赖很多，可能你修改列一些代码，部署测试环境，咔嚓咔嚓报错，为什么呢？因为可能你修改的代码影响了别人的代码，导致别人的代码报错，这个时候光是部署测试环境，都要找其他人来一块部署 

（4）部署上线，每次上线部署，涉及到很多步骤的，然后这里就很尴尬，如果你部署，一不小心因为你的修改的代码导致别人的地方报错了，怎么办呢？部署上线，失败了，你还要找其他的哥儿们来给你排查问题 

（5）测试的时候，可能你就只是修改了一点代码而已，如果要确保你的修改没有导致系统其他的地方报错或者是异常，需要所有人配合，测试人员、前端人员、后端人员，全量把这个系统几十万行代码的功能给回归测试一遍 

一般来讲，现在行业里流行的，以及过去我们在各大公司里实践的一些东西，其实都是将单块系统拆分为分布式系统，比如说流量充值中心，可能会拆分为下面这个样子，拆分为多个服务，每个服务让一两个人来负责和维护： 

（1）活动服务

（2）流量券服务

（3）积分服务

（4）资金服务

（5）抽奖服务

（6）充值订单服务

（7）流量套餐服务

（8）其他的一些服务 

20个人，一定会有一个大leader，19，10来个服务中去，每个服务也就一两个人去维护和负责，代码量可能也就几万行代码而已 

整个这个系统就维护的方便了很多了，解决了传统大单块系统，几十人协同开发的场景很多的传统的问题都解决了： 

（1）一两个人维护一个程序，代码冲突的概率大大降低 

（2）方便多了，每个服务都有自己的测试环境，不会说你部署了自己的版本我就不能部署了，测试了；部署测试环境的时候，我就是自己熟悉的这套代码去部署而已，绝对不可能说部署的时候，我把别人的代码给弄坏了，导致测试环境部署失败；如果你这次修改就改动了你自己的一个服务，那么QA把这一个服务给回归一遍就ok了 

（3）部署上线，其实也是同理，你都是自己的代码部署上线，跟别人是没关系的 

我们的流量充值中心，面临的其实就是说一个业务极度复杂，20人协作开发的一个场景，单块系统改造成分布式的系统，势在必行，就会几讲的时间，使用spring cloud技术将流量充值中心给拆分为多个服务，分布式系统

### 41_基于Spring Cloud完成流量充值中心系统的微服务化拆分（一） 

我们就基于sping cloud技术来重构和拆分流量充值中心的系统，拆分为8个服务，还要单独拆出来一个流量充值中心服务，总控的服务，具体的spring cloud技术，以及源码，以及怎么用，不讲 

之前课程我们都已经给大家说的很详细了 

（1）我们把8个服务先拆分出来，拆分出来之后，给每个服务都定义一个spring cloud接口

（2）我们将流量充值中心服务，作为一个总控服务，全部重构为基于spring cloud去调用底层的各个服务

（3）我们会加入spring cloud的一些其他的东西，比如说是eureka服务注册中心工程和zuul网关工程给 

拆分成多个服务之后，每个服务又变成是单系统单库了 

下一讲，我们在各个服务里融入sping cloud的东西，给每个服务拆出来一个定义接口的工程，还有一个服务的工程，让各个服务不再报错 

再下一讲，我们就可以弄好eureka注册中心以及zuul网关 

再来一讲，整体跑起来测试一遍是否可以跑通

### 42_基于Spring Cloud完成流量充值中心系统的微服务化拆分（二） 

**1、改造接口工程** 

<distributionManagement>

​          <repository>

​               <id>nexus-releases</id>

​               <name>Nexus Release Repository</name>

​               <url>http://localhost:8081/repository/maven-releases/</url>

​          </repository>

​          <snapshotRepository>

​               <id>nexus-snapshots</id>

​               <name>Nexus Snapshot Repository</name>

​               <url>http://localhost:8081/repository/maven-snapshots/</url>

​          </snapshotRepository>

​     </distributionManagement> 

   <dependencies>

​       <dependency>

​               <groupId>org.springframework.boot</groupId>

​               <artifactId>spring-boot-starter-web</artifactId>

​               <version>1.5.9.RELEASE</version>

​          </dependency>

   </dependencies> 

将service接口的定义，改造为符合http接口的定义，以及domain一起放入api工程中 

**2、改造服务工程** 

依赖自己的接口工程，同时改造为一个spring cloud的服务 

​     <dependencyManagement>

​       <dependencies>

​         <dependency>

​           <groupId>org.springframework.cloud</groupId>

​           <artifactId>spring-cloud-dependencies</artifactId>

​           <version>Edgware.SR3</version>

​           <type>pom</type>

​           <scope>import</scope>

​         </dependency>

​          </dependencies>

​     </dependencyManagement> 

<dependencies>

​          <!-- spring boot的核心starter -->

​       <dependency>

​         <groupId>org.springframework.boot</groupId>

​         <artifactId>spring-boot-starter-web</artifactId>

​       </dependency>

​          <dependency>

​            <groupId>org.mybatis.spring.boot</groupId>

​            <artifactId>mybatis-spring-boot-starter</artifactId>

​            <version>1.3.1</version>

​          </dependency>

​          <dependency> 

​            <groupId>org.springframework.boot</groupId> 

​            <artifactId>spring-boot-starter-data-jpa</artifactId> 

​          </dependency>

​          <dependency>

​            <groupId>org.springframework.boot</groupId>

​            <artifactId>spring-boot-starter-jdbc</artifactId>

​          </dependency>          

​          <!-- spring cloud相关的依赖 -->

​          <dependency>

​               <groupId>org.springframework.cloud</groupId>

​            <artifactId>spring-cloud-starter-config</artifactId>

​          </dependency>

​          <dependency>

​            <groupId>org.springframework.cloud</groupId>

​            <artifactId>spring-cloud-starter-eureka</artifactId>

​          </dependency>

​          <dependency>

​            <groupId>org.springframework.cloud</groupId>

​            <artifactId>spring-cloud-starter-ribbon</artifactId>

​          </dependency>

​          <dependency>

​               <groupId>org.springframework.cloud</groupId>

​               <artifactId>spring-cloud-starter-feign</artifactId>

​          </dependency>

​          <dependency>

​               <groupId>org.springframework.cloud</groupId>

​               <artifactId>spring-cloud-starter-hystrix</artifactId>

​          </dependency>          

​          <!-- spring boot提供的辅助开发工具 -->

​          <dependency>

​         <groupId>org.springframework.boot</groupId>

​         <artifactId>spring-boot-devtools</artifactId>

​         <optional>true</optional>

​       </dependency>          

​          <!-- MySQL数据库连接需要的依赖 -->

​          <dependency> 

​            <groupId>mysql</groupId> 

​            <artifactId>mysql-connector-java</artifactId> 

​            <scope>runtime</scope> 

​          </dependency>

​          <dependency> 

​            <groupId>com.alibaba</groupId> 

​            <artifactId>druid</artifactId> 

​            <version>1.1.6</version> 

​          </dependency>          

​          <!-- 测试需要的依赖 -->

​          <dependency>

​            <groupId>org.springframework.boot</groupId>

​            <artifactId>spring-boot-starter-test</artifactId>

​          </dependency>        

​          <!-- json处理相关的依赖 -->

​          <dependency>

​            <groupId>com.alibaba</groupId>

​            <artifactId>fastjson</artifactId>

​            <version>1.2.45</version>

​          </dependency>          

​          <!-- 系统监控相关的依赖 -->

​          <dependency>

​         <groupId>org.springframework.boot</groupId>

​         <artifactId>spring-boot-starter-actuator</artifactId>

​       </dependency>       

​       <!-- cglib的BeanCopier需要的依赖 -->

​       <dependency> 

​      <groupId>asm</groupId> 

​      <artifactId>asm</artifactId> 

​      <version>3.3.1</version> 

​    </dependency> 

​    <dependency> 

​      <groupId>asm</groupId> 

​      <artifactId>asm-commons</artifactId> 

​      <version>3.3.1</version> 

​    </dependency> 

​    <dependency> 

​      <groupId>asm</groupId> 

​      <artifactId>asm-util</artifactId> 

​      <version>3.3.1</version> 

​    </dependency> 

​    <dependency> 

​      <groupId>cglib</groupId> 

​       <artifactId>cglib-nodep</artifactId> 

​      <version>2.2.2</version> 

​    </dependency>    

​    <dependency> 

​            <groupId>commons-fileupload</groupId> 

​            <artifactId>commons-fileupload</artifactId> 

​            <version>1.3.2</version> 

​          </dependency>           

​          <dependency>

​            <groupId>com.fasterxml.jackson.core</groupId>

​            <artifactId>jackson-databind</artifactId>

​          </dependency>          

​     </dependencies> 

spring:

 application:

name: eshop-commodity 

eureka:

 instance:

  hostname: localhost

 client:

  serviceUrl:

   defaultZone: http://peer1:8761/eureka,http://peer2:8762/eureka 

ribbon:

 ConnectTimeout: 3000

 ReadTimeout: 3000

 OkToRetryOnAllOperations: true

 MaxAutoRetries: 1

 MaxAutoRetriesNextServer: 1 

@EnableEurekaClient

@EnableFeignClients 

在api包下定义对其他各个服务的调用

### 43_基于Spring Cloud完成流量充值中心系统的微服务化拆分（三）

### 44_服务化之后的流量充值中心的分布式事务问题的分析说明 

再加@Transactional注解就已经没用了，流量充值中心的总控服务，都不操作数据库了，一点儿用没有，如果你是用XA分布式事务，更加没有了，XA分布式事务，适用的场景其实是单系统多库的时候，协调多个库的分布式事务 

分布式系统，服务化的系统，分布式事务就已经失效了，无论是单库事务，XA分布式事务，无法解决我们面对的问题 

不做任何的事务控制，一定是会有问题的，比如说，资金服务、订单服务、抽奖服务的接口调用都成功了，资金也转账了、订单也创建了、抽奖次数也增加了，结果，积分服务的接口调用失败，网络超时，问题很多的 

结果楞是说好的1.2积分没给人家加上去，不搞笑呢 

需要的分布式事务的技术方案，就跟传统的分布式事务方案完全不一样了，接下来从下一讲开始，我们将要进入分布式事务的全新的领域，主要是针对分布式系统，服务化系统的场景下，如何完成多个系统多个库之间的涉及到的一个分布式事务

### 45_分布式事务的业内常见解决方案的初步介绍以及基础知识筑基

01_单块系统里的事务

![](C:\Users\zy199005\Desktop\中华石杉\images\java\06\0304501.png) 

02_分布式系统里的事务

![](C:\Users\zy199005\Desktop\中华石杉\images\java\06\0304502.png)

03_两阶段提交方案

![](C:\Users\zy199005\Desktop\中华石杉\images\java\06\0304503.png)

04_TCC方案

![](C:\Users\zy199005\Desktop\中华石杉\images\java\06\0304504.png)

05_本地消息表方案

![](C:\Users\zy199005\Desktop\中华石杉\images\java\06\0304505.png)

06_可靠消息最终一致性方案

![](C:\Users\zy199005\Desktop\中华石杉\images\java\06\0304506.png)

07_最大努力通知方案

![](C:\Users\zy199005\Desktop\中华石杉\images\java\06\0304507.png)

1、面试题 

分布式事务了解吗？你们如何解决分布式事务问题的？ 

2、面试官心里分析 

只要聊到你做了分布式系统，必问分布式事务，你对分布式事务一无所知的话，确实会很坑，你起码得知道有哪些方案，一般怎么来做，每个方案的优缺点是什么。 

现在面试，分布式系统成了标配，而分布式系统带来的分布式事务也成了标配了。因为你做系统肯定要用事务吧，那你用事务的话，分布式系统之后肯定要用分布式事务吧。。。呵呵。。。先不说你搞过没有，起码你得明白有哪几种方案，每种方案可能有啥坑？比如TCC方案的网络问题、XA方案的一致性问题 

3、面试题剖析 

（1）两阶段提交方案/XA方案 

也叫做两阶段提交事务方案，这个举个例子，比如说咱们公司里经常tb是吧（就是团建），然后一般会有个tb主席（就是负责组织团建的那个人）。 

tb，team building，团建 

第一个阶段，一般tb主席会提前一周问一下团队里的每个人，说，大家伙，下周六我们去滑雪+烧烤，去吗？这个时候tb主席开始等待每个人的回答，如果所有人都说ok，那么就可以决定一起去这次tb。如果这个阶段里，任何一个人回答说，我有事不去了，那么tb主席就会取消这次活动。 

第二个阶段，那下周六大家就一起去滑雪+烧烤了 

所以这个就是所谓的XA事务，两阶段提交，有一个事务管理器的概念，负责协调多个数据库（资源管理器）的事务，事务管理器先问问各个数据库你准备好了吗？如果每个数据库都回复ok，那么就正式提交事务，在各个数据库上执行操作；如果任何一个数据库回答不ok，那么就回滚事务。 

这种分布式事务方案，比较适合单块应用里，跨多个库的分布式事务，而且因为严重依赖于数据库层面来搞定复杂的事务，效率很低，绝对不适合高并发的场景。如果要玩儿，那么基于spring + JTA就可以搞定，自己随便搜个demo看看就知道了。 

这个方案，我们很少用，一般来说某个系统内部如果出现跨多个库的这么一个操作，是不合规的。我可以给大家介绍一下， 现在微服务，一个大的系统分成几百个服务，几十个服务。一般来说，我们的规定和规范，是要求说每个服务只能操作自己对应的一个数据库。 

如果你要操作别的服务对应的库，不允许直连别的服务的库，违反微服务架构的规范，你随便交叉胡乱访问，几百个服务的话，全体乱套，这样的一套服务是没法管理的，没法治理的，经常数据被别人改错，自己的库被别人写挂。 

如果你要操作别人的服务的库，你必须是通过调用别的服务的接口来实现，绝对不允许你交叉访问别人的数据库！ 

（2）TCC方案 

TCC的全程是：Try、Confirm、Cancel。 

这个其实是用到了补偿的概念，分为了三个阶段： 

1）Try阶段：这个阶段说的是对各个服务的资源做检测以及对资源进行锁定或者预留

2）Confirm阶段：这个阶段说的是在各个服务中执行实际的操作

3）Cancel阶段：如果任何一个服务的业务方法执行出错，那么这里就需要进行补偿，就是执行已经执行成功的业务逻辑的回滚操作 

给大家举个例子吧，比如说跨银行转账的时候，要涉及到两个银行的分布式事务，如果用TCC方案来实现，思路是这样的： 

1）Try阶段：先把两个银行账户中的资金给它冻结住就不让操作了

2）Confirm阶段：执行实际的转账操作，A银行账户的资金扣减，B银行账户的资金增加

3）Cancel阶段：如果任何一个银行的操作执行失败，那么就需要回滚进行补偿，就是比如A银行账户如果已经扣减了，但是B银行账户资金增加失败了，那么就得把A银行账户资金给加回去 

这种方案说实话几乎很少用人使用，我们用的也比较少，但是也有使用的场景。因为这个事务回滚实际上是严重依赖于你自己写代码来回滚和补偿了，会造成补偿代码巨大，非常之恶心。 

比如说我们，一般来说跟钱相关的，跟钱打交道的，支付、交易相关的场景，我们会用TCC，严格严格保证分布式事务要么全部成功，要么全部自动回滚，严格保证资金的正确性，在资金上出现问题 

比较适合的场景：这个就是除非你是真的一致性要求太高，是你系统中核心之核心的场景，比如常见的就是资金类的场景，那你可以用TCC方案了，自己编写大量的业务逻辑，自己判断一个事务中的各个环节是否ok，不ok就执行补偿/回滚代码。 

而且最好是你的各个业务执行的时间都比较短。 

但是说实话，一般尽量别这么搞，自己手写回滚逻辑，或者是补偿逻辑，实在太恶心了，那个业务代码很难维护。 

（3）本地消息表 

国外的ebay搞出来的这么一套思想 

这个大概意思是这样的 

1）A系统在自己本地一个事务里操作同时，插入一条数据到消息表

2）接着A系统将这个消息发送到MQ中去

3）B系统接收到消息之后，在一个事务里，往自己本地消息表里插入一条数据，同时执行其他的业务操作，如果这个消息已经被处理过了，那么此时这个事务会回滚，这样保证不会重复处理消息

4）B系统执行成功之后，就会更新自己本地消息表的状态以及A系统消息表的状态

5）如果B系统处理失败了，那么就不会更新消息表状态，那么此时A系统会定时扫描自己的消息表，如果有没处理的消息，会再次发送到MQ中去，让B再次处理

6）这个方案保证了最终一致性，哪怕B事务失败了，但是A会不断重发消息，直到B那边成功为止 

这个方案说实话最大的问题就在于严重依赖于数据库的消息表来管理事务啥的？？？这个会导致如果是高并发场景咋办呢？咋扩展呢？所以一般确实很少用 

（4）可靠消息最终一致性方案 

这个的意思，就是干脆不要用本地的消息表了，直接基于MQ来实现事务。比如阿里的RocketMQ就支持消息事务。 

大概的意思就是：

1）A系统先发送一个prepared消息到mq，如果这个prepared消息发送失败那么就直接取消操作别执行了

2）如果这个消息发送成功过了，那么接着执行本地事务，如果成功就告诉mq发送确认消息，如果失败就告诉mq回滚消息

3）如果发送了确认消息，那么此时B系统会接收到确认消息，然后执行本地的事务

4）mq会自动定时轮询所有prepared消息回调你的接口，问你，这个消息是不是本地事务处理失败了，所有没发送确认消息？那是继续重试还是回滚？一般来说这里你就可以查下数据库看之前本地事务是否执行，如果回滚了，那么这里也回滚吧。这个就是避免可能本地事务执行成功了，别确认消息发送失败了。

5）这个方案里，要是系统B的事务失败了咋办？重试咯，自动不断重试直到成功，如果实在是不行，要么就是针对重要的资金类业务进行回滚，比如B系统本地回滚后，想办法通知系统A也回滚；或者是发送报警由人工来手工回滚和补偿 

这个还是比较合适的，目前国内互联网公司大都是这么玩儿的，要不你举用RocketMQ支持的，要不你就自己基于类似ActiveMQ？RabbitMQ？自己封装一套类似的逻辑出来，总之思路就是这样子的 

（5）最大努力通知方案 

这个方案的大致意思就是： 

1）系统A本地事务执行完之后，发送个消息到MQ

2）这里会有个专门消费MQ的最大努力通知服务，这个服务会消费MQ然后写入数据库中记录下来，或者是放入个内存队列也可以，接着调用系统B的接口

3）要是系统B执行成功就ok了；要是系统B执行失败了，那么最大努力通知服务就定时尝试重新调用系统B，反复N次，最后还是不行就放弃 

（6）你们公司是如何处理分布式事务的？ 

这个，说真的，确实我们这个课程没法带着大家来实战，因为定位不是这个。但是如果你真的被问到，你可以这么说，我们某某特别严格的场景，用的是TCC来保证强一致性；然后其他的一些场景基于了阿里的RocketMQ来实现了分布式事务。 

你找一个严格资金要求绝对不能错的场景，你可以说你是用的TCC方案；如果是一般的分布式事务场景，订单插入之后要调用库存服务更新库存，库存数据没有资金那么的敏感，可以用可靠消息最终一致性方案 

友情提示一下，rocketmq 3.2.6之前的版本，是可以按照上面的思路来的，但是之后接口做了一些改变，我这里不再赘述了。 

当然如果你愿意，你可以参考可靠消息最终一致性方案来自己实现一套分布式事务，比如基于rabbitmq来玩儿。 

4、昨天学员给我提的一个问题 

老师，我们现在想保证我们的某个系统非常的可靠，任何一个数据都不能错，我们用的是微服务架构，几十个服务。结果我们一盘点，发现，如果到处都要搞的话，一个系统要做几十个分布式事务出来。 

我们的经验，我带几十人的team，最大的一个项目，起码几百个服务，复杂的分布式大型系统，里面其实也没几个分布式事务。 

你其实用任何一个分布式事务的这么一个方案，都会导致你那块儿代码会复杂10倍。很多情况下，系统A调用系统B、系统C、系统D，我们可能根本就不做分布式事务。如果调用报错会打印异常日志。 

每个月也就那么几个bug，很多bug是功能性的，体验性的，真的是涉及到数据层面的一些bug，一个月就几个，两三个？如果你为了确保系统自动保证数据100%不能错，上了几十个分布式事务，代码太复杂；性能太差，系统吞吐量、性能大幅度下跌。 

99%的分布式接口调用，不要做分布式事务，直接就是监控（发邮件、发短信）、记录日志（一旦出错，完整的日志）、事后快速的定位、排查和出解决方案、修复数据。

每个月，每隔几个月，都会对少量的因为代码bug，导致出错的数据，进行人工的修复数据，自己临时动手写个程序，可能要补一些数据，可能要删除一些数据，可能要修改一些字段的值。 

比你做50个分布式事务，成本要来的低上百倍，低几十倍 

trade off，权衡，要用分布式事务的时候，一定是有成本，代码会很复杂，开发很长时间，性能和吞吐量下跌，系统更加复杂更加脆弱反而更加容易出bug；好处，如果做好了，TCC、可靠消息最终一致性方案，一定可以100%保证你那快数据不会出错。

1%，0.1%，0.01%的业务，资金、交易、订单，我们会用分布式事务方案来保证，会员积分、优惠券、商品信息，其实不要这么搞了

### 46_分布式相关的核心理论之CAP与BASE的基础知识筑基

11_CAP理论

![0304601](C:\Users\zy199005\Desktop\中华石杉\images\java\06\0304601.png)

 

CAP、BASE跟后面要看的分布式事务有直接的关系，但是这两个分布式的理论对我们研究分布式系统里面的一些技术和方案都是作为基础的知识需要掌握的 

这个CAP这个东西啊，也是个在研究分布式相关的问题中，比较经典的这么一个理论，大家在学习下面的知识之前，最好是先有相关知识的一个积累，这样下面学习起来才会比较轻松一些 

CAP，就是Consistency、Availability、Partition Tolerence的简称，简单来说，就是一致性、可用性、分区容忍性，所以这个CAP理论讲的就是这么个东西，但是这里的话呢，其实大家觉得很虚，虚的不行，简直是虚头巴脑啊 

所以网上很多类似的什么CAP理论的文章和博客，都是这么讲解的，大家看了就觉得心里凉凉的，不知道是啥玩意儿 

（1）一致性 

先说说C，就是一致性吧，这个其实很好理解，就是说一个分布式系统中，一旦你做了一个数据的修改，那么这个操作成功的时候，就必须是分布式系统的各个节点都是一样的， 

能说，客户端发起一个数据修改的请求，然后服务器告诉他成功了，结果去查的时候，从某个节点上查询数据，发现这个数据不对啊，这样的话就成了数据不一致了，就是分布式系统的各个节点上的数据是不一样的，就是不一致 

这个所谓一致性还分成几种： 

啥叫**强一致性**呢，就是说上面讲的那种就是强一致性；**弱一致性**呢，就是你更新个数据，鬼知道能不能让各个节点都更新成功；**最终一致性**，就是可能更新过后，一段时间内，数据不一致，最后过了一段时间成功了 

最终一致性，应该是分布式系统中非常常见的这么一个东西，redis主从同步，你可以做成主从异步同步的，主节点同步数据到从节点上去的时候，异步，最终一致性的体现。 

你的一个客户端往redis主节点里面写入了一条数据，在一段时间内，你客户端如果从redis从节点去查询数据，此时可能是查不到的，但是redis主从机制给你保证的是，过了一段时间之后，你再查，一定是可以从redis从节点里查到的 

（2）可用性 

这个A，就是可用性，其实也很好理解，就是你的分布式系统必须是可用的啊，说句不好听的，要是一会儿访问你是成功，一会儿访问你失败，那失败的时候就是不可用，有不可用的情况存在，就导致可用性降低了 

什么叫做可用？客户端往分布式系统的各个节点发送请求，都是可以获取到响应的，要不是可以写入成功，要不是可以查询成功；什么叫做不可用呢？客户端往分布式系统中的各个节点发送请求的时候，获取不到响应结果，这个时候，系统就是不可用了，写入失败，人家不让你写入，不接受你的请求 

可用性分成好多级别，比如99%，99.9%，99.99%，99.999% 

99%，一年中只能有80小时左右是可以允许访问失败的

99.9%，一年中大概有8小时左右是可以访问失败

99.99%，一年中有大概不到1小时是可以访问失败的

99.999%，一年中有大概不到5分钟是可以访问失败的

99.9999%，一年中只能有大概不到1分钟可以访问失败 

那一般来说，就我个人观察，很多行业大部分的系统，其实99%可用性都没到，或者可能大概就在99%是一个很正常的水平，每年总得故障几次。能做到99.9%的系统就算是比较牛的了，也算很不错了，毕竟一年内就几个小时不可用 

一般做到99.99%，也就是所谓的4个9，那就是比较高的水平了。而至于说99.999%，五个9，那是行业内的顶尖水平 

（3）分区容忍性 

分区，partition，network partition，网络分区 => 分布式系统之间的网络环境出了故障，分布式系统的各个节点之间现在已经无法进行通信了 

分区容忍性，你的分布式系统可以容忍网络分区的故障，出现上面说的那种网络分区的故障之后，分布式系统的各个节点之间无法进行通信，无所谓，整套分布式系统各个节点，各自为战，该干嘛干嘛，只不过互相之间无法通信而已 

分布式系统还是在运转着，你分别给各个节点发送请求，人家还是可以给你一些响应结果的，这个就是实现了分区容忍性 

这玩意儿搞的稀奇古怪的，啥东西啊，其实说白了，就是一个分布式的系统，如果遇到了网络分区的故障，也就是说，分布式系统互相之间无法联通了，这个时候咋整呢，有点儿恶心啊，这里要求的是，遇到网络分区故障，也类似于传说中的脑裂吧，然后系统还是可以正常对外提供服务的 

如果不具备分区容忍性，那会怎么样呢？那就是说一旦网络故障，整套系统崩溃，你哪怕给各个节点发送消息，全部失败，清一色失败，整套系统甚至会宕机，不再运转了 

（4）CAP => CP or AP 

不可能CAP三者兼得的，CAP理论里面，最最重要的一点，就是说，不可能一个分布式系统同时兼备一致性、可用性、分区容忍性，要么几句是CP（一致性 + 分区容忍性），要么就是AP（可用性 + 分区容忍性） 

基于这套理论，redis、mongodb、hbase什么什么的分布式系统，都是参照着CAP理论来设计的，有些系统是CP，有些系统是AP 

（4）CP 

一般来说，CAP要么同时满足AP，要么同时满足CP，不可能同时满足CAP的，啥意思呢 

如果实现CP的时候，为什么就无法同时满足AP了？为什么有了一致性，就不能有可用性了？CAP里面，为什么要们是CP，要么是AP？为什么一定要有P？分区容忍性，分布式系统，如果一旦出现了一些网络分区的故障之后，保证整套系统继续运转是非常重要的一点，所以很多分布式系统es，都设计了防止脑裂的机制 

P是一定要有，CP，AP，CA（不存在的） 

CP，为什么就没有A了呢？

假设，出现了网络分区的故障，但是因为有P，所以分布式系统继续运转，但是此时分布式系统的节点之间无法进行通信，也就无法同步数据了 

此时客户端要来查询数据，也就是那个key1的数据了，此时系统实际上是处于一个不一致的状态，因为各个节点之间的数据是不一样的，如果客户端来查询key1这条数据，你要是要保证CP的话，就得返回一个特殊的结果（异常）给客户端 

任何一个节点此时不接收任何查询的请求，返回一个异常（系统当前处于不一致的状态，无法查询），这样的话呢，客户端是看不到不一致的数据的 

此时对客户端而言，要么查到的是一致性的数据，要么如果数据不一致什么都查不到，不让你看到不一致的数据，这就保证了CAP里的C，一致性，分布式系统本身处于不一致的时候，让你看不到不一致的数据，就保证了一致性，保证了CP 

但是此时的话，就牺牲掉了A，可用性，因为此时不让你看到不一致的数据，所以你发送请求过来是返回异常的，请求失败了，此时分布式系统就暂时处于不可用的状态下，也就是保证了CP，就没有了A 

弄个分布式系统给大家演示一下，就俩节点，假设现在发生了网络分区故障，好了，那么P起码要保证吧，就是网络分区的时候，系统还是要正常可以运行的，所以P先保证了，对吧，然后呢，因为网络分区，导致俩节点互相不能通信了 

现在呢，你写入一条数据到其中一个节点，好了，结果这个节点没法同步数据到其他的节点上去啊，咋整呢，尴尬啊尴尬，俩节点上数据不一致了 

所以这个时候，如果你要满足C，也就是一致性，你觉得应该怎么办，你要是继续让所有人访问两个节点，那数据100%不一致，一会儿数据这样，一会儿数据那样，这个时候，你就只能牺牲掉A了 

也就是说，在这种情况下，你的系统直接对外不再提供服务，人家查询直接返回异常，不让查到不一致的数据，不就可以保证一致性了，呵呵，但是你就牺牲了可用性了，因为这个时候你的系统是不可用的 

经典的就是一些分布式存储，比如说zookeeper、mongodb、hbase等等，跟他们都是CP的，也就是说数据100%一致，但是有可能有些时候你请求是失败的，不让你请求到不一致的数据，这就是CP 

如果要保证CP的话，C，保证说你在任何情况下写入一条数据，接着从任何一个节点去查都可以看到一致的数据，不可能让你一会儿看到旧数据，一会儿看到的是新数据，这样就保证了一致性 

有些特殊的情况下，确实数据就是没法同步，没法一致性，此时可能就得牺牲A了，可能短暂的情况下，你发送请求过去人家返回异常给你，此时就是短暂不可用的，让你过段时间在重试查询 

（5）AP 

如果网络故障，数据没同步，数据处于不一致的状态下，要保证A，可用性，你两个节点都要允许任何客户端来查询，都可以查到，这样的话呢，整个系统就处于可用的状态下，但是此时就牺牲掉了C 

一会儿可以查到key1的数据，一会儿从另外一个节点去查又查不到了，这就是对客户端而言，看到了不一致的数据 

在各种分布式系统里面，CAP不可能同时兼得，指的主要是什么呢，就是发生网络故障的时候，可能一些数据没有同步一致性，此时要么就是CP，要么就是AP 

那如果要保证AP呢，也就是可用性必须保证，人家过来查必须给人查，那就牺牲掉一致性咯，随便查，要怎么查怎么查，但是查到的数据不一致，那我不管了，反正就这么回事儿了，哈哈哈。。。起码我可用性保证了，一致性就没了 

对于12306、电商系统，这种业务类系统，一般都是AP，也就是说，你可能看到的商品库存或者火车票的库存，是错的，有可能是旧的啊，那么数据很可能看到的都是不一致的，但是呢，你买东西或者买票的时候，一定会检查库存，就可以了 

但是保证了可用性就ok，任何时候都要响应结果，不能动不动就失败 

12306买票，AP，C其实是没保证的。很多人同时在订票，每次订票之后这个车票的库存就会扣减，但是车票库存扣减之后，可能不能及时的被你的12306网站展示出来，可能你查询的车票的库存，是从另外一个库里去查的，最新的库存数据还没同步过来，此时数据是不一致的 

所以你看到的是不一致的数据，C，但是AP，可用性是保证的，时时刻刻都让你可以看到数据，可以买票，可以查询，但是呢可能你看到的车票还剩5张，但是你发起订票的时候，人家一检查最新的库存，判断已经是0张了，就不让你买了呗 

（6）BASE理论 

所谓的BASE，Basicly Available、Soft State、Eventual Consistency，也就是基本可用、软状态、最终一致性 

BASE希望的是，CAP里面基本都可以同时实现，但是不要求同时全部100%完美的实现，CAP三者同时基本实现，BASE，基本可用、最终一致性 

此时要保证基本可用性，应该怎么办呢？两个节点都可以查询的，但是这个时候你会发现说有的节点可以返回数据，有的节点无法返回数据，会看到不一致的状态，这个不一致的状态，就是指的是BASE中的S，soft state，软状态 

基本可用，降级，正常情况下，是查询可以负载均衡到各个节点去查的，也就是可以多节点抗高并发查询，但是此时如果你要降级的话，可以降级为，所有客户端强制查询主节点，这样看到的数据暂时而言都是一样的，都是从主节点去查 

但是因为客户端访问量太大了，同时用一个主节点来支撑很坑，扛不住，怎么办呢，主节点做限流降级，也就是说如果流量太大了，直接返回一个空，让你稍后再来查询 

如果你这样子来降级了，保证的就是所谓的基本可用，降级的措施在里面了，跟正常的可用是不一样的，比正常的可用要差一些，但是还是基本可以用的 

最终一致性，一旦故障或者延迟解决了，数据过了一段时间最终一定是可以同步到其他节点的，数据最终一定是可以处于一致性的 

这个基本可用的意思，就是说可以适当进行降级，比如说某些系统是可以进行降级的，在故障的时候，直接引导到降级的一些功能里去，举个例子吧，本来商品详情页可以是个极度华丽的页面，但是如果降级的话，那么就变成一个比较简陋的页面，里面包含少量数据 

软状态意思就是说，可以存在中间的数据状态，就是比如多个节点在同步数据，在一段时间内，可能每个节点数据不一致，正在同步过程中，这个就是软状态 

最终一致性，就是说，虽然存在软状态，但是最终还是会变成一致的 

所以说，CAP和BASE是俩理论，是俩基础理论，你在设计分布式系统的话，可以用CAP中的CP或者AP，也可以采用BASE理论，有一些不一样，也有一些关系

### 47_各种分布式事务技术方案如何结合起来运用在流量充值中心内 

分布式事务常见的几种方案： 

（1）XA分布式事务，一般用于单系统多库的场景，当然要是多系统多库，也可以，但是就很麻烦了，不适用于这个方案了

（2）TCC方案，try-confirm-cancel方案

（3）可靠消息最终一致性方案，都不能叫做分布式事务的方案，事务，分布式一致性的方案

（4）最大努力通知方案

（5）适合长事务（分布式）的sagas方案，之前在分布式事务解决方案的筑基里面，没有提到sagas，不会放在流量充值中心系统里面来实战，会放到后面我们的实际的大电商项目里去实战 

在我们这里而言，非常简单 

（1）TCC方案，适合于，你的多个服务的操作都比较快 

TCC相当于是一堆同步服务调用的操作，包裹在一个事务里面，同步，关键词，人家给你发起一个请求，触发了一个复杂的TCC事务，人家要等你这个事务完成结束了，然后才能接续往下走的 

假如你的TCC事务里面涉及了10来个服务的调用，要10来秒才能结束，太不靠谱了 

TCC方案应对的其实是大量的同步服务调用的复杂的事务场景，如果要用TCC来保证分布式事务的执行，一般来说尽量确保每个服务的调用都比较快，一般来说确保一个TCC分布式事务的执行，大概需要总共1秒以内的时间 

资金转账、创建订单、抽奖机会、积分、流量券相关的服务调用的逻辑，包裹在一个分布式事务内，用TCC来控制这个分布式事务，因为这里的一些操作基本都是在流量充值中心内部的一些服务，都比较快 

TCC来控制，try他们一把，锁定一些资源；confirm一把，执行各个服务的业务逻辑；如果任何一个服务出现报错和失败；那么tcc就去cancel掉各个服务的逻辑，各个服务通过补偿来的方法逻辑，去回滚之前做出的数据变动 

（2）可靠消息最终一致性的方案 

这个方案，适合于那那种比较耗时的操作，通过这个消息中间件做成异步调用，发送一个消息出去，人家服务消费消息来执行业务逻辑，CAP理论，C（最终一致性），也就是说包裹在一个事务中的多个操作，其中有些操作可能在一定时间内是没执行的 

可能要等过一段时间之后，然后才能去执行，最终一定会执行的，最终一致性的方案，通过MQ消息中间件保证消息的可靠性，最终来实现最终一致性的方案 

调用起来很耗时的操作，比如说流量充值内，调用第三方运营商的系统接口完成流量充值，坑爹了，很可能会出问题，网络调用超时，人家系统代码写的太烂，一个流量充值要耗费个10秒钟才能完成 

你就很不适合包裹在TCC里面了，因为这个东西调用第三方的系统接口，如果一旦超时了，很容易影响系统本地其他服务的操作 

而且的话呢，一般来说，如果你充值话费，或者是充值流量，肯定不是说你刚付钱充值完毕，人家会通知你充值成功了，发你一个短信，告诉你说，具体是否充值到账，请以运营商那边的信息为准 

你付钱之后，其实流量还没充值好，在一段时间内是没充值的，最终过一段时间，几分钟之后，人家一定会保证给你把流量充值到位 

调用第三方运营商系统接口的操作，很适合用可靠消息最终一致性的方案 

（3）最大努力通知方案 

跟可靠消息最终一致性方案是类似的，可靠消息最终一致性方案，会保证最终必须要让那个执行成功的，但是最大努力通知方案，不一定保证最终一定会成功，可能会失败，但是他会尽力给你去给你通知那个服务的执行 

比较适合那种不太核心一些服务调用的操作，比如说消息服务，充值好了以后发送短信，一般来说肯定是要发出去短信的，但是如果真的不小心发送失败了，发送短信失败了也无所谓的。。。 

可以一共最大努力通知方案

### 48_画图说明TCC分布式事务的具体技术方案以及几种变种方案的原理

12_TCC方案细节

![](C:\Users\zy199005\Desktop\中华石杉\images\java\06\0304801.png)  

**1、通用性TCC技术方案** 

其实所谓的TCC思想，画一张图来说，大致说起来就很简单，我们就用自己的流量充值中心来举个例子好了，你要是不考虑具体的技术实现的话，大概来说呢，相当于就是下面这样的思路： 

（1）主业务服务：相当于流量充值中心的服务，他就是TCC事务的主控服务，主要控制的服务，负责整个分布式事务的编排和管理，执行，回滚，都是他来控制

（2）从业务服务：相当于我们的资金服务、订单服务、积分服务、抽奖服务、流量券服务，主要就是提供了3个接口，try-confirm-cancel，try接口里是锁定资源，confirm是业务逻辑，cancel是回滚逻辑

（3）业务活动管理器：管理具体的分布式事务的状态，分布式事务中各个服务对应的子事务的状态，包括就是他会负责去触发各个从业务服务的confirm和cancel接口的执行和调用。。。 

（1）try阶段，资源的锁定，先冻结掉用户的账户资金，将一部分资金转出到冻结资金字段里去；可以创建一个充值订单，但是状态是“交易中”

（2）confirm阶段，就是将用户的冻结资金口减掉，转移到商户的账户里去；同时将充值订单的状态修改为“交易成功”；完成抽奖机会、积分、流量券的新增

（3）cancel阶段，try阶段任何一个服务有问题的话，那么就cancel掉，相当于是将冻结的资金还回去，将订单状态修改为“交易失败”；如果confirm阶段任何一个服务有问题的话，也是cancel掉，相当于是将商户账户里的资金还到用户账户里去，同时将订单的状态修改为“交易失败” 

有一张比较经典的图，就是主业务服务->数据库，然后几个从业务服务->数据库，接着主业务服务会访问业务活动管理器（有活动日志），主业务服务发起执行try，然后主业务服务通知业务活动管理器，业务活动管理器再通知各个从业务发起confirm或者是cancel操作，可以把这张图给体现一下 

这里主业务服务其实就是总控整套逻辑的，然后从业务服务就是干活儿的，业务活动管理器主要是记录整个分布式事务活动状态的，这个还是挺有必要的吧，这样保存分布式事务进行过程中的各种状态才可以啊，兄弟！ 

不然分布式事务临时终端了，你系统重启，谁知道你之前跑到哪一步了啊，哥儿们！ 

所以他会记录整个分布式事务的状态，分布式事务里各个服务代表的子事务的状态，而且他是负责在提交分布式事务的时候，调用各个从业务服务的confirm接口的，如果出问题的话也是他调用各个从业务服务的cancel接口的 

所以说这里的一个执行流程和步骤大概是这样子的： 

（1）主业务服务会先在本地开启一个本地事务（这个本地事务说白了，就是你的主业务服务是不是也可能会干点儿什么事儿）

（2）主业务服务向业务活动管理器申请启动一个分布式事务活动，主业务服务向业务活动管理器注册各个从业务活动

（3）接着主业务服务负责调用各个从业务服务的try接口

（4）如果所有从业务服务的try接口都调用成功的话，那么主业务服务就提交本地事务，然后通知业务活动管理器调用各个从业务服务的confirm接口

（5）如果有某个服务的try接口调用失败的话，那么主业务服务回滚本地事务，然后通知业务活动管理器调用各个从业务服务的cancel接口

（6）如果主业务服务触发了confirm操作，但是如果confirm过程中有失败，那么也会让业务活动管理器通知各个从业务服务cancel

（7）最后分布式事务结束 

**2、异步确保型TCC技术方案**

如果要接入到一个TCC分布式事务中来，从业务服务必须改造自己的接口，本来就是一个接口，现在要新增两个接口，try接口，cancel接口。改造起来比较麻烦 

这个大概来说就是把之前的通用型TCC方案给改造了一下，就是在主业务服务和从业务服务之间加了一个可靠消息服务，但是这个可靠消息服务可不是在请求什么MQ之类的东西，而是将消息放在数据库里的 

大致来说呢，就是主业务服务的try、confirm和canel操作都调用可靠消息服务，然后可靠消息服务在try阶段插入一条消息到本地数据库；接着主业务服务执行confirm操作，可靠消息服务就是根据之前的消息，调用从业务服务实际的业务接口；如果要是这个调用失败的话，那么主业务服务发起cancel，可靠消息服务删除自己本地的消息即可 

这种方案大家可以看到，其实说白了最大的优点，就是不需要从业务服务配合改造，提供try、confirm和cancel三个接口了，本来人家可能就一个接口，现在你楞是要求人家提供三个接口，真尴尬 

那要是用了这种方案，就可以用可靠消息服务替代各个从业务服务提供TCC三个接口了 

**3、补偿性TCC解决方案** 

这个其实是跟通用型的TCC方案类似的，只不过从业务服务就提供俩接口就ok了，Do和Compensate，就是执行接口和补偿接口，这种方案的好处就是折中一下了，不需要从业务服务改造出来一个T接口，就是锁定资源的接口，只需要加一个补偿接口，如果业务逻辑执行失败之后，进行补偿 

这样就可以少做一个接口了，但是因为没有做资源的一个锁定，那么大家需要自己注意类似资金转账的余额检查之类的事儿了，还有就是补偿的时候，因为你没做资源锁定，所以要注意一下补偿机制是否一定会成功 

其实说实话，这个补偿性的TCC方案还是蛮不错挺有吸引力的  

Do接口，Compensate接口，不要try接口，不要锁定资源，直接执行业务逻辑，如果有失败就调用Compensate接口，补偿接口，回滚刚才的操作

### 49_分析一下TCC分布式事务技术方案具体落地在项目中的一些细节

其实这个所谓TCC方案里有很多细节要考量一下啊！！！ 

**1、接口拆分问题** 

首先就是，从业务服务的每个接口都要拆分为三个接口，一个是try接口，一个是confirm接口，一个是cancel接口，也就是说要提供分布式事务实现的业务接口，自己就要考虑好这个，要提供3个接口 

虽然真是够麻烦的，不过也没办法 

try接口里，一般就是预留资源，比如说经典的资金转账，卡掉一些锁定资金，你要是不这么干，万一别的分布式事务给你干掉了一些资金，那你实际执行confirm的时候一旦检查资金余额就会发现转账失败，余额不足了 

有些接口，没有资源锁定的操作，try接口就留空 

confirm就是原来的业务方法，该干嘛干嘛 

cnacel接口，要提供回滚的方法，就是把try或者confirm里的操作给他回滚了 

就比如说，如果是try阶段，资金服务的try成功了，资金被冻结了24块钱，结果订单服务的try失败了，主业务服务就会通知回滚，调用资金服务的cancel接口，就要检查一下lock_amount字段里的值，将里面的24块钱转回到原来的amount字段里面去 

confirm阶段，资金服务，都把24块钱从id=1的账号里转移到id=2的账号里去了，lock_amount也扣减掉了24块钱。结果积分服务的confirm失败了，整个分布式事务回滚，调用各个接口的cancel接口 

资金服务，就变成了需要将id=2的账号的amount字段扣减掉24块钱，给id=1的账户增加24块钱 

**2、接口的几种特殊情况** 

（1）空回滚：那要是try阶段，比如网络问题，人家压根儿没调通你的try接口，结果就认定失败，直接调用你的cancel接口，咋办？所以你这个时候啥都不能干 

（2）try回滚以及confirm回滚：try阶段如果执行了，但是其他服务try失败了，那么会调用cancel来回滚，你要可以回滚掉try阶段的操作；confirm阶段要是你执行了，但是有别的服务失败了，此时你就要回滚掉confirm阶段的操作 

（3）倒置请求：比如说人家调用try接口，中间网络超时了，结果认定失败，直接调用cancel空回滚了；结果过了几秒钟try接口请求到来，此时咋整呢？尴尬了吧，你要在这个时候不允许执行try接口操作；同理啊，confirm请求超时了，结果都cancel掉了，但是过了几秒请求来了，让你confirm，你能干这事儿吗？ 

**3、接口的幂等性保证** 

你有没有考虑过一个问题，就是try、confirm和cancel都可能被多次调用，所以无论怎么样，你都得保证这几个接口的幂等性，分布式接口幂等性那必须依赖第三方的中间件来实现，可以考虑使用经典的zk，zk非常适用于分布式系统的协调类操作 

所以一个接口对同一个参数调用，只能调用一次，保证幂等操作 

**4、tcc分布式事务框架** 

我们的主业务服务那块，那必须得用tcc事务框架，不然各种接口调用，还有就是业务活动管理器，难不成都大家自己来写代码搞？？？？那就废掉了啊！所以必须要选用一种tcc分布式事务框架，来实现主业务服务的各种try confirm concel控制逻辑，同时实现业务活动的管理 

**5、总结** 

玩儿tcc初步来讲主要就是上述那些问题，其实说白了，一个就是从业务服务那块的接口的问题，还有一个其实就是主业务服务那块的业务活动管理器的控制，以及整个分布式事务的控制

### 50_对国内作者开源的几种热门的tcc分布式事务框架简单介绍一下 

**1、tcc-transaction框架** 

https://github.com/changmingxie/tcc-transaction 

看一个开源的项目是否热门，主要看什么呢，star，相当于粉丝，点赞，关注，一般来说热门的项目star比较多 

其实还行，国内开源的tcc框架里算是最热的了，因为github上star有2000多，但是有个问题，暂时而言，对spring cloud支持不好，所以一般建议还是选择跟你用的服务框架整合比较好的 

跟spring cloud整合的不是太好，但是提供了跟dubbo的整合，所以这次咱们就不用了，因为我们的基础的微服务技术栈主要还是spring cloud来实战，dubbo后面也会讲，不是现在，这个就过了 

**2、himly框架** 

https://github.com/yu199195/hmily 

这个其实还算不错，star有1000多，也算国内比较热门的tcc框架，而且对各种服务框架支持比较好，比如spring cloud，dubbo，等等 

这个框架我觉得还不错，唯一的一点，就是在他的官方文档里大量用的是spring xml来进行配置，这个就有点不好了，因为现在spring boot以后，基于spring的项目风格基本都是基于注解来驱动配置了 

**3、ByteTCC框架** 

https://github.com/liuyangming/ByteTCC 

这个框架其实也还行，github上的star跟himly是差不多的，也是1000多的star 

也还不错，而且对注解的支持比较彻底一些，所以我们考虑使用ByteTCC框架来结合spring cloud进行tcc事务的开发和控制，还支持saga事务，长事务 

看懂一个框架的源码之后，tcc类分布式事务框架的源码，就熟悉了，熟悉了之后的话呢，你就可以去哪怕以后你要用别的tcc分布式事务的框架，也没问题，你可以快速的看一下别的框架的源码 

**4、我自己在公司里分布式事务这块** 

分布式事务的框架，都是自己研发的，核心思想跟ByteTCC、tcc-transaction之类的框架，都差不多，但是肯定框架会围绕我们自己公司内部的开发环境来做

### 51_授人以鱼不如授人以渔（一）：动手跑一下ByteTCC框架的入门demo 

tcc事务开源框架，主要都是国内的几个哥儿们给开源的，那几个哥儿们的技术水平都还是不错的，那几个框架都不错，tcc-transaction主要问题没有对spring cloud提供原生的支持，himly很多地方用了xml格式的配置 

bytetcc框架，spring cloud有原生支持，而且基本都是spring boot风格的纯注解驱动的配置风格，我觉得也是比较不错的 

我们先花费个几讲的时间，快速来学习一下bytetcc框架的使用 

玩儿一下bytetcc框架的helloworld级别的demo，我们仿照他的spring cloud sample，里面的几个工程，eureka server，一个是服务的提供者，provider，另一个是服务的消费者，consumer，三个工程考别他里面的所有的内容，在本地来搭建一把 

我们会来尝试一下几种故障的场景下，try失败，confirm失败，cancel失败，分别都会发生什么事情，我们把常见的几种故障场景都来给大家尝试一下，测试一下这个框架的功能，ok，我们就来玩儿 

从这里其实也能看出来，人家做出来这个开源框架的哥儿们，技术水平肯定是不错的，但是里面肯定也是有一些不足的，如果以后我们也以架构班的名义，发布开源项目，刚开始也技术肯定是不错的，但是不足之处肯定也是有的 

你也可以直接从github上clone人家的工程到自己本地直接跑，但是我一般来说建议，helloworld级别的工程，最好是仿照人家的自己搭建一遍，pom.xml里依赖哪些东西，代码和包都自己手动玩儿一下 

try，冻结资金；confirm；cancel；通过他自己的一套注解的机制，都已经提供好了 

inst1作为hostname，放到本地电脑的配置文件里去，inst1和127.0.0.1配置起来配对 

之前还出过一个事儿，ByteTCC这个开源项目，spring cloud demo有个其他的兄弟去跑，都没跑起来，如果让各位同学自己玩儿，也不一定能靠自己跑起来 

稍微做一点总结，从代码层面来看，如果你要用bytetcc来实现tcc事务的话，有哪些地方不一样呢： 

（1）将对外发布的服务，直接相关的业务逻辑定义在controller里面，我们现在也是这样子来搞的，这里的方法加transactional注解

（2）这个controller里的方法相当于是try逻辑，锁定资源

（3）在controler要配置compensable注解，这个注解就指定了每个接口的confirm和cancel的逻辑，try-confirm-cancel配对组合好了

（4）bytetcc框架会负责在适当的时机来调用和执行try，然后自动去调用confirm和cancel，这里一大堆关于tcc事务的控制，都是人家框架自己搞定的  

1、转账的逻辑 

（1）try：provider服务里的扣款try接口（将资金冻结）；consumer服务里，增加资金，给自己的冻结资金进行增加；比如说从账户1里转账1000块钱到账户2里去：账户1，amount = 9000，frozen = 1000；账户2，amount = 10000，frozen = 1000 

（2）如果try成功了，肯定就会走这个connfirm，账户1，amount = 9000，frozen = 0；账户2，amount = 11000，frozen = 0 

（3）如果try失败了，假如说是账户2的try失败了，那么就会走这个cancel：账户1，amount = 10000，frozen = 0；账户2因为try失败了，所以账户2本身在try阶段就什么都没干，不需要走cancel的 

（4）如果try失败了，假如说是账户1的try失败了，那么账户1什么都没变，amount = 10000，frozen = 0；账户2已经变成amount = 10000，frozen = 1000，但是此时走cancel，此时frozen = 0 

（5）如果confirm失败了呢，账户2的confirm失败了，那么账户2还是停留在amount = 10000，frozen = 1000，此时账户2一定会走cancel，frozen = 0；账户1的confirm成功的，amount = 9000，frozen = 0，此时走cancel，amount = 10000，frozen = -1000 

我们看到这里，就会发现，tcc事务里面坑很多，细节很多，很多东西，需要我们去实践一下，实验，才可以验证这套bytetcc框架的功能，最后我们还要通过阅读这个框架的源码，具体的看看这个框架的作者对里面的很多东西实现的思路是什么 

如果能启动，然后如果访问一个接口，感觉转账的逻辑可以跑通，那么就算成功了 

demo已经跑通，下一讲，检验一下这个框架是否ok了，try阶段可能会出现失败；confirm也可能会出现失败；cancel也可能会出现失败

### 52_授人以鱼不如授人以渔（二）：测试一下try、confirm、cancel三个阶段的故障 

1、try阶段的故障 

（1）账号1的try操作失败了 

正常来说，账号1，amount = 9000，frozen = 1000；账号2，amount = 10000，frozen = 1000 

账号1的try失败了，账号1的try操作的本地事务，回滚，导致账号1，amount = 10000，frozen = 0 

账号2的try操作，压根儿就没机会去执行 

{

  "timestamp": 1534916667690,

  "status": 500,

  "error": "Internal Server Error",

  "exception": "feign.FeignException",

  "message": "status 500 reading IAccountService#decreaseAmount(String,double); content:\n{\"timestamp\":1534916667459,\"status\":500,\"error\":\"Internal Server Error\",\"exception\":\"java.lang.IllegalStateException\",\"message\":\"error\",\"path\":\"/decrease\"}",

  "path": "/simplified/transfer"

} 

此时资金都是正常的 

（2）账号2的try操作失败了 

正常来说，账号1，amount = 9000，frozen = 1000；账号2，amount = 10000，frozen = 1000 

如果账号1的try操作先成功了，账号1，amount = 9000，frozen = 1000；账号2的try操作失败了，所以此时将frozen = 1000的操作就会回滚，然后amount = 10000，frozen = 0 

此时bytetcc框架要自动感知到这个问题，然后将账号1执行cancel的逻辑，amount = 10000，frozen = 0 

此时资金都是正常的，根据日志可以判断出来接口的调用，跟我们分析的几乎是一样的 

（3）小结 

根据我们的分析，其实你用了这种tcc框架，try阶段失败，其实都没什么问题，try失败的那个本地事务回滚，所以什么都不会干；其他执行了try的服务，都会被调用对应的cancel接口，直接就可以回滚掉之前的try操作做出的数据的变更 

2、confirm阶段的故障 

正常来说，try阶段结束后，账号1，amount = 9000，frozen = 1000；账号2，amount = 10000，frozen = 1000 

正常来说，执行confirm阶段后，账号1，amount = 9000，frozen = 0；账号2，amount = 11000，frozen = 0 

（1）如果账号1的confirm失败了 

账号1，停留在try的那个阶段的数据，amount = 9000，frozen = 1000；账号2的confirm成功了，此时账号2变成amount = 11000，frozen = 0 

如果去执行账号1的cancel操作，amount = 10000，frozen = 0；去执行了账号2的cancel操作，不可能变成amount = 11000，frozen = -1000；我们推测，账号1的confirm失败了，报错了，此时就根本不会去执行后面的账号2的confirm操作了 

账号1会停留在，amount = 9000，frozen = 1000；账号2，也是停留在，amount = 10000，frozen = 1000；然后分别对账号1和账号2执行cancel的操作，就会还原成，amount = 10000，frozen = 0；账号2，amount = 10000，frozen = 0 

推测的失误了！！！ 

账号1，amount = 9000，frozen = 1000；账号2，amount = 11000，frozen = 0 

很明显的发现，bytetcc框架，并没有根据识别到的账号1的confirm的失败，来执行对应的cancel回滚的操作 

这个场景下，测试失败，导致我们的数据已经不正常了 

相当于是，账号1的confirm失败了；账号2的confirm成功了 

bytetcc事务框架他的一个概念，实际上来说，就是会采用一个策略，不停的重试，已经重试了16次 

如果try阶段有人失败了，那么绝对没问题，针对已经执行try成功的，可以通过cancel来进行回滚；try失败的，本地事务自己就会回滚；数据100%是一致的 

如果confirm阶段有人失败了，那么别人都会confirm成功，但是有少数服务confirm失败的，此时bytetcc框架，就会不停的重试调用那个服务的confirm操作，直到他执行成功为止 

（2）如果账号2的confirm操作失败了 

账号1的confirm操作是成功的，amount = 9000，frozen = 0；账号2，amount = 10000，frozen = 1000 

此时按照bytetcc框架的一个逻辑，肯定也是会账号1就那样放着吧，账号2会被不断的调用和重试，直到确保账号2的confirm操作成功 

3、总结一下 

在bytetcc框架的逻辑里面，try-confirm-cancel，走的是try和cancel是配对的，try阶段成功了以后如果要回滚，可以通过cancel来进行回滚；但是confirm，如果有失败的，那不好意思，人家默认的一个策略，就是让别人confirm成功好了，你的confirm会被bytetcc后台框架不停的重试和调用 

其实可能有些同学会想，confirm如果失败了，不能去cancel回滚呢？ 

try、confirm是不一样的，如果你用一个cancel来回滚try和confirm的话，那是不行的，所以bytetcc框架的逻辑，try和cancel配对，执行好的try一定可以用cancel来回滚，confirm如果失败了，是不会通过cancel来回滚，人家默认就是不停的重试和调用 

4、分析一下 

bytetcc框架的设计的哲学，理念，try阶段很有可能会出现失败，如果失败需要对所有服务进行回滚，try-cancel配对，他是绝对可以做到的；然后如果try阶段都成功了，confirm有服务失败了，那么confirm只要不停的重试一定是可以成功的，就可以保证数据的一致性，作者肯定是默认confirm阶段如果失败可能一般都是网络调用超时、或者数据库不小心压力过大拒绝反问 

他就是让失败的confirm操作不断的重试，直到成功为止 

我们重启了provider之后，consumer里的bytetcc框架其实还是在不停的调用和重试，但是一旦重试调用成功了之后，那么他就ok了，数据也一致了，他也不会继续重试和调用了，是不是这么回事

### 53_授人以鱼不如授人以渔（三）：将demo改造为我们的spring cloud版本 

人家的demo用的都是自己的那一套spring cloud的一些版本，但是我们需要将那套spring cloud版本改造我们的，来试一下，用我们的spring cloud + spring boot的版本，结合上bytetcc框架的引入，能否成功的使用 

在这里可以看到，在账号1的扣款的接口的时候，有timeout的问题，报错了，整个就没执行成功

### 54_授人以鱼不如授人以渔（四）：带着大家通读一下ByteTCC的使用文档 

带着大家快速的通读一下人家bytetcc框架的使用文档 

告诉你，人家有哪些功能可以用 

你如果要在你的系统里使用人家的框架，就按照demo来做可以了 

咱们在上一讲还没意识到这个东西，这个表确实还没建立，如果你要用他来玩儿tcc的话，必须得专门在数据库里，都要建立一张表，专门给bytetcc框架自己来用的 

业务活动管理器，其实就是bytetcc框架，负责调用confirm和cancel接口 

bytetcc框架还要负责管理活动日志，这个活动日志其实就是可以记录在本地的数据库中，比如说每个库里都可以创建一张bytejta表，在刚刚短短的一瞬间，看到每个分布式事务，都会对应着由bytetcc框架在参与分布式事务的各个库中插入对应的一些事务日志、记录一样的东西 

然后分布式事务成功结束之后，也同时会自动清理掉这些数据 

发现的很彻底了，全局事务决定提交时，try接口全部成功了，进入confirm阶段的时候，会保证所有服务的confirm接口必须成功调用， 

像这种bytetcc开源框架，如果你不读一读人家的源码，看看人家具体的实现细节和逻辑是什么，那么其实来说的话呢，就是一般也不太敢放心在生产系统里使用 

TCC模式，定义 

try -> confirm / cancel 

try -> cancel

try -> confirm

try -> confirm -> cancel（不是bytetcc采用的理念和思想） 

cancel接口的回滚逻辑都是针对的是try阶段的 

try如果有人失败了，就走cancel来回滚，cancel如果有失败也会不停的重试的；如果try都成功了，就一定要执行confirm，人家会给你不停的重试confirm 

涉及到一些事务的通信，和事务状态的一些传播，所以负载均衡的算法，跟以前我们学到的robin轮询是不太一样的，我们后面可以给大家讲源码的时候再细说

### 55_授人以鱼不如授人以渔（五）：研究一下ByteTCC作者自己给出的底层原理

如果你的系统宕机了，事务执行到了一半，但是没关系，人家都把事务执行的日志和状态都记录在数据库中了，所以说你的系统重启，人家就会自动读取事务执行，将没有完成的事务继续给执行 

我们从最初的最原始的spring事务源码开始看，就看到了TransactionManager的源码；然后呢看到Atomikos框架做XA分布式事务的源码，也是基于TransactionManager来实现的；玩儿到了TCC分布式事务的源码，看到也是基于TransactionManager来实现的

### 56_授人以鱼不如授人以渔（六）：注意查看ByteTCC的常见提问与回答 

新技术的顺序，跑demo，玩儿源码，通读一遍文档，然后你对这个技术的掌握可以说就是相当不错了 

接着就是将技术运用到项目里去玩儿

### 57_结合ByteTCC的demo梳理一下如何引入流量充值中心里

我们基本上把ByteTCC这个tcc分布式事务框架，怎么用demo基本上已经做通了；官网里面大致过了一遍他的一些文档，但是发现他的这个文档，授人以鱼不如授人以渔，带着大家去体验一下，做完一个demo而已，看他的这个文档，有点看不懂 

看他的文档，让我讲，我都讲不清楚 

做完一个demo之后，先仿照这个demo，讲bytetcc框架引入到流量充值中心里去，解决多个服务调用的分布式事务的问题，tcc来解决多个服务的调用的分布式事务 

对这个框架，对这个技术都体验的差不多了，然后我们就来尝试把bytetcc的一些核心的源码来看一下，这种开源框架很多很多，如果atomikos、bytetcc各种框架都给你分析源码到100%，每个小框架都花几十个小时来分析源码，课程是不可以接收的 

意义也不是很大 

一般来说，你只要看通核心的一点源码，明白他比较底层的机制和原理就ok了 

tvb一部港片，巾帼英雄，人生有几个10年，人生有多少青春 

程序员的时间是非常宝贵的，不太可能说吧各种乱七八糟的小框架，源码研究的特别特别的透彻，作为一个靠谱的工程师，把你用到的框架的核心源码，10%~20%，一般来说<40%的源码，看一下就ok了 

看一下核心源码，了解一下开源技术的底层原理 

**1、服务提供者如何改造** 

（1）pom.xml 

<dependency>

​               <groupId>org.bytesoft</groupId>

​               <artifactId>bytetcc-supports-springcloud</artifactId>

​               <version>0.4.17</version>

​               <exclusions>

​                    <exclusion>

​                         <groupId>asm</groupId>

​                         <artifactId>asm</artifactId>

​                    </exclusion>

​               </exclusions>

​          </dependency> 

<dependency>

​               <groupId>org.springframework</groupId>

​               <artifactId>spring-core</artifactId>

​          </dependency> 

<dependency>

​               <groupId>org.aspectj</groupId>

​               <artifactId>aspectjweaver</artifactId>

​          </dependency> 

<dependency>

​               <groupId>org.apache.commons</groupId>

​               <artifactId>commons-dbcp2</artifactId>

​          </dependency> 

（2）配置文件 

几乎不用修改 

（3）数据库表 

对每个他操作的数据库，你都要去专门搞一个表 

CREATE TABLE `bytejta` (

 `xid` VARCHAR(32) NOT NULL,

 `gxid` VARCHAR(40) DEFAULT NULL,

 `bxid` VARCHAR(40) DEFAULT NULL,

 `ctime` BIGINT(20) DEFAULT NULL,

 PRIMARY KEY (`xid`)

) ENGINE=INNODB DEFAULT CHARSET=utf8 

（4）日志文件 

他其实通过文件和数据库，都会记录分布式事务执行过程中的一些日志或者记录，状态，进度，这些东西其实是用来在分布式事务执行到一半，服务挂了，服务重启，需要根据之前记录的日志和数据库里的记录，恢复这个分布式事务，继续执行 

（5）数据源配置config 

@Import(SpringCloudConfiguration.class) 

相当于是导入了bytetcc框架为了整合spring cloud他自己的一个SpringCloudConfiguration，里面肯定会配置一大堆bytetcc框架实现的spring cloud相关的组件 

@Bean(name = "dataSource") 

这个是给DataSource起一个固定的名字，有没有作用，现在看不出来，但是难保人家会用这个名字去获取DataSource bean 

LocalXADataSource dataSource = new LocalXADataSource(); 

LocalXADataSource，其实是bytetcc框架自己封装的一个东西，一看就是对数据源做了一层包装，这样的话呢在执行SQL语句的时候，这个bytetcc可以做一些事情，比如说根据SQL的执行去记录一些数据库里的状态 

我们其实从这个框架的引入中，都可以发现一些端倪，bytetecc这种框架如果要实现一整天的分布式事务，肯定会侵入到哪几个点去实现自己的组件呢？ 

1）spring cloud的feign、ribbon相关的组件，很有可能会被人家做一些定制化，从@import导入一个SpringCloudConfiguration，一看就是人家框架自定义了一些spring cloud的一些组件 

2）DataSource肯定被包装了，LocalXaDataSource，这块就可以让人家感知到我们在分布式事务里各个地方做的一些SQL操作 

3）TransactionManager，屁股想想，肯定会是bytetcc自己实现了一些TransactionManager相关的东西，所以@Transactional注解启动的事务都是bytetcc在管理 

（6）改造服务接口 

在服务Controller上一般要加一个注解 

@Compensable(interfaceClass = AccountAmountApi.class, 

​                    confirmableKey = "accountAmountConfirmService", 

​                    cancellableKey = "accountAmountCancelService") 

在这个controller中的接口，其实就是try接口，负责锁定资源，或者尝试预分配一些资源，预处理，如果能正常执行的话，那么后面应该就是可以正常进行confirm的 

在这个controller中的每个接口的方法，都需要加一个@Transactional注解，这个是人家强制要求的，规约 

然后呢就是基于这个接口，再实现2个service bean，confirm bean和cancel bean，都实现了同一个接口，然后在里面实现confirm和cancel的逻辑 

cancel，就是说如果try失败了，要用cancel来回滚；如果try成功了，要用confirm来完成操作；如果cancel或者是confirm失败了，那么就会被bytetcc框架不停的重试调用，直到你执行成功为止 

（7）改造main类

@ImportResource({ "classpath:bytetcc-supports-springcloud.xml" })  

**2、服务消费者如何改造** 

（1）pom.xml 

<dependency>

​               <groupId>org.bytesoft</groupId>

​               <artifactId>bytetcc-supports-springcloud</artifactId>

​               <version>0.4.17</version>

​               <exclusions>

​                    <exclusion>

​                         <groupId>asm</groupId>

​                         <artifactId>asm</artifactId>

​                    </exclusion>

​               </exclusions>

​          </dependency> 

<dependency>

​               <groupId>org.springframework</groupId>

​               <artifactId>spring-core</artifactId>

​          </dependency> 

​          <dependency>

​               <groupId>org.springframework.cloud</groupId>

​               <artifactId>spring-cloud-starter-hystrix-dashboard</artifactId>

​          </dependency> 

<dependency>

​               <groupId>org.apache.httpcomponents</groupId>

​               <artifactId>httpclient</artifactId>

​          </dependency> 

<dependency>

​               <groupId>org.apache.commons</groupId>

​               <artifactId>commons-dbcp2</artifactId>

​          </dependency> 

（2）配置文件 

（3）数据库表 

CREATE TABLE `bytejta` (
  `xid` varchar(32) NOT NULL,
  `gxid` varchar(40) DEFAULT NULL,
  `bxid` varchar(40) DEFAULT NULL,
  `ctime` bigint(20) DEFAULT NULL,
  PRIMARY KEY (`xid`)
 ) ENGINE=InnoDB DEFAULT CHARSET=utf8 

（4）数据源配置bean 

@Import(SpringCloudConfiguration.class) 

@Bean(name = "mybatisDataSource") 

LocalXADataSource dataSource = new LocalXADataSource(); 

（5）接口调用改造 

controller上也要加一个注解 

@Compensable(interfaceClass = ITransferService.class, confirmableKey = "transferServiceConfirm", cancellableKey = "transferServiceCancel") 

接口方法：@Transactional 

在接口里，可能会执行本地数据库操作，也会同时基于feign调用远程的其他服务 

此时本地数据库操作以及feign调用远程服务，就被包裹在一个分布式tcc事务里了，这个时候就会由bytetcc框架来托管管理这个事务的一个执行 

1）本地的controller里面的接口，其实就是属于try接口，调用的其他服务的feign接口，也是try接口，无论有多少个其他的服务，都会去依次调用try接口 

2）如果某个服务的try失败了，就会调用之前try成功的那些服务的cancel接扩来回滚，那个try失败的不用管他 

3）如果所有服务的try成功了，那么就会依次执行本地和远程其他各个服务的confirm接口，来完成分布式事务操作 

在本地需要实现confirm接口和cancel接口 

（6）改造main类 

@ImportResource({ "classpath:bytetcc-supports-springcloud.xml" }) 

### 58_流量充值中心重构（一）：在资金服务中引入TCC分布式事务

tcc分布式事务 

（1）资金服务：转账

（2）订单服务：创建充值订单

（3）抽奖服务：增加抽奖机会

（4）积分服务：增加积分

（5）流量券服务：使用流量券，赠送流量券 

要把这5个服务，依次给重构成基于bytetcc的一种模式，也就是说每个接口都要拆分成try、confirm、cancel三个接口 

资金服务来重构一下 

try接口，应该是什么样的逻辑呢，一般来说都是那种锁定资源，或者是预分配资源 

我们可以在表里加一个字段，冻结资金字段，对于用户的账号，将资金扣减，然后将钱转入到冻结字段里去；对商户的账号，直接在冻结字段里加入一笔资金 

如果try都成功了，就进行confirm，完成最终的转账

### 59_流量充值中心重构（二）：在订单服务中引入TCC分布式事务 

订单服务： 

（1）try：新建一个订单，状态设置为“交易中”

（2）confirm：修改订单的状态为“交易成功”

（3）cancel：修改订单的状态为“交易失败” 

bytetcc是支持try-confirm-cancel几个阶段的变量的传递的 

try里面是新建了一个订单，会产生一个order的自增长的id，我们需要将这个id传递给confirm或者是cancel的阶段 

我们在confirm的时候，才可以拿到这个order的id，然后将订单的状态进行修改

### 60_流量充值中心重构（三）：在抽奖服务中引入TCC分布式事务

抽奖服务改造成tcc模式 

（1）try：锁定资源，预分配资源，你可以这样子，给抽奖表加一个锁定抽奖次数字段，给冻结抽奖次数的字段增加1

（2）confirm：将锁定抽奖次数字段减去1，给正式的抽奖次数字段增加1

（3）cancel：将锁定抽奖次数字段给减去1

### 61_流量充值中心重构（四）：在积分服务中引入TCC分布式事务 

积分服务的tcc事务： 

（1）try：可以搞一个锁定积分字段，在锁定积分字段里先增加一些积分

（2）confirm：扣减掉锁定积分字段的积分，然后给正式的积分字段增加一些积分

（3）cancel：扣减掉锁定积分字段里的积分

### 62_流量充值中心重构（五）：在流量券服务中引入TCC分布式事务  

使用流量券 

（1）try：他这个业务操作其实非常的简单，只是修改这么一个状态，你可以设计一个中间的这么一个状态，比如说“修改中”，-1

（2）confirm：正式给修改成2，“已使用”

（3）cancel：修改成1，“未使用” 

流量券的状态：-1（修改中），0（不可用），1（可用，但是未使用），2（已使用） 

赠送流量券 

（1）try：新建一个流量券，但是状态是0，不可用

（2）confirm：状态修改为1，未使用

（3）cancel：删除这个赠送的流量券 

具体结合你的业务要求来，try的时候，就是预分配或者锁定一些资源，做一些跟正式操作类似的操作，确保说，如果你的try可以成功，那么confirm基本上也可以成功

### 63_流量充值中心重构（六）：为流量充值总控服务引入TCC分布式事务

### 64_基于TCC分布式事务控制下跑通正常运行的流量充值流程 

**1、问题1：循环依赖**

***************************

APPLICATION FAILED TO START

***************************

Description: 

The dependencies of some of the beans in the application context form a cycle: 

┌─────┐

| org.springframework.boot.autoconfigure.orm.jpa.HibernateJpaAutoConfiguration

↑   ↓

| dataSource

└─────┘ 

这儿会有一个循环依赖的问题 

在main类上加入： 

@ImportResource({ "classpath:bytetcc-supports-springcloud.xml" })  

**2、问题2：spring mvc重复映射** 

Caused by: java.lang.IllegalStateException: Ambiguous mapping. Cannot map 'couponCancelService' method 

public void com.zhss.data.refill.center.service.CouponCancelService.insert(com.zhss.data.refill.center.domain.Coupon)

to {[/coupon/],methods=[POST]}: There is already 'couponService' bean method

public void com.zhss.data.refill.center.api.CouponService.insert(com.zhss.data.refill.center.domain.Coupon) mapped.

​     at org.springframework.web.servlet.handler.AbstractHandlerMethodMapping$MappingRegistry.assertUniqueMethodMapping(AbstractHandlerMethodMapping.java:576) ~[spring-webmvc-4.3.13.RELEASE.jar:4.3.13.RELEASE]

​     at org.springframework.web.servlet.handler.AbstractHandlerMethodMapping$MappingRegistry.register(AbstractHandlerMethodMapping.java:540) ~[spring-webmvc-4.3.13.RELEASE.jar:4.3.13.RELEASE]

​     at org.springframework.web.servlet.handler.AbstractHandlerMethodMapping.registerHandlerMethod(AbstractHandlerMethodMapping.java:264) ~[spring-webmvc-4.3.13.RELEASE.jar:4.3.13.RELEASE]

​     at org.springframework.web.servlet.handler.AbstractHandlerMethodMapping.detectHandlerMethods(AbstractHandlerMethodMapping.java:250) ~[spring-webmvc-4.3.13.RELEASE.jar:4.3.13.RELEASE]

​     at org.springframework.web.servlet.handler.AbstractHandlerMethodMapping.initHandlerMethods(AbstractHandlerMethodMapping.java:214) ~[spring-webmvc-4.3.13.RELEASE.jar:4.3.13.RELEASE]

​     at org.springframework.web.servlet.handler.AbstractHandlerMethodMapping.afterPropertiesSet(AbstractHandlerMethodMapping.java:184) ~[spring-webmvc-4.3.13.RELEASE.jar:4.3.13.RELEASE]

​     at org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping.afterPropertiesSet(RequestMappingHandlerMapping.java:127) ~[spring-webmvc-4.3.13.RELEASE.jar:4.3.13.RELEASE]

​     at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.invokeInitMethods(AbstractAutowireCapableBeanFactory.java:1687) ~[spring-beans-4.3.13.RELEASE.jar:4.3.13.RELEASE]

​     at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.initializeBean(AbstractAutowireCapableBeanFactory.java:1624) ~[spring-beans-4.3.13.RELEASE.jar:4.3.13.RELEASE]

​     ... 21 common frames omitted 

这个是因为一个controller以及2个service都是实现了同一个接口，按个接口里有@RequestMapping的，这不就是重复映射了么，所以说，要把两个service的@RequestMapping给改一下就好了 

**3、小问题：写错了一些配置** 

**4、重构了一下总控服务** 

正常的运行流程下，数据都是对的，try -> confirm的分支 

**5、尝试一下让某个服务报错** ，看看分布式tcc事务能否回滚** 

try -> cancel 

### 65_关于通过研究源码来解决遇到的tcc事务无法生效问题的说明 

已经初步成功的将bytetcc框架整合到了我们使用的spring cloud技术栈里面去了，我们可以初步的将正常的流程给跑通，try -> confirm，我后来又调整了一下代码 

现在有这么一个问题，就是说明明多个服务已经构成了一个tcc分布式事务了，结果呢，你却会发现，抽奖服务报错了，我们期望的是其他的服务可以调用cancel接口回滚，结果不是，还是正常的去运行了confirm接口提交了 

完全失去了tcc分布式事务的意义了 

这个问题不太好排查，我觉得正好以这个问题，tcc事务不生效的问题，作为一个引子，bytetcc框架遇到了一个问题，我们开始直接来探索bytetcc框架的核心源码，调试一下这个源码，来分析一下，为什么try阶段，明明有个服务报错了 

bytetcc实际上也感知到了这个报错了，结果bytetcc却没有去回滚整个这个事务呢？ 

借助研究源码，来解决这个问题，这样子来讲课，对大家的技术的提高特别的有好处，分析源码，通过源码来解决问题 

我把目前为止的代码，给到大家，放在这一课的文件夹，把我的代码自己部署跑一下，复现一下这个问题，然后针对这个问题，我们开始一步一步探索源码，来解决这个问题

### 66_先来大胆的猜测一下tcc分布式事务框架的实现原理以及画图说明

13_猜测的tcc事务框架的实现原理

![](C:\Users\zy199005\Desktop\中华石杉\images\java\06\0306601.png)        

这一讲，咱们还是老规矩，不要来上来就直接调试源码，先来一张大的图 

我先不从源码的角度出发，我就是直接拍屁股来猜想一下，这个bytetcc框架的实现原理 

我们已经用过这个框架了，我们也知道他的核心的功能，try -> confirm/cancel

### 67_分析一下tcc事务框架的核心源码主要在哪里以及哪些地方引入 

这一讲我们开始来分析bytetcc框架的源码 

我可以跟大家说一下，如果一般你要分析一个开源框架的源码，首先就是看看你是怎么用这个框架的，比如说服务里面 

（1）LocalXADataSource，bytecc框架的，来封装了一下底层的数据源

（2）@Compensable注解，以及tcc三个接口

（3）@Import(SpringCloudConfiguration.class)

（4）@ImportResource({ "classpath:bytetcc-supports-springcloud.xml" })  

LocalXADataSource，封装底层的数据源，我认为他主要是要捕获到在一个分布式事务中，到底对哪些数据库执行了哪些SQL操作呢 

在分布式事务中操作的各个库，都要创建一个他的bytejta的表，LocalXADataSource主要是看到分布式事务中执行的各个SQL语句，记录一下状态，插入一些自己的数据到底层的各个库的bytejta表中，记录分布式事务的状态 

@Compensable，我们大概可以想象到，tcc（try、confirm、cancel），三个接口，这个注解也不是核心的入口，他就是将每个接口定义成tcc三个接口 

@Import和@ImportResource里面一定是搞了一大堆bytetcc自己的一些bean以及组件，在系统启动的时候这里的bean和组件就会开始工作，比如说，在服务里，你既然加了@Compensable注解之后，肯定得有组件去扫描和识别这个注解，然后将每个接口封装成tcc三个接口 

bytetcc-supports-springcloud-0.4.17.jar 

**org.bytesoft.bytetcc.supports.springcloud.config.SpringCloudConfiguration** 

CompensableFeignBeanPostProcessor，实现了一个BeanPostProcessor接口，就是说他是要对每个bean在实例化好了之后来处理一下每个bean，他是专门处理feign里面的FeignInvocationHandler这个bean的 

你可以认为说，他其实针对feign的一个bean，创建了一个自己的动态代理，然后自己的动态代理就可以去拦截spring cloud底层对feign的一些执行和机制，他可以在你执行feign进行接口调用的时候，干一些事情 

如果是使用了hystrix之后，他也会拦截hytrixInvocationHandler这个bean，他创建了自己的动态代理来拦截对这个相关的bean的调用 

在这个所谓的SpringCloudConfiguration里面，他其实是对spring cloud原生的一些组件，比如说feign执行过程中涉及到的一些bean组件创建了自己的动态代理以及拦截器什么的，这样的话，就可以在spring cloud进行服务调用的时候，进行一些自己的特殊的处理 

正式开始调试源码的时候，就可以在这些核心的地方加一些断点，分析一下，看看，就ok了，之前我们研究spring cloud源码有多么的重要 

他很可能是在spring cloud服务调用的时候，干了很多的事情，比如说传递分布式事务的上下文 

**org.bytesoft.bytetcc.supports.spring.TransactionConfigPostProcessor** 

在一大堆的xml中配置了一大堆的bean，我们如果一个一个bean去打断点，也不太现实，最好还是找到一些核心的一些东西，或者是，我们如果在视频里一点点找这个bean，打断点，最好还是思路已经给大家演示了 

跟我一样，看看对应的xml，在里面核心的一些bean里打上一些断点，跟着我后面的视频看得了，我会在结束视频之后，自己给核心的一些bean里都打上断点

### 68_重启服务来探查一下在服务启动的时候tcc事务框架会干哪些事儿（一）

14_bytetcc框架的源码架构

![](C:\Users\zy199005\Desktop\中华石杉\images\java\06\0306801.png)    

上一讲基本上来分析了一下bytetcc框架的一些核心源码，还是比较复杂的，你别看bytetcc框架是那种很不知名的这么一个国产的一个框架，你如果后面跟着我把这个框架好好的去看一下的话 

其实这个bytetcc一个分布式事务框架，源码就完全不比spring cloud简单 

spring cloud源码：eureka、feign、ribbon、hystrix、zuul，核心几个源码就是这几个，除了eureka还相对复杂一些，其他的几个都还好 

bytetcc框架也还是比较复杂的 

看这块的源码，我已经自己给bytetcc他的很多核心的源码，打上了大量的断点，现在的话，这一讲，我们可以先来看一下，比如说流量券服务，他启动的时候bytetcc框架会去干些什么事情呢 

FeignClientFactoryBean，如果不是这个bean，就continue掉，这段代码没干什么，忽略，属于不需要仔细看的源码 

org.springframework.transaction.interceptor.TransactionInterceptor，是我们之前给大家讲解过的，就是如果你给某个方法加了一个@Transactional注解的话，就一定会先去执行这个TransactionInterceptor拦截器 

在这个拦截器中启动一个事务，执行实际的业务逻辑方法，提交/回滚事务 

TransactionManager。。。 

这段代码，感觉也没干什么关键的一些事情 

研究源码也好，我们去针对源码做笔记，画图也好，其实非核心的源码都不用太过于留意，看了一个开源框架的源码，20万行代码，10万行代码，多则大几十万行代码，尤其是一些比如说大数据领域的hadoop，上百万行源码 

主要就是关注核心的点，非核心的一些点无所谓，太过于顾及他 

CompensableAnnotationValidator，遇到了一个核心，验证了我们之前的一个设想，就是在一个服务启动的时候，bytetcc肯定会有一个组件，会去扫描所有的spring bean，尝试获取spring bean上是否加了@Compensable注解 

@Compensable注解是定义了tcc三个接口的核心注解 

ManagedConnectionFactoryPostProcessor 

扫描到了我们自己创建的一个LocalXADataSource，然后的话呢针对这个LocalXADataSource，他创建了一个动态代理，动态代理的InvocationHandler是ManagedConnectionFactoryHandler，所以我们就知道了，后续如果代码找LocalXADataSource的时候，其实会找到对应的这个动态代理 

到这里为止，初步来说，主要是执行了SpringCloudConfiguration以及那堆xml里配置的一堆bean，干的事情，比较核心的是两个，一个是扫描了@Compensable注解的类，还有一个是针对LocalXADataSource创建了一个动态代理 

其他的都是一些比较琐碎的一些处理性的工作 

好像是在启动一些后台运行/定时运行的任务，task，work

### 69_重启服务来探查一下在服务启动的时候tcc事务框架会干哪些事儿（二）

14_bytetcc框架的源码架构(1)

![](C:\Users\zy199005\Desktop\中华石杉\images\java\06\0306901.png)  

ResourceAdapterImpl 

TransactionRecovery compensableRecovery = this.beanFactory.getCompensableRecovery(); 

在服务启动的时候，bytetcc框架会通过后台线程启动一个task，CompensableWork，这个里面会启动一个事务恢复的这么一个过程，如果一个事务执行到了一半儿，然后这个系统就崩溃了 

系统重启的时候，一定会有一个事务恢复的过程，也就是说从数据库、日志文件里加载出来没完成的事务的状态，然后继续去执行这个事务，自己去研究一下人家的事务恢复是怎么来做的 

CompensableCoordinatorController，这个controller里面对外暴露了一些接口，其实我们可以想象一下，prepare、commit、rollback、forget、recover，分别对应着事务的try，事务的confirm，事务的rollback，事务的forget忽略，事务的恢复 

我们进一步大胆的猜测一下，很可能是不是说，流量充值服务在启动了一个分布式事务之后，然后我们各个接口进行调用的时候，不是用的那个spring cloud的feign，然后人家框架对spring cloud feign尤其特别做了很多的扩展、拦截器、动态代理 

spring cloud feign在进行调用的时候，人家完全重写了一些逻辑，比如说你请求的是某个接口，结果人家给重新定位到了请求那个服务的CompensableCoordinatorController，来进行某个接口的try、confirm、cancel

### 70_重启服务来探查一下在服务启动的时候tcc事务框架会干哪些事儿（三）

14_bytetcc框架的源码架构(2)

![](C:\Users\zy199005\Desktop\中华石杉\images\java\06\0307001.png)   

流量充值服务在启动的时候跟我们之前想的就有点不太一样了，在这个服务里有@FeignClient，我们可以看到的，bytetcc框架针对spring cloud的支持，他其实是大量的扩展和拦截了spring cloud原生的feign的行为 

feign.ReflectiveFeign$FeignInvocationHandler 

这个东西不就是feign针对@FeignClient接口创建的feign动态代理么，就是这个动态代理的InvocationHandler，所有的方法调用都会走这个InvocationHandler作为一个入口 

CompensableFeignBeanPostProcessor 

这个组件，是bytetcc框架的一个组件，一看就是对feign动态代理的FeignInvocationHandler在进行处理，写这个bytetcc框架的作者技术水平还是相当好的，不要看人家开发了一个开源框架 

如果要让自己的开源框架跟比如最新的流行的spring cloud来进行整合，他必须精读spring cloud的核心组件的源码，他必须精读feign的源码，然后才能针对feign进行一个扩展 

CompensableFeignHandler，bytetcc自己搞了一个CompensableFeignHandler来封装了这个feign自己原生的InvocationHandler，这样的话，所有对@FeignClient接口的调用，首先都会走到bytetcc里面去 

你的某个服务是服务的调用方，就是说你定义了@FeignClient去调用别的服务，非常核心的一点，就是说bytetcc框架自己搞了一个CompensableFeignHandler会去拦截所有对feign client的一个调用

### 71_先来看看tcc事务框架是如何启动一个tcc分布式事务以及xid是啥

14_bytetcc框架的源码架构(3)

![](C:\Users\zy199005\Desktop\中华石杉\images\java\06\0307101.png) 

我们可以来试一下，就是 发送一个请求，看看bytetcc框架在干些什么事情 

你只要加了这个@Transactional注解，就可以看到TransactionInterceptor的东西就会运行，他会拦截掉这个请求，这个东西会走一套流程： 

（1）begin，启动一个事务 => TransactionManager

（2）执行目标方法内部的业务逻辑

（3）根据目标方法执行的结果，是否成功，或者是报错，来选择commit / rollback => TransactionManager 

tcc事务框架启动一个tcc分布式事务的话，肯定是走TransactionManager的begin()方法，就会启动一个分布式的事务 

CompensableHandlerInterceptor，他是迎接一个http请求的第一道防线，他是一个interceptor，拦截器，他的本质跟TransactionInterceptor是一样的，就是在一个请求过来的时候，一定会先拦截掉 

CompensableMethodInterceptor，获取到了目标controller方法的@Transactional注解，还获取到了目标contorller的@Compensable注解，simplified模式，在当前的类中，就会有@CompensableConfirm和@CompensableCancel 

CompensableInvocation，封装了本次调用的一些信息，比如说目标的controller，目标的方法，目标的@Compensable注解等等一些信息 

​          if (transaction != null) {

​               compensableManager.begin();

​          } else if (invocation != null) {

​               compensableManager.compensableBegin();

​          } else {

​               transactionManager.begin();

​          } 

即使你引入了这个bytetcc框架，他的TransactionManagerImpl其实也是完全可以处理那种普通的事务的 

compensableXid：8127-0a00270000110000016589ede49a0001bdb0b38b-

transactionXid： 

1207-0a00270000110000016589ede49a0001bdb0b38b- 

branchXid： 

1207-0a00270000110000016589ede49a0001bdb0b38b-0a00270000110000016589f5d04b0002ea6ef329 

TransactionContext：分布式事务上下文 

CompensableTransactionImpl：相当于是代表了一个分布式事务的对象

TransactionImpl：也是代表了一个分布式事务的对象 

compensable transaction begin! 

tcc事务，就是一个compensable事务，可补偿的事务，tcc事务已经启动了

### 72_研究一把tcc框架对feign动态代理封装了哪些特殊的处理业务逻辑

14_bytetcc框架的源码架构(4)

![](C:\Users\zy199005\Desktop\中华石杉\images\java\06\0307201.png)  

在这里，他基于feign发起一个请求的时候，不出意外的话，应该是重构了一下ribbon的负载均衡算法 

流量充值服务，请求资金服务，资金服务其实部署了5台机器，有5个服务实例 

流量充值服务要保证一点，就是如果某个try请求走的是资金服务的实例01，那么后面再对资金服务执行confirm或者cancel的时候，肯定还是要请求那个资金服务的实例01，否则如果你的confirm请求了资金服务的实例02，可能会出问题 

正常的ribbon的负载均衡算法，就很可能是try服务实例01，confirm/cancel就请求服务实例02，很可能是这样子的 

return this.delegate.invoke(proxy, method, args);，他其实是直接要求让原生的feign的InvocationHandler去执行http请求 

到此为止，流量充值服务的工作就干的差不多了，你可以认为他就直接基于原生的feign，将请求发送到人家的资金服务上去了

### 73_一鼓作气来看看被调用服务是如何配合开启和执行分布式事务的

14_bytetcc框架的源码架构(5)

![](C:\Users\zy199005\Desktop\中华石杉\images\java\06\0307301.png)

资金服务被调用的时候，会走一个拦截器，在这个拦截器中就可以通过请求的header获取到对应的分布式事务，此时资金服务就知道，自己本次的请求调用是被包裹在一个分布式事务中的，是有人开启了一个分布式事务来调用自己 

byte[] byteArray = transactionText == null ? new byte[0] : ByteUtils.stringToByteArray(transactionText); 

​          TransactionContext transactionContext = null;

​          if (byteArray != null && byteArray.length > 0) {

​               transactionContext = (TransactionContext) CommonUtils.deserializeObject(byteArray);

​               transactionContext.setPropagated(true);

​               transactionContext.setPropagatedBy(propagationText);

​          } 

transactionText，这是代表了分布式事务的一坨二进制数字，对其处理一下可以获取到一个二进制字节数组，然后通过工具方法的处理，可以从二进制字节数组反序列化，还原出来一个TransactionContext，事务上下文 

也就是说，如果你开启了一个分布式事务之后，你就可以在调用其他的服务的时候，通过header传递分布式事务的上下文 

globalXid：8127-0a00270000110000016589ede49a0001bdb0b38b- 

prepare-transaction complete successfully：其实就是资金服务的try阶段成功了 

下一讲，我们要调整一下这个断点，我们希望能够看到，比如说资金服务和订单服务的try都成功了之后，在调用抽奖服务的时候如果说报错了，那么他是如何在处理的，分析一下，我们之前测试的时候分布式tcd事务为什么不生效 

明明在try阶段，让一个服务都已经故障了，结果没有去走cancel逻辑

### 74_灵光一闪：解决之前遇到的tcc分布式事务没有生效的问题 

我已经解决了那个问题了 

就跟之前用spring cloud的时候遇到的问题一样，很多问题都是一些小问题 

我们把核心的业务逻辑代码包裹在了try cache里面，这就不对了，会导致什么？，我们如果遇到try阶段某个服务报错了之后，我们就在cache中将那个报错给吞掉了，然后就会导致bytetcc框架是感知不到异常报错的 

bytetcc还以为try阶段都成功了，反而还会去执行各个服务的confirm操作 

tcc分布式事务已经实践成功了，bytetcc框架整合到spring cloud技术栈中来使用，已经完全成功了 

下一讲，我们来调试源码，来分析一下如果try阶段有报错的话，然后bytetcc框架是如何触发之前已经try成功的各个服务的回滚的呢？ 

如果try阶段全部都成功了之后，是如何触发各个服务的confirm的呢 

我们可以来看看如果confirm/cancel阶段执行报错，bytetcc框架是如何自动不断的去重试调用人家的confirm/cancel接口的，无限次重试，不停的重试，直到你confirm/cancel执行成功为止 

bytetcc框架如果有一个分布式事务执行到了一半儿的时候，然后系统挂掉了，他在重启之后是如何恢复事务的呢 

### 75_重新找断点调试一下try阶段有报错时是如何进行cancel的（一）

15_bytetcc框架的源码架构（二）

![](C:\Users\zy199005\Desktop\中华石杉\images\java\06\0307501.png) 

我来告诉大家，这块东西里，要调试哪几个断点 

bytetcc框架，是通过请求header和响应header来互相传递和同步分布式事务的上下文和信息的 

搞清楚里面的一些细节，xid是干嘛的，没必要，你对于这种框架，没必要研究的那么的详细，这种框架，你主要是把握里面的核心的架构、机制、运行流程、原理、各种事情，把握一些大的东西 

花费很大的事情，慢慢研究，一点点调试，才能搞明白他的各种代码逻辑 

除非是你们公司里现在要引入一个分布式tcc事务框架，然后还决定要对这个框架做二次开发，由你来负责二次开发，或者是维护，未来1年内，你就专门维护这个分布式tcc事务框架，当这个框架的引入和使用都成了你的本职工作之后 

你为了把这个工作干好，解决公司里遇到的一切技术问题，你必须非常非常仔细的去调试和研究这个框架的源码的每个细节，把这个框架涉及到的代码，全部都看懂，每个细节都很了如指掌 

当你做到这个程度的时候，你对这个开源框架的一个掌握的水平，也就跟开源框架的作者差不多了，你每天投入几个小时来研究一款开源框架，起码要两三个月，才能把这个框架100%给吃透 

那个时候你就是这个tcc分布式事务在国内绝对的顶尖的专家了 

像这种框架，要把握一个度，对于你的技术功底的积累，解决一些常规的技术问题，出去面试，包括对分布式事务技术的掌握的深度，我觉得把握好一些大的流程、架构和机制、原理就ok了 

你对tcc分布式事务的技术的掌握，起码在国内可以达到top 1% 

XA分布式事务，Atomikos框架的源码，其实课程里的内容你可以掌握，在国内，在XA分布式事务这块，你已经是top 1%了，但是如果你把atomikos框架的源码彻底吃透，花费几个月的时间，100%的细节都ok了，XA分布式事务这块，你在国内也没几个人水平可以跟你差不多了 

但是如果你要是跟我说的一样，每天投入几个小时来研究，连续研究几个月，这个bytetcc小框架100%彻底掌握，那么你在tcc分布式事务这个细分的小小领域里，在全国可以进入万分之一的水平 

几十个人，java这块的码农大概是几十万，每年还在呈现几万的增长，未来可能会达到100万的java码农吧 

如果你要成为一个领域的顶尖专家，花费1年的时间，专门研究分布式事务，从XA、tcc、最终一致性、saga长事务，把这些技术，各种底层框架，源码，各种技术选型，全部研究的100%透彻 

那么1年之后，你将会成为国内，在分布式事务领域的顶尖专家 

外面网上也有一些博客，也有少数的分布式事务的课程，如果你是把那种比较浅的课程看过了，就是看了一下分布式事务的解决方案，初步可以用，那样的水平，大概在国内可以排到，30%，20%，大概是那样的一个水平 

但是我们的课程，是对分布式事务的底层原理，框架的源码，是剖析的，100%，但是起码看完了以后，分布式事务这块的技术的掌握，top 1%的行列，除非是那种研究到100%的顶尖专家来面试你 

否则普通的面试官，在分布式事务这块完全是你在教他，不是他在考察你 

// Standard transaction demarcation with getTransaction and commit/rollback calls.

TransactionInfo txInfo = createTransactionIfNecessary(tm, txAttr, joinpointIdentification);

Object retVal = null;

​               try {

​                    // This is an around advice: Invoke the next interceptor in the chain.

​                    // This will normally result in a target object being invoked.

​                    retVal = invocation.proceedWithInvocation();

​               }

​               catch (Throwable ex) {

​                    // target invocation exception

​                    completeTransactionAfterThrowing(txInfo, ex);

​                    throw ex;

​               }

​               finally {

​                    cleanupTransactionInfo(txInfo);

​               }

​               commitTransactionAfterReturning(txInfo);

​               return retVal; 

在completeTransactionAfterThrowing()方法中，一定会去调用已经try成功的各个服务的cancel的接口，调用cancel接口，是如何去调用的呢？bytetcc框架是提供了一个内置的一个controller的 

就可以调试出来在遇到try报错的时候，如何将之前已经执行成功的服务调用cancel接口 

在流量充值服务，感知到try阶段有报错的时候，会执行哪些业务逻辑 

在资金服务和订单服务里，是如何被调用rollback（cancel）去回滚之前的业务逻辑的

### 76_重新找断点调试一下try阶段有报错时是如何进行cancel的（二）

15_bytetcc框架的源码架构（二）

![](C:\Users\zy199005\Desktop\中华石杉\images\java\06\0307601.png) 

大家可以去想象一下，这个数据库里记录的那个东西是什么？ 

在一个分布式事务中，比如说资金服务，对应的bytejta表里，一定会有两条记录，第一条记录是说，如果你这个服务执行了try接口之后，就会有一条记录 

但是如果只有一条记录，就说明这个事务一定没有执行完整 

必须有两条记录，第二条记录代表的是confirm或者是cancel，这个分布式事务才算是结束了 

刚才在执行的事务的回滚，实际上抽奖服务他不是报错了么，然后在抽奖服务本地进行回滚刚才报错的那个事务 

因为刚才的那个分布式事务没有成功，所以说一会儿我们重启流量充值服务之后，流量充值服务自己本地是记录了分布式事务执行的日志的，他会感知到上一个分布式事务没有执行完，他会自动去让资金服务和订单服务进行cancel的 

resourceList 

[xa-res-archive[descriptor: remote-resource[id= 192.168.56.1:DATA-REFILL-CENTER-FINANCE:9004]], 

xa-res-archive[descriptor: remote-resource[id= 192.168.56.1:DATA-REFILL-CENTER-ORDER:9006]], 

xa-res-archive[descriptor: remote-resource[id= 192.168.56.1:DATA-REFILL-CENTER-LOTTERY:9005]]] 

就是按照调用顺序，如果你调用了一个服务，bytetcc分布式事务框架，会将你分布式事务中调用其他的服务作为一个resource放到一个resourceList中去，这样的话，分布式事务中调用了哪些其他服务，具体的状态是成功还是失败，都可以感知到 

如果所有服务都try成功了，只要依次对这些服务调用confirm接口就可以了 

但是如果一个分布式事务中要调用5个服务，结果只有2个服务调用成功了，第3个服务调用失败了，在进行cancel的时候，只要对try成功的服务执行cancel就可以了 

http://192.168.56.1:9004/org/bytesoft/bytetcc/rollback/0a0027000011000001658de58e540006e052e312 

在这里，就会拼接出来一个针对资金服务的cancel接口调用的请求URL，使用RestTemplate来发送这个请求，会去请求资金服务里的bytetcc内置的一个controller，带过去的是一个xid，分布式事务id，资金服务内部的bytetcc controller就可以根据分布式事务id，来执行对应的cancel操作

### 77_重新招断点调试一下try阶段有报错时是如何进行cancel的（三）

15_bytetcc框架的源码架构（二）(2)

![](C:\Users\zy199005\Desktop\中华石杉\images\java\06\0307701.png)  

抽奖服务，是属于try执行失败的，所以在进行cancel的时候，他自己会根据之前记录的一些状态感知到说，我其实是不需要执行cancel

### 78_在try阶段所有服务都成功的情况下是如何执行各个服务的confirm

16_bytetcc框架的源码架构（三）

![](C:\Users\zy199005\Desktop\中华石杉\images\java\06\0307801.png) 

大家还记得么，其实资金服务，各个服务本地事务提交成功了之后，也会在本地提交自己的本地事务，所以各个服务都会进入刚才我们打的那个断点里面，所以说我们需要将这个断点设置一下是针对哪个服务来执行这个断点 

所以说只有在流量充值服务的运行期间，断点才会进入，此时我们就可以看到流量充值服务里的bytetcc框架是如何提交整个tcc分布式事务的 

我们好不容易，在那个断点的地方，快速的通过5次，让5个服务的try阶段的本地事务的提交先过去，终于在流量充值服务的那个断点处停了下来 

[xa-res-archive[descriptor: remote-resource[id= 192.168.56.1:DATA-REFILL-CENTER-FINANCE:9004]], 

xa-res-archive[descriptor: remote-resource[id= 192.168.56.1:DATA-REFILL-CENTER-ORDER:9006]], 

xa-res-archive[descriptor: remote-resource[id= 192.168.56.1:DATA-REFILL-CENTER-LOTTERY:9005]], 

xa-res-archive[descriptor: remote-resource[id= 192.168.56.1:DATA-REFILL-CENTER-CREDIT:9003]], 

xa-res-archive[descriptor: remote-resource[id= 192.168.56.1:DATA-REFILL-CENTER-COUPON:9002]]] 

就是说，在try阶段，只要你调用的服务，都会记录到resourceList中去，这样的话，在confirm阶段，就可以依次调用各个try成功的服务的confirm接口了 

之前跟大家分析过，如何去读静态源码，正是因为这个原因，所以大家更加要锻炼出来阅读静态源码的能力，不需要debug，完全肉眼去扫描代码，脑子里咔嚓咔嚓代码就开始运行，一定要有这个能力 

http://192.168.56.1:9004/org/bytesoft/bytetcc/commit/0a0027000011000001658e9a3bdd0001a4c5afcb/true 

事务恢复怎么来做？你必须得将一个分布式事务运行过程中各种状态都记录到日志文件里去，bytetcc有一个活动事务管理器，记录活动日志，在系统启动的时候，发现某个分布式事务没有结束 

然后他就会去恢复

### 79_如果confirm或cancel执行失败了tcc事务框架是如何不断重试的 

我们这一讲来看一下，如果confirm活着是cancel失败了，bytetcc框架默认是会自动的进行重试调用的，我们在这里其实可以看到，bytetcc框架正在不断的重试调用资金服务的confirm接口 

CompensableWork，这个东西是用来干什么的？ 

干两个事情的，第一件事情，就是在系统每次刚启动的时候，对执行到一半儿的事务，还没执行结束的事务，进行恢复，继续执行这个分布式事务 

第二件事情，如果就像我们现在的这个场景，就是分布式事务中所有服务的try都成功了，然后执行confirm，其他服务的confirm都成功了，可能就1个服务的confirm失败了，此时CompensableWork会每隔一段时间，定时不断的去重试那个服务的confirm接口 

直到那个服务的confirm接口执行成功，才能认为这个分布式事务执行成功了 

timingRecover，就是在进行定时不断执行的恢复 

整个这块的，confirm或者是cancel有某个服务没有执行成功，bytetcc框架的CompensableWork会不断的去进行重试 

通过源码，揭示出来了，如果有那种confirm或者cancel没成功的服务，CompensableWork会每隔60s去调用一次你的/commit接口或者是/rollback接口，尝试去完成你的分布式事务中的confirm操作或者是cancel操作 

TransactionRecoveryImpl，这个东西是专门负责事务恢复的一个组件 

CompensableWork每隔60s会去调用一次这个组件的timeingRecovery()方法，这个里面会去调用一个recoverCommit()方法，这个方法底层会去执行SpringCloudCoordinator的方法，去发送一个http请求，调用资金服务的/commit接口 

但是目前为止，我的资金服务的/commit接口对应的那个ConfirmService始终是报错的，所以他是没办法进行恢复的 

confirm或者cancel执行失败的时候，bytetcc框架是如何不停的，永不停歇的重试confirm和cancel接口的机制，就揭示清楚了

### 80_如果tcc分布式事务执行到了一半服务挂了重启时如何恢复事务 

就是流量充值服务突然挂了，重启是可以自动去恢复执行未完成的事务的 

正好接着目前的一个场景给大家来演示一下他重启的时候是从哪里入口去恢复事务的 

CompesnableWork，刚启动的时候，就会先去恢复一次事务，后面才会开始尝试每隔60s去恢复一次未完成的事务 

如果有的服务这个try都没执行完毕，然后直接挂掉了，此时会怎么样呢？其实此时可以让已经try成功的服务直接全部cancel掉 

如果是try都成功了，confirm没有都成功，就是我们现在的这个场景，有一个资金服务的confirm没成功，此时流量充值服务重启，会知道说应该调用资金服务的confirm接口，无法就是读取和解析一下没有完成的分布式事务的数据和信息 

根据那些日志什么的，对没有执行成功的服务去调用对应的接口不就得了，confirm，cancel 

我再重新调整一下断点，给大家看一下这个启动的时候恢复的一个过程 

重启恢复事务的时候，一定会去调用资金服务的confirm接口，一定会报错，所以只要跟踪一下启动过程中的报错的异常堆栈，就可以分析出来重启恢复事务的一个代码 

在这里我们可以分析出来，其实在重启的过程中，他去对没完成的分布式事务进行恢复的一个过程，也是通过timingRecover()方法实现的，在刚开始启动的时候，这个方法就会执行一次，就承担了系统重启恢复事务的过程 

读取自己的分布式事务的活动日志，找出来没完成的分布式事务，对里面没完成的服务，发起对应的confirm/cancel接口的调用就ok了，如果还是没法成功，后续timeingRecover会不断的去执行对应的接口的调用，来完成这个事务

### 81_加一个账单服务来把流量充值中心搞成复杂的链式调用模式 

我们要把我们的项目案例搞的再更加复杂一些，tcc分布式事务的方案，是不是仅仅适用于一个服务 -> 调用了多个服务，但是被调用的其他服务是没有继续再调用其他服务的，当然不是了 

tcc分布式事务方案，仅仅适用于上面这种简单的场景，那么大量的场景是没办法用分布式事务的 

流量充值服务

-> 资金服务 -> 其他服务 -> 其他服务

-> 订单服务 -> 其他服务

-> 抽奖服务

-> 积分服务 -> 其他服务

-> 流量券服务 

但是大家一定要认识到一点，我们其实真是的分布式系统中，或者是微服务系统中，一定是多个服务链式调用的，服务一般会形成一个复杂的调用链条，一个服务调用一个服务，再调用一个服务 

如果是上面我说的那种复杂的服务之间链式调用的场景，组成了一个比较复杂的服务调用链条的场景，那么我们应该如何来实现tcc分布式事务呢？我们之前给大家讲解的tcc分布式事务的实践，以及他的源码分析，都是停留在一个比较简单的场景，就是一个服务直接调用多个其他的服务，没有形成一个调用链条 

服务链式调用的场景，模拟出来这样的场景，然后来给大家演示tcc事务框架是如何支持服务链式调用场景的tcc分布式事务的，包括tcc事务框架在支持这种复杂场景的时候，底层的源码逻辑是什么样子的 

我们来加一个服务，搞成链式调用的模式，然后基于更加复杂的场景来研究tcc事务 

流量充值服务

-> 资金服务 -> 账单服务

-> 订单服务

-> 抽奖服务

-> 积分服务

-> 流量券服务 

账单服务，资金服务 -> 账单服务，资金转账的时候，一般都会有自己的转账的账单记录，也就是会记录下来每一笔资金交易的流水的情况，订单服务是另外一码事儿，其实是包括的是整个流量充值的这个行为的一些信息 

bill 

下一讲就要来分析一下，如何让资金服务去调用账单服务，因为每个人都有这个tcc三个接口，如何来进行调用呢？来分析一下在服务链式调用的时候，如果你要去考虑那个tcc分布式事务的一些问题，我们应该如何来考虑 

### 82_针对复杂的服务链式调用的场景分析一下分布式事务遇到的问题

17_服务链式调用的分布式事务的问题

![](C:\Users\zy199005\Desktop\中华石杉\images\java\06\0308201.png) 

服务链式调用的一个问题了，我们现在就要考虑一下，在服务链式调用的场景下，分布式事务怎么来实现呢，资金服务如何来调用这个账单服务 

之前已经理解过bytetcc源码之后，confirm和cancel接口是不直接对外的，直接对外的是bytetcc框架自己搞的一个controller，里面提供了/commit接口和/rollback接口，bytetcc框架自己的controller会去回调对应的confirm和cancel的逻辑 

如果按照分布式事务的这套理论来走的话，在服务链式调用的场景下，在try的阶段，应该就是会按照服务调用的链条，依次去调用所有服务的try接口，整个服务调用链条里面的这个try接口应该全部执行 

如果在服务链条里，有任何一个服务的try接口是报错了，那么这个报错必须依次往上传递，报错异常绝对不要吞掉，全部往上传递，一直上传到最根部的开启分布式事务的那个服务里面 

只有这样子，那个开启分布式事务的根服务，他才会感知到try阶段有异常，然后就会针对之前已经try成功的服务依次调用cancel接口，很大的一个困难，我们现在对这种服务链式调用的分布式事务的最大的一个难题就在于说 

比如说资金服务的cancel接口被调用了，然后资金服务的cancle接口如何去触发账单服务的cancel接口呢？因为代码层面是不能让你直接调用的 

如果try阶段没有感知到任何的报错，那么开启分布式事务的根服务就会依次调用confirm接口，也是在于说这个资金服务的confirm接口被执行，然后资金服务如何触发下游的账单服务的confirm接口也被执行呢？ 

代码层面是不能直接调用账单服务的confirm接口的

### 83_大胆的设想一下如何设计服务链式调用的分布式事务解决方案

18_服务链式调用的分布式事务解决方案

![](C:\Users\zy199005\Desktop\中华石杉\images\java\06\0308301.png)   

流量充值服务 -> 资金服务 -> 账单服务 

我们可以想象一下，正常的一个分布式事务的机制和流程应该是如下的： 

（1）流量充值服务的try -> 资金服务的try -> 账单服务的try

（2）如果try全部成功了，那么流量充值服务内部的bytetcc框架会自动去调用资金服务内部的bytetcc框架

（3）那么资金服务的confirm接口被调用了之后，如何触发账单服务的confirm接口呢？但是我们设想的是，bytetcc这种框架，如果你要做企业级的tcc分布式事务的框架，你必须得支持一点，资金服务之前调用过账单服务的try接口，还成功了，所以应该记录好，自己是调用过账单服务的这个事儿的

（4）然后当资金服务的confirm接口被调用的时候，是被谁调用呢？是bytetcc框架的controller去执行了资金服务的confirm逻辑，那么我们可以想象一下，bytetcc框架在执行了自己本地的confirm逻辑之后，是不是可以根据自己之前调用过哪些其他的服务的try，来判断，自己现在执行了confirm之后，其实也需要去调用之前自己try成功过的其他服务的confirm接口

（5）如果try阶段有任何一个服务报错了，try失败了

（6）那么就需要流量充值服务去调用资金服务的cancel接口，资金服务也需要触发账单服务的cancel接口 

大概来设想一下，都可以想象到，我们应该如何来做这块的分布式事务，理论上来说，都是应该是tcc分布式事务框架来负责的 

每个服务的try，是可以通过spring cloud的feign去调用其他服务的try接口的 

每个服务的confirm和cacnel，都是只要执行自己本地的confirm和cancel的逻辑就可以了，不需要你去触发其他服务的confirm和cancel，为啥呢？因为这都是bytetcc事务框架在底层都把事儿给你做了 

我们把这种服务链式调用的相关的事务的源码，看一下，你就会发现说，跟我们想象的这个图是一模一样的

### 84_精读源码之后再读tcc事务框架文档发现链式调用分布式事务的支持

其实的话呢，我们刚刚做过一个bytetcc事务框架的demo之后，其实当时直接去看那个bytetcc框架的文档，我们当时会觉得很别扭，有点看不懂，但是我们现在已经大量的实践过bytetcc事务框架的使用之后，同时还阅读了bytetcc框架的核心源码之后 

我们现在再回过头来去看看bytetcc事务框架的使用文档，非常的简单 

如果你对某个技术在看他的使用文档之前，直接自己先阅读一下源码，然后反过来再去看他的使用文档，你会觉得非常的简单，学习和使用一个技术，是非常简单的，你只要照着他的一些官方文档，他就是提供了一些功能 

你只要了解一些基本的原理，学习一些功能的使用，就ok了 

真正的技术绝对不是简单的使用，一定是深入看过源码，有深厚的技术功底的 

使用这种国内作者开源的项目，有一点好，人家发起人的作者一般都会搞一个QQ群，人家平时也会忙着自己的工作，每天都会看看群里的一些问题，然后你进了群以后可以给作者发一些私聊的消息 

你们是可以交流的 

看过源码之后，也就是看过了这个作者整体架构设计的一个思路，包括里面的实现的原理和机制，我们都了解了之后，通过http请求的headers，会包含这个事务上下文的序列化的信息，你调用了其他的服务之后，其他的服务就会通过请求headers反序列化出来事务上下文，所以这个就跟文档对上了 

bytetcc框架是不是包含了一个事务管理器，资金服务本地的事务管理器，是不是会之前记录下来之前调用过哪些服务的try接口，resouceList，看过源码的人都知道，就会自动去调用远程的账单服务的confirm接口 

对于这种开源技术的学习，大家应该就可以理解了，我之前带着大家快速的做了一个demo，然后呢快速的过了一下他的文档，当时过的很快，很粗，没有细讲，因为其实当时细节是讲不清楚的，很多东西都在源码里 

然后我们带着还没完全跑通的一个项目案例，就直接进入源码的阅读了，在阅读源码的过程中，我也是突然发现了之前的一个疏忽导致了一个小bug，当时项目案例里面的分布式事务的回滚，没有成功 

我们看完了源码之后，反过来，回过头再来看看这个东西里面的文档，会发现易如反掌，非常的简单，那一大段话，说的就是我们之前遇到的那个问题 

当时抽奖服务报错了，但是流量充值服务有一个try catch吞掉了这个异常，就导致流量充值服务里面的bytetcc框架以为try都成功了，因为没有感知到异常，所以还是已无法股的执行了之前已经try成功的服务的confirm逻辑 

我们之前遇到的就是这个问题 

我们通过再次阅读bytetcc框架的文档，其实也搞清楚了，我们其实之前设想的服务链式调用的分布式事务解决方案，其实就是跟bytetcc设计的方案是一模一样的 

### 85_模拟一个故障来演示tcc事务框架对链式调用分布式事务提交回滚的支持 

咱们实际上来说，就是会将之前做好的账单服务加入到服务调用链里面去，然后呢，我们本身就是已经按照tcc的格式做好的一个服务，直接加入进去，我们就可以看到效果了，加入进去了以后呢，我们先试一下正常的调用链路 

都会正常的会触发整个调用链条里的服务的try ->confirm，再来模拟一下try阶段某个服务报错了，然后可以看到说之前调用链里面的服务都会被cancel 

我们先来试一下，尝试成功了之后，我们就可以来研究一下服务链式调用的时候confirm和cacnel是如何触发的 

整个这个数据都是对的 

演示出来了，这一块，在正常的情况下，其实都是会去执行try -> confirm的那套流程的，链条里面的所有服务都执行了try，try都成功了，然后就执行了confirm 

涉及到一些spring cloud内部实例化一些bean的开销 

其实在confirm的时候，流量充值服务会去触发资金服务的confirm，资金服务内部的bytetcc框架会自动触发账单服务的confirm 

抽奖服务是会报错的，只要报错，try阶段失败，一定会回滚之前已经执行成功的资金服务和订单服务，资金服务的cancel执行之后一定会触发账单服务的cancel 

我们下一讲来给大家演示一下，源码级别的调试，让大家看一下，这个资金服务的confirm或者是cancel执行的时候，其实是会触发他调用过的账单服务的confirm或者是cancel的，这块源码，我们下一讲一起来调试一下

### 86_通过源码的调试来分析tcc事务框架的链式调用事务提交和回滚的机制 

我们就看一下在服务链式调用的场景下，如何提交和回滚事务的源码 

我们可以先来分析一下，在bytetcc框架的controller里面，给/commit接口打上一个断点就ok了，看一下资金服务的/commit接口被调用的时候，除了执行自己本地的confirm逻辑之外，是如何去调用账单服务的/commit接口的 

这块的图我就不画了，比较简单，我们主要是在源码里去看一下确认一下这个服务链式调用的分布式事务的实现细节，跟我们想的是否一样 

CompensableTransactionImpl.fireCommit() 

就这个方法，是执行commit的核心方法，他首先会先执行自己本地的confirm逻辑，this.fireNativeParticipantConfirm();，这行代码，就是在触发自己本地的confirm逻辑的执行，但是还没到触发账单服务的confirm 

this.fireRemoteParticipantConfirm();，这行代码的调用其实是在触发远程的账单服务的confirm逻辑的执行，为什么呢？因为之前资金服务调用过账单服务的try接口，只要成功调用了其他服务的try接口，就会将这个服务记录到一个本地的resourceList里面去 

现在执行confirm的时候，不就可以用到了吗 

[xa-res-archive[descriptor: remote-resource[id= 192.168.56.1:DATA-REFILL-CENTER-BILL:9009]]] 

在resourceList里记录了之前try成功过的其他的服务，比如这里，就是记录了bill账单服务福，然后就可以对这个resourceList里的服务，通过RestTemplate，执行http请求，访问远程的账单服务的bytetcc controller，执行confirm逻辑 

http://192.168.56.1:9009/org/bytesoft/bytetcc/commit/0a002700001100000165a386ba0c0019f13ca869/true，这个东西就是在请求账单服务的commit接口，进而执行账单服务的confirm逻辑 

那么这样的话呢，我们其实就是可以看到，在资金服务的bytetcc controller的/commit接口被调用之后，关键的一点就是在CompensableTransactionImpl里面，在commit的时候，除了执行自己本地的confirm逻辑，还会执行自己之前try成功过的其他服务的confirm逻辑 

如果是资金服务被调用了/cancel呢？其实原理是一样的，我们不需要调试了，直接看一下源码就可以了 

在CompensableTransactionImpl.rollback()里面，就是先执行本地的cancel逻辑，然后去触发调用远程的cancel逻辑，this.fireNativeParticipantCancel();，this.fireRemoteParticipantCancel();，说句实话，公平公正的说，这个大兄弟，虽然看着不是很出名，做的这个框架也是不太出名，跟大名鼎鼎的spring cloudd不可以比 

但是说实话，人家的技术水平，代码水平，代码质量，我个人认为，远超eureka的源码，远超hystrix的源码，那些开源项目的源码，虽然是大名鼎鼎的netflix公司开源的，但是那个代码之烂 

简直让人难以忍受，难以去看，那个代码写的太不优雅了 

不过说实话，也是带着大家来学习了bytetcc框架的使用、技术、原理、源码、实战，仔细看人家的源码，从整体的架构设计，以及一些实现，面向对象的设计，类、包以及项目结构的设计来看 

我个人对这个作者的水平还是挺认可的，第一我觉得技术实力没问题；第二人家的代码写的还是挺优雅的，设计还是挺不错的 

最终，一定会通过SpringCloudCoordinator来发送http请求给账单服务的bytetcc controller，来执行/rollback接口，以执行账单服务自己本地的那个cancel逻辑 

tcc这块，到这里为止，我觉得就全部结束了，tcc事务，从头到尾，讲成这个样子，我说实话这个课程里面大部分的东西，你百度是找不到的，这些分布式事务的技术和资料，没任何书籍，没任何博客，没任何视频课程讲 

虽然全网有两个分布式事务的视频课程，但是那两个课程说实话，也就是简单的带着用一用分布式事务而已，对底层的源码，原理，没有任何深入的剖析 

### 87_saga分布式事务介绍以及其两种核心思想：编排模式与命令模式

19_saga事务的原理 

![](C:\Users\zy199005\Desktop\中华石杉\images\java\06\0308701.png) 

分布式事务方案： 

（1）XA（两阶段提交）：适用于单系统多数据库的分布式事务 

（2）TCC（补偿型的分布式事务）：特别适用于微服务场景，尤其是dubbo技术栈，spring cloud技术栈，跟这些微服务技术栈整合，在服务链式调用的场景里，给服务调用链条加上TCC型的分布式事务 

（3）可靠消息最终一致性方案：比较适用于不是微服务复杂调用链条的场景，适用于的是调用之间可以通过MQ异步解耦，走异步化的方式，在不太复杂的一个服务调用场景里，可以使用，主要是将比较耗时的一些操作放在MQ异步化的方式来实现，同时还能实现最终一致性的一个事务的效果 

（4）最大努力通知方案：分布式数据一致性，比较适用于，哪怕是数据不一致也可以的非关键性的操作，走MQ异步通知，重试多次，实在执行不成功就算了 

（5）saga事务：他的地位是类似于TCC的，他跟TCC你可以从中间选择一种方案出来使用，就可以了，saga事务的本质也可以用来解决微服务里，复杂的服务调用链条下，如何加上分布式事务 

我主要是会用3讲的时间，给大家初步介绍一下saga事务就可以了，不会带着大家来实战saga事务以及深入的研究 

TCC事务，其实就是将一个接口拆分为3个接口，try -> confirm -> cancel，try成功了就confirm，try失败了就cancel。那如果confirm或者cancel失败了呢？在bytetcc框架里，confirm失败了就是一直重试，应该是有cancel接口直接一下子全部给cancel掉的 

cancel失败了反复的重试，是可以的 

saga是将每个接口，拆分为2个接口，一个是业务接口，另外一个是补偿接口，相当于就是说将tcc里面的try和confirm合并为一个接口，就是先执行业务接口，直接就尝试完成整个业务逻辑的操作 

然后如果在服务调用链条里面，某个服务的业务接口执行失败了，那么直接对已经执行成功的所有服务都调用其补偿接口，将之前执行成功的业务逻辑给回滚 

saga这个东西，其实核心和本质，就是把每个操作分为实际的业务逻辑以及补偿业务逻辑，正常情况下，就依次执行各个服务的业务逻辑就好了，如果某个服务调用失败的话，直接对之前执行成功的那些服务都依次执行补偿逻辑 

saga事务的思想，就是将一个长的分布式事务，拆分为一连串的每个服务的本地事务，然后每个服务对每个接口提供两个接口，一个是业务接口，一个是回滚的补偿接口，正常情况下就是依次的进行调用 

异常情况下，就对之前已经执行成功的服务执行补偿接口，回滚业务逻辑 

saga其实说白了，主要是两种思想，一种是编排模式，一种是命令模式 

编排模式，是事件驱动类型的模式，就是每个服务执行成功了自己发布个事件，下一个服务会监听到这个事件，然后继续执行，类似这样子，画个图来解释一下好了，那谁知道要监听谁的事件呢？ 

很简单啊，提前自己定义一下流程不就得了，看看哪个服务依赖下一个服务这样子 

在saga的时候，你就需要基于saga事务框架来定义一个服务调用流程，服务1 -> 服务2 -> 服务3 -> 服务4 

很多人说，我去，这个不是跟tcc很类似吗，是啊，是很类似的，但是你别忘了，他的思想可是消息驱动的，是异步的，不是同步的哦 

tcc可不是，服务调用链的场景，但是他是同步调用，特别适合于我们之前的编程思维和模型，因为我们正常写微服务的系统里面，都是各个服务同步调用的 

而且另外一个，saga就俩接口，业务接口，补偿接口；tcc是try/confirm/cancel，三个接口，他们的事务模型是不一样的 

编排模式，优点在于去中心化；缺点在于太麻烦了，如果你有连续几十个服务连续调用，会导致服务对消息的监听非常复杂，而且不好调试和定位问题，服务调用异常，服务调用链的问题排查特别麻烦，引入一个MQ，特别不好，你的服务执行依赖于MQ完成各个服务的调用，引入了复杂性，如果MQ挂掉了以后 

第二种就是命令模式咯，其实说白了，就是某个服务如果要开启一个saga分布式事务，那么就得自己搞一个类似saga流程管理器的东西，然后来负责依次调用和执行各个服务，如果某个服务调用失败，就对之前调用成功的服务依次执行补偿接口 

saga分布式事务管理器，来管理整个saga事务的调用和执行的流程，如果某个节点失败了，那么就会回滚，重新执行补偿接口 

优点在于系统比较简单，定位和处理问题都比较简单，不涉及复杂的消息监听什么的；缺点的话，主要就是万一saga事务流程管理器挂了呢？那不就惨了 

所以大体上来说，就是这样子了 

这就是saga事务的一些思想性的东西，但是具体如何实现，还是要落地到每个不同的框架怎么来实现了 

如何具体的来实现saga事务，就跟tcc一样，我们光是了解tcc的思想是没用的，一定要去看具体的tcc框架的实现，saga事务也是一样的，要看saga事务框架是如何来实现这个saga事务的

### 88_AxonFramework介绍：DDD、EventSourcing、CQRS以及Saga 

AxonFramework其实是CQRS的一个框架，这个框架在国内几乎没人用，DDD以及CQRS相关的东西在国内的公司里实践非常的少，但是因为这个框架里自带了saga事务的一个实现，所以说我们为了在之后给大家来介绍saga事务框架，所以在这里先把AxonFramework和相关的概念都给大家来说一下 

这个关于DDD是啥，真的很不好解释，其实说实话，我讲这点儿东西主要也就是为了大家理解一下Axon这个框架的一些理念罢了，然后看看Axon这个框架里是怎么来解决saga事务的机制的 

毕竟目前国内用saga很少，也就是华为的ServiceComb微服务技术栈里用了saga的思想，所以也没什么资料或者是框架，所以权且拿Axon这个框架来体验一把saga 

DDD，反正就是领域驱动模型设计了，具体是啥别管了，直接看里面的一些概念吧，我用大白话给你讲讲，其实挺容易看懂的

 （1）概念一 

aggregate，聚合，说白了，就是一个组合 

在设计类的时候一个概念 

啥意思呢，搞三个对象，一个是汽车，一个是轮胎，一个是引擎，这三个东西可以聚合成一个整体吧，就是一辆完整的汽车，对吧 

public class Car { 

 private Tyre tyre;

 private Engine engine;   

} 

所以o了，aggregate指的就是汽车 + 轮胎 + 引擎，三个东西聚合起来的一个整体 

如果有个人要开车，那么只能调用汽车，因为汽车是aggregate root，他是aggregate对外提供的一个门面，不能有人直接调用轮胎或者是引擎吧 

就好比人开车只能坐到车子里开车，你不会去自己推着轮子走，或者是自己去操作汽车引擎吧，那太傻了 

（2）概念二 

event sourcing的概念，其实说白了啊，就是事件回溯的意思 

这个也是个概念，说白了，比如数据库里有一条记录，现在呢，先改一次，再改一次，再改一次，连续改了三次，你觉得是不是数据库里就保存了最后一次修改后的数据啊，对了，这就是普通的保存数据当前状态的模式 

event sourcing是不同的，他是说，在数据库里保存3条记录，每条记录都对应那次修改的完整快照，就是对数据做了什么修改，那如果你现在要获取当前最新的数据咋整？那就依次执行一下所有的事件，不就能算出来当前最新的数据了？ 

正常情况下，往数据库里存放数据 

id name age

1 张三 20 

一年过去了，张三的年龄增长了1岁 

id name age

1 张三 21 

如果用event sourcing模式来存放数据 

id name updated_age

1 张三 20

1 张三 1

1 张三 1

1 张三 1 

我们如果要知道现在张三是几岁，怎么办呢？ 

张三的age变更的所有event，sourcing，回溯，20 + 1 + 1 + 1 = 23岁 

呵呵，这就是event sourcing的意思，如此简单 

所以在event sourcing模型里，很多时候也是会系统启动提前完成事件回溯，然后算出最新数据，放内存里缓存的，这样可以节约回溯开销，然后也可以多搞几个中间快照，每次从某个快照开始回溯 

（3）概念三 

Actor模型，这个模型的意思，就是说多线程在进行交互的时候，你假设一个Actor是一个线程，互相之间是基于消息进行通信的，每个Actor有个mailbox就是信箱，拿到了消息，然后内部单线程处理的 

每个Actor都有一个mailbox，各个Actor之间是可以进行通信的，通信非常的简单，一个Actor可以给另外一个Actor发送一个消息，发送到另外一个Actor的mailbox里面去，Actor内部就是单个线程不断的去消费mailbox里面的消息 

这样的话有啥好处啊，那很简单啊，如果要修改一个Actor里的某个数据，随便多少个线程并发更新，都是没有并发问题的，反正在Actor内部是mailbox排队，然后顺序处理的，所以就不要紧了 

Actor的状态修改就是event sourcing模型的，保存每个event，然后最新的状态都是回溯出来放内存里的，大概是这个意思 

scala编程语言就是actor并发模型的，然后actor模型的并发框架就是akka 

（4）概念四 

CQRS，Command Query Responsiblity Segregation，就是中文大概的翻译是，命令与查询职责的分离模型，大概意思，就是说，Command指的是类似增删改之类的处理命令，Query就是查询数据，然后让你在设计系统的时候，把增删改服务和查服务分离开来，就是在服务设计的层面，实现读写分离 

C，command，指的就是增删改

Q，query，指的就是查询 

你得用两个独立的服务来提供增删改操作和查询操作 

写服务，负责接收增删改的请求，将数据更新到存储里面去，比如说可以使用mysql

就是会有专门的数据同步的组件，会将写服务的数据存储里面的数据，更新到读服务的数据存储里面去，比如说elasticsearch 

读服务，就直接从elasticsearch里面提供数据的读取 

读写服务的分离 

大概意思呢，就是单独拉一个写服务出来，这是Command Side，处理增删改操作，每个增删改操作是一个Command，修改一个Aggregate的状态，保存到数据库里去，然后会通过一个事件驱动的组件，接收到了数据变更的事件之后，将数据同步到另外一个专门用于查询的数据存储里去，因为读写分离了，所以你可以让写是mysql，读是es，都可以的 

然后专门就专门有个查服务，是Query Side，专门负责查询数据，就比如从es来查询 

大概就是这么个意思吧 

这种的话，一般用在什么场景呢，其实我们也经常会用到这种读写分离的架构，最经典的，就是电商里的读写分离的场景，就是你的各种数据的变更统一都是走各种后台服务，都是mysql的 

但是比如商品详情页，读流量那么的大，肯定不能直接从各个服务的mysql里查啊，那就私人了要，可以分离出来一个专门的读服务，每次数据变更就获取事件，同步到比如redis里，作为查数据的存储，然后别人就可以从读服务里查redis的数据 

思想是一样的 

（5）概念五 

Event Sourcing + CQRS 

写服务在更新完自己的mysql之后，有一个专门同步组件会将数据同步到另外一个存储里去，比如es，或者是hbase，此时可以按照Event sourcing格式来同步数据，在es或者hbase里存放的是数据变更的快照，一个一个事件 

读服务在读的时候，可以基于一个一个事件来聚合数据提供查询 

大家注意到了吧，CQRS是不是有个组件是监听数据变更消息的，那么有event了，是不是可以按照event sourcing的思想来存储event啊，每个event都存下来，然后读服务里每隔一段时间回溯event算出最新快照让内存里供查询 

这样的话，比较适合一个场景，就是实时流量数据分析，比如storm负责不停的计算，相当于是写服务，然后写完数据之后发布个事件，读服务监听到之后将event放到比如hbase里去，这样的话，如果实时数据统计出错，可以回溯一下某个指标的计算历史，到底是怎么计算出来的 

这个回溯的过程，特别适合追踪那种BI统计数据出错的场景 

但是坑就在于说要存储的event量太大了，耗费存储啊，兄弟！！！ 

（6）概念六 

有一个框架，是专门帮助你实现CQRS模式，他里面的核心概念，都是DDD，领域驱动模型设计里的一些概念，包括了aggregate、event sourcing、actor、CQRS，那些概念就组成了一个CQRS框架，AxonFramework 

在DDD里面提出了一个事务的模型，就是saga事务模型，AxonFramework里面实现的就是saga事务模型 

CQRS框架以及saga，说白了，什么aggregate啊、CQRS啊、saga啊，其实都是在DDD这套理论里的，所以如果你要玩儿CQRS模型，那么可以选用AxonFramework这个框架，这就是一个专门的CQRS框架 

里面也提供了saga事务的支持 

所以，咳咳。。。本来我们就是简单玩玩儿saga的，结果因为特殊的背景，引出了一堆相关的概念，扯到DDD上去了，没关系，反正后面讲到DDD的时候，肯定是要玩儿CQRS架构的，AxonFramework到时候也会讲的 

所以提前入个门，Axon框架，然后玩儿下里面的saga事务就好

### 89_saga分布式事务的几种框架的介绍以及国内使用saga事务的实际情况 

**1、Eventuate Tram Saga** 

其实这里给大家介绍三个框架吧 

一个是Eventuate Tram Saga框架，这个兄弟呢，是一本国外的书，叫做《Microservice Patterns》的，没有翻译版本的，是这个书的作者，微服务设计模式的一本书 

他是定义了一整套的微服务面临的一些技术问题，然后他对于微服务的事务问题，比较推崇的是saga事务，然后自己写了个框架 

但是不幸的是，咳咳。。。。居然github的star才100多个，天。。。这几乎就是不太活跃啊，兄弟们，这种框架要慎用慎用慎用。。 

https://github.com/eventuate-tram/eventuate-tram-sagas 

star太少了，说明在国外几乎都没什么人用的，不是很热门的框架，这个框架作者的更新速度很缓慢，也不是特别的好 

所以这个框架，咱们真的也别用了，而且跟bytetcc这种框架不一样，你没看人家bytetcc框架经历了几年的发展，有0.3.x，0.4.x，好几个系列，活跃度也不错么，人家还是中国人，关键时刻，你可以在github里发个issue要人家的qq，是不是 

**2、AxonFramework** 

所以另外一个框架，叫做AxonFramework，这个框架本质其实是个CQRS框架，是基于DDD理论来的，你可以认为说，后面我们如果学习了DDD之后来建模和解决业务极度复杂的系统，那么就可以使用类似Axon这种框架了 

这个AxonFramework呢，有一个好处就是他里面也提供了saga事务的支持和实现，而且这个框架总体来说名气大一些，活跃度高一些，github的star也多一些，1000多。。这还凑合是吧 

所以目前在国内用saga分布式事务的其实很少，BAT等大公司，其实主要都是tcc事务用来解决核心业务逻辑复杂调用链路里面的分布式事务问题，比如说蚂蚁金服还有专门的tcc事务框架，当然我们团队也是自己研发的tcc事务框架，然后用基于MQ的方案实现最终一致性方案，这是比较常见的两种，当然XA分布式事务也不少 

因为不少系统都是单系统多数据源的，你得用XA分布式事务来解决分布式事务问题，兄弟 

但是这个AxonFramework有个问题啊，这里的关键点就在于说，他主要是适用于CQRS以及DDD一些领域的框架，也就是说，他不是一个saga事务框架，他其实是一个CQRS框架，只不过顺带支持了saga事务而已。 

我们下一讲给大家简单介绍一下这个框架相关的一些概念，你就知道了，你如果为了用saga而用盲目用了Axon框架，你绝对会死的很惨，他这套编程模型，他会要求你按照DDD里面的一套编程模型来玩儿，你死的很惨，系统弄的乱七八糟的 

所以也不要乱用Axon框架了 

我可以给大家吐槽一点，网上有一个网站，发布了一个分布式事务的课程，人家的重点你知道是什么呢？是saga事务，用AxonFramework的saga支持来演示saga事务，完全是在误导广大的青少年 

saga事务在国内用的很少，没几个公司是用saga事务的，tcc + MQ最终一致性，AxonFramework来演示，牛头不对马嘴，诱导性，Axon是CQRS框架，一般来说我真的不太推荐大家近几年在国内来使用 

那个分布式事务的一个视频课程，某知名网站发布的，而且在他的课程里，居然tcc仅仅只是简单介绍了一下，tcc在BAT、以及很多公司里，针对复杂的服务调用链场景下的分布式事务，tcc是目前国内实践最多，使用广泛的一种思想 

**3、华为的ServiceComb** 

还有就是华为的ServiceComb，那是华为弄的微服务的一套技术栈，框架，然后里面的分布式事务用的是saga事务的思想，不过说实话，挺少听说互联网公司里用华为的开源项目或者是非开源项目的，那一般是企业级系统开发的领域 

所以我们这里就算了吧 

**4、总结** 

综上所述，saga事务在国内公司实践和运用是极其少的，而且也没有成熟的技术方案，所以我们这里仅仅就是稍作介绍，不再详细展开了，如果带着大家研究上面那几个冷门技术，耗费时间不说，意义并不是很大 

实际上，你如果一定要说的话，tcc和saga是属于类似的分布式事务方案，所以有了tcc以及对服务链式调用的支持，我觉得我们就不需要saga也是ok的

### 90_可靠消息最终一致性方案（一）：整体架构以及核心流程设计

20_可靠消息最终一致性方案

![](C:\Users\zy199005\Desktop\中华石杉\images\java\06\0309001.png) 

分布式事务方案 

（1）XA事务：单系统多数据库

（2）TCC事务：服务链式调用的场景 

（3）saga事务：国内使用比较少，有TCC后不用saga也可以 

（4）可靠消息最终一致性方案：在事务里，有些操作特别的耗时 

比如说，电商系统下订单之后要走调度系统去进行调度出库，那块特别耗时，可以做成异步化；流量充值中心，调用运营商BOSS系统完成流量充值，特别耗时，第三方的系统调用比较慢，可以做成异步化；针对有异步化的场景，同时还要将这个异步化的操作包裹到一个事务中去，此时就可以使用可靠消息最终一致性的方案 

（5）最大努力通知方案：在事务里，有些操作无关紧要，可以成功也可以失败，而且还比较耗时 

比如说，流量充值中心里面的发送短信，发送邮件，发送一个通知，很多系统里面，都有一个栏目，叫做“我的消息”，比如说公司发布活动，推送一条消息，这种数据是无关紧要的，可以成功也可以不成功，同时还比较耗费时间。然后最好还是包裹在一个大的事务里面，此时可以用最大努力通知方案 

提前剧透一下，说实话，分布式事务里面，最难的是TCC事务、其次是XA事务、再其次才是可靠消息最终一致性方案，你研究过了前面的TCC和XA，源码都看过了，对分布式事务底层的源码和执行原理都有比较透彻的了解了 

再来看看这个可靠消息最终一致性方案，你会觉得其实一点儿都不难，他其实整个就是一套方案，一套思路，不难 

可靠消息最终一致性方案涉及到4个组件： 

（1）上游服务：发送MQ消息通知下游服务执行某个操作 

（2）可靠消息服务：协调上下游服务的消息传递，确保数据一致性，可以认为这个所谓的可靠消息服务是我们自己开发的，也是一个spring cloud的服务，只不过这个服务是通用的，是所有服务所有系统都基于这个可靠消息服务来实现可靠消息最终一致性的方案。“可靠消息”四个字，这一切都是基于可靠消息服务来做的，方案设计，消息如何保持可靠性 

（3）MQ消息中间件：这个一般是RocketMQ或者是RabbitMQ 

（4）下游服务：就是那个要被调用的服务 

所谓的分布式事务，上游服务他要执行一个本地的数据库操作，下游服务也要执行一个本地的数据库操作，现在尽量就是希望是说上游服务和下游服务的数据库操作要么同时完成，要么同时不完成 

具体的执行流程如下所示 

（1）上游服务发送一个待确认消息给可靠消息服务 

（2）可靠消息服务将这个待确认的消息保存到自己本地数据库里，保存起来，但是不发给MQ，这个时候消息的状态是“待确认” 

（3）上游服务操作本地数据库 

（4）上游服务根据自己操作本地数据库的结果，来通知可靠消息服务，可以确认发送消息了，或者是删除消息 

操作完本地数据库之后，会有两个结果，第一个结果是操作失败了，第二个结果是操作成功了，如果本地数据库操作失败了，本地操作会回滚，回滚之后，上游服务就要通知可靠消息服务删除消息；如果本地数据库操作成功了，那么此时本地事务就提交了，接着就可以通知可靠消息服务发送消息 

（5）可靠消息服务将这个消息的状态修改为“已发送”，并且将消息发送到MQ中间件里去 

这个环节是必须包裹在一个事务里的，如果发送MQ失败报错，那么可靠消息服务更新本地数据库里的消息状态为“已发送”的操作也必须回滚，反之如果本地数据库里的消息状态为“已发送”，那么必须成功投递消息到MQ里去 

@Transactional

public void confirmMessage(Long messageId) {

messageDAO.updateStatus(messageId, MessageStatus.SENT);

rabbitmqProducer.send(message);

} 

如果更新数据库里的消息状态报错了，那么消息根本不会投递到MQ里去；如果更新数据库里的消息状态成功了，但是事务还没提交，然后将消息投递到MQ里去报错了，此时事务管理器会感知到这个异常，然后会直接回滚掉整个事务，更新数据库里消息状态的操作也会回滚掉的 

就可以保证说，更新数据库里的消息状态和投递消息到MQ，要么一起成功，要么一起失败，这里这第5个步骤，必须是一起成功或者是一起失败 

MQ，rabbitmq，都有事务消息的一个实现，你可以先去投递一个prepare的消息，接着如果说数据库操作成功过了，那么就commit那个消息发送给rabbitmq，然后如果数据库操作失败了，就通知mq去rollback一条消息 

但是MQ的事务消息最好别轻易用，因为那个性能实在是太低了，吞吐量太差 

所以说我这里给大家介绍的是上面的那种方案 

（6）下游服务从MQ里监听到一条消息 

（7）下游服务根据消息，在自己本地操作数据库 

（8）下游服务对本地数据库操作完成之后，对MQ进行ack操作，确认这个消息处理成功 

现在的MQ中间件，无论是rabbitmq、rocketmq、kafka，都是支持手动ack。如果你是使用的默认自动ack的模式，那么就会导致消息的丢失；现在一般都会用手动ack，当本地操作执行成功之后，再对MQ执行手动的ack确认 

只有当我手动ack确认之后，mq才会删除消息 

如果我还没ack，本地数据库比如操作失败报错了，此时MQ一直没收到ack消息，会怎么样呢？此时MQ会保证重新投递一次消息，可以给其他的消费者实例去消费 

（9）下游服务对MQ进行ack之后，再给可靠消息服务发送个请求，通知该服务说，ok，我这里处理完毕了，可靠消息服务收到通知之后，将消息的状态修改为“已完成” 

可靠消息方案，方案思想，大概就是这样子，分为这么几个组件，整个流程基本上就是这样子，当然还得加一些额外机制进去 

activemq，都可以

### 91_可靠消息最终一致性方案（二）：各个环节消息投递失败的处理预案  

咱们来针对下面9个步骤里的任何一个环节如果失败了，进行一下分析 

（1）上游服务发送一个待确认消息给可靠消息服务 

比如说springcloud服务之间的调用，超时了，网络问题，调用失败，通知失败了 

如果这个环节失败了，也就是上游服务就没法发送一个待确认消息给可靠消息服务，那么无所谓啊，从头儿开始就失败了，数据没有任何不一致吧 

（2）可靠消息服务将这个待确认的消息保存到自己本地数据库里，保存起来，但是不发给MQ，这个时候消息的状态是“待确认” 

可能就是可靠消息服务插入自己本地数据库的时候报错了，不知道是因为什么愿意吧，反正就是报错了 

如果这个环节失败了，也就是说可靠消息服务没有成功的将消息保存在本地数据库，比如自己本地数据库插入报错了，那也没事啊，因为肯定会返回给上游服务一个失败的消息的，此时上游服务就不会继续往下执行了，对吧 

（3）上游服务操作本地数据库 

如果这个环节失败了，上游服务执行本地数据库操作以及发送确认消息这个绑定在一块儿的事儿没干成功，那么也无所谓啊，因为这个时候，本地操作也会回滚，然后也不会继续发送确认消息给可靠消息服务了 

如果本地事务回滚了之后，正常来说就会发送消息通知可靠消息服务，删除那条消息 

其实也不要紧的 

（4）上游服务通知可靠消息服务，可以确认发送消息了 

如果这个环节失败了，那么尴尬死了，上游服务的本地数据库操作都成功了，结果没发个消息给可靠消息服务，什么鬼！那就不会通知下游服务了，直接数据不一致 

问题就大了，也就是说，上游服务通过spring cloud feign调用可靠消息服务，通知确认/删除消息的时候，服务调用失败，异常，因为此时会导致可靠消息服务的数据库里，留着一条状态为“待确认”的消息 

（5）可靠消息服务将这个消息的状态修改为“已发送”，并且将消息发送到MQ中间件里去，这个环节是必须包裹在一个事务里的 

如果发送MQ失败报错，那么可靠消息服务更新本地数据库里的消息状态为“已发送”的操作也必须回滚，反之如果本地数据库里的消息状态为“已发送”，那么必须成功投递消息到MQ里去 

如果这个环节失败了，更加尴尬了，上游服务的本地数据库操作成功了，而且也成功的通知了可靠消息服务了，结果可靠消息服务将消息发送到MQ里去居然失败了，那还是没能成功把消息发出去啊，兄弟！ 

数据不一致了 

分成两种情况来说，如果上游服务操作本地数据库失败了，会通知可靠消息服务去删除消息，此时可靠消息服务删除消息的操作失败了，会导致有问题，有一个消息“待确认”始终停留在可靠消息服务的数据库里 

如果上游服务操作本地数据库成功了，会通知可靠消息服务去确认和投递消息，但是确认消息+投递消息（绑定在一起），现在一起失败了，消息还是“待确认”的状态，而且没有投递到MQ里去，此时也是不对的 

（6）下游服务从MQ里监听到一条消息 

下游服务如果压根儿不知道为啥没有从MQ里消费到消息，那没关系，现在的MQ都很强大的，后面我们给大家讲解，这个MQ如何可靠的投递消息。如果你没消费成功，人家MQ一定会确认给你重试投递的 

因为你是手动ack的，只要MQ没有收到ack的通知，会重新投递消息的 

（7）下游服务根据消息，在自己本地操作数据库 

如果下游服务操作自己本地数据库失败了，那么本地事务就会回滚咯，然后就不会发送ack给MQ，那么MQ会继续不断的重试的，所以也没关系的，这是现在的MQ中间件都支持的功能 

（8）下游服务对本地数据库操作完成之后，对MQ进行ack操作，确认这个消息处理成功 

如果下游服务处理完了本地操作，给MQ发送ack的时候失败了，这个。。。你就得考虑下怎么处理了，其实我们可以考虑将下游服务的本地数据库操作和MQ的ack操作包裹在一个事务里，这样的话呢，如果MQ ack操作报错了，本地事务直接回滚 

这样的话，MQ后续会再次重发消息的，所以没关系 

rabbitmq也好，kafka也好，都是这样子，只要你关闭了自动ack以后，你迟迟的没有进行手动ack，人家会进行消息的重发，成功的手动ack之后，然后才会让mq将这条消息给删除掉不再重新投递 

kafka，手动提交offset，关闭自动提交offset，变成手动提交offset 

rabbimq，关闭自动ack，手动进行ack，就可以了 

就算不用rabbitmq手动ack重新投递消息的机制，只要依靠可靠消息服务的完善，我们其实也可以把这块做的很完善，可靠消息服务本身最重要的一点就是去重新投递消息 

（9）下游服务对MQ进行ack之后，再给可靠消息服务发送个请求，通知该服务说，ok，我这里处理完毕了，可靠消息服务收到通知之后，将消息的状态修改为“已完成” 

如果人家下游服务都ok了，MQ也ack了，结果下游服务发送给可靠消息服务通知，以及修改消息状态为“已完成”的时候，居然出错了，那么就麻烦了，无论是怎么回事，总之在可靠消息服务的数据库里，那个消息的状态是“已发送”，但是不是“已完成”！ 

这样整个系统状态是有问题的！ 

可靠消息服务的数据库里的消息的状态一直是“已发送”，所以这个状态是不对的

### 92_可靠消息最终一致性方案（三）：回调确认以及消息重投机制

20_可靠消息最终一致性方案(1) 

![](C:\Users\zy199005\Desktop\中华石杉\images\java\06\0309201.png)   

如果1和2两个步骤失败了，应该怎么处理呢？这个是你的上游服务自己应该去做的一个重试的机制，如果你发现调用服务失败或者人家给你返回一个处理失败的结果，你可以做几次重试，一般重试几次就可以了 

3这个步骤，如果成功了皆大欢喜，如果失败了，他也会调用可靠消息服务的接口通知一下，让人家删除消息 

所以我们先来看看，45这几个步骤要是失败的话怎么办 

其实这里就需要开发一个上游服务执行状况的回调确认，以及消息重投的机制了，在可靠消息服务里面来开发，具体的实现思路大致如下： 

如果4和5两个步骤失败了，会呈现出的一个场景就是说，消息在可靠消息服务的数据库里的状态是“待确认”，一直是待确认，从来不会改变了 

（1）可靠消息服务得开一个后台线程，专门扫描那些数据库里处于“待确认”状态的消息，同时该消息的创建时间到现在已经超过了比如10分钟了，这个10分钟是你自己设定的一个超时阈值，一般来说，用个几分钟，或者10分钟都行 

（2）发现那种一直处于“待确认”状态的消息，还超过了一定的时间，就认为是超时了 

（3）对超时的消息，需要回调上游服务特意提供的查询这个操作状态的一个接口，然后上游服务自己判断一下这个操作是否执行，举个例子，比如说上游服务本来应该是将订单状态修改为“交易成功”的，此时回调过去以后，上游服务就得自己去判断下那个操作执行了没有，查下那个订单的状态，对吧 

（4）如果操作是还没执行，那么证明是3那个步骤失败了，就是上游服务的本地数据库操作失败了，所以导致消息一直处于“待确认”的状态，此时可靠消息服务需要将这条消息给删除即可 

（5）如果操作是已经执行了，那么说明是4或者5失败了，要不是上游服务没通知到可靠消息服务，要不是可靠消息服务自己没成功投递出去消息，此时可靠消息服务就是再次尝试用一个事务来更新本地消息状态为“已发送”，同时尝试再次发送消息给MQ 

通过上述机制，可以解决4和5失败的情况 

4和5失败结果是一样的，都是导致一条消息状态一直是“待确认” 

（1）如果是上游服务的本地数据库操作失败了，然后发送删除消息的通知给可靠消息服务，结果人家可靠消息服务的4和5失败了

（2）可靠消息服务后台线程过了一段时间，会扫描出来这条待确认的消息是超时了

（3）可靠消息服务会回调上游服务的一个接口，上游服务判断了一下发现说，当时步骤3的本地事务是失败的

（4）可靠消息服务得到了这个回调通知之后，就会将消息给删除 

如果步骤3是成功的 

（1）如果是上游服务的本地数据库操作成功了，然后发送确认消息的通知给可靠消息服务，结果人家可靠消息服务的4和5失败了

（2）可靠消息服务后台线程过了一段时间，会扫描出来这条待确认的消息是超时了

（3）可靠消息服务会回调上游服务的一个接口，上游服务判断了一下发现说，当时步骤3的本地事务是成功的

（4）可靠消息服务得到了这个回调通知之后，就会将消息状态再次改为“已发送”，同时将消息再次投递到MQ里去

如果说可靠消息服务再次尝试删除消息，或者投递消息，还是失败了呢？因为消息的状态只要一直停留在“待确认”的状态，后台线程会不停的扫描到这条消息，然后再次发送请求去回调，然后再次尝试重新处理

### 93_可靠消息最终一致性方案（四）：基于幂等性的消息重投机制完善

20_可靠消息最终一致性方案(2)

![](C:\Users\zy199005\Desktop\中华石杉\images\java\06\0309301.png)   

所有的MQ自己都会确保说让你消费到这条数据，而且尤其是配合我们打开了手动ack的机制 

那么如果678出了问题呢，其实678出了问题啊，因为MQ没有得到ACK，MQ都会自己不断的重新投递的，多次投递这样子 

然后9出了问题，其实数据是对的，只不过可靠消息服务里的消息状态不对而已 

我们可以去考虑说将6789四个步骤如果有失败的话，都不要完全依赖MQ的重投机制，我们可以依赖于自己设计的可靠消息服务的重投机制来做保证其处理 

所以6789出问题，其实消息的状态都是“已发送”，如果是8和9出问题，那么下游数据库的操作已经执行成功了 

（1）可以开一个后台线程，专门监控“已发送”的消息，如果超过了10分钟，那么就需要判定为超时了

（2）这个时候也是需要可靠消息服务再次重新投递消息给到MQ，让下游服务再次去消费

（3）下游服务的接口一定要保证幂等性，数据库操作只能成功的执行一次 

如果是6和7出问题，那么下游服务的本地数据库操作还没执行，此时重新投递了一条消息，那么正常情况下，就会执行数据库操作，反过来通知可靠消息服务变更消息状态为“已完成”，但是如果是8和9出问题，那么实际上此时下游服务的本地数据库操作已经执行成功了，只不过消息状态还是“已发送”而已 

所以此时如果你的可靠消息服务再次投递消息，导致下游服务再次执行了数据库操作，就会导致数据可能出现异常，所以此时需要依靠幂等性的保证，下游服务的本地数据库操作只能成功的执行一次，如果再次重复执行，要通过幂等性保证机制来实现 

但是这里有个问题啊，下游服务是可能接收到多次这个消息的，所以下游服务必须有一个幂等性的保证，保证他的本地数据库操作一旦成功之后，只能执行一次，第二次如果再来执行必须报错，要保证幂等性 

保证幂等性之后，我们可以想象一下，如果是678出了问题，然后反复重试了几次，接着可靠消息服务又重新投递了消息，那么下游服务有幂等性保证，所以就还好，不会造成数据错乱的 

那么如果是9出了问题呢，就是没有通知可靠消息服务更新消息的状态为“已完成”，那么通过重新投递，数据库操作不会再次执行了，但是反而会再次通知一次可靠消息服务，这个消息的状态是“已完成” 

6和7出问题，那么通过上面那套机制，就可以保证下游服务重新执行数据库操作，以及通知变更消息状态为“已完成”；如果是8和9出问题，那么可以通过上面那套机制，保证，数据库操作仅仅执行过一次，而且还重新通知消息状态变更为“已完成” 

通过这套机制，就可以保证整个可靠消息最终一致性，上游服务和下游服务的数据最终一定是一致的，说实在的，这个方案比TCC麻烦多了，要借助MQ什么的，还要考虑各种超时和重试 

而且你考虑一下，你有可能在一个10多个服务链式调用的核心链路场景下，单纯用这个方案来做分布式事务吗，那就成了每个服务都是发送消息出去了，极其的麻烦，麻烦的不行，让人痛苦想死，每个服务都要弄一个回调查询操作是否执行的接口之类的，还要跟MQ重度耦合 

而且从好好的同步服务链式调用，变成了MQ异步调用，时效性，问题排查都极为麻烦，所以这个方案，可靠消息最终一致性方案一般会跟TCC方案结合在一起，来实现复杂场景下的分布式事务 

在我们公司里实践的时候，一般都是会将TCC事务和可靠消息最终一致性方案结合起来使用，对于服务调用链的分布式事务，可以用tcc事务来保证，但是对于一些耗时可以做成异步化的服务的调用，同时也要包裹在事务里的话呢，可以使用可靠消息最终一致性的方案来做，基于MQ来做异步化，但是因为中间加了一个可靠消息服务，可以保证上游服务执行成功了以后，一定会保证下游服务也会执行成功

### 94_可靠消息最终一致性方案（五）：RocketMQ对分布式事务的支持介绍 

如果使用rabbitmq、activemq、kafka这类的MQ的话呢，你的可靠消息服务是要自己来实现的，但是自己实现也不难，而且可以自己深度定制和掌控 

阿里的RocketMQ以前的老版本就是支持我们之前说的那套类似的机制的，只不过可靠消息服务干的活儿被RocketMQ给干了，但是后来RocketMQ又阉割掉了对分布式事务的支持，导致很尴尬，大家又不能基于RocketMQ直接实现之前说的那套机制了，还是得自己开发可靠消息服务 

但是最近2018.08，RocketMQ发布了4.3.0版本，开源了分布式事务的支持，所以这个就可以直接基于RocketMQ来实现这套方案了 

他的大概思路如下 

（1）上游服务发送一个prepare消息，可以认为是一个待确认消息到RocketMQ

（2）RocketMQ会在自己内部保存这条消息，然后返回一个状态给上游服务

（3）接着上游服务执行本地事务

（4）如果失败了就发送rollback给RocketMQ，RocketMQ会删除掉那条消息，如果成功就发送commit给RocketMQ

（5）rocketmq会根据状态来处理消息，如果是rollback就删除消息，如果是commit就将消息标识为可以被下游服务消费

（6）下游服务消息消息

（7）接着下游服务会消费这个消息，执行本地事务

（8）下游服务然后返回ack给rocketmq，如果消费失败，或者是本地事务执行失败，或者ack发送失败，那么rocketmq都会有自己的重试策略，重发消息

（9）rocketmq如果能够成功的收到ack消息就会将消息删除 

但是如果上游服务本地事务执行失败，也没发送rollback或者commit给rocketmq呢？那rocketmq会有异样的啊，一个检查消息状态超时的机制，发现消息超时了，就回调上游服务的一个接口，上游服务自己负责检查这个操作是否执行，如果没有就要执行，然后发送commit或者rollback给rocketmq；如果执行过了，那就执行发送commit给rocketmq好了，这个回调的机制是一样的 

那下游服务只要自己保证了幂等性就可以了 

但是这里我们就不带着大家来使用RocketMQ了，因为原理其实是类似的，何况RocketMQ之前很长一段时间都没开源这个分布式事务的解决方案，大量的实践里，我们还是自己开发可靠消息最终一致性方案的 

而且为了大家深入理解里面的原理，这次课程实战还是自己来手工开发一下整套方案吧，RocketMQ的支持大家其实暂时了解下就行了 

我们后面还会有专门的RocketMQ课程，剖析RocketMQ的源码，那个时候会带着大家来实战这块的分布式事务方案，以及研究内部的实现源码的 

### 95_可靠消息最终一致性方案（六）：基于RabbitMQ的事务方案设计 

如果在这个方案里，使用rabbitmq的一些细节 

**1、下游服务的ack** 

其实用rabbitmq在这里还是比较简单的，主要就是用一个ack机制就好了，因为ack之后，就可以保证只有你处理完之后才会ack掉这条消息，然后的话呢，如果你没ack，rabbitmq会给你重新投递消息 

其他的没什么特殊的了 

如果是自动ack，那么rabbitmq只要一旦投递出去这个消息给消费者，立即就删除这条消息了，要是你消费者没处理成功，这条消息就丢了，这种的话主要是针对的那种对消息少量丢失不太敏感的，然后要求高吞吐量的场景 

但是可以使用手动ack的方式只有当你手动ack的时候，rabbitmq才会认为说你已经消费成功了，就会删除那条消息，官网给出的示例如下所示： 

```
boolean autoAck = false;
channel.basicConsume(queueName, autoAck, "a-consumer-tag",
     new DefaultConsumer(channel) {
         @Override
         public void handleDelivery(String consumerTag,
                                    Envelope envelope,
                                    AMQP.BasicProperties properties,
                                    byte[] body)
             throws IOException
         {
             long deliveryTag = envelope.getDeliveryTag();
             // positively acknowledge a single delivery, the message will
             // be discarded
             channel.basicAck(deliveryTag, false);
         }
     });
 
channel.basicReject，是说，消息没处理成功，但是还是给删除掉吧
 
channel.basicNack，是说，消息没处理成功，但是你给我让这个消息重新排队来进行投递，可以投递给其他消费者实例来处理
 
如果说你对本地数据库的操作报错了失败了，此时你就可以使用basicReject这个方法，通知rabbitmq重新投递一次消息；也可以通过这个方法通知rabbitmq就不要自己重新投递了，直接标识消息处理失败，删除就可以了
 
boolean autoAck = false;
channel.basicConsume(queueName, autoAck, "a-consumer-tag",
     new DefaultConsumer(channel) {
         @Override
         public void handleDelivery(String consumerTag,
                                    Envelope envelope,
                                    AMQP.BasicProperties properties,
                                    byte[] body)
             throws IOException
         {
             long deliveryTag = envelope.getDeliveryTag();
             // requeue the delivery
             channel.basicReject(deliveryTag, true);
         }
     }); 
```

所以说，如果下游服务的本地数据库操作成功了，那就ack，否则处理失败了就nack，就可以了，这样的话就会不断的将消息重新入队让其他消费者实例来消费和处理

当然其实还有一种做法也是可以的，因为考虑到了可靠消息自己就会进行重新投递，所以如果操作数据库成功了就ack，否则就reject，都会删除掉消息的，但是如果操作数据库失败了，那么就不会去通知可靠消息服务了

此时可靠消息过一段时间会感知到，然后会再次重新投递消息，也可以用这种方式来做

如果本地数据库操作成功了，就ack给rabbitmq删除消息；如果本地数据库操作失败了，就reject给rabbitmq删除消息；不需要rabbitmq自己重投递消息

**2、上游服务的confirm** 

有一种可能，在5这个步骤里，发送rabbitmq消息，看起来是成功了，其实消息并没有成功的投递到rabbitmq里去，是有这种可能的，同时你以为成功了，没有报错，消息可能在网络传递中丢掉了 

你本地的消息状态也变更为“已发送了”，结果消息并没有投递到mq里去，下游的6789四个步骤没有执行 

```
channel.confirmSelect();
//发送一条消息
if (channel.waitForConfirms()) {
 
} else {
 
} 
```

这套机制我不打算带着大家来用，因为有点画蛇添足，如果你在这个步骤5里面，发送mq出去，你以为成功了，消息状态是“已发送”，结果消息在rabbitmq里面丢了，可靠消息服务，可靠的，他会发现已发送的但是超时的消息

其实自己就会重新再次投递一次消息到rabbitmq里去了

你呢，将你的可靠消息服务的机制设计的越是健壮，越是依赖你的可靠消息服务，而不是依赖MQ，就越好，最好对MQ的依赖是非常的轻量级的

这样的话，出现任何的问题都在你的可控范围之内，你可以去完善和升级你的可靠消息服务，解决你遇到的一些问题，反之，如果你太过于依赖MQ了，可能导致MQ里的而一些bug，会导致你束手无策，无法解决

### 96_可靠消息最终一致性方案（七）：流量充值服务与运营商BOSS系统调用服务

20_可靠消息最终一致性方案(3)

![](C:\Users\zy199005\Desktop\中华石杉\images\java\06\0309601.png)

 

在流量充值中心的项目案例中，最最典型的可以用可靠消息最终一致性方案的，其实就是调用运营商BOSS系统的案例，你的系统调用远程的第三方的运营商BOSS系统去进行流量充值，其实是很耗时的，完全可以异步化 

用户是可以支持说，你付钱了成功了，但是流量可能要等个10分钟，30分钟才能充值到账，大家都是认可的 

但是呢因为调用运营商BOSS系统这个事情还是得包裹在一个事务里面，所以这块东西还是需要去使用可靠消息最终一致性方案的 ，就是要保证说，流量充值服务自己本地都ok了，远程的运营商BOSS系统也必须被调用成功 

我们可以剥离出来一个运营商BOSS系统调用服务，也是我们自己开发的

### 97_完成可靠消息最终一致性方案中的RabbitMQ的相关准备 

从这一讲开始，我会开始来尽量的教会大家，渔 

我会带着大家来学习，如何自己根据现有的一些技术资源，官方文档，来快速入门一个新技术，以及如何通过官方文档的快速阅读，系统性的学习一个新技术 

很多视频课程，都是照着官方文档讲，讲的还不好，你从他那里学到的还是二手的技术，他可能咀嚼过一次之后教给你的 

最吓人的一点，是你学了一个视频课程，你就只能按照视频课程里的东西来操作和开发，那就完蛋了，你学到的就是一条鱼，不是捕鱼的技巧，想学的都是捕鱼的技巧，在课程里着重的带着大家来学习方法 

先在要本地的windows上部署来RabbitMQ作为我们的开发环境 

在安装rabbitmq之前，先要在windows上安装一个符合要求的erlang（erlang是rabbitmq的开发语言，编程语言，我们如果用java来开发，是不是要在windows上安装JDK，JRE，erlang这种编程语言，你得在windows上安装erlang） 

人家也给你提供了windows操作系统上的一键式安装erlang编程语言的安装程序 

我们就进入了erlang编程语言的官网中去了 

我们应该安装哪个版本的erlang呢？我带着大家通过分析官网，来学习如何入门和使用一个技术，其实大家可以看到整个捕鱼的思路 

我给大家写好一套笔记，大家就按照这套东西来做，你学到了鱼，但是你没学到渔 

有些生僻单词的发音，我会根据我的英文的经验来发，其实很多发音的话呢，我可能是有问题的，facade 

通过分析这个官方文档，我们就可以知道，rabbitmq .37.7这个版本，是用erlang的21.0.x系列的最新的版本就可以，在文件IO读写性能上有提升，而且对TLS的支持是最好的，人家也是建议你用这个版本的 

在erlang的官网，我们可以看到最新的版本就是erlang 21.0.x系列，我们直接找64位的windows安装程序即可，21.0.1版本的windows安装的二进制程序包 

说实话，你如果是入门一个技术的话，严格的按照官网一步一步来是没问题的 

**1、安装erlang** 

http://www.erlang.org/downloads 

点击：[OTP 21.0.1 Windows 64-bit Binary File ](http://erlang.org/download/otp_win64_21.0.1.exe)，进行下载

右击otp_win64_21.0.1.exe，以管理员权限来运行，必须要这么来运行，选择一个安装目录，完成erlang的安装 

**2、安装和运行rabbitmq** 

http://www.rabbitmq.com/install-windows.html#run-windows 

下载：[rabbitmq-server-3.7.7.exe](https://dl.bintray.com/rabbitmq/all/rabbitmq-server/3.7.7/rabbitmq-server-3.7.7.exe) 

rabbit-server-3.7.7.exe，这个东西一看就是在windows上的一个一键式安装rabbitmq的安装工具，双击他，会显示一个界面，然后下一步下一步下一步，就可以通过这个东西装好rabbitmq 

双击：[rabbitmq-server-3.7.7.exe](https://dl.bintray.com/rabbitmq/all/rabbitmq-server/3.7.7/rabbitmq-server-3.7.7.exe)，直接会完成rabbitmq的安装，将其安装为windows的一个服务，而且会直接以默认的配置来启动rabbitmq 

刚开始使用用默认的环境变量来运行rabbitmq就ok了，但是你也可以定制化修改rabbitmq的环境变量，对于我们来说，刚开始使用，其实不用调整他的环境变量 

**3、rabbitmq服务的管理** 

rabbitmq作为一个windows服务默认就安装完就启动了，后面如果停止、重启rabbitmq服务，直接在我刚才给大家演示的那个windows服务界面就可以操作 

防火墙和其他的一些安全工具可能会阻止rabbitmq绑定到端口上去，所以我的windows默认是把防火墙关闭的，不关闭的话，可能会有问题 

如果要通过命令来停止rabbitmq的broker节点（在MQ消息中间件里，通常将一个消息中间件的节点，称呼为broker），rabbitmq安装目录的sbin目录内的rabbitmqctl.bat，来停止broker或者是检查状态 

rabbitmqctl.bat stop

rabbitmqctl.bat status 

我们找不到rabbitmq的日志文件存放的目录，明显不是在rabbitmq的安装目录中的，此时怎么办呢？渔，我们去找找readme-service.txt，里面肯定会有一些信息的 

C:\Users\lixue\AppData\Roaming\RabbitMQ 

默认情况下，给放到了C盘下面去了，我们会教大家如何来设置这个目录 

默认情况下，rabbitmq的日志，是不断的写入一个日志文件中的，默认是不会新建更多的日志文件的，如果你觉得日志文件内容太多了，要换一个新的日志文件，使用下面的命令 

rabbitmqctl.bat rotate_logs 

**4、通过管理后台来访问rabbitmq** 

15672是默认的http接口的端口，以及管理后台界面的端口 

rabbitmq默认会创建一个用户，guest，密码也是guest，如果是在本机来使用管理后台，可以用guest用户 

rabbimq-plugins.bat enable rabbitmq_management 

http://localhost:15672/

### 98_完成可靠消息服务的开发（一）：基于spring cloud搭建服务 

整个这个技术架构，最好是不要跟某种MQ的高阶特性重耦合，因为那样的话会导致你以后如果要切换MQ的话就会很麻烦，有大量的重构要做 

最好还是将业务逻辑放在我们自己开发的可靠消息服务里面去 

删除消息，最好是不要物理删除，一般最好是做成逻辑删除，这样的话呢，就可以后面追溯一些消息的历史操作记录

### 99_完成可靠消息服务的开发（二）：完成正常流程下的接口与功能开发 

我们就是把各个接口在正常流程下的功能逻辑，无法就是更新数据以及发送消息到MQ，给做好 

<dependency>

<groupId>org.springframework.boot</groupId>

<artifactId>spring-boot-starter-amqp</artifactId>

</dependency>

 

spring:

rabbitmq:

host: localhost

port: 5672

username: guest

password: guest

 

@Configuration

public class RabbitConfig { 

@Value("${spring.rabbitmq.host}")

private String host;

@Value("${spring.rabbitmq.port}")

private int port;

@Value("${spring.rabbitmq.username}")

private String username;

@Value("${spring.rabbitmq.password}")

private String password;

 

public static final String EXCHANGE_RELIABLE_MESSAGE = 

"my-mq-exchange_RELIABLE_MESSAGE";

public static final String QUEUE_RELIABLE_MESSGE = 

"QUEUE_RELIABLE_MESSAGE";

public static final String ROUTINGKEY_RELIABLE_MESSAGE = 

"spring-boot-routingKey_RELIABLE_MESSAGE";

 

@Bean

public ConnectionFactory connectionFactory() {

CachingConnectionFactory connectionFactory = 

new CachingConnectionFactory(host,port);

connectionFactory.setUsername(username);

connectionFactory.setPassword(password);

connectionFactory.setVirtualHost("/");

connectionFactory.setPublisherConfirms(true);

return connectionFactory;

}

 

@Bean

@Scope(ConfigurableBeanFactory.SCOPE_PROTOTYPE)

public RabbitTemplate rabbitTemplate() {

RabbitTemplate template = new RabbitTemplate(connectionFactory());

return template;

}

 

@Bean

public DirectExchange defaultExchange() {

return new DirectExchange(EXCHANGE_RELIABLE_MESSAGE);

}

 

@Bean

public Queue queueReliableMessage() {

return new Queue(QUEUE_RELIABLE_MESSAGE, true); 

} 

 

@Bean

public Binding binding() {

return BindingBuilder

.bind(queueReliableMessage())

.to(defaultExchange())

.with(RabbitConfig.ROUTINGKEY_RELIABLE_MESSAGE);

}  

}

 

@Component

public class MsgProducer implements RabbitTemplate.ConfirmCallback { 

private RabbitTemplate rabbitTemplate; 

@Autowired

public MsgProducer(RabbitTemplate rabbitTemplate) {

this.rabbitTemplate = rabbitTemplate;

rabbitTemplate.setConfirmCallback(this); 

}

 

public void sendMsg(String content) {

CorrelationData correlationId = new CorrelationData(UUID.randomUUID().toString());

rabbitTemplate.convertAndSend(RabbitConfig.EXCHANGE_RELIABLE_MESSAGE,

RabbitConfig.ROUTINGKEY_RELIABLE_MESSAGE, content, correlationId);

}

 

@Override

public void confirm(CorrelationData correlationData, boolean ack, String cause) {

if (ack) { 

} else { 

}

}

}

 

@Component

@RabbitListener(queues = RabbitConfig.QUEUE_RELIABLE_MESSAGE)

public class MsgReceiver { 

@RabbitHandler

public void process(String content) { 

} 

}

### 100_完成可靠消息服务的开发（三）：操作状态回查以及待确认消息重投 

这块的话呢，我们要用spring boot结合调度来做，我们要做一个后台自动调度每隔5分钟运行一次的一个后台线程，自动来扫描，启动调度相关的一些配置 

@EnableScheduling

@Component

@Scheduled(fixedRate = 1 * 60 * 1000) 

去查询处于待确认状态，同时创建时间超过10分钟的消息，认为是超时

### 101_完成可靠消息服务的开发（四）：已发送消息重投功能的开发

### 102_在流量充值服务内完成可靠消息最终一致性方案相关部分的开发

### 103_将运营商BOSS系统调用服务单独剥离成一个独立的服务 

如果你的用到这个方案的分布式事务的场景不多，业务比较简单，并发量也不是很大，其实说实话，这套方案可以满足大部分的中小型公司的需求了，但是当然了，如果你要在公司里用这个方案，其实你肯定要考虑到你的可靠消息服务如何做才能保证各个团队，各个系统，如果要接入你的可靠消息服务来传递事务消息 

你如何做到非常的便捷，透明，简单配置一下就可以了 

如果你们公司用的MQ恰巧就是RocketMQ，那走运了，你都不需要自己做可靠消息服务了，只要依靠RocketMQ的分布式事务支持的功能个，原理跟这个是一样的，就ok了，RocketMQ对分布式事务的支持，是高并发、高吞吐量、高性能、高可用性 

RocketMQ这块是怎么做的，我们后面在RocketMQ课程里专门去讲解，分析里面的实现源码

### 104_为可靠消息最终一致性方案完成运营商BOSS系统调用服务的开发

### 105_测试正常情况下可靠消息最终一致性方案的流程运行 

一次充值的请求，会有一个唯一的流量充值的串号 

之前已经测过的那块逻辑就不用去关注了，那块肯定是没问题了，我们现在主要是测试调用boss系统，可靠消息最终一致性方案这块就可以了，这块要好测的多，他的原理远远没有tcc事务的底层源码等那么复杂

### 106_测试上游服务各种故障时的可靠消息最终一致性方案的容错性

### 107_测试下游服务各种故障时的可靠消息最终一致性方案的容错性 

1、缺陷 

可靠消息服务这块，这块东西，大量的基于mysql来存储了message消息，第一个问题是并发的问题，如果这个消息发送的特别频繁，每秒钟有几万个消息，mysql绝对就扛不住了，你要不就是分库分表，用多台数据库服务器来支撑高并发的写入，要么就是使用NoSQL类的存储 

举个例子，比如可以使用redis、zookeeper、hbase 

数据量可能会太大了，并发量很大，消息的增长绝对是大量的，每秒钟几万个消息，一分钟就上百万消息，10分钟，上千万消息，1小时，上亿，1天，几十亿数据量 

定时的清理数据，人家过来只要确认消息成功了，就立马删除，不要保存太多的数据 

2、适用场景 

大部分的中小型公司，大公司，也可以用，不是那么多的公司都有所谓的高并发，其实主要还是针对分布式复杂的业务系统，保证分布式事务的最终一致性，那么其实哪怕就直接用我们的这个方案也是ok的 

用到这个方案的只不过是核心系统的里少量场景的话 

3、如果在公司里要大面积使用 

现在是直接在代码里面写死了，直接就是回调流量充值服务，其实如果很多其他的服务要接入你的话，你可能得做一个界面，对每个服务分配一个AppKey，每个服务的AppKey设置一个回调接口 

然后在发送message的时候，标识一下是哪个服务发送过来的 

如果要回调服务，那么就根据message里的AppKey以及配置的回调接口，通过一些反射或者别的什么，反过来就调用发送这个message的服务的指定的一个接口 

4、分布式事务：慎用慎用 

你为了解决分布式事务的问题，引入了一大堆的技术，XA、TCC、最终一致性，结果反过来那些技术的复杂性，反而导致你的系统很容易出其他的一些问题，最后分布式事务没问题，反而是分布式事务技术本身一大堆的bug要你去查 

性能比较好，不要轻易的出现网络调用超时，除了资金、交易相关的核心业务逻辑，其他的普通的业务逻辑其实都无所谓，比如说电商里面，审核出库单，商品出库，这些复杂又非核心的业务逻辑，99.99%的场景下不会报错就可以了 

没必要大面积的引入分布式事务，非核心的场景，只不过是业务复杂，出错了，手工修复数据，可能一个月就出几次问题，大不了派个小弟，洗个数据，手工修复一下数据，就可以了，出问题的几率很小 

资金、交易、订单、支付，绝对不能出错的一些，必须有什么高大上的技术都要投入去使用，投入重兵和资源攻克技术难题，保证那些核心环节的稳定性

### 108_不是事务的事务：最大努力通知方案的整体架构设计

21_最大努力通知方案

![](C:\Users\zy199005\Desktop\中华石杉\images\java\06\0310801.png)      

咱们整个分布式事务课程的最后一个方案 

流量充值中心，他里面完成一个流量充值业务逻辑中有一个步骤，是通过消息服务发送一个短信通知，这个过程发短信，耗时，而且也不要求立马立刻就要发出去，其实流量充值完毕之后，隔了个5分钟，10分钟短信发出去，也ok 

非常适合在分布式事务里面包裹一个最大努力通知方案 

这个方案其实极为的简单，他适合的就是包裹在某个事务里的非核心的操作，而且比较耗时可以异步化的操作，常见的有啥子呢？比如说增加个积分啦，发放个优惠券拉，之类的，但是这种你可以放到TCC，也可以放到最大努力通知里去，看你们的业务定义了 

但是有一种绝对是非常不核心的，就是发送短信、邮件这个事儿，比如说交易成功之后，发个短信、微信、邮件通知一下你，那就别提了，直接走最大努力通知吧，这个方案顾名思义，尽可能保证成功，但是不能完全保证。要是失败了，多试几次，尽量试下，不行的话，你也别别勉强我，就这么回事儿了 

最大努力通知方案，其实非常简单，他的核心在于最大努力通知服务，这个服务的核心在于根据上游服务定义的重试规则对调用事变的消息，重试几次，最大努力尝试调用成功，跟可靠消息最终一致性的方案，区别在哪儿呢？ 

可靠消息服务会保证，如果你的下游服务执行不成功，永久性不停的重试，重试重试重试，直到有一天你下游服务执行成功了为止，最终一致性，但是中间可能有很长的一段时间数据是不一致的 

两个方案都很简单，tcc事务的底层源码和底层原理 

其实就是个上游服务，下游服务，以及一个最大努力通知服务，核心的点就在于这个重试的规则的制定，你要支持几种规则： 

（1）失败了之后，按照一定的间隔，连续重试指定的次数，比如失败之后，每隔5分钟重试一次，连续重试10次

（2）失败了之后，每次间隔都增加个5分钟，连续重试5次，举个例子啊，第一次重试是5分钟以后，第二次是10分钟以后，第三次是15分钟以后，第四次是20分钟以后，第五次是25分钟以后 

为啥要支持上游服务自己在发送消息的时候定义重试规则呢？因为很简单啊，不同的业务场景可能重试的要求不同，得由上游服务来定义，有些人觉得应该这样，有些人觉得应该那样，那你自己定义不就得了 

最大努力通知服务，如果一次请求没成功，那么就将消息存到数据库里去，然后记录下来他的重试规则，以及上一次重试的时间，是第几次重试，然后搞一个后台线程不停的扫描，每次扫出来就根据规则去重新调用下游服务 

如果超出了规则范围之外还是不行，就状态标记为：失败，就ok了

其实非常简单的，就这么回事儿

### 109_从流量充值中心内剥离出来独立的消息服务

### 110_为该方案完成独立的最大努力通知服务的搭建

### 111_完成最大努力通知服务的重试相关业务逻辑的开发 

无非包含三个东西，一个是电话号码，一个是短信内容，一个是重试规则 

{

 “type”: 1,

 “retryInterval”: 10,

 “maxRetryCount”: 3

} 

每隔10秒重试一次，重试3次 

{

 “type”: 2,

 “retryInterval”: 10,

 “maxRetryCount”: 3

} 

第一次重试是10秒以后，第二次是20秒，第三次是30秒 

### 112_在流量充值服务中完成基于最大努力通知方案调用消息服务的逻辑

### 113_基于bytetcc源码调试解决一个spring cloud找不到服务server的报错 

通过源码的调试，发现了大概问题是出在哪儿 

报的异常是什么呢，就是说可靠消息服务找不到server，但是这个东西只是一个表象，我告诉大家为什么会报这个异常，通过分析源码来看，基于源码来解决这个问题，本来咱们这个课程都快结尾了，但是遇到这么个梗，也挺有意思的 

bytetcc重写了spring cloud ribbon里面的rule，所以负载均衡的刷算法是bytetcc框架去实现的，就是说，本来直接返回可靠消息服务的机器就可以了，结果人家走了一些拦截器 

​               RemoteCoordinator resource = request.getTargetTransactionCoordinator();

​               RemoteResourceDescriptor descriptor = new RemoteResourceDescriptor();

​               descriptor.setDelegate(resource);

​               descriptor.setIdentifier(resource.getIdentifier()); 

​               boolean participantEnlisted = transaction.enlistResource(descriptor); 

出问题的代码是在这里，RemoteResourceDescriptor，他在这里其实是在调用可靠消息服务之前，就尝试将可靠消息服务封装为一个远程的资源描述符，对这个东西，将其enlistResource，大家还记得一点儿吗？ 

try阶段只要是你调用过的服务，都会在一个resourceList的地方，大家其实在这里就可以看到什么时候调用服务会将服务放入resourceList呢？就是在你调用服务的时候，不是会走ribbon负载均衡选择一个server出来 

在这时候，bytetcc就会将这个服务放入resourceList，enlistResource操作 

但是可惜的是，我们的这个可靠消息服务压根儿就没有按照bytetcc事务框架来执行，他其实就是一个普通的这么一个服务，所以说这里就尴尬了，肯定会报错，肯定会有异常的 

通过源码我们就看到了，我们在bytetcc框架内，在confirm逻辑中，我们去调用了一个远程的服务，在对那个远程服务spring cloud ribbon负载均衡获取一个server的时候，人家会去执行叫做enlistResource的操作 

但是此时分布式事务的状态是不对的，不是ACTIVE状态，所以直接报错，导致获取server返回的是个null，就说可靠消息服务找不到server 

主要原因就是在于，我们是将三个分布式事务的方法代码混一块儿了 

其实我们本来就应该给他拆分成3个接口 

在一个bytetcc分布式事务的confirm逻辑里面调用了一个非tcc的一个接口，所以就报错了，enlistResource()，在这个方法里，会判断事务的状态，你这个时候已经进入了confirm阶段了，所以在这里分布式事务的状态肯定是不对的 

所以bytetcc框架就会报错 

然后就会导致spring cloud ribbon没有获取到server

### 114_整体对最大努力通知方案进行测试以及确保重试机制生效 

（1）Spring事务框架

（2）XA分布式事务：单系统多数据库的场景

（3）TCC分布式事务：解决的就是大多数的分布式事务场景，服务链式调用

（4）可靠消息最终一致性方案：重要必须执行成功，但是耗时，可以接受异步化

（5）最大努力通知方案：耗时，可以接受异步化，而且可有可无，可以接受失败不成功 

如果遇到那种多个方法要结合起来使用的话，尽量不要将多种方案的代码混在一起，因为这样子会导致很多的混乱 

可以拆分成多个接口，一个接口开启一个tcc事务；另外一个接口开启一个可靠消息最终一致性事务；再来一个接口，开启最大努力通知事务 

结合你们公司自己的项目的业务，自己思考，如何运用到你们公司里去，实践一下 

分布式事务这块，你的功底和掌握已经很扎实了 

读过、读懂源码是如此的重要，可以让你在行业里直接进入top 5%的高手的行列

 

  

 