# 06_分布式架构之大型电商系统中的项目实践

## 01_Spring Cloud从0基础入门到精通核心组件源码

### 001_从项目阶段一到项目阶段二的阶段性总结 

首先，咱们的项目阶段一已经干完了，当时咱们模拟的就是你是一个技术leader，带着4个弟兄一起，做出来了电商系统v1.0的第一个版本，非常雏形的一个版本。那个v1.0版本，其实不是给人用的，也不是用来内测的，因为还达不到内测的程度。那个版本，实际上是一个雏形版本，用来给老板和投资人看的。大公司里面的话，你做出来的这个第一个版本，也不是给别人用的，其实是用来给公司的高层看的，让人家看看先。 

大公司，孵化很多新的项目，从已经有的成熟团队中，拉出来一批人，比如从后端、前端、测试、客户端、UI、产品，内部创业团队，内部孵化团队，内部新产品团队，后端就四五个人，前端就两三个人，客户端就两三个人，测试一两个人，UI就一两个人，产品就一个人。20人以内的团队。 

对标我们项目阶段一的时候我们的那个整体项目的背景和团队的规模。 

1个月的时间，做各种调研，产品经理，抄袭一下竞争对手的产品设计，规划一下产品的roadmap，设计第一个版本，v1.0，一般来说都是极其阉割的版本，就仅仅包含了这个产品必不可少的最核心的一些功能。 

第1个月的时候，后端、前端、客户端、UI，因为比如说我们之前是做搜索引擎系统的，我们开始转型转方向，开始来做这个电商系统，所有人对这块业务不是专家，都是从0开始做。技术人员全部需要去熟悉业务，体验竞争对手的产品。主要是买一些书，会上网查阅一些资料，看看竞争对手的一些系统设计相关的报道，体验人家的产品。 

3个月以内的时间，1个月~2个月的时间，产品经验v1.0的需求文档已经出来了，所有技术开始做设计、研发、测试、部署上线。 

就开始从1到10的这么一个过程，6个月~12个月。用最快的速度，追平竞对。分成两个阶段，头6个月，追平竞对，就是比如说你现在要做一个电商系统，所有的功能，要跟竞争对手几乎差不多，起码达到人家的功能的70%~80%左右。 

后6个月，一旦追平了竞对，大规模铺开推广，公司会给你派驻各种营销、推广、导流，大量的用户开始涌入。如果是一个大公司内部孵化的产品，在后6个月大推的时候，搞到几百万用户，没什么问题，小千万用户，日活用户量都上百万，高峰期60万用户同时在线使用，20次pv，1200万pv，1小时，3600秒，高峰期每秒很快就上一两千个请求，甚至是两三千个请求。 

从1到10的这么一个过程，对标着项目阶段二、项目阶段三、项目阶段四 

就开始从10到100，漫长的过程，可能要持续几年甚至十年，上亿，几亿，几万qps，几十万qps。从阶段六~阶段十，都是对标从10到100的过程。 

你还没到100，但是已经到了60,70，80，此时你的公司积累了很深的技术实力，一般来说，京东云，网易云，百度云，阿里云，腾讯云，360云，国内最大的这些互联网公司，因为自己公司有很大的用户体量和技术挑战，然后自己的技术积累的非常扎实，在自己的技术积累的很扎实之后，就会转向开始对外输出自己的技术能力，开始各种云服务。 

搞Java的架构师来说，IaaS、PaaS、SaaS。IaaS比较偏向于特别特别底层，不是搞java的人干的，机器、网络、磁盘、计算。PaaS，我们可以到时候去看看，我们可以提供一些基础技术平台，SaaS开箱即用，标准化、统一化、透明化、按需付费、按需定制功能，SaaS应用。 

就是说，先有这个个东西出来，大家先看一眼，大体的采购、仓储、库存、用户注册登录、浏览商品、购物、退货，一些电商的核心流程都走通。 

接着其实就进入了从1到10的阶段了，这个阶段是要干啥呢？其实就干一个事儿，追平竞对。因为你做任何业务，肯定不是你第一个干的，肯定你是有行业里的竞争对手的，那么此时你就是要在功能层面，跟你的竞争对手，哪怕是抄袭人家，也得抄的差不多。对吧。所以这个时候就是要追平竞对的系统功能。 

这个阶段，公司里会组建一个10人+的产品团队，这帮产品经理，每个人会负责一块儿东西，比如有人负责订单，有人负责商品，有人负责仓储，有人负责采购，有人负责会员，然后他们就没事儿就去琢磨竞对的电商网站的功能，然后直接抄过来。同时有些PM是之前在这个领域就有一定的经验的，比如库存啥的，那么他们都不用抄袭别人，就是靠自己的经验，就可以去设计产品。 

然后这个时候，技术团队可能会快速膨胀到50人~100人+，这里面，后端团队占个一半，20多人，是妥妥的。你作为一个技术leader，马上手下可能就是有20多人了，此时你肯定也是分为多个小team，每个小团队在3~5人之间，然后一个小团队负责一个或者多个子系统，或者是中心。比如说，有个3人的小团队，专门负责订单中心这块的开发；然后有一个4人的小团队，专门负责商品中心这块的开发。 

你就是一个技术leader，20多人~四五十人不等，不断的在招人 

架构出来一整套标准和规范的微服务架构，让手下的几十个弟兄，能够以最高的效率支持业务和版本的快速迭代。。。。

### 002_没有服务化的复杂单块系统有哪些问题？

几十个人开发一个复杂单块系统，问题在哪儿呢？ 

**1、代码重复问题** 

但是这个时候就会出现一些问题了，首先第一个问题就是代码的复用性问题。 

你看，人多了以后，可能相同的一些基础性的代码，每个业务都会自己重复的写。给你举个例子吧，订单中心是几个同学负责，商品中心是几个同学负责。比如说订单中心现在要查询商品的数据，但是现有的商品服务接口没有可以满足需求的接口。那么如果是项目阶段一里面，就5个人，大家坐一块儿，你说一句，人家就给你写好了。 

问题是，现在20多个人啊，分成几个小team，交流协作是很困难的，你以为呢。你现在找人家给你写个接口，人家手头有活儿，得给你拖着，而且可能还不太愿意做这个东西，这个时候你绝对着急了，你作为一个订单中心，想，反正就一个库，表就在那儿，就啥大不了的，我直接写个SQL查出来我要的商品数据不就得了。 

得，订单中心自己干了这个事儿，自己查商品了。 

码农，习惯，宁愿自己干，也不愿意去沟通，找别人帮忙。 

然后呢，要是WMS中心、会员中心，啥啥中心的，都干这事儿，会怎么样？全部乱套了，类似的商品查询的代码，将会出现在各个中心的DAO和Service里，重复代码到处都是。 

重复代码，人越多，沟通成本越高，协作成本越高。码农，一般如果能自己干活儿，他就不会去找别人去干。20人+的团队，10人-的团队这个问题还好一些。20人+的团队，分成了四五个小团队，这四五个小团队，就会形成自己的小圈子，平时中午吃饭都是小圈子自己去的。小团队A里面的一个人，小团队B里面的一个人，关系可能不会太好，中国的码农，性格特点。尤其你找别人说个事儿，帮个忙， 都不太方便，人家如果让你等，你就不耐烦了，SQL，接口不要了。 

绝对会出现一大堆的重复代码。 

**2、多人协作效率问题** 

你看看，20多个人，一起改动一个10万+行代码的系统，不断的快速的在里面添加代码。最后会有哪些问题，咱们来想一下。从源头开始。 

你说所有人都在一个工程里编码，common。然后大量的修改代码，说不定改着改着就串到别人那儿去改一下了，而且有些公共的基础代码，可能所有人都会胡乱修改，谁都保证呢，是不是。然后在提交代码merge的时候，绝对是大量的冲突，这个想都不用想。 

超过5个人修改一份代码，冲突就很常见了，修复代码冲突的时候，一般要好几个人坐在一块儿，看着那个代码，仔仔细细的解决冲突。 

大块的系统，商品中心，订单中心 

接着不就是集成测试、QA测试了么，这个时候你的代码依赖了别人的代码，有没有想过一个问题，部署测试环境的时候，都是有一整套部署步骤的，可能别人的代码依赖了MQ、Redis，甚至是Cassandra等乱七八糟的基础设施，你可能都不懂那些东西。 

那么问题来了，你就修改了你负责的比如一个商品中心，一小块代码，然后你把一个大块头的单块系统部署到了测试环境，结果人家的模块依赖了cassandra，kafka，因为一些环境的原因，报错了，或者出了问题，哪儿哪儿卡住了，启动不了，这个时候怎么办？ 

也许人家的模块每次部署之前都要先跑个脚本初始化一下数据，你嫩，压根儿不知道这事儿。所以胡乱部署，结果测试环境的系统启都启动不了。你就得找其他的很多人，过来看，系统启动不了。 

完了到部署上线的时候，更是这样了，可能人家的模块每次上线之前，都要做点什么操作，比如说检查个日志，观察个监控啥的。结果呢，你们这个大个子的单块系统，你就修改了商品中心里面的一点点代码，然后楞是给部署上线了，完了你的模块倒是正常了，人家的模块呢？也许日志都是异常的！结果你根本都不知道，以为没事儿，喜滋滋回家睡觉了 

所以说，一个大型复杂的系统，依赖的东西特别特别多，可能还会依赖本地的磁盘目录什么的，还有各种基础组件，你要是自己修改了里面一点点东西，然后自己部署，就可能出问题，测试环境和生产环境都是。你要是拉上一堆人，陪你上线，你不觉得很尴尬吗？人家都没修改代码，结果上线楞是要陪着你，浪费时间，人效极其低。 

这就是大团队多人协作开发一个复杂单块系统的问题，我们都经历过，所以实在是太痛苦了，感觉非常的不合适。 

**3、扩容问题** 

完了呢，后面你要是系统要扩容，更加麻烦。本身你就是可能比如订单中心、商品中心，少数几个中心访问量特别高，所以要扩容加机器，然后什么采购中心、WMS中心是不需要扩容的。结果因为大家绑一块儿了，你要扩一块儿扩，这真是。。。。 

人家的中心不需要扩容，你楞是给人家扩容了，浪费资源

而且你以为扩容那么容易？万一人家某个中心的代码，是有状态的，在内存里保存了一些状态呢，你扩容咋扩？可能都没法扩容，你还瞎扩。。。。到时候不就bug了？ 

单块系统，部署了一台机器，内存里维护每个用户的访问次数 

扩容，2台机器，同一个用户的请求可能会打到不同的机器上去，可能就会出现，一台机器统计了用户A的访问次数是5次，另外一台机器统计了用户A的访问次数是3次。其实如果是在一台机器上的话，应该统计出来的是用户A的访问次数是8次。 

我们几个系统耦合在一起，扩容的时候，别的系统保存了内存级别的状态，一旦扩容了多台机器，就会导致代码出bug。 

**4、可用性问题**

大量的代码耦合在一起，任何一个中心的代码出点问题，给你举个例子，比如说采购中心如此无关紧要的模块，有个新来的应届生，乱写代码，写了个死循环。好了，完了，直接把所有机器的cpu打满，所有机器hang死，我们还真遇到过这事儿，惨不忍睹啊。。。。 

100% 

所有的14个中心代码在一起，一起部署的，采购中心处一个死循环，直接所有机器的cpu 100%，整套系统都跑不动了 

客服中心的代码，出了oom，jvm死了，整套系统宕机

###  003_微服务架构师如何解决单块系统的那些问题的呢？

简陋版的微服务架构

![](C:\Users\zy199005\Desktop\中华石杉\images\java\06\00301.png)

**1、微服务架构的最简陋表述** 

啥是微服务架构？来个最简陋的表述 

14个中心，10万行代码，就是一个工程，部署在一台机器上，单块应用 

14个中心，拆分成14个服务，每个服务几千行代码，14个工程，部署在14台机器上，微服务架构，通过网络通信来调用接口。订单中心，本来调用商品中心的接口，走的是本地的spring ioc，调用商品中心的service就 可以了。发送http请求，请求商品中心的一个http接口，就可以了。 

**2、代码复用性问题** 

好，现在每个中心拆成独立的服务，每个服务有自己的库，而且只有本中心的同学有访问那个库的权限，其他中心的同学没权限访问。这个时候订单中心的同学绝对不可能自己写SQL去查商品中心的表了，只能找商品中心的同学帮忙写接口。 

虽然人商品中心的同学可能会慢一点儿，但是没有代码重复了啊，同样的一份代码就仅仅会在商品中心里的一个接口罢了，完全收了口子，同样的代码就在一个地方有就可以了。 

订单中心一个哥儿们，我要一份商品数据，去找商品中心的那个哥儿们，说，开个接口，提供一份数据。忙着呢，接口，稍等，等我个几天。我干脆自己来写代码和SQL来查商品的数据吧，这个傻眼了，我没有商品库的用户名、密码和url地址，完蛋了。 

订单中心那个哥儿们，悻悻而归，找商品中心那个哥儿们商量，给我个排期，商品那个哥儿们就说，可以啊，给你个排期，3天吧。 

**3、多人协作效率问题** 

整个世界都清爽了，你自己就搞好自己的一个小服务就行了，代码仓库是你自己的，没有冲突，测试是你自己的事儿，就部署你自己的测你自己的好了，上线就你自己的服务上线，跟人家没关系。体验过几十人开发一个单块应用之后，再来微服务，你就一个字：爽。 

**4、扩容问题** 

同上，你就自己管自己的好了，哪儿来那么多事儿，自己需要就扩容，自己不需要就不扩容，跟人家没关系。体验过几十人开发一个单块应用之后，再来微服务，你就一个字：爽。 

**5、可用性问题** 

同上，人家死循环服务死掉了，是他的事儿，你做好熔断和降级就好了，他的服务死了，你就降级。体验过几十人开发一个单块应用之后，再来微服务，你就一个字：爽。

### 004_基于微服务架构的大型分布式电商系统整体设计以及学习目标

上一讲，微服务架构，最简陋版本的微服务架构，可以解决几十个人大团队协作开发复杂系统的很多技术问题，但是微服务架构又会产生很多新的问题，所以我们又需要一整套的复杂的微服务架构，来既能用上微服务的各种好处，还可以解决微服务架构引入的各种问题 

提纲挈领的说一下，整体的微服务架构的设计，里面包含了哪些东西，每个东西的基本的用处是什么。很简单的说一下，不能说的太复杂。说一下，我们要学习到什么程度，掌握到什么程度，学习目标是什么。 

**1、微服务基础技术架构** 

spring cloud，dubbo，不是说完整的微服务的构成 

spring cloud技术栈来作为整体的微服务架构的技术技术栈，我们不用dubbo来做，趋势，大量的公司，尤其是中小型的公司，拥抱spring cloud。spring cloud的功能更加强大，一站式的微服务架构解决方案，spring开源社区加持。 

不爱使用dubbo，做所谓的微服务架构，前几年，还是dubbo，中小型的公司，也是用的dubbo。阿里开源的，很长时间开源社区没人去管，dubbo黄了一段时间，没有什么更新。大家都对dubbo的前途感觉比较的迷茫。dubbo的功能，没有涵盖像spring cloud那么多和完整的功能，dubbo的定位RPC框架。spring cloud，一站式微服务架构解决方案，微服务全家桶。 

dubbo，比如说一些大型的互联网公司，RPC框架，自己基于dubbo改造源码和定制源码。可以使用dubbo框架。围绕dubbo去做大量的周边的工具平台。 

（01）服务网关：zuul

（02）服务注册发现：Eureka 

（03）负载均衡：Ribbon

（04）声明式REST调用：Feign

（05）限流熔断：Hystrix

（06）认证授权：Spring Security + OAuth2 + JWT

（07）消息中间件：RabbitMQ + Spring Cloud Stream

（08）分布式协调：Spring Cloud ZooKeeper

（09）开发框架：Spring Boot + Spring Web MVC + Spring Core + MyBatis

（10）服务文档：SwaggerUI

（11）消费者驱动式契约：Spring Cloud Contract 

第一块就会带着大家把整个上面那套技术体系，给大家来讲解一下，会采取一个思路，快速的将spring cloud的整体技术栈的知识给大家来讲解一下，快速的写一堆demo出来。把上面所有的技术都给掌握了。 

第二块，学会了spring cloud技术栈原理、使用和开发之后，我们就来将spring cloud整体的技术栈的源码，都阅读一遍。 

将整个这个spring cloud掌握的非常精通之后，我们才有这个底气，说，将spring cloud运用到我们的10万行代码的电商系统v1.0里面去，先来设计一下将电商系统v1.0版本，拆分成哪些服务，就接着基于上面那套基础技术架构，一整套东西，将系统彻底给改造成微服务的技术架构。 

**2、分布式系统架构** 

电商系统，就已经变成分布式系统架构了，分布式电商系统。 

微服务之后就变成了分布式系统了，此时分布式事务、分布式锁、分布式会话、单点登录、分布式一致性、分布式接口幂等性，等等技术问题，都会显现出来，所以我们需要对分布式电商系统，解决各种各样的技术问题 

**3、微服务高可用架构** 

微服务之后，保证系统基本的可用性以及可靠性，避免服务雪崩等问题 

**4、容器技术** 

微服务化了之后，就会导致本来就1台机器，1个工程。几十个服务，几十台机器。管理大量的微服务，就要使用docker + k8s容器技术。 

docker + k8s（kubernetes） 

**5、DevOps + 持续集成 + 持续交付** 

jenkins + 自动化测试 + 自动化部署 

打包 -> 单元测试 -> 运行静态代码检测 -> 自动部署到集成测试环境 -> 运行自动化的集成测试 -> 自动部署到系统测试环境 -> 运行自动化的系统测试 -> 自动部署到预发布环境 -> 运行自动化的压力测试/可用性测试 

手动控制，全自动化部署到线上生产环境，部署之后，自动化检查日志、监控项、线上验证测试 

**6、微服务支撑运维平台** 

（1）日志中心：ELK + Kafka + 自研组件，亿级大规模日志中心架构设计

（2）机器与Metrics监控：OpenFalcon

（3）配置中心：Apollo，先剖析源码，再投入使用 

**7、敏捷开发和项目管理** 

敏捷式的支持快速迭代的开发流程以及项目管理流程 

**8、微服务治理平台** 

自己研发。。。。先看下大众点评CAT的源码，因为CAT是开源的实现了调用链跟踪的监控系统，但是CAT实际上在国内应用不广泛，而且有很多问题，那我们还不如自己做一个包含调用链监控的整套微服务治理平台 

（1）服务分层

（2）服务鉴权

（3）自动化故障诊断

（4）容量预估以及扩容告警

（5）可用性监测

（6）QPS、请求量、响应时间的监测

（7）性能瓶颈定位
（8）调用链跟踪

（9）接口版本管理

（10）服务上下线审批

（11）流量控制

（12）等等。。。。。 

在这里，我们来全程自己研发一个可以投入生产环境使用的微服务治理平台v0.1，一站式满足微服务架构的治理需求 

**9、100台机器部署整套系统**

阿里云，租用100台机器，大部分都是4核8G的标配虚拟机，把上面做好的整套系统，都部署到上百台机器的线上生产环境中去，线上环境是怎么部署的，参数怎么设置的 

**10、线上生产环境的工程实践** 

（1）A/B测试

（2）蓝绿部署

（3）灰度发布

（4）全链路压测

（5）系统回滚 

**11、线上生产环境的4000/s压力测试以及高可用容灾演练** 

（1）线上系统部署之后，压测验证可以支撑高峰期4000/s的请求，绝对没问题，系统无压力

（2）线上系统演示各种服务宕机、流量过载、服务雪崩之后的故障，同时验证系统在各种故障下可以保持可用 

**12、微服务核心技术源码剖析** 

（1）Spring Cloud核心技术源码剖析

（2）Dubbo学习一下&源码剖析

（3）Apollo源码剖析 

**12、学习目标与成果** 

从项目阶段二开始，每个阶段学习完毕，都要让大家成为这个领域的一个技术专家，微服务技术专家，出去面试，没人面的倒你，到任何公司都可以作为微服务这个领域的专家，帮助任何公司搭建出来一整套的微服务技术架构，微服务这块出了任何问题，你都可以搞定。 

==> 微服务基础技术架构：Spring Cloud和Dubbo，技术架构实践绝对没问题，深入到源码级 

==> 分布式系统架构：全部结合复杂的业务实践各种分布式系统的技术方案，绝对不是玩儿demo 

==> 微服务高可用架构：初步对微服务架构实现了高可用架构保障，而且一整套高可用保障机制都是基于复杂的业务系统来的，线上生产环境进行了容灾演练，绝对不是玩儿demo 

==> 容器技术：熟练掌握，我们不是运维，但是作为RD可以熟练掌握docker和k8s，同时理解其中的核心原理，就可以，已经比普通人好多了 

==> DevOps + 持续集成 + 持续交付：基于复杂的业务系统全程实战演练，实现全自动化集成流水线，自动化测试，自动化部署，自动化验证，全流程自动化，让一个复杂的业务系统可以跑起来，绝对不是玩儿demo 

==> 微服务支撑运维平台：日志中心是我们的重点，要自己设计和开发可以支撑亿级数据量的日志中心，这套日志中心架构掌握了，秒杀大部分人；OpenFalcon我们全程实战演示一套复杂系统，100台机器，是如何对机器和业务metrics进行监控的，而且基于复杂业务系统来实践，绝对不是玩儿demo；Apollo配置中心，达到源码级别 

==> 敏捷开发和项目管理：全部基于复杂业务系统实战全流程，绝对不是玩儿demo 

==> 微服务治理平台：基于大量的技术，包括很多大数据领域的技术，全程自己研发，这个自己研发出来之后，绝对是专家级别 

==> 100%掌握，微服务技术专家，绝对没问题 

==> 任何公司面试，微服务这块不可能面倒你，你的积累已经非常好了 

==> 任何公司工作，小公司可以自己从0开始搭建一整套的微服务架构；大公司可以快速利用公司已有的各种基础系统和工具，搭建起来完整的微服务架构 

==> 看过我100台机器的线上生产环境部署，以及标准的大公司大系统全流程，你到任何公司都可以照着我的步骤来走，绝对没问题 

==> 系统架构支撑4000/s请求量，绝对没问题 

**13、领域驱动建模** 

我仔细想了下，现在我们的10万行代码的系统，业务还是不够复杂，没法充分体现出领域驱动建模的价值，所以我打算将领域驱动建模放到后面的业务复杂10倍的阶段去，那个时候业务复杂了10倍，我们可以来实践领域驱动建模。

### 005_Spring Cloud之Eureka：服务注册与发现的原理

eureka的大白话版的基本原理

![](C:\Users\zy199005\Desktop\中华石杉\images\java\06\00501.png)

首先，我们要来学习整套微服务的基础技术架构，以spring cloud为核心的一套技术架构，不能够干学怎么来使用spring cloud，spring cloud的使用，外面多如牛毛的教程、书籍，教你怎么用，各种api，各种功能。 

如果你要投入生产环境去使用的话，解决spring cloud在生产环境中可能出现的任何问题，先精读一下源码。投入生产环境，一旦生产环境出了问题，我们就完蛋了。 

spring cloud每个组件，eureka，hystrix，ribbon，feign，都快速学习一下怎么使用，写一堆demo，每学习一个组件怎么使用之后，就立即深入研究这个技术的源码。 

spring cloud eureka注册中心，注册服务，发现服务，学习一下eureka怎么使用，极其简单。学完eureka怎么使用之后，立马就开始研究eureka的源码。再来学习下一个东西。

### 006_来一个Eureka服务注册和调用的HelloWorld

eureka helloworld的基本原理 

![](C:\Users\zy199005\Desktop\中华石杉\images\java\06\00601.png) 

**1、开发Eureka服务端** 

搭建工程，用最新版本的spring cloud，Edgware.SR3 

```
<parent>
    <groupId>org.springframework.boot</groupId>
    <artifactId>spring-boot-starter-parent</artifactId>
<version>1.5.13.RELEASE</version>
</parent>
<dependencyManagement>
    <dependencies>
        <dependency>
            <groupId>org.springframework.cloud</groupId>
            <artifactId>spring-cloud-dependencies</artifactId>
            <version>Edgware.SR3</version>
            <type>pom</type>
            <scope>import</scope>
        </dependency>
</dependencies>
</dependencyManagement>
<dependencies>
    <dependency>
        <groupId></groupId>
        <artifactId>spring-cloud-starter-config</artifactId>
    </dependency>
    <dependency>
        <groupId></groupId>
        <artifactId>spring-cloud-starter-eureka</artifactId>
</dependency>
<dependency>
        <groupId></groupId>
        <artifactId>spring-cloud-starter-eureka-server</artifactId>
</dependency>
</dependencies>
```

```
@SpringBootApplication
@EnableEurekaServer
public class Server {
public static void main(String[] args) {
SpringApplication.run(EurekaServer.class, args);
} 
} 
```

src/main/resources/application.yml

```
server:
	port: 8761
	eureka:
		client:
			registerWithEureka: false		
			fetchRegistry: false
```

直接运行，就可以启动一个Eureka服务，对外开放的是8761端口 

上面那俩配置，就是说不要把自己注册到Eureka，因为他自己就是Eureka的服务，让别人来注册的；还有就是不要到Eureka服务抓取注册信息，因为他不需要，他自己就是Eureka服务 

打开浏览器，输入http://localhost:8761/，就可以看到Eureka的控制台 

**2、开发一个服务** 

```
<dependency>
<groupId></groupId>
    <artifactId>spring-cloud-starter-config</artifactId>
</dependency>
<dependency>
    <groupId></groupId>
    <artifactId>spring-cloud-starter-eureka</artifactId>
</dependency> 
```

src/main/resources/application.yml

```
server:
port: 8080
spring:
application:
name: ServiceA
eureka:
instance:
hostname: localhost
client:
serviceUrl:
defaultZone: http://localhost:8761/eureka 
```

上面的，配置了自己的服务名称，主机地址，还有eureka服务的地址 

```
@RestController
public class ServiceAController {
@RequestMapping(value = “/sayHello/{name}”, method = RequestMethod.GET)
public String sayHello(@PathVariable(“name”) String name) {
return “hello, ” + name;
}
}

@SpringBootApplication
@EnableEurekaClient
public class ServiceAApplication {
public static void main(String[] args) {
SpringApplication.run(EurekaServer.class, args);
}
}
```

上面那个@EnableEurekaClient，就是说这是个Eureka客户端应用，需要向Eureka服务端注册自己为一个服务，启动这个就好。完事儿了，看一下Eureka控制台，就会发现一个服务出现了。

**3、开发一个服务调用者** 

```
<dependency>
<groupId></groupId>
    <artifactId>spring-cloud-starter-config</artifactId>
</dependency>
<dependency>
    <groupId></groupId>
    <artifactId>spring-cloud-starter-eureka</artifactId>
</dependency>
<dependency>
    <groupId></groupId>
    <artifactId>spring-cloud-starter-ribbon</artifactId>
</dependency> 
```

src/main/resources/application.yml

```
server:
port: 9000
spring:
application:
name: ServiceB
eureka:
instance:
hostname: localhost
client:
serviceUrl:
defaultZone: http://localhost:8761/eureka
```

上面就是个ServerB，也配置了eureka地址，就可以从eureka抓取到所有注册的服务了 

```
@RestController
@Configuration
public class ServiceBController {
@Bean
@LoadBalanced
public RestTemplate getRestTemplate() {
return new RestTemplate();
}

@RequestMapping(value = “/greeting/{name}”, method = RequestMethod.GET)
public String greeting(@PathVariable(“name”) String name) {
RestTemplate restTemplate = getRestTemplate();
return restTemplate.getForObject(“http://ServiceA/sayHello/” + name, String.class);
}
} 
```

上面那个服务B，就会去调用服务A的sayHello接口 

RestTemplate，本来就是访问单个http接口的，但是现在加了@LoadBalanced以后，就可以通过Ribbon的支持，实现负载均衡了，假如ServiceA部署了几台机器，那么可以自动负载均衡，轮询调用每一个实例

```
@SpringBootApplication
@EnableEurekaClient
public class ServieBApplication {
public static void main(String[] args) {
SpringApplication.run(ServiceBAppliciation.class, args);
}
}
```

@EnableDiscoveryClient，这个意思就是说可以去eureka抓取注册的服务了，而且自己也会到eureka上去注册一下。这个时候启动了ServiceB以后，在eureka控制台上，就可以看到ServiceA和ServiceB两个服务了

然后在浏览器里访问，http://localhost:9000/greeting/leo，就可以看到结果了 

**4、画图讲解HelloWorld原理**

### 007_把Eureka搭建成高可用集群架构以及服务集群实战

eureka生产环境部署原理

![](C:\Users\zy199005\Desktop\中华石杉\images\java\06\00701.png)

 

**1、eureka注册中心集群** 

Eureka如此重要的服务注册中心，怎么能单节点呢？那就太搞笑了，挂掉就完蛋了 

这一讲来搞一个eureka集群，然后ServiceA也搞成集群玩儿一下 

```
server:
 port: 8761
eureka:
 instance:
  hostname: peer1
 client:
  serviceUrl:
   defaultZone: http://peer2:8762/eureka/ 
```

就上面这个配置，先启动，会尝试向本机的8762端口的eureka服务注册自己 

然后修改配置：

```
server:
 port: 8762
eureka:
 instance:
  hostname: peer2
 client:
  serviceUrl:
   defaultZone: http://peer1:8761/eureka/ 
```

这个就是自己对外开放8762端口，但是自己向8761端口的eureka注册中心来注册自己 

说白了，就是启动两个eureka服务，互相注册，组成一个集群 

**2、将服务改造为集群** 

正常情况下，都是会将服务部署多台机器，组成一个集群的，起码都是双击部署，因为冗余一下避免单点 

将服务的applicationl.yml改造为下面那样：

```
eureka:
client:
serviceUrl:
defaultZone: http://localhost:8761/eureka/,http://localhost:8762/eureka/ 
```

这个，说白了，就是让这个服务注册到一个eureka集群上去 

另外，在服务的接口里打印日志到控制台，这样后面观察到每个服务实例被调用了几次 

然后分别使用8080和8088两个端口，来启动这个服务，这样这个服务就有两个实例了 

**3、改造服务调用者** 

```
eureka:
client:
serviceUrl:
defaultZone: http://localhost:8761/eureka/,http://localhost:8762/eureka/ 
```

这个也是说让服务调用者感知到eureka集群，可以从eureka集群获取注册信息 

一共访问了服务B的接口7次，会负载均衡到服务A的两个实例上去，一个实例是3次调用，一个实例是4次调用 

**4、开发一个测试工程**

```
<dependency>
<groupId>org.apache.httpcomponents</groupId>
<artifactId>httpclient</artifactId>
<version>4.5.2</version>
</dependency>
```

```
CloseableHttpClient httpClient = HttpClients.createDefault();
for(int i = 0; i < 10; i++) {
HttpGet request = new HttpGet(“http://localhost:9000/greeting/leo”);
HttpResponse response = httpClient.execute(request);
System.out.println(EntityUtils.toString(response.getEntity()));
}
```

### 008_基于Eureka的服务健康自检机制实现

默认情况下，你的所有的服务，比如服务A和服务B，都会自动给eureka注册中心同步心跳，续约，每隔一段时间发送心跳，如果说某个服务实例挂了，那么注册中心一段时间内没有感知到那个服务的心跳，就会把那个服务给他下线 

如果你要自己来实现一个服务的健康检查的机制，自己来检查服务是否宕机，比如说，如果底层依赖的MQ、数据库挂了，你就宣布自己挂了，通知注册中心 

在服务中加入以下依赖：

```
<dependency>
<groupId>org.springframework.boot</groupId>
<artifactId>spring-boot-starter-actuator</artifactId>
<version>1.5.13.RELEASE</version>
</dependency> 
```

http://localhost:8080/health，可以看到服务的健康状态 

正常情况下就这样就可以了，但是有一个问题，就是可能这个服务依赖的其他基础设施，比如redis、mysql、mq，都挂掉了，或者底层的基础服务挂掉了，此时这个服务已经不可用了，那么这个服务就可以认定自己是不可用了 

所以可以自己实现一个健康检查器，就是自己检查自己依赖的基础设施，或者是基础服务，是否挂掉了，来决定自己是否还是健康的

```
@Component
public class ServiceAHealthIndicator implements HealthIndicator { 
@Override
public Health health() {
// 这里可以通过返回UP或者DOWN来指示服务的状态
return new Health.Builder(Status.UP).build();
}
}

@Component
public class ServiceAHealthCheckHandler implements HealthCheckHandler {
@Autowired
private ServiceAHealthIndicator indicator;

public InstanceStatus getStatus(InstanceStatus currentStatus) {
Status status = indicator.health().getStatus();
// 根据这个status，可以决定这里返回什么
return InstanceStatus.UP;
}
}     
```

eureka client里面会有一个定时器，不断调用那个HealthCheckHandler的getStatus()方法，然后检查当前这个服务实例的状态，如果状态变化了，就会通知eureka注册中心。如果服务实例挂掉了，那么eureka注册中心就会感知到，然后下线这个服务实例。 

不过其实一般很少自己去实现这个健康检查，在大规模的部署中，每个服务都很复杂，不可能都这样去搞一堆健康检查的。大部分情况下，我们就是会对外暴露一个/health接口，然后专门外部来定时调用各个服务的/health接口来判断当前这个服务能够调通。 

但是eureka默认是client通过心跳机制跟eureka注册中心保持心跳通信，如果心跳不及时或者没有心跳了，那么就说明那个服务挂了，然后eureka注册中心就会摘除这个服务实例。这个机制就足够了。

### 009_Eureka的心跳检测、注册表抓取、自我保护等常见配置 

**1、心跳检测** 

eureka客户端，默认会每隔30秒发送一次心跳的eureka注册中心，下面的那个参数可以修改这个心跳间隔时间，如果在90秒内没收到一个eureka客户端的心跳，那么就摘除这个服务实例，别人就访问不到这个服务实例了，通过下面的参数可以修改这个90秒的值。但是一般这俩参数建议不要修改。 

另外这个心跳检测的机制其实叫做renew机制，看下面的参数配置就知道了，也可以叫做服务续约 

eureka.instance.leaseRenewallIntervalInSeconds

eureka.instance.leaseExpirationDurationInSeconds 

如果一个服务被关闭了，那么会走cancel机制，就是类似是服务下线吧 

如果90秒内没收到一个client的服务续约，也就是心跳吧，但是他这里叫做服务续约，那么就会走eviction，将服务实例从注册表里给摘除掉 

**2、注册表抓取** 

默认情况下，客户端每隔30秒去服务器抓取最新的注册表，然后缓存在本地，通过下面的参数可以修改。 

eureka.client.registryFetchIntervalSeconds 

**3、自定义元数据** 

```
eureka:
instance:
hostname: localhosto
metadata-map:
company-name: zhss
```

可以通过上面的metadata-map定义服务的元数据，反正就是你自己需要的一些东西，不过一般挺少使用的 

**4、自我保护模式** 

如果在eureka控制台看到下面的东西： 

EMERGENCY! EUREKA MAY BE INCORRECTLY CLAIMING INSTANCES ARE UP WHEN THEY'RE NOT. RENEWALS ARE LESSER THAN THRESHOLD AND HENCE THE INSTANCES ARE NOT BEING EXPIRED JUST TO BE SAFE.

这就是eureka进入了自我保护模式，如果客户端的心跳失败了超过一定的比例，或者说在一定时间内（15分钟）接收到的服务续约低于85%，那么就会认为是自己网络故障了，导致人家client无法发送心跳。这个时候eureka注册中心会先给保护起来，不会立即把失效的服务实例摘除，在测试的时候一般都会关闭这个自我保护模式： 

eureka.server.enable-self-preservation: false 

在生产环境里面，他怕自己因为自己有网络问题，导致别人没法给自己发心跳，就不想胡乱把别人给摘除，他就进入保护模式，不再摘除任何实例，等到自己网络环境恢复。

### 010_源码阅读的意义：技术功底、hold住全场、设计能力、职场竞争

首先明确一件事情，源码，不是谁想读就可以读的 

行业里，读过一些源码的，可能就10%~20%，但是仅仅停留在了解点源码和原理的程度。有能力自主透彻阅读源码，深入吃透源码，化为自己的技术功底，而且运用到自己的项目里的，不足1%。 

所以源码实际上是码农技术水平的分水岭 

那么阅读和分析源码的意义在哪儿？ 

**（1）技术功底** 

当你阅读了一个技术的源码之后，你的技术功底会得到大幅度的提升。 

比如说spring cloud，你阅读了spring cloud的源码之后，你对微服务技术架构的底层原理、架构设计、核心思想都了如指掌了，那么以后如果再出个啥啥啥微服务的相关的技术，你绝对很快就能上手，而且很快就可以自己去阅读那个细腻技术的源码。你的技术功底决定了你的学习能力，技术功底越深厚，以后不断学习新技术的能力、速度以及深度就越强，扎实的技术功底是保证你不断跟进新技术的基础。 

而且技术功底一旦扎实了，比如你阅读了spring cloud的源码，后面你再读zookeeper、kafka、rocketmq其他技术的源码，因为你深厚的技术功底，都会轻松和顺利很多。 

否则如果你从没读过什么源码，对每个技术的学习就是仅仅会用，使用，浮于表面，那么以后对其他的新技术，你又是从头再来一遍，你对新技术的学习速度和深度都会很差，学习的很慢，而且对任何技术都无法深入研究。 

**（2）hold住全场** 

阅读一个技术的源码，最直接的效益，就是你在公司里，直接会成为这个领域的专家级的人物。因为尤其我们在大公司里，因为访问量和数据量太大了，用的一些技术经常各种出问题，比如说spring cloud框架在每天几百亿次请求下，也许某个地方的一个bug立马暴露出来，导致系统异常。那么此时，就必须要有那种对这个技术精通源码的专家，才可以立马根据异常，从源码级别分析和定位问题，然后从源码角度出发给出问题的解决方案。 

如果你不精通源码，一个技术处问题的时候，你就是盲人摸象，在哪儿瞎猜，百度，各种瞎试，有些工作过很多年经验丰富一些的人，可能就可以连蒙带猜把问题给解决了。但是有的时候这问题解决了，你自己心里都心虚，或者自己也有点不知所以然。 

所以我们在大公司里，引入一个新技术的流程，就是首先得派一个技术专家级别的人，去研究那个技术，至少核心源码都读一下，一般一个技术专家级别的人，做到这一点，大概一两个月就够了。 

一两个月之后，这个新技术就可以投入生产环境使用，如果出问题，那个人可以从源码级别来解决，我们根本不担心。 

**（3）架构设计能力** 

首先，要知道，最优秀的那些开源技术，都是全世界最最顶尖的各种技术大牛写的，他们写的框架和系统，都是他们多年的技术积累和功底，才能写出来的。所以如果你去读各种知名开源框架或者系统的源码，相当于就是在学习人家设计框架、设计系统的设计思想，同时可以学习人家设计出来的大型框架或者大型分布式系统的架构设计。 

如果你读了大量的开源项目之后，你的系统设计能力会得到大幅度的增强，你会不由自主的今后在自己设计系统的时候，将人家的各种架构设计理念、核心技术实现、复杂实现机制都学习后，应用到你自己的系统中去。 

在这个层面上，你自己负责设计的系统，会设计的越来越好，而且你看过大量的别人设计的优秀系统之后，也能够让你有能力去设计优秀的系统。 

否则，很多人，如果没读过什么源码，那么最后系统设计能力实际上是很弱的，因为完全凭借自己的很多年自己闭门造车的一些经验和思想在设计系统，那么始终设计不出来什么太好的系统架构。 

**（4）职场竞争力** 

看完了一二三点，就会发现，读源码有很多的好处，最近的好处，就是立马可以让你秒变公司里、行业里这个领域的专家，出问题绝对能搞定；远一点儿的，就是以后学习新的技术，绝对会事半功倍；再远一点儿的，以后你设计系统，立马会不由自主吸收人家思想，自己设计的系统会越来越好。 

这都是内功，慢慢积累出来的，但是你积累多了，量变产生质变，你的技术实力就跟普通人完全不一样了。你会发现你在公司里顶梁柱，有问题人家都得来找你，公司里公认你是技术大牛；而且你学习新技术特别快，出了新东西，一周熟悉，一个月读完源码，精通；同时你发现你的系统设计能力越来越得心应手，因为你看过人家大量的系统是怎么设计的，自己设计的时候也非常的有章法，绝对不是那些年轻的生瓜蛋子可以比的。 

最后一点，就是在职场上，你综合上面的一二三点，是不是发现你在公司里的职场竞争力很强悍？绝对不是一般人可以比的。同时你出去面试，有没有发现你成为了行业里的top 10%？你的简历各种精通和源码，面试的时候跟面试官侃侃而谈，而且人家也会认可你的技术功底。对不对？ 

这就是你的综合职场竞争力

### 011_我们到底应该怎么读源码以及从源码里要读到什么？ 

我们难道就是浮光掠影把源码给过一遍就ok了吗？你觉得你记得住源码吗？ 

不是的，我们要读源码，一边读源码，一边沉淀自己的理解，否则干读一堆源码是没意义的 

（1）将源码下载下来，导入一个IDE中（Eclipse或IntelliJ IDEA），保证项目别报错，maven或gradle来下载需要的依赖。gradle构建的项目，用gralde处理一下；maven构建的项目，mvn eclipse:eclipse。

（2）接着就直接按照我们平时使用这个技术的过程，比如启动或者调用API，来在源码里直接写一些demo，来打断点调试，根据源码运转的流程，进入源码里去阅读。看看人家的单元测试或者集成测试的代码，从这些测试类来作为入口，调用各种核心的功能，你就跟着这些测试，把核心的功能，给读一遍。 

（3）从一个HelloWorld开始阅读源码，HelloWorld一般代表了这个技术最核心的功能，先把HelloWorld的流程读懂 

（4）一边读源码，一边写中文注释，一边画图，就是源码的整体架构设计，包含哪些类，每个类代表了系统里的什么组件，然后层次结构，依赖关系，全都画出来，可以给整个系统画一个大的静态图，还可以针对每个部分画一些细节的静态图。就是将整个系统运转的流程画出来，先干嘛，再干嘛，谁调用谁，一步一步如何完成一个功能的。这个图都画出来了，那么你对整个源码的架构设计以及运行流程，就全都了如指掌了。会画很多副图出来，eureka，先看eureka server的启动，画一幅图；eureka client，服务注册，画一幅图；eureka client，服务发现，画一幅图；eureka server集群模式，画一幅图；服务跟注册中心之间的心跳机制，画一幅图；eureka的自我保护机制，画一幅图。 

（5）寻找源码中的各种技术亮点，比如说设计模式的使用，或者是零拷贝技术的运用，或者是TCP通信的机制，或者是磁盘读写的机制，等等吧。对各种复杂的机制或者是技术的亮点，全部独立进行总结，要进行画图和文字的总结。 

（6）HelloWorld驱动的核心流程的源码读完之后，就可以阅读周边的一些高级特性相关的源码，此时就会容易很多了，具体流程跟上面是类似的。 

（7）这个过程结束之后，你能读通读透一个开源项目的源码，你的技术功底就深厚了很多；同时你对这个开源技术的架构设计、运行原理、实现细节、复杂机制全都了如指掌，那么你在公司里就可以hold住全场了；而且你在阅读了人家的架构设计之后，学习了人家的各种复杂机制实现之后，你再次自己设计系统的时候，自动就会借鉴别人的思想，来设计你自己的系统哦；最后就是，你如果出去面试，那简直是可以秒杀面试官了，源码的理解全部说出来，面试官绝对会听得一愣一愣的。 

### 012_Netflix Eureka的github浏览以及项目结构说明

讲这个eureka的源码，不是从spring cloud eureka开始的 

spring cloud eureka server和client是对netflix的eureka进行了封装，加了一些注解，对spring boot进行支持。所以上来如果你要看eureka的源码，是先从netflix eureka开始看起，后面结束了再把spring cloud eureka server和client两个项目的源码给看一下就可以了。 

https://github.com/spring-cloud/spring-cloud-netflix

https://github.com/Netflix/eureka 

就这个地址，说白了，spring cloud eureka，就是对netflix的eureka做了一层封装，加了一些注解和其他的机制来跟spring boot进行配合，所以我们要看eureka的源码，肯定是先看netflix eureka的源码，包含了eureka所有的服务注册和发现的机制 

spring cloud Edgware.SR3对应的是netflix eureka的1.7.2的版本 

（1）eureka-client：这个就是指的eureka的客户端，注册到eureka上面去的一个服务，就是一个eureka client，无论是你要注册，还是要发现别的服务，无论是服务提供者还是服务消费者，都是一个eureka客户端。

（2）eureka-core：这个就是指的eureka的服务端，其实就是eureka的注册中心

（3）eureka-resources：这个是基于jsp开发的eureka控制台，web页面，上面你可以看到各种注册服务

（4）eureka-server：这是把eureka-client、eureka-core、eureka-resources打包成了一个war包，也就是说eureka-server自己本身也是一个eureka-client，同时也是注册中心，同时也提供eureka控制台。真正的使用的注册中心

（5）eureka-examples：eureka使用的例子

（6）eureka-test-utils：eureka的单元测试工具类 

咱们来一点点儿看，第一个要看的，肯定是eureka-server了，因为就是用eureka-server先启动注册中心的，然后人家才能来注册服务和发现服务

### 013_Eureka的源码阅读环境搭建：IntelliJ IDEA & Gradle 

说实话，我个人开发清一色都是Eclipse + Maven + Git，很少用IntelliJ IDEA + Gradle的 

但是Netflix Eureka项目是用的Gradle来构建的，而且阅读这个源码，用IntelliJ IDEA确实更加的方便，而且包括是spark等一些开源项目，我都是用IntelliJ IDEA来阅读源码的，但是平时自己系统用Eclipse来开发 

先从IntelliJ IDEA官网，直接下载最新版本的就可以了，然后直接一步一步安装，很简单的，自己装一个IntelliJ IDEA，记得下载社区版本的，就是community版本的，这个是开源和免费的，别下载那个商业版本的。 

然后下载Gradle，从官网下载就可以了，非常简单 

（1）https://gradle.org/releases/，从这个地址去下载

（2）我下载的gradle-2.10-bin.zip，然后你找个目录，解压缩，比如我的目录是：F:\development\gradle\gradle-2.10，因为eureka是基于gradle 2.10来的，你就下载这个吧，不然出问题了麻烦，反正咱就是读个源码罢了

（3）设置GRADLE_HOME环境变量，值就是：F:\development\gradle\gradle-2.10

（4）在PATH环境变量中，加入%GRADLE_HOME%/bin

（5）在cmd命令行中，直接gradle -v，就ok了，可以看到gradle装好了，跟maven其实是一样的 

进入git bash命令行，自己找个目录，用来存放eureka源码，然后在目录里面，执行git clone https://github.com/Netflix/eureka.git，就可以了，这个是需要点时间的，稍微有点慢，你等一会儿好了 

然后在eureka目录中，直接双击gradlew.bat就可以，这个是人家给你提供的命令，直接就会下载所有需要的依赖，这个过程需要等待很长时间，得耐心点，因为走网络下载人家国外很多的依赖包什么的，速度会慢一些，你要是跟我一样搞个加速度，加速一下，估计就会快很多。我用了加速度之后，是可以随意上facebook、youtube的。./gradlew，他自己会下载自己对应的gradle版本，我这里的eureka对应的是1.9.0，那么gradle下载的就是2.10版本，他自己会下载了然后基于gradle来下载其他的依赖的 

然后下载完了之后，就将代码导入IntelliJ IDEA，这个时候会有一些坑，很恶心。我本机的环境，导入，报错，空指针异常，removeMessages，IDE的bug。你得直接先选择基于已有的项目来创建，不要选择那个import，然后过程中，别的没什么，就是配置一些JDK之类的，然后就创建出来一个项目，结果你发现创建出来的是一堆什么main，根本不是你要的项目。 

然后你就把项目close掉，然后在welcmoe界面里，也把项目给remove掉，重新再次用import来导入那个项目，这个时候会提示你，已经有了一个项目了，是不是要覆盖掉，你选择是，然后结果奇迹发生，就直接给导入进来了，然后各种gradle分析依赖，重新下载依赖，这个过程很慢，可能要1个小时 

完事儿了就好了 

也许你不用执行前面的gradlew也可以，但是保险起见，你还是搞那么一次吧，因为导入源码，一般都很麻烦，你没弄好，可能就出问题了 

这就是IDE的坑，各种bug，各种异常，虽然磕磕碰碰，但是好歹导入进来了 

选择你要读的那个版本的源码，git checkout v1.7.2，转到1.7.2版本的源码去

### 014_修改Eureka自带的测试代码准备调试环境

如果你要看这个源码，你从哪儿来入手？ 

第一个流程，一定是看eureka server（注册中心）的启动，启动一个eureka client（服务），注册服务，获取服务列表 

其他的就是底层的机制：心跳机制、抓取注册表、自我保护机制 

要不然就是自己基于这个源码来写个HelloWorld程序，加上断点来跑来看，要不然就是从他们的单元测试、集成测试的代码作为入口，来打断点，跟进去调试 

eureka，非常适合的是通过测试代码，打断点跟进去看 

**1、手动启动eureka注册中心** 

eureka-server的src/test/java下，有一个com.netflix.eureka.resources包，里面有一个EurekaClientServerRestIntegrationTest类，我们就通过这个类的示例代码，尝试手动启动Eureka注册中心吧。 

有一个setUp()方法，就是会在运行集成测试之前，调用startServer()方法先启动注册中心。 

所以我们在startServer()里面替换掉一些代码，直接就把注册中心给跑起来。 

```
server = new Server(8080); 
WebAppContext webAppCtx = new WebAppContext(new File("./eureka-server/src/main/webapp").getAbsolutePath(), "/");
webAppCtx.setDescriptor(new File("./eureka-server/src/main/webapp/WEB-INF/web.xml").getAbsolutePath());
webAppCtx.setResourceBase(new File("./eureka-server/src/main/resources").getAbsolutePath());
webAppCtx.setClassLoader(Thread.currentThread().getContextClassLoader());
server.setHandler(webAppCtx);
server.start();
eurekaServiceUrl = "http://localhost:8080/v2";
```

说白了，上面的那段代码啥意思呢？本来很麻烦，他是要你先把eureka-server打成一个war包，然后他这里找到那个war包去启动，但是太麻烦了啊，每次都打包，耗费时间，不好调试。现在这段代码，直接就是自己加载eureka-server的各种资源，比如web.xml，配置文件啥的，然后直接就启动注册中心了 

在setUp()方法里加入：Thread.sleep(Long.MAX_VALUE)，就是让他启动之后就hang住，然后可以用别的client去注册他。 

这里的启动注册中心的代码都可以看看 

后面咱们可以通过这个为入口，这里不是好多单元测试方法么，其实把单元测试方法都调试一遍，就差不多了，每个单元测试方法都是集成测试一个功能，都看一遍，你对eureka server提供的各种功能理解的就差不多了 

**2、启动eureka客户端**

eureka-examples里面，src/main/java的com.netflix.eureka包下，有个ExampleEurekaClient类，就用这个类来模拟eureka客户端好了。 

在之前那个集成测试类里，有个injectEurekaConfiguration()方法，复制到这个ExampleEurekaClient类里，然后在这个类的main()的第一行，就加入这个方法的调用，就是提前设置好一些参数罢了。 

然后就可以运行main方法，往注册中心发送请求就可以开始调试了 

而且eureka-examples里面，有别的例子，都可以按照上面的方法，来分别调试，基本把这些东西都弄完，整个eureka的原理就全部搞懂了

### 015_Eureka Server的web工程结构分析以及web.xml解读

eureka的源码 

eureka server的启动，相当于是注册中心的启动 -> 启动的过程搞清楚，初始化了哪些东西 

eureka client的启动，相当于是服务的启动，初始化了哪些东西 

eureka运行的核心的流程，eureka client往eureka server注册的过程，服务注册；服务发现，eureka client从eureka server获取注册表的过程；服务心跳，eureka client定时往eureka server发送续约通知（心跳）；服务实例摘除；通信，限流，自我保护，server集群 

eureka server怎么启动的？ 

eureka server是依赖eureka client的，为啥呢？eureka server也是一个eureka client，因为后面我们讲到eureka server集群模式的时候，eureka server也要扮演eureka client的角色，往其他的eureka server上去注册。 

eureka core，扮演了核心的注册中心的角色，接收别人的服务注册请求，提供服务发现的功能，保持心跳（续约请求），摘除故障服务实例。eureka server依赖eureka core的，基于eureka core的功能对外暴露接口，提供注册中心的功能 

jersey框架，eureka server依赖jersey框架，你可以认为jersey框架类比于spring web mvc框架，支持mvc模式，支持restful http请求。jersey在国内几乎没什么公司使用，很少很少，在国外有一些公司用，netflix就会用，jersey去开发eureka。eureka里面，服务通信，都是基于http请求的，restful接口来通信的。 

eureka client和eureka server之间进行通信，都是基于jersey框架实现http restful接口请求和调用的。eureka-client-jersey2，eureka-core-jersey2，猜测一下，就知道，其实这两个工程，就是eureka为了方便自己，对jersey框架的一个封装，提供更多的功能，方便自己使用。 

mocktio，mock测试框架，之前项目阶段一里面，我们大量用了mockito框架，来写单元测试。在eureka框架里面，他每个工程都是有src/test/java的哦，里面都写了针对自己本工程的单元测试，必须得写。mock就是用的mockito框架。 

jetty，方便你测试的，测试的时候，是会基于jetty直接将eureka server作为一个web应用给跑起来，jetty作为web容器，跑起来eureka server这个web应用。跑起来之后，eureka server不就活在jetty web容器里面了，jersey对外暴露了一些restful接口，然后测试类里，就可以基于jersey的客户端，发送http请求，调用eureka server暴露的restful接口，测试比如说：服务注册、心跳、服务实例摘除，等等功能。 

你猜测一下，如果把这个eureka-server工程，打成一个war包，会怎么样，会将eureka-resources下面的那些jsp、js、css给搞到这个war包里面去，然后就可以跑起来，提供一个index页面。我们之前启动了eureka-server之后，第一件事儿就是访问他的控制台，可以去看看有谁来注册了。控制台的代码，就在jsp里面，就是eureka-resources的jsp提供的，人家还有对应的css和js呢。 

人家eureka-server的web.xml里，设置好了welcome-file-list，就是status.jsp页面，这个页面就会在打war包的时候，从eureka-resources里面给打到eureka-server里的，eureka-server里就会包含jsp目录，里面就有这个status.jsp。我们之前看到的那个eureka控制台的页面，就是这个status.jsp，里面一堆jsp代码，把你注册的服务的信息，全部都提出来，显示到页面上去。 

eureka-server的本质，就是一个web应用，跟你用spring mvc+spring+mybatis+jsp写出来的这个web应用没两样。你看着这个东西有点陌生，只不过是因为人家用了gralde来构建，国内很少用gradle来构建的。 

分析一下eureka-server的web.xml，你呢已经知道eureka-server就是个web应用的本质，无论是用tomcat还是jetty都可以启动，如果用tomcat启动，你就用gradle把这个eureka-server打成一个war包，让tomcat的webapps里面，启动tomcat就ok了。如果是用jetty的话，人家是在测试代码里用jetty去启动这个web应用的。 

web应用最最核心的就是web.xml。 

最最重要的就是listener，listener是在web应用启动的时候就会执行的，负责对这个web应用进行初始化的事儿，我们如果自己写个web应用，也经常会写一个listener，在里面搞一堆初始化的代码，比如说，启动一些后台线程，加载个配置文件。 

com.netflix.eureka.EurekaBootStrap 

上面那个listener，在eureka-core里，就是负责eureka-server的初始化的。下一讲，重点就是开始分析这个EurekaBootStrap这个类里面的代码，都分析好了，eureka-server的初始化的源码分析，就可以结束了。 

有连着4个Filter，任何一个请求都会经过这些filter，这些filter会对每个请求都进行处理，这个4个filter都在eureka-core里面 

（1）StatusFilter：负责状态相关的处理逻辑

（2）ServerRequestAuthFilter：一看就是，对请求进行授权认证的处理的

（3）RateLimitingFilter：负责限流相关的逻辑的（很有可能成为eureka-server里面的一个技术亮点，看看人家eureka-server作为一个注册中心，是怎么做限流的，先留意算法是什么，留到后面去看）

（4）GzipEncodingEnforcingFilter：gzip，压缩相关的；encoding，编码相关的 

jersey框架的一个ServletContainer的一个filter，我可以告诉大家，类似于每个mvc框架，比如说struts2和spring web mvc，都会搞一个自己的核心filter，或者是核心servlet，配置在web.xml里，用了框架之后，相当于就是将web请求的处理入口交给框架了，框架会根据你的配置，自动帮你干很多事儿，最后调用你的一些处理逻辑。 

jersey也是一样的，这里的这个ServletContainer就是一个核心filter，接收所有的请求，作为请求的入口，处理之后来调用你写的代码逻辑。 

StatusFilter和RequestAuthFilter，一看就是通用的处理逻辑，是对所有的请求都开放的 

RateLimitingFilter，默认是不开启的，如果你要打开eureka-server内置的限流功能，你需要自己把RateLimitingFilter的<filter-mapping>的注释打开，让这个filter生效 

GzipEncodingEnforcingFilter，/v2/apps相关的请求，会走这里，仅仅对部分特殊的请求生效 

jersey核心filter，是拦截所有的请求的 

welcome-file-list，是配置了status.jsp是欢迎页面，首页，eureka-server的控制台页面，展示注册服务的信息 

==> 如果要启动eureka-server，就打成war包，找一个web容器，比如说tomcat，就可以启动了 ==> 测试类里，是基于jetty代码层面来启动jetty web容器和eureka-server，方便测试发送http restful接口的调用请求 

下一讲的预告，eureka-server启动的时候那个初始化的逻辑，就该看EurekaBootStrap listener，里面就包含了eureka-server启动的时候初始化的所有的逻辑          

eureka-server -> build.gradle中的依赖和构建的配置

eureka-server -> web应用 -> war包 -> tomcat就可以启动

web.xml -> listener -> 4个filter -> jersy filter -> filter mapping -> welcome file

### 016_Eureka Server启动之环境初始化以及基于单例模式的配置管理器

double check+volatile的单例模式原理  

![](C:\Users\zy199005\Desktop\中华石杉\images\java\06\01601.png) 

 

web容器（tomcat还是jetty）启动的时候，把eureka-server作为一个web应用给带起来的时候，eureka-server的初始化的逻辑，监听器，EurekaBootStrap。eureka-core里面，监听器的执行初始化的方法，是contextInitialized()方法，这个方法就是整个eureka-server启动初始化的一个入口。 

快捷键，在IntelliJ IDEA里面读源码，如果要跟进一个方法里，那么就用ctrl + 鼠标左键，按住ctrl键，鼠标左击一下，就可以跟进一个方法里去看，或者是一个类里。如果要回退到上一个地方，就按ctrl + alt + 方向键左。 

initEurekaEnvironment()，初始化eureka-server的环境 

在这里，其实会调用ConfigurationManager.getConfigInstance()方法，这个方法，其实就是初始化ConfigurationManager的实例，也就是一个配置管理器的初始化的这么一个过程。ConfigurationManager是什么呢？看字面意思都猜的出来，配置管理器，管理eureka自己的所有的配置，读取配置文件里的配置到内存里，供后续的eureka-server运行来使用。 

配置管理器，是一个单例，用的是单例模式 

经典的单例模式的使用，比较广泛的运用，倒不是说用那个静态内部类的方法，很多人觉得那样写加了一个内部类，比较麻烦。在各种开源项目里，你看源码，人家用的比较多的，其实是double check + volatile。 

（看到这里，如果没有看过面试突击第二季里的volatile原理的同学，麻烦先把面试突击第二季的volatile原理给看一下，因为在人家源码里会大量的看到volatile的使用，所以我们要先熟悉这个关键词的原理，不是轻量级锁，保证多线程可见性的） 

这里，重点理解和熟悉人家的源码的单例模式是怎么用的，单例模式一个经典的作用，就是将配置作为单例，但是一般来说如果你要自己解析配置文件，读取配置的话，一般来说除非你是底层自研的框架。此时你可以设计一个ConfigurationManager，就是一个配置管理器，一般这个会做成单例的。 

如果是单例模式的话，看看人家是如何用double check + volatile来实现线程安全的单例模式的。。。。可以参考一下 

将ConfigurationManager（配置管理器，初始化单例的过程） 

（1）创建一个ConcurrentCompositeConfiguration实例，这个东西，其实就是代表了所谓的配置，包括了eureka需要的所有的配置。在初始化这个实例的时候，调用了坑爹的clear()方法，fireEvent()发布了一个事件（EVENT_CLEAR），fireEvent()这个方法其实是父类的方法，牵扯比较复杂的另外一个项目（ConfigurationManager本身不是属于eureka的源码，是属于netflix config项目的源码）。 

（2）就是往上面的那个ConcurrentCompositeConfiguration实例加入了一堆别的config，然后搞完了以后，就直接返回了这个实例，就是作为所谓的那个配置的单 

（3）看源码，不要较真儿，你是不可能100%把一个源码的每一行代码的细节都仔仔细细的看完，都看懂，都背下来的，是不可能的，抓大放小，搞清楚大的流程、架构以及核心的一些实现的机制和细节 

（4）初始化数据中心的配置，如果没有配置的话，就是DEFAULT data center 

（5）初始化eurueka运行的环境，如果你没有配置的话，默认就给你设置为test环境 

（6）initEurekaEnvironment的初始化环境的逻辑，就结束了 

读源码，以后每一讲结束之后，我都会给大家做点总结，把思路给拉回来，给大家布置课后自己看源码的作业和思路： 

（1）自己把ConfigurationManager的单例初始化的过程看一下

（2）重点理解，ConfigurationnManager源码中体现的double chehck + volatile的单例实现模式的思想和技巧

（3）理解initEurekaEnvironment，初始化环境的逻辑，数据中心 + 运行环境，没设置的话，都给你搞成默认的和测试的1627098499  

### 017_Eureka Server启动之配置文件加载以及面向接口的配置项读取 

加载eureka-server.properties中的配置 

EurekaServerConfig，这是个接口，这里面有一堆getXXX()的方法，包含了eureka server需要使用的所有的配置，都可以通过这个接口来获取 

想象一下，eureka-sever.properties文件里，都是一个一个的key=value的很多的配置项，肯定是将这些key-value格式的配置项加载到内存的Properties对象去存放，Map。一般来说，如果让我们自己来设计这个读取properties文件的配置的代码，也许我们就是做到将配置加载到Properties对象中就结束了。 

EurekaServerConfig，代表了eureka-server需要的所有的配置项，通过接口定义了大量的方法，让你可以从这里获取所有你需要的配置 

Properties prop = new Properties();

prop.load(inputStream) 

如果要获取一个配置项，提供一个方法，get(String key)，return prop.get(key);。 

在外面如果要获取一个配置项，可能会这样子，在一个常量类里搞一堆配置的常量，比如说下面： 

public class Configs { 

public static final String REMOTE_REGION_TOTAL_CONNECTIONS_PER_HOST = “remote.region.total.connections.per.host”; 

} 

get(Configs.REMOTE_REGION_TOTAL_CONNECTIONS_PER_HOST) 

通过这种方式去获取你这个框架配置的各种配置项 

这种方式也不错，因为比如说流行的spark源码里面，就是大量的基于这种常量的方式来获取配置属性的 

但是eureka-server这里，使用了另外一种思想，人家没有用大量的常量，而是针对配置定义了一个接口，接口里通过方法暴露了大量的配置项获取的方法，你呢直接通过这个接口来获取你需要的配置项，即可。 

DefaultEurekaServerConfig，是上面那个接口的实现类，创建实例的时候，会执行一个init()方法，在这个方法中，就会完成eureka-server.properties文件中的配置项的加载，EUREKA_PROPS_FILE，对应着要加载的eureka的配置文件的名字。 

eureka server的配置文件的默认的名称，就是eureka-server 

ConfigurationManager，是个单例，负责管理所有的配置的，ConfigurationManager是属于netfilx config开源项目的，不是属于eureka项目的源码，所以我们大概看一下就可以了，不要去深究了。eureka-server跟.properties给拼接起来了，拼接成一个eureka-server.properties，代表了eureka server的配置文件的名称。 

将eureka-sesrver.properties中的配置，加载到了Properties对象中去；然后会加载eureka-server-环境.properties中的配置，加载到另外一个Properties中，覆盖之前那个老的Properties中的属性。 

将加载出来的Properties中的配置项都放到ConfigurationManager中去，由这个ConfigurationManager来管理 

比如说eureka-server那个工程里，就有一个src/main/resources/eureka-server.properties文件，只不过里面是空的，全部都用了默认的配置 

DefaultEurekaServerConfig.init()方法中，会将eureka-server.properties文件中的配置加载出来，都放到ConfdigurationManager中去，然后在DefaultEurekaServerConfig的各种获取配置项的方法中，配置项的名字是在各个方法中硬编码的，是从一个DynamicPropertyFactory里面去获取的，你可以认为DynamicPropertyFactory是从ConfigurationManager那儿来的，因为ConfigurationManager中都包含了加载出来的配置了，所以DynamicPropertyFactory里，也可以获取到所有的配置项 

在从DynamicPropertyFactory中获取配置项的时候，如果你没配置，那么就用默认值，全部都给你弄好了各个配置项的默认值，相当于所有的配置项的默认值，在DefaultEurekaServerConfig的各个方法中，都可以看到，如果你没配置，那么就用这里的默认值就可以了 

加载eureka-server.properties的过程： 

（1）创建了一个DefaultEurekaServerConfig对象

（2）创建DefaultEurekaServerConfig对象的时候，在里面会有一个init方法

（3）先是将eureka-server.properties中的配置加载到了一个Properties对象中，然后将Properties对象中的配置放到ConfigurationManager中去，此时ConfigurationManager中去就有了所有的配置了

（4）然后DefaultEurekaServerConfig提供的获取配置项的各个方法，都是通过硬编码的配置项名称，从DynamicPropertyFactory中获取配置项的值，DynamicPropertyFactory是从ConfigurationManager那儿来的，所以也包含了所有配置项的值

（5）在获取配置项的时候，如果没有配置，那么就会有默认的值，全部属性都是有默认值的 

我希望大家，这节课过后，顺着上面的思路，创建DefaultEurekaServerConfig对象开始，把上面的思路给捋一遍，自己看一遍源码 

重点体会一个东西，eureka-server的配置管理的机制和思想是什么？不是通过一大堆的常量类获取配置项的，提供了一个获取配置的接口，接口里包含大量的方法，每个方法可以获取一个配置，获取配置的方法里对配置的名称进行硬编码了

### 018_Eureka Server启动之基于构造器模式的服务实例构造 

Application是个什么概念，就是说，如果你是一个eureka client，客户端，扮演的角色其实是一个服务，你作为一个服务会向eureka server去注册。Application，其实你可以认为，就是一个eureka client -> Application，服务。 

EurekaInstanceConfig，其实不用多讲了，其实跟之前的是类似的，其实就是将eureka-client.properties文件中的配置加载到ConfigurationManager中去，然后基于EurekaInstanceConfig对外暴露的接口来获取这个eureka-client.properties文件中的一些配置项的读取，而且人家提供了所有配置项的默认值 

你可以大致认为EurekaInstanceConfig是服务实例相关的一些配置。eureka server同时也是一个eureka client，因为他可能要向其他的eureka server去进行注册，组成一个eureka server的集群。eureka server把自己也当做是一个eureka client，也就是一个服务实例，所以他这里肯定也是有所谓的Application、Instance等概念的。 

InstanceInfo，你可以认为就是当前这个服务实例的实例本身的信息，直接用了构造器模式，用InstanceInfo.Builder来构造一个复杂的代表一个服务实例的InstanceInfo对象。核心的思路是，从之前的那个EurekaInstanceConfig中，读取各种各样的服务实例相关的配置信息，再构造了几个其他的对象，最终完成了InstanceInfo的构建。 

eureka server自己本身代表的一个服务实例，把自己作为一个服务注册到别的eureka server上去，精华，就在于构造器模式的使用。InstanceInfo.Builder，拿到静态内部类的对象，InstanceInfo.Builder.newBuilder()，这个里面就构造了一个InstanceInfo。然后就是基于这个builder去set各种需要的属性和配置，别的对象，搞完了之后，就完成最终的一个复杂的InstanceInfo服务实例对象的这么一个构造。 

直接基于EurekaInstanceConfig和InstnaceInfo，构造了一个ApplicationInfoManager，后面会基于这个ApplicationInfoManager对服务实例进行一些管理。  

自己去读源码的思路： 

（1）加载eureka-client.properties文件的配置，对外提供EurekaInstanceConfig接口的逻辑，去看一下，巩固一下基于接口的配置项读取的思路

（2）基于构造器模式完成的InstanceInfo（服务实例）的构造的一个过程，精华，闪光点，设计模式是怎么用的，怎么玩儿的

（3）EurekaInstanceConfig（代表了一些配置），搞了InstanceInfo（服务实例），基于这俩玩意儿，搞了一个ApplicationInfoManager，作为服务实例的一个管理器

### 019_Eureka Server启动之将自己作为Eureka Client完成复杂构造 

EurekaClientConfig，这个东西也是个接口，也是对外暴露了一大堆的配置项，看名字就知道了啊，这里包含的是EurekaClient相关的一些配置项。也是去读eureka-client.properties里的一些配置，只不过他关注的是跟之前的那个EurekaInstanceConfig是不一样的，代表了服务实例的一些配置项，这里的是关联的这个EurekaClient的一些配置项。 

基于ApplicationInfoManager（包含了服务实例的信息、配置，作为服务实例管理的一个组件），eureka client相关的配置，一起构建了一个EurekaClient，但是构建的时候，用的是EurekaClient的子类，DiscoveryClient。 

说一下基于接口的配置项读取的优势，跟直接拿常量来读取配置项的区别 

假如说你现在要获取一个配置，你调用了Config.get(ConfigKeys.XX_XX_XX)，结果有可能说，你不小心把常量给打错了，或者是搞混了。但是如果你是基于接口，Config.getXxXxXx()，这种方式，还是不错的，不太容易会搞错了。 

优势，Config.get(ConfigKeys.XX_XX_XX)这行代码出现在了20个地方，结果坑爹的事情是，有一天，版本升级，要修改常量的名字，常量名字一修改，你可能要到20个地方去修改，很麻烦，很容易出错。Config.getXxXxXx()，20个地方都调用了这个方法罢了，如果要调整这个常量的名称，直接在方法里修改即可，对调用这个配置项的地方，都是透明的。 

很值得大家来吸收和使用 

AppName，代表了一个服务名称，但是一个服务可能部署多台机器，每台机器上部署的就是一个服务实例，ServiceA/001 

讲一个看源码的技巧，你就顺着整个你平时用这个技术的一个思路去看就好了，而且在看的过程中，记住一个原则：抓大放小，把握大的架构、流程、机制，核心的细节看一下，千万别强迫自己把每个细节每行代码都要看懂。到了后面，针对各个功能、流程以及高级特性，有针对性的看细节的代码，包括各个参数是怎么用的。 

AtomicLong和AtomicReference，都看一下面试突击第二季，原子性操作的一些类 

如果是eureka server的话，我们在玩儿spring cloud的时候，会将这个fetchRegistry给手动设置为false，因为如果就单个eureka server启动的话，就不能设置，但是如果是eureka server集群的话，就还是要保持为true。registerWithEureka是否要设置为true。 

（1）读取EurekaClientConfig，包括TransportConfig

（2）保存EurekaInstanceConfig和InstanceInfo

（3）处理了是否要注册以及抓取注册表，如果不要的话，释放一些资源

（4）支持调度的线程池

（5）支持心跳的线程池

（6）支持缓存刷新的线程池

（7）EurekaTransport，支持底层的eureka client跟eureka server进行网络通信的组件，对网络通信组件进行了一些初始化的操作

（8）如果要抓取注册表的话，在这里就会去抓取注册表了，但是如果说你配置了不抓取，那么这里就不抓取了

（9）初始化调度任务：如果要抓取注册表的话，就会注册一个定时任务，按照你设定的那个抓取的间隔，每隔一定时间（默认是30s），去执行一个CacheRefreshThread，给放那个调度线程池里去了；如果要向eureka server进行注册的话，会搞一个定时任务，每隔一定时间发送心跳，执行一个HeartbeatThread；创建了服务实例副本传播器，将自己作为一个定时任务进行调度；创建了服务实例的状态变更的监听器，如果你配置了监听，那么就会注册监听器 

课后的作业，你就把EurekaClient初始化的过程的源码，按照上面的思路，自己仔细去看一遍，但是注意，抓大放小，不要过度纠结于细节，把握大的流程就可以了

### 020_Eureka Server启动之完成服务器上下文的构造以及初始化

剩余的初始化的步骤 

（1）构造了一个东西：PeerAwareInstanceRegistry 

从名字上我们先来猜测一下，这个是个什么东东？看源码，英文还是要有点功底，源码是用英文写的，人家是老外写的，人家对英文的使用，就跟我们对汉文的使用是一样的。人家对类名、变量名、方法名，全都是通过英文名字来表述出对应的意思的。所以写的好的代码，光是通过上面3个名字，就能让你看懂了，可读性极强。注释不怎么写都可以。 

PeerAware，可以识别eureka server集群的：peer，多个同样的东西组成的一个集群，peers集群，peer就是集群中的一个实例 

InstanceRegistry：实例注册，服务实例注册，注册表，这个里面放了所有的注册到这个eureka server上来的服务实例，就是一个服务实例的注册表 

PeerAwareInstanceRegistry：可以感知eureka server集群的服务实例注册表，eureka client（作为服务实例）过来注册的注册表，而且这个注册表是可以感知到eureka server集群的。假如有一个eureka server集群的话，这里包含了其他的eureka server中的服务实例注册表的信息的。 

抓大放小：抓住主流程、主架构、主要的机制，放掉很多细节性的代码 

连蒙带猜：刚开始你对这个源码没有一个整体上的认识，所以很多东西你开始拿捏不稳，猜测一下 

看源码的技巧，为什么说自己看不懂源码？因为其实你们完全掌握错了看源码的思路、方法还有技巧。像我刚才那样看，直接懵了，一个源码，绝对不是那样看的。一开始，必须是按照一个最基本的主流程，主流程看明白了之后，你回过头来，再把之前看过的每个步骤的细节，再扣进去看，看一些细节，那个时候你才能看懂源码的细节。 

（2）构造了一个东西：PeerEurekaNodes 

猜，PeerEurekaNodes，代表了eureka server集群，peers大概来说多个相同的实例组成的一个集群，peer就是peers集群中的一个实例，PeerEurekaNodes，大概来说，猜测，应该是代表的是eureka server集群 

连蒙带猜的时候，可以根据人家的类的注释，来猜测一下他的大概的用途，写的不一定很清晰，大体上可以猜测出来的 

（3）构造了一个东西：EurekaServerContext 

将上面构造好的所有的东西，都一起来构造一个EurekaServerContext，代表了当前这个eureka server的一个服务器上下文，包含了服务器需要的所有的东西。将这个东西放在了一个holder中，以后谁如果要使用这个EurekaServerContext，直接从这个holder中获取就可以了。这个也是一个比较常见的用法，就是将初始化好的一些东西，放在一个holder中，然后后面的话呢，整个系统运行期间，谁都可以来获取，在任何地方任何时间，谁都可以获取这个上下文，从里面获取自己需要的一些组件。 

（4）EurekaServerContext.initialize() 

peerEurekaNodes.start(); 

这里呢，就是将eureka server集群给启动起来，这里干的事情，我们猜测一下，就是更新一下eureka server集群的信息，让当前的eureka server感知到所有的其他的eureka server。然后搞一个定时调度任务，就一个后台线程，每隔一定的时间，更新eureka server集群的信息。 

registry.init(peerEurekaNodes); 

猜测一下，基于eureka server集群的信息，来初始化注册表，大概猜测，肯定是将eureka server集群中所有的eureka server的注册表的信息，都抓取过来，放到自己本地的注册表里去，多事跟eureka server集群之间的注册表信息互换有关联的 

（5）registry.syncUp(); 

从相邻的一个eureka server节点拷贝注册表的信息，如果拷贝失败，就找下一个 

鱼，没有教你渔 

（6）EurekaMonitors.registerAllStats(); 

跟eureka自身的监控机制相关联的 

读源码，千万不要有强迫症， 很多时候，刚开始看源码的时候，要允许自己对很多细节都不太清楚，但是能大体把握住大的流程就ok了

### 021_边看边思考：来手画一张Eureka Server启动的流程图

eureka server启动的流程图

![](C:\Users\zy199005\Desktop\中华石杉\images\java\06\02101.png)

 

我们看源码，一定要有几个技巧： 

（1）抓大放小：把握主流程、主架构、主机制，放掉一些小的细节

（2）连蒙带猜：有些细节，你不可能跟进去往死里看，都看懂，很多东西要结合源码的注释，先来猜测一下

（3）抓住核心的闪光点（亮点）：设计模式的使用、优秀的实现机制、复杂的算法，等等吧

（4）边看边画图：每次看完源码的一块东西，比如说启动初始化，某个功能，就把这个流程的图画出来，别写类名，一定要自己理解的中文组件的名字，加上英文类名就可以了

### 022_基于eureka自带的例子来体验服务实例的eureka client如何启动的

eureka client启动过程

![](C:\Users\zy199005\Desktop\中华石杉\images\java\06\02201.png)

eureka-examples，有一个类，ExampleEurekaClient，就是一个自带的例子，如果是一个eureka服务，一定会有一个eureka client，服务实例启动的时候，一定会启动eureka client，eureka client去向eureka server去服务注册 

ExampleEurekaClient，相当于是一个你自己写的普通的服务

 

（1）读取eureka-client.properties配置文件，形成一个服务实例的配置，基于接口对外提供服务实例的配置项的读取

（2）基于服务实例的配置，构造了一个服务实例（InstanceInfo）

（3）基于服务实例的配置和服务实例，构造了一个服务实例管理器（ApplicationInfoManager）

（4）读取eureka-client.properites配置文件，形成一个eureka client的配置，接口接口对外提供eureka client的配置项的读取

（5）基于eureka client配置，和服务实例管理器，来构造了一个EurekaClient（DiscoveryClient），保存了一些配置，处理服务的注册和注册表的抓取，启动了几个线程池，启动了网络通信组件，启动了一些调度任务，注册了监控项

### 023_在眼花缭乱的代码中找到eureka client是如何进行服务注册的

我这边直接告诉大家，我个人认为，在eureka client这里的设计思路上，不是特别好。 

说实话，其实一般来说，我个人崇尚的是比较简化的这么一个设计思路，就是类的层次关系，可以有一定的继承、实现接口、父类子类，但是问题是，我们不是很建议把代码搞的特别复杂，就是你想找一个代码，结果发现找半天都找不到。 

这个就会导致你的代码的可读性，并不是特别好 

我说实话，站在局外人的角度，来看待eureka client的注册，我会发现说，我把eureka client的启动过程都看了一下，结果居然没发现注册的地方，这个我认为就是eureka client的代码设计有问题。 

eureka server是一个注册中心，肯定是要接受服务注册的，eureka client，注册这个事儿，就是一个非常非常重要的一个环节，你是不应该在代码的设计中，把他隐藏的过于深的， 这会导致你的核心流程的逻辑不通畅，可读性不是特别好 

我当时找这个eureka client注册的代码，找了很多地方，然后找来找去，终于找到了是在哪里，一会儿我带着大家来看一下，大家一看就会发现，这个代码，设计的不好 

我这里先来给大家揭示一下，我告诉大家，服务注册的地方，就在这个InstanceInfoReplicator组件里面，服务实例信息复制组件，就是这么一个复制组件，来负责服务的注册。我觉得这么设计很不好。明明是一个注册的概念，结果他搞了一个复制的概念，replicate绝对不是用在这种地方的。 

用在比如说，你有一个数据，你现在要复制几个副本，放到其他的机器上去，一般对这种行为，我们称之为replicate。把服务实例的信息replicate到一个eureka server上去，是非常不合适的。 

InstanceRegisterManager，实例注册管理器，专门来管理实例注册的这个事情 

（1）InstanceInfoReplicator的start()方法里面，将自己作为一个线程放到一个调度线程池中去了，默认是延迟40s去执行这个线程，还将isDirty设置为了ture 

（2）如果执行线程的时候，是执行run()方法，线程 

（3）先是找EurekaClient.refreshInstanceInfo()这个方法，里面其实是调用ApplicationInfoManager的一些方法刷新了一下服务实例的配置，看看配置有没有改变，如果改变了，就刷新一下；用健康检查器，检查了一下状态，将状态设置到了ApplicationInfoManager中去，更新服务实例的状态 

（4）因为之前设置过isDirty，所以这里会执行进行服务注册 

（5）服务注册的时候，是基于EurekaClient的reigster()方法去注册的，调用的是底层的TransportClient的RegistrationClient，执行了register()方法，将InstanceInfo服务实例的信息，通过http请求，调用eureka server对外暴露的一个restful接口，将InstanceInfo给发送了过去。这里找的是EurekaTransport，在构造的时候，调用了scheduleServerEndpointTask()方法，这个方法里就初始化了专门用于注册的RegistrationClient。 

（6）找SessionedEurekaHttpClient调用register()方法，去进行注册，看到这里，基本上就被他的这个类体系给绕晕了，我在项目阶段一里面虽然用了很多的设计模式，但是基本上就一两层，或者是两三层，一般很快你就会找到一个东西的实现类 

（7）他对RegistrationClient的类体系的设计，非常的不合理，我们找了半天，都没找到，到底是哪个client，找的人是眼花缭乱。如果说你在看源码的时候，发现了这个问题，其实这个时候，发挥一个思想：连蒙带猜。我个人坚决不支持这样来设计源码，如果你这么来设计，没几个人能看懂你的这个源码。好的开源项目，代码必须写的非常好，非常优雅，非常容易阅读。 

（8）eureka大量的基于jersey框架，在eureka server上提供restful接口，在eureka client如果要发送请求到eureka server的话，一定是基于jersey框架，去发送的http restful接口调用的请求 

（9）真正执行注册请求的，就是eureka-client-jersey2工程里的AbstractJersey2EurekaHttpClient，请求http://localhost:8080/v2/apps/ServiceA，将服务实例的信息发送过去 

eureka client这一块，在服务注册的这块代码，很多槽点： 

（1）服务注册，不应该放在InstanceInfoReplicator里面，语义不明朗 

（2）负责发送请求的HttpClient，类体系过于复杂，导致人根本就找不到对应的Client，最后是根据他是使用jersey框架来进行restful接口暴露和调用，才能连蒙带猜，找到真正发送服务注册请求的地方 

听完这一堂课之后，你要明白的eureka client的核心机制： 

（1）eureka client的服务注册，是在InstanceInfoReplicator中的

（2）实际发送服务注册请求的是AbstractJersey2EurekaHttpClient，调用了一个restful接口

### 024_打断点调试一下eureka server端是如何完成服务注册的

eureka client，启动初始化的时候，有一个组件，叫做InstanceInfoReplicator，服务实例信息复制组件，EurekaClient里面设计一个register()方法就可以了。调用了一个EurekaHttpClient，发送了一个http请求，调用了eureka server的一个restful接口。 

我们就是看一下eureka server的restful接口接到了这个请求之后，后面是怎么完成服务实例的注册的。 

在这个eureka core的resources包下面，有一堆的resources，这些resource相当于是spring web mvc的controller，用来接收这个http请求的。resources相当于是jersey里面的controller吧。 

所有的请求都会发送到eureka server的web应用，最后都会走jersey的servlet，jersey的servlet会根据请求的路径，将请求转发给eureka core里面的resource（相当于是转发给某个controller）。 

ApplicationResources，里面是接收这个请求的。http://localhost:8080/v2/apps/ServiceA，这么一个地址。ServiceA可以认为是一个app name，也可以是app id，标志了一个服务，就是服务名称。用ApplicationResource来处理，看看对这个url发起的是什么请求，GET？POST？PUT？DELETE？post请求，带着InstanceInfo实例打成的一个json过来的。 

ApplicationResource的addInstance()方法，是接收post请求的，看方法名就知道是服务实例的注册的。接收的是一个InstanceInfo，代表了一个服务实例。服务可能会部署在多台机器上，每台机器上部署的就是一个服务实例。 

看源码，可以大量的使用人家的单元测试，通过单元测试作为入口进去，一步一步调试人家的源码。 

所谓的InstanceInfo，服务实例，里面最主要的就是包含2块数据： 

（1）主机名、ip地址、端口号、url地址

（2）lease（租约）的信息：保持心跳的间隔时间，最近心跳的时间，服务注册的时间，服务启动的时间 

**闪光点1** 

在ApplicationResource.addInstance()方法中，进来就是大量的check相关的代码逻辑，防御式编程，保持代码的健壮性。一个写的非常好的代码，一定要能够应对别人胡乱传递的各种参数，所以重要的接口，上来就是一个代码逻辑，对请求参数进行大量的校验。 

但是一般建议，将这种重要接口的请求参数的校验逻辑，都放在单独的私有方法中 

**槽点1** 

在eureka的代码中，大量的硬编码，对是否在亚马逊的AWS云上运行，还是在自己部署的机器上运行，都做了if else的判断，这个是很不好的。不应该这样子的，起码得用策略模式，屏蔽掉这一块的if else。 

策略模式，在外面的配置文件中，专门搞一个配置项，eureka.server.env = default，但是可以配置为eureka.server.env = aws。然后在代码里，如果是要区别对待AWS云环境的地方，直接就是根据这个外部的配置项，获取一个专门的对应的一个策略，比如说DefaultDataCenter逻辑，AWSDataCenter。 

对外都是统一的接口，DataCenter。统一的都是面向DataCenter来执行的。 

**槽点2** 

“true”.equals()：硬编码了，这个绝对是低级的，应届生级别的代码 

Response.status(204)：硬编码，magic number，绝对是应届生级别的代码 

PeerAwareInstanceRegistry：注册表，包含所有的服务实例注册的信息 

PeerAwareInstanceRegistry.register()方法，将服务实例往注册表去进行注册，实际上会调用父类AbstractInstanceRegistry的register()方法中去了 

appName，APPLICATION0，服务名称，ServiceA，或者是别的什么名称 

instanceId，i-0000001，服务实例id，一个服务名称会对应多个服务实例，每个服务实例的服务名称当然是一样的咯，但是服务实例id是不一样的 

如果是一个服务实例第一次来注册，就很简单，将服务实例信息放到了一个map中去，形成了这样的数据结构： 

**闪光点2** 

ConcurrentHashMap<String, Map<String, Lease<InstanceInfo>>> 

这个就是所谓的注册表，核心的数据结构

```
{
“ServiceA”: {
“001”: Lease<InstanceInfo>,
“002”: Lease<InstanceInfo>,
“003”: Lease<InstanceInfo>
},

“ServiceB”: {
“001”: Lease<InstanceInfo>
}
} 
```

可以跟人家学习一个类似这种内存注册表的一种实现形式，就是最简单的就是用ConcurentHashMap保证多线程并发安全就可以了，然后将每个服务的每个服务实例的信息，都保存在这个map里面。

读写锁的一个应用，ReentranctReadWriteLock，注册的时候，上的是读锁。多个服务实例，可以同时来注册。灵活的运用读写锁，可以控制多线程的并发，有些操作是可以并发执行的，有些操作是互斥的。 

布置一个作业： 

（1）跟我一样，从单元测试方法入手，来断点调试服务注册的代码，把代码的逻辑大致看一遍就可以

（2）重点关注的是服务注册表的数据结构，map

（3）服务注册的本质：就是将服务实例的信息放入一个map中

（4）如果一点点扣这个细节，看源码的速度就太慢了，而且没有意义 

你能达到我们这个读源码的程度，无论是对你的技术功底的积累，对底层的源码核心流程、主要架构、核心机制，都是有研究的，如果出现一些源码级别的报错，或者是异常，你随时可以找到源码，再仔细看那一小块的源码。 

把控住了整体的源码的设计思想，以后你自己设计系统的时候，也可以借鉴别人的架构设计的思想，代码设计的思想 

你大量读了底层的源码之后，你就一直跟着课程来看源码，到了后面读其他的源码，会觉得越来越的容易 

出去面试的话，读到的这些源码的逻辑，直接可以给面试官开喷，人家只能傻愣愣的听着，甚至你可以现场各种画图，画这些技术的底层逻辑

### 025_咱们来画张图梳理一下eureka的服务注册的流程

eureka的服务注册的流程

![](C:\Users\zy199005\Desktop\中华石杉\images\java\06\02501.png)

 

一旦完成了服务注册之后，咱们平时访问的eureka控制台，其实就是个jsp，status.jsp 

在jsp代码中，拿到了EurekaServerContext，所以之前为什么要将这个东东放到一个Holder里面去，就是随时都要从这个里面去获取一些数据 

然后会从EurekaServerContext，获取到注册表，PeerAwareInstanceRegistry，注册表，从里面获取所有的服务信息，从底层的map数据结构中，获取所有的服务注册的信息，遍历，封装到一个叫Application的东西里去，一个Application就代表了一个服务，里面包含很多个服务实例。 

然后就是将每个服务实例的信息，处理一下，形成一个服务的完整的这么一份信息，比如说有几个服务实例，每个服务实例的url地址是什么。

### 026_eureka client第一次启动时全量抓取注册表的源码剖析 

（1）eureka server启动以及初始化

（2）eureka client启动以及初始化

（3）eureka client向eureka server进行服务实例的注册，eureka控制台可以看到注册的服务

（4）eureka client完成自身的注册之后，我们肯定要来看抓取注册表的逻辑 

先来看看eureka client端的抓取注册表的逻辑，抓取注册的逻辑，真正复杂的地方是在eureka server端，那边有一套较为复杂和优秀的缓存机制 

全量抓取注册表，eureka client第一次启动的时候，必须从eureka server端一次性抓取全量的注册表的信息过来，在本地进行缓存，后面的话呢，每隔30秒从eureka server抓取增量的注册表信息，跟本地缓存进行合并 

如果你配置了应该要抓取注册表的信息，那么就会在启动的时候来一次全量的注册表的抓取过程： 

（1）EurekaClient初始化的时候，就会自动全量抓取注册表 

（2）先获取本地的Applications缓存，Applications是什么东西？就是所有的服务，Applicaiton是一个服务，Applications是所有的服务，Application中包含了他自己的所有的InstanceInfo，就是一个服务包含了自己的所有的服务实例 

（3）**槽点1**：判断是否要进行全量抓取注册表的时候，来了一大坨的if表达式，这个是要不得的，这个代码可读性太差了。netflix的这个写eureka client的这个哥儿们，代码功底不太ok。

（4）调用jersey client，发送http请求（http://localhost:8080/v2/apps），GET请求，调用eureka server的getApplications restful接口，获取全量注册表，缓存在自己的本地

### 027_eureka server的注册表多级缓存机制源码剖析（只读缓存+读写缓存）

eureka-server的多级缓存机制

![](C:\Users\zy199005\Desktop\中华石杉\images\java\06\02701.png)

eureka client初始化的时候，就会自动发送个请求到eureka server拉一次清抓取全量的注册表，这一讲，我们来看看eureka server端如何处理抓取全量注册表的请求的，eureka client发送的请求是：http://localhost:8080/v2/apps/，get请求  

ApplicationsResource的getContainers()方法，获取全量注册表的方法 

说一个源码阅读的小技巧：抓大放小，看源码的整体架构、核心流程、复杂机制 

很多琐碎的小代码，你可能很难看懂，不是你的问题，是开源项目的源码贡献者写的代码其实也很乱，很凌乱，命名都不太靠谱，可能就导致代码的可读性不高，一般来说，你看，一些牛叉的开源项目，最最核心的几个人，其实都是那种特别牛的大牛，一开始就做这个开源项目的人，对这个开源项目很熟悉 

如果是一个开源项目开始以后，临时半路杀进去的一个人，成为这个开源项目的核心贡献者，挺少的，很多开源项目的代码也是挺烂的，看都不好看 

eureka server端，支持你来读取注册表的时候，搞了一套短小精干的多级缓存机制 

也就是说，你eureka client发送请求过来读取全量注册表的时候，其实会从多级缓存里去读取注册表的数据，所以这里的cacheKey，就是全量注册表的缓存key 

ResponseCache，就是eureka server端的缓存机制 

多级缓存机制，用了两个map，来做了两级缓存，只读缓存map，读写缓存map，先从只读缓存里去读，如果没有的话，会从读写缓存里去读，如果还是没有呢？如果这个读写缓存，没有缓存的话，会从eureka server的注册表中去读取

从注册表中获取所有的Applications，ServerCodecs，json序列化的组件，将Applications对象序列化为了一个json字符串，将注册表中读取出来的Applications，放入读写缓存，接着放入只读缓存中去 

最后呢，就是将从多级缓存机制中读取出来的全量的Applications作为响应来返回

### 028_eureka server的注册表多级缓存过期机制：主动过期+定时过期+被动过期

eureka-server的多级缓存过期机制 

![](C:\Users\zy199005\Desktop\中华石杉\images\java\06\02801.png)   

（1）主动过期 

readWriteCacheMap，读写缓存 

有新的服务实例发生注册、下线、故障的时候，就会去刷新readWriteCacheMap 

比如说现在有一个服务A，ServiceA，有一个新的服务实例，Instance010来注册了，注册完了之后，其实必须是得刷新这个缓存的，然后就会调用ResponseCache.invalidate()，将之前缓存好的ALL_APPS这个key对应的缓存，给他过期掉 

将readWriteCacheMap中的ALL_APPS缓存key，对应的缓存给过期掉 

（2）定时过期 

readWriteCacheMap在构建的时候，指定了一个自动过期的时间，默认值就是180秒，所以你往readWriteCacheMap中放入一个数据过后，自动会等180秒过后，就将这个数据给他过期了 

（3）被动过期 

readOnlyCacheMap怎么过期呢？ 

默认是每隔30秒，执行一个定时调度的线程任务，TimerTask，有一个逻辑，会每隔30秒，对readOnlyCacheMap和readWriteCacheMap中的数据进行一个比对，如果两块数据是不一致的，那么就将readWriteCacheMap中的数据放到readOnlyCacheMap中来。 

比如说readWriteCacheMap中，ALL_APPS这个key对应的缓存没了，那么最多30秒过后，就会同步到readOnelyCacheMap中去 

（4）很重要的问题 

假设有服务实例注册、下线、故障，要调用这个服务的其他服务，可能会过30秒之后才能感知到，为什么呢？因为这里在获取服务注册表的时候，有一个多级缓存的机制，最多是30秒才会去更新缓存

### 029_eureka client每隔30秒增量抓取注册表的源码剖析（一致性hash比对机制）

eureka client增量抓取注册表

 ![](C:\Users\zy199005\Desktop\中华石杉\images\java\06\02901.png)

 eureka client启动的时候，会去抓取一次全量的注册表，整个这套机制，我们都已经在源码看的比较清晰了，启动的时候，同时会启动一个定时调度的线程，每隔30秒，会发送一次请求到eureka server，抓取增量的注册表 

什么叫做增量的注册表呢？就是说跟上一次抓取的注册表相比，有变化的部分，给抓取过来就可以了，不需要每次都抓取全量的注册表 

（1）定时任务，每隔30秒来一次

（2）因为本地已经有了缓存的Applications，所以再次抓取注册表的时候，走的是增量抓取的策略

（3）这块会走EurekaHttpClient的getDelta()方法和接口，http://localhost:8080/v2/apps/delta，get请求

（4）说实话，我在这里都看的出来，写eureka client和eureka server的哥儿们，估计就不是一个人，这家伙，编码的风格，不太像，包括对方法的命名，eureka core的ApplicationsResource的getContainerDiffretional。

（5）在eureka server端，会走多级缓存的机制，缓存的Key，ALL_APPS_DELTA，唯一的区别在哪儿呢？就是在那个readWriteCacheMap的从注册表获取数据那里是不一样的，registry.getApplicationDeltasFromMultipleRegions()获取增量的注册表，就是从上一次拉取注册表之后，有变化的注册表

（6）recentlyChangedQueue，代表的含义是，最近有变化的服务实例，比如说，新注册、下线的，或者是别的什么什么，在Registry构造的时候，有一个定时调度的任务，默认是30秒一次，看一下，服务实例的变更记录，是否在队列里停留了超过180s（3分钟），如果超过了3分钟，就会从队列里将这个服务实例变更记录给移除掉。也就是说，这个queue，就保留最近3分钟的服务实例变更记录。delta，增量。

（7）eureka client每次30秒，去抓取注册表的时候，就会返回最近3分钟内发生过变化的服务实例

（8）抓取到的delta的注册表，就会跟本地的注册表进行合并，完成服务实例的增删改

（9）对更新完合并完以后的注册表，会计算一个hash值；delta，带了一个eureka server端的全量注册表的hash值；此时会将eureka client端的合并完的注册表的hash值，跟eureka server端的全量注册表的hash值进行一个比对；如果说不一样的话，说明本地注册表跟server端不一样了，此时就会重新从eureka server拉取全量的注册表到本地来更新到缓存里去 

确实觉得，写eureka server的同学的水平，技术确实很不错，有很多亮点，eureka client的同学，技术有点问题的，从代码层面可以看出来，eureka clinet的这个人经验不是很丰富，就不是比较厉害的 

**eureka server这块，学到两个闪光点：** 

（1）增量数据的设计思路：如果你要保存一份增量的最新变更数据，可以基于LinkedQuueue，将最新变更的数据放入这个queue中，然后后台来一个定时任务，每隔一定时间，将在队列中存放超过一定时间的数据拿掉，保持这个队列中就是最近几分钟内的变更的增量数据 

（2）数据同步的hash值比对机制：如果你要在两个地方，一个分布式系统里，进行数据的同步，可以采用Hash值的思想，从一个地方的数据计算一个hash值，到另外一个地方，计算一个hash值，保证两个hash值是一样的，确保这个数据传输过程中，没有出什么问题 

上两讲，多级缓存的机制，也是eureka server端的那个哥儿们写的，eureka server端的哥儿们，代码，系统设计，机制的设计，一看就是有经验的；eureka client，技术不错，但是系统设计的经验不够丰富

### 030_服务实例与注册中心之间的心跳机制（服务续约）源码剖析以及源码重构示范 

eureka server启动，eureka client启动，服务注册，注册中心控制台，服务发现 

心跳，eureka client每隔一定的时间，会给eureka server发送心跳，保持心跳，让eureka server知道自己还活着 

lease renewal，续约，心跳 

（1）DiscoveryClient初始化的时候，会去调度一堆定时任务，其中有一个就是HeartbeatThread，心跳线程 

（2）在这里可以看到，默认是每隔30秒去发送一次心跳，每隔30秒执行一次HeartbeatTHread线程的逻辑，发送心跳 

（3）这边的话就是去发送这个心跳，走的是EurekaHttpClient的sendHeartbeat()方法，http://localhost:8080/v2/apps/ServiceA/i-000000-1，走的是put请求 

（4）负责承接服务实例的心跳相关的这些操作的，是ApplicationsResource，服务相关的controller。jersey的mvc框架，国内很少有用jersey，spring web mvc大家都看得懂。找到ApplicationResource，再次找到InstanceResource，通过PUT请求，可以找到renewLease方法。 

（5）通过注册表的renew()方法，进去完成服务续约，实际进入AbstractInstanceRegistry的renew()方法 

（6）从注册表的map中，根据服务名和实例id，获取一个Lease<InstanceInfo>，对服务续约的代码进行了调整，让代码可读性更好，更加的优雅。实际的服务续约的逻辑，其实就是在Lease对象中，更新一下lastUpdateTimestamp这个时间戳，每次续约，就更新一下这个时间戳就ok了。 

最后给大家说一点： 

（1）分布式系统里面，心跳机制，是很重要的，可以让一个中枢控制的服务，监控所有其他的工作服务是否还活着，这个所以是一个心跳机制，就是每次更新心跳，就更新最近的一次时间戳就可以了 

（2）学习一下，如何编写优雅的代码，可读性强、扩展性强

### 031_停止服务实例时的服务下线以及实例摘除机制源码剖析

服务下线的逻辑

![](C:\Users\zy199005\Desktop\中华石杉\images\java\06\03101.png)

本来现在就是一个注册中心，还有很多个服务，在线上跑着，各个服务都会时不时来一个心跳，一切都很好，但是现在的话是这样子的。如果某个服务现在要停机，或者是重启，首先就会关闭，此时会发生什么样的事情呢？ 

eureka client关闭的话，服务停止，需要你自己去调用EurekaClient的shutdown()，将服务实例停止，所以说呢，我们重点就是从EurekaClient的shutdown()方法开始入手来看。 

比如说你如果eureka client也是跟着一个web容器来启动的，ContextListener，里面有一个contextDestroyed()，在这个方法里，你就调用eureka client的shutdown()方法就可以了。 

（1）DiscoveryClient中的shutdown()方法，需要你自己调用这个方法

（2）DiscoveryClient中的unregister()方法中，取消注册，调用EurekaHttpClient的cancel()方法，http://localhost:8080/v2/apps/ServiceA/i-00000-1，delete请求

（3）会在eureka core中的InstanceResource中，调用注册表的cancelLease()方法，调用父类的canel()方法，interlCancel()方法

（4）将服务实例从eureka server的map结构的注册表中移除掉

（5）最最核心的是调用了Lease的cancel()方法，里面保存了一个evictionTimestamp，就是服务实例被清理掉，服务实例下线的时间戳

（6）将服务实例放入最近变化的队列中去，让所有的eureka client下一次拉取增量注册表的时候，可以拉取到这个服务实例下线的这么一个变化

（7）服务实例变更过了，必须将之前的缓存都清理掉，从readWriteCacheMap中清理掉

（8）然后我之前给大家讲过，定时过期的一个过程，就是有一个定时的任务，每隔30秒，将readWriteCacheMap和readOnlyCacheMap进行一个同步

（9）下次所有的eureka client来拉取增量注册表的时候，都会发现readOnlyCacheMap里没有，会找readWriteCacheMap也会发现没有，然后就会从注册表里抓取增量注册表，此时就会将上面那个recentCHangedQuuee中的记录返回 

有一个机制，给大家说一下，服务实例下线 

（1）在注册中心，将服务实例从注册表中移除，下线的服务放入recentChangedQueue中去

（2）每个服务都会定时拉取增量注册表，此时可以从recentChangedQueue中感知到下线的服务实例，然后就可以在自己本地缓存中删除那个下线的服务实例

### 032_服务实例的自动故障感知以及服务实例自动摘除机制源码剖析

如果eureka client要停机，你呢要在代码里自己调用DiscoveryClient的shutdown()方法，就会发送请求到eureka server去下线一个服务实例。很多时候，可能不是说你把某个服务给停机了，而是说服务自己宕机了，就不会调用shutdown()方法，也不会去发送请求下线服务实例。 

eureka自己，有一个所谓到自动故障感知机制，以及服务实例摘除的机制 

eureka靠的是心跳，来感知，可能某个服务已经挂掉了，就不会再发送心跳了，如果在一段时间内没有接收到某个服务的心跳，那么就将这个服务实例给摘除，认为这个服务实例已经宕机了 

给大家找一下，自动检查服务实例是否故障宕机的入口：EurekaBootStrap，eureka server在启动初始化的时候，registry.openForTraffic(applicationInfoManager, registryCount);。如果没有我告诉你，你要自己找到这个入口，你该在哪里找呢？你思考一下，如果要启动一个定时检查服务实例有没有宕机的后台线程任务，eureka server启动初始化的时候，会去启动那么一个后台线程。 

EurekaBootStrap里面找，检查服务实例有没有宕机的这个东西，最可能跟谁是相关的呢？肯定是注册表啊。。。。服务实例信息都在注册表里，registry。所以就在registry相关的地方来寻找一下。eureka代码写的不好，服务实例是否故障宕机的后台检查线程任务，绝对应该是在Registry初始化的过程中来启动。 

PeerAwareInstanceRegistry.openForTraffic()方法里，最后隐藏了一行调用，postInit()。每隔60s会运行一次定时调度的后台线程任务，EvictionTask。eureka的代码写的很随意，就是没有任何系统设计感，里面一些组件的划分和设计，系统运行流程的设计，都不太清晰和合理。 

对并发的东西大量的使用：volatile、synchronized、ReentractReadWriteLock、Atomic。分布式系统，因为要在内存中保存大量的东西，所以在这里会使用大量的并发编程的这个东西。网上看视频课程，看一些文章，都是并发编程的东西，我平时写业务系统，几乎用不到。 

用并发编程的东西，都是一些底层的分布式系统，或者是基础框架，分布式系统或者框架，需要在内存中保存很多的数据，只要是在内存中保存的数据，一定会有多线程并发读写的风问题。此时一定是大量的使用并发编程相关的东西。 

但是如果是那种业务代码，CRUD，基于数据库，来增删改查。 

但是我们的并发编程，我就压根儿从来了没想过要在前面的地方来讲，因为我是打算到了后面的底层分布式系统研发，基础框架的研发，我们要做这些东西的时候，肯定会大量在内存里基于数据结构来保存各种东西，队列、map、set、list，到时候我们要是对JDK的数据结构的源码来深度剖析。并发编程这一块，我们会大量的使用。 

讲完这些集合源码、并发包源码，我们再来开发这些底层的基础框架，或者是分布式系统，学完立马在项目里来实战，效果是非常好的。 

（1）获取一个补偿时间，是为了避免说EvictionTask两次调度的时间超过了设置的60s，**补偿时间的机制**，大家可以学习一下这个东西的使用 

19:55:00 3分钟 19:58:00 -> 过期

EvictionTask本身调度的就慢了，比上一次该调度的时间晚了92s

19:55:00过后，3分钟内没有心跳，在他延迟的这92s之内，也没心跳，19:59:32，都没心跳发送过，才能认为是失效 

（2）遍历注册表中所有的服务实例，然后调用Lease的isExpired()方法，来判断当前这个服务实例的租约是否过期了，是否失效了，服务实例故障了，如果是故障的服务实例，加入一个列表。如果上次的心跳到现在间隔了90s * 2 = 180s，3分钟，才会认为是故障了。闪光点，突出你的牛的地方，**eureka bug**。 

（3）不会一次性将所有故障的服务实例都摘除，每次最多讲注册表中15%的服务实例给摘除掉，所以一次没摘除所有的故障实例，下次EvictionTask再次执行的时候，会再次摘除，**分批摘取机制** 

（4）在摘除的时候，是从故障实例中随机挑选本次可以摘除的数量的服务实例，来摘除，**随机摘取机制** 

（5）摘除服务实例的时候，其实就是调用下线的方法，internelCancel()方法，注册表、recentChangeQueue、invalidate缓存

### 033_eureka server网络故障时的的自我保护机制源码剖析

eureka自我保护机制

![](C:\Users\zy199005\Desktop\中华石杉\images\java\06\03301.png)

eureka server启动、eureka client启动、服务注册、注册表拉取、心跳（服务续约）、服务下线、服务故障 --> eureka自我保护机制 

假如说，20个服务实例，结果在1分钟之内，只有8个服务实例保持了心跳 --> eureka server是应该将剩余的12个没有心跳的服务实例都摘除吗？ 

这个时候很可能说的是，eureka server自己网络故障了，那些服务没问题的。只不过eureka server自己的机器所在的网络故障了，导致那些服务的心跳发送不过来。就导致eureka server本地一直没有更新心跳。 

自己进入一个自我保护的机制，从此之后就不会再摘除任何服务实例了 

注册表的evict()方法，EvictionTask，定时调度的任务，60s来一次，会判断一下服务实例是否故障了，如果故障了，一直没有心跳，就会将服务实例给摘除。 

1、evict()方法内部，先会判断上一分钟的心跳次数，是否小于我期望的一分钟的心跳次数，如果小于，那么压根儿就不让清理任何服务实例 

2、我期望的一分钟的心跳次数是怎么算出来的？ 

（1）eureka server启动的时候，就会初始化一次这个值 

EurekaBootStrap是启动的初始化的类 

registry.openForTraffic(applicationInfoManager, registryCount); 

完成了numberOfRenewsPerMinThreshold这个值，我期望一分钟得有多少次心跳的值，初始化。刚开始会调用syncUp()的方法，从相邻的eureka server节点，拷贝过来注册表，如果是自己本地还没注册的服务实例，就在自己本地注册一下。 

会记录一下从别的eureka server拉取过来的服务实例的数量，将这个服务实例的数量，就作为自己eureka server本地初始化的这么一个服务实例的数量。将服务实例数量 * 2。代码写的很垃圾，期望心跳次数的计算，居然hard code了。 

大名鼎鼎的spring cloud的源码，也就这么回事，netflix可是全世界的微服务的鼻祖，非常厉害的一个公司，代码水准。 

假设你现在有20个服务实例，每个服务实例每30秒发送一次心跳，于是一分钟一个服务实例应该发送2次心跳，1分钟内我期望获取到的心跳的次数，应该是20 * 2 = 40个心跳。我甚至很怀疑，这个代码是那种刚毕业的学生，应急生，或者是实习生的。 

假设现在我们默认的心跳是30秒1次，如果我调整了撑10秒一次心跳了？？？怎么办？？这里的count * 2，就错了。 

用这个服务实例 * 2 * 0.85 = 20 * 2 * 0.85 = 34，期望的是最少一分钟20个服务实例，得有34个心跳。根据当前的服务实例的数量，计算出来的一分钟最少需要的心跳次数。服务实例个数 * （60 / 心跳时间间隔） * 0.85 = 每分钟最少的心跳次数。 

（2）注册、下线、故障 

这个每分钟期望的心跳的次数，是跟咱们的这个服务实例的数量相关的，服务实例随着上线和下线、故障，都在不断的变动着。注册的时候，每分钟期望心跳次数 + 2。服务下线的时候，直接每分钟期望心跳次数 - 2。 

故障的时候，摘除一个服务实例，居然没找到更新期望心跳次数的代码。bug，如果说有很多的服务实例都是故障下线的，摘除了。结果每分钟期望的心跳次数并没有减少，但是实际的服务实例变少了一些，就会导致实际的心跳次数变少，如果说出现较多的服务实例故障被自动摘除的话，很可能会快速导致eureka server进自我保护机制。 

实际的心跳次数比期望的心跳次数要小，就不会再摘除任何服务实例了 

（3）定时更新 

Registry注册表，默认是15分钟，会跑一次定时任务，算一下服务实例的数量，如果从别的eureka server拉取到的服务实例的数量，大于当前的服务实例的数量，会重新计算一下，主要是跟其他的eureka server做一下同步 

触发概率很小 

3、实际的上一分钟的心跳次数是怎么算出来的 

抓大放小，之前我们看源码的时候，看到过这个MeasutredRate，当时肯定是看不懂的，因为很多代码，都是一个机制相关的。每次一个心跳过来，一定会更新这个MeasturedRate。来计算每一分钟的心跳的实际的次数。 

MeasuredRate，好好看看，**技术亮点：如何计算每一分钟内的一个内存中的计数的呢？计算每一分钟内的心跳的次数？** 

4、来看看自我保护机制的触发 

如果上一分钟实际的心跳次数，比我们期望的一分钟的心跳次数要小，触发自我保护机制，不允许摘除任何服务实例，此时认为自己的eureka server出现网络故障，大量的服务实例无法发送心跳过来 

5、eureka这一块，自我保护机制，你必须从源码级别要看懂 

因为其实在线上的时候，最坑爹的就是这儿，就是你会发现有些服务实例下线了，但是eureka控制台老是没给他摘除，自我保护机制了。线上生产环境，如果你可以的话，你可以选择将这个自我保护给关了。如果eureka server接收不到心跳的话，各个服务实例也是无法从eureka server拉取注册表的。每个服务实例直接基于自己的本地的注册表的缓存来就可以了。自我保护机制给打开也可以，从源码层面硬知道了，服务故障摘除，自我保护的源码，如果你发现线上生产环境，出现了一些问题，你可以从源码级别去看一下是怎么回事。

### 034_eureka server集群机制源码剖析：注册表同步以及高可用 

eureka server集群机制

![](C:\Users\zy199005\Desktop\中华石杉\images\java\06\03401.png)

我来大家讲一下eureka server集群的机制 

我打算换一种方式给大家来讲这个源码，我之前的一个思路，是说带着疑问，从对应的源码入口进去，开始一点一点的读源码，读完了之后，来把这一块机制给画一幅图 

我呢上来先给你把图画出来，让你对我们这一讲要剖析源码的这个机制，的大体的原理有一定的了解，脑子里先有数，这样的话呢，在看明白了这个图之后，再来进入源码，一点一点的看源码 

（1）eureka core的BootStrap里面，有一块代码，是PeerEurekaNodes的代码，其实是在处理eureka server集群信息的初始化，会执行PeerEurekaNodes.start()方法 

解析配置文件中的其他eureka server的url地址，基于url地址构造一个一个的PeerEurekaNode，一个PeerEurekaNode就代表了一个eureka server。启动一个后台的线程，默认是每隔10分钟，会运行一个任务，就是基于配置文件中的url来刷新eureka server列表。 

（2）registry.syncUp() 

就是说，当前这个eureka server会从任何一个其他的eureka server拉取注册表过来放在自己本地，作为初始的注册表。将自己作为一个eureka client，找任意一个eureka server来拉取注册表，将拉取到的注册表放到自己本地去。 

eurekaClient.getApplications(); 

eureka server自己本身本来就是个eureka client，在初始化的时候，就会去找任意的一个eureka server拉取注册表到自己本地来，把这个注册表放到自己身上来，作为自己这个eureka server的注册表 

（3）注册、下线、故障、心跳 

如何从一台eureka server同步到另外一台eureka server上去的 

ApplicationResource的addInstance()方法，负责注册，现在自己本地完成一个注册，接着会replicateToPeers()方法，这个方法就会将这次注册请求，同步到其他所有的eureka server上去。。。 

如果是某台eureka client来找eureka server进行注册，isReplication是false，此时会给其他所有的你配置的eureka server都同步这个注册请求，此时一定会基于jersey，调用其他所有的eureka server的restful接口，去执行这个服务实例的注册的请求 

eureka-core-jersey2的工程，ReplicationHttpClient，此时同步注册请求给其他eureka server的时候，一定会将isReplication设置为true，这个东西可以确保说什么呢，其他eureka server接到这个同步的请求，仅仅在自己本地执行，不会再次向其他的eureka server去进行注册

### 035_eureka server集群之间注册表同步使用的3层队列任务批处理机制

eureka server同步任务批处理机制

![](C:\Users\zy199005\Desktop\中华石杉\images\java\06\03501.png)

 

1、集群同步的机制：闪光点，client可以找任何一个server发送请求，然后这个server会将请求同步到其他所有的server上去，但是其他的server仅仅会在自己本地执行，不会再次同步了 

2、数据同步的异步批处理机制：闪光点，三个队列，第一个队列，就是纯写入；第二个队列，是用来根据时间和大小，来拆分队列；第三个队列，用来放批处理任务 ==》 异步批处理机制

### 036_将eureka的整体架构、运行流程以及核心机制画一张图来梳理一下

eureka整体架构设计

![](C:\Users\zy199005\Desktop\中华石杉\images\java\06\03601.png)

 

其实到这里为止，eureka自己本身的核心的源码，我们都已经分析过了。到此为止，我们对eureka的整体的架构设计、运行流程、核心机制，都已经理解了，而且从源码层面可以理解，对这些东西，在代码的层面，你应该差不多都知道是怎么回事了。 

给大家来画一张图，我们把之前学过的eureka架构设计、运行流程、核心机制，都画在一张图里面，全部给他来串一遍，但是我们的这个图会比较high-level一点，高级别一点，很多的细节可能我们不会考虑到 

（1）eureka server启动：注册中心

（2）eureka client启动：服务实例

（3）服务注册：map数据结构

（4）eureka server集群：注册表的同步，多级队列的任务批处理机制

（5）全量拉取注册表：多级缓存机制

（6）增量拉取注册表：一致性hash比对机制

（7）心跳机制：服务续约，renew

（8）服务下线：cancel

（9）服务故障：expiration，eviction

（10）自我保护：自动识别eureka server出现网络故障了

（11）控制台：jsp页面 

将一个源码读到这个程度就可以了 

我可以大概给大家来说一下，我个人读源码的原则，一般来说，我广泛的阅读源码的时候，是不会将一个源码，要求理解到100%，很难的，除非你是这个开源项目的创始人，从一开始这些代码都是你来写的 

一般来说，广泛的阅读大量的开源项目的源码，对任何一个开源项目的源码，核心代码就占据了60%~80%，所以我一般阅读源码，就是理解其中60%~80%的源码，就足够了，大部分情况下你理解60%的源码，已经非常不错了，够用了。 

eureka，eureka-core和eureka-client，对这两个工程的源码，我们这次大概剖析了百分之多少呢？对于这两个工程里的源码，大部分开源项目的源码，其实都是包含了大量的基础类库、工具类、边缘化的次要的模块和代码，任何一个开源项目，核心以及精华的代码，大概占比，就在40%~60%，我们以40%举例，核心代码可能就这么多。 

我们阅读的，主要是这40%的核心代码，剩下的60%的代码阅读的意义以及价值不是很高。而且我们不是把40%的核心代码全部都读一遍的，我们一般来说是把核心代码的60%的代码，给他仔细读一下。 

哪怕是核心代码中，也有大量的琐碎的代码，或者是一些跟主要的功能关系不大的一些。真正有价值，或者是最重要的精华代码，可能也就40%~60%左右。 

大概来说，比如对于eureka这样的开源你项目，把里面20%~30%的代码读一下，就可以了。这20%的代码，4万行代码，其实你可能就读里面8000行代码，就足够了。28法则，任何一个开源项目，你经常用到里面的东西，可能就20%的功能，源码里面，真正需要你花费心思去理解和阅读的，可能就20%的代码。 

如果你能把20%的代码给读透了，就是掌握了这个开源的架构设计、运行流程、核心机制。 

（1）深厚的技术功底：如果你能不断的吃透一个一个的开源项目20%的精华代码，你的技术功底本身就自在不断的增强，后面学习新的技术，速度会越来越快。我现在这样的技术功底，如果我要快速的理解任何一个新的开源项目的20%的精华代码的源码，大概只需要2~3天的时间。把任何一个开源项目的helllo world跑一下，结合这个hello world去读源码，我只要2~3天的时间，就可以把这个开源项目的20%的精华代码给读一遍。 

（2）hold住全场：比如说eureka这一块，你们公司里平时可能就用一个开源项目的20%的重要功能。spring，多么牛叉，复杂的项目，你以为国内大部分的公司用spring都是怎么用的？用spring各种复杂高级的功能吗？spring，最多用20%的功能。所以说如果你阅读了一个开源项目20%的精华代码，那么对你们平时常用的20%的核心功能对应的代码，你就完全理解了。在公司里面已经可以hold住全场了，因为如果你用的20%的功能出了任何的问题，你立马就可以结合自己对源码的理解去解决他。如果说，你们公司用到的这个东西的功能的源码，你恰巧没有看到。。。。。。。你把20%的精华代码都吃透了，你以为你看剩下的80%的其他的代码，就很难吗？只不过是多花点时间而已 

（3）系统设计：如果你能把20%的精华吃透，核心的架构、分布式系统的运行流程、核心机制，对你未来的架构设计的帮助就很大了。 

（4）职场竞争力：100个工程师，大概会有9个人号称自己看过一个开源项目的源码，但是其实对开源项目的源码的理解，可能就只有1%，大概了解一点点源码罢了。对源码的理解，大部分是从一些不靠谱的技术博客来的。理解都错了。1个人是可以达到理解20%的精华代码的程度。剩下90个人，基本上是没看过源码的。你要是能吃透spring cloud 20%的精华代码，你出去，已经是百里挑一了。除非是什么样的人可以理解一个开源项目的100%的代码呢？开源项目的创始人。理解一个开源项目的40%，60%，80%的代码呢？就是这个项目长期贡献代码的commiter。 

如果你没掌握上面的那套理念和方法，你瞎努力，硬是要读懂各种源码的细节，40%，60%，80%，你傻了。如果你要把eureka源码读懂50%，你可能要花费一个月的时间；80%，两三个月的时间；100%，半年到一年。 

28法则，你花费20%的时间，读懂20%的源码，你就可以帮助你cover住80%的工作场景里的问题。。。。花费80%的时间，读懂剩下的80%的源码，可能对你的意义就不是很大 

就是针对那一个问题，精看，细看，就可以了 

咱们后面读源码，其实都是一个道理，任何一个开源项目，源码都很多，你如果每个源码都要读到100%的话，你可以完蛋了。。。。你一年读不了几个源码项目的源码的。。。但是你花费了那么多的时间，对你的意义其实是不大的 

项目阶段一里面，20%的设计模式相关的精华代码，就可以了；80%的crud的业务代码，直接看看就可以，对你来说影响不大

### 037_spring-cloud-eureka-server注解式启动注册中心的源码剖析

各位同学，还记得不记得，eureka，netflix的eureka，仅仅用在netflix公司内部的注册中心，负责微服务架构的服务注册和发现的。spring cloud eureka，其实不是一个什么所谓很复杂的项目，他其实就是一个将netflix eureka整合到spring技术体系中的这么一个包装类的技术，spring-cloud-netflix-eureka项目，仅仅是对netflix eureka的一个封装。 

spring-cloud-starter-eureka-server项目，无稽之谈，薄薄的一层，就是封装了对一些eureka-server相关的一些依赖。依赖了spring-cloud-netflix-eureka-server项目，https://github.com/spring-cloud/spring-cloud-netflix，eureka-server项目。 

所以说呢，真正spring cloud对eureka server进行封装的是spring-cloud-netflix-eureka-server项目，只是简单的将netflix的eureka-server的工程，给简单的封装了一下罢了。https://github.com/Netflix/eureka/tree/v1.7.2，仅仅不过是封装了netflix eureka-server工程罢了。 

我们来简单看一下，我们如果基于spring-cloud-netflix-eureka-server，是如何依托spring cloud对eureka整合到spring boot技术栈中，依托一些简单的注解，直接启动一个main方法，就可以将eureka server给启动起来呢？ 

入口，@EnableEurekaServer注解，这个注解实际上来说就在spring boot跑起来一个内嵌的tomcat容器之后，就将eureka server在tomcat内部给启动起来了。ctrl + 左键。这个注解，最最重要的是基于spring boot auto configuration机制，就是很简单的，我们只要用一些简单的注解，他直接基于这个auto configuration的机制，将我们需要的所有的东西都给配置好了，不需要我们额外做什么事情。 

EurekaServerAutoConfiguration，依托spring boot的auto configuration机制，直接我们就是使用一个注解@EnableEurekaServer，触发了EurekaServerAutoConfiguration的执行，直接一站式将我们需要的eureka server给初始化和启动。 

我来给大家说一下，就是，其实EurekaServerAutoConfiguration以及额外相关的几个类似的东西，直接替代掉了，eureka的BootStrap监听器。原始的netflix的eureka server，其实本身是个web应用，无论在哪个web容器中启动，都会执行eureka core中一个的监听器，BootStrap。 

通过BootStrap启动了一个eureka server，包括所有的组件的初始化，然后可以接收http retful接口的调用。 

但是到了spring boot + spring cloud的环境中，人家用spring-cloud-netflix-eureka-server这个工程给你改掉了这个启动eureka server的方式。人家靠的不是说web容器启动的时候，来一个监听器来初始化。 

直接将BootStrap的代码，几乎是全部拷贝到了EurekaServerAutoConfiguration以及相关的几个类中去，在这些类中，将BootStrap中eureka server启动的代码全部copy，全部还原了一遍。大致理解了，eureka server在spring cloud的环境下是如何启动的？ 

@EnableEurekaServer注解 

在spring boot本身将自身的web容器启动之后，然后依托上面那个注解，来执行原来BootStrap中的所有的代码逻辑，初始化所有需要的代码组件，然后完成eureka server的启动和初始化。 

EurekaServerConfigBean，实现了EurekaServerConfig接口，相当于是什么，将spring boot风格的配置，application.yml风格的配置，全部用这个东西来表示配置相关的持有类以及加载。 

InstanceRegistry，是对注册表，进行了薄薄的一层封装，在注册、下线的时候，会先通过这个类执行一下简单的逻辑，然后将请求转发给eureka自己的注册表类，PeerAwareInstanceRegistryImpl类。 

只不过你用脑子随便想想，你大概都知道 

eureka，本身在实例化EurekaServerConfig、EurekaClientConfig、EurekaInstanceConfig的时候，都是从自己的eureka-client.properties，eureka-server.properties中去读取的。 

但是在spring cloud + spring boot的环境中，肯定不是，需要的EurekaServerConfig、EurekaClientConfig、EurekaInstanceConfig，都是从application.yml中去读取的，读取了之后的话呢，由spring cloud封装的对象去对外提供配置项的读取。 

具体的细节我们就不去看了，其实你看也没什么意义，连蒙带猜，是说很多东西，你用屁股想想，你都知道大概是怎么回事儿。然后的话呢，就是让eureka内部的代码，基于他的配置项读取的类，去读取所有的配置项的值。 

肯定是基于上面的那种方式，读取aplication.yml的方式，形成了EurekaServerConfig、EurekaClientConfig、EurekaInstanceConfig，然后呢基于这些东西，构造了InstanceInfo，构造了ApplicationInfoManager。 

spring boot人家启动了自己本身的web应用，使用内嵌的tomcat容器，就会来执行这坨东西，完成BootSrrap监听器一模一样的逻辑。 

EurekaServerInitializerConfiguration 

这个类本身是有生命周期的，在spring boot启动之后，就会来执行这个东西的start()方法。启动一个后台线程，完成了剩余的eureka server初始化的这么一个过程。 

EurekaServerAutoConfiguration、EurekaServerInitializerConfiguration、EurekaServerBootstrap，三个类，在spring boot启动之后，完成了原来BootStrap初始化和启动eureka server的几乎一模一样的所有的代码逻辑。 

唯一的区别，就是比如说读取配置，变成从application.yml中去读取，然后有几个类稍微变成了自己的实现类，继承了eureka的父类。稍微做了一点点薄薄的封装。 

我一开始为什么没给你讲所谓的spring cloud eureka的源码，你必须得先明白和学会netflix原生的eureka之后才可以，然后我们来看一下spring cloud eureka，其实说白了，就是把BootStrap启动eureka server的代码全部拷贝出来，让在自己的几个跟spring boot相关的类中，重新实现了一遍。 

spring boot的main方法启动，内嵌tomcat容器启动，自身作为一个web应用启动，然后带着@EnableEurekaServer注解走。EurekaServerAutoConfiguration、EurekaServerInitializerConfiguration、EurekaServerBootstrap执行，完成了原来的BootStrap一模一样的代码。完成eureka server的所有组件的初始化，已经eukrea server的启动。 

eureka server等待http请求调用了，人家自己有自己的jersey mvc框架，对外可以接收这个请求。

### 038_spring-cloud-eureka-client注解式启动服务实例的源码剖析

看完了spring cloud eureka server的注解式启动的这个过程，spring cloud eureka client是如何通过一个注解就启动一个服务实例的呢？肯定是那个注解触发了一个sping boot auto configuration，用屁股想想。肯定是spring boot启动了一个main方法，启动了内嵌的tomcat容器，然后同时会执行相关的auto configuration的类。 

在那些auto configuration的类中，就会完成eureka client的初始化和构造。而且这些eureka client初始化的代码，几乎都是跟netflix eureka中的代码是一样的。 

一跟进去发现说，没有源码，在github上，将你需要的源码通过zip包的形式下来下来，选择你需要的那个版本的源码即可。通过这个方式，你可以在eclipse中，包含所有开源项目的源码，然后接下来你要跟进去阅读源码，或者是打断点，调试源码，都没问题了。 

就是通过上面的方式，就将你需要的源码从github上下载下来，然后在eclipse中attach source一把，就可以关联所有的开源项目的源码。 

[EurekaClientConfigBean，](https://github.com/spring-cloud/spring-cloud-netflix/blob/v1.4.4.RELEASE/spring-cloud-netflix-eureka-client/src/main/java/org/springframework/cloud/netflix/eureka/EurekaClientConfigBean.java)一看就是，用屁股想想，从application.yml中，将你的格式的配置项读取出来，通过这个bean来对外提供所有的eureka client相关的配置项的读取。实现的就是EurekaClientConfig接口。EurekaInstanceConfigBean，同理，加载application.yml中的服务实例相关的配置项。 

这个里面EurekaClientAutoConfiguration，完成了DiscoveryClient的构造和初始化，eureka client初始化和启动的流程，全部在DiscoveryClient中的。EurekaDiscoveryClient，自己对eureka原生的DiscoveryClient进行了一层封装和包装，实现了eureka的DiscoveryClient接口，依赖了一个原生的EurekaClient。提供了一些额外的方法的实现。 

你能看到EurekaAutoServiceRegistration，这里就是将原来的InstanceInfoReplicator组件里面的服务注册的逻辑，进行了一定的封装，服务注册相关的重要的逻辑，不能封装在那么不清不楚的InstanceInfoReplicator中。在这里提供了服务注册的这么一些方法。 

我给大家来说一下，这块逻辑做的是什么事情呢？在原生的eureka client的注册里，其实eureka client启动之后，要延迟几十秒，才会去完成注册。EurekaAutoServiceRegistration，里面包含了一个start()方法，在这个spring boot启动之后，直接就会执行start()方法，我，一启动，不要按照原来的40秒才去注册，我一启动，直接就去执行一个注册。 

EurekaRegistration包含了一些组件，EurekaClient、ApplicationInfoManager之类的组件。 

实际上，在spring boot一启动的时候，就会去执行EurekaServiceRegistry.register()方法，这个方法什么啊？看都看不懂，感觉根本没有注册啊。。。。spring cloud也是无奈之举，因为这个eureka client对注册这块的代码， 写的确实是太差了。 

ApplicationInfoManager.setInstanceStatus()调用的时候，会通知自己所有的注册的监听器，状态发生改变。DiscoveryClient.initScheduledTasks()方法的时候，会给ApplicationInfoManager注册一个监听器，在DiscoveryClient初始化的时候就会调用，注册这个监听器。 

搞了一个匿名内部类。。。。。。。。吓人。。。。搞这么个匿名内部类，如此重要的一个监听器，居然搞了匿名内部类，以后人家要找这个ApplicationInfoManager注册了哪些监听器，找都不招不到。通知InstanceInfoReplicator.onDemandUpdate()方法。。。。。。 

往线程池中提交一个线程任务，调用了InstanceInfoReplicator的run()方法，完全违反了Runable接口的语义。我是Runable接口，run()方法是不能直接调用的，一般是将Runnable线程扔给一个线程池，或者是放到一个Thread类里去构造，然后调用start()方法启动一个线程，由线程内部来执行run()方法。 

这里直接会调用DiscoveryClient.register()方法，完成一个服务的注册。。。。。。 

这个代码极烂，我可以跟大家说一下，我们去看spark这个分布式大数据计算引擎的源码，好的源码，整个设计的特别好，层次结构，概念思想，核心机制，特别棒。这种小众的开源项目，eureka。不可掩饰的是，eureka源码写的很烂，不是很好。 

eureka源码这种级别的架构设计、运行流程、核心机制、面向对象的设计，我们觉得大家把后面的一些课程学号了之后，你们每个人都有实力做出来类似这样的开源项目。唯一的优势就是在netflix这个公司每天几百亿，几千亿的请求量下，大量的实践，bug比较少，比较稳定。 

@EnableEurekaClient，触发了一个EurekaClientAutoConfiguration类的执行，完成从application.yml中读取配置，完成DiscoveryClient的初始化和启动，通过自己额外加的一些代码，一启动，直接触发一次register()服务注册，向eureka server完成一次注册。

### 039_在eclipse中嵌入spring-cloud-eureka源码来debug断点调试

eureka:

 client:

  registerWithEureka: false

fetchRegistry: false 

eureka server，他也是eureka client，如果你希望就是将eureka server以单节点的eureka client启动的话，将registerWithEureka设置为false，那么这个eureka server就不会向任何其他的eureka server来注册。fetchRegistry设置为false，也不会从其他的eureka server来抓取注册表。 

2018-05-31 18:19:53.002 INFO 25352 --- [      main] s.b.c.e.t.TomcatEmbeddedServletContainer : Tomcat initialized with port(s): 8761 (http)

2018-05-31 18:19:53.038 INFO 25352 --- [      main] o.apache.catalina.core.StandardService  : Starting service [Tomcat]

2018-05-31 18:19:53.039 INFO 25352 --- [      main] org.apache.catalina.core.StandardEngine : Starting Servlet Engine: Apache Tomcat/8.5.31

2018-05-31 18:19:53.303 INFO 25352 --- [ost-startStop-1] o.a.c.c.C.[Tomcat].[localhost].[/]    : Initializing Spring embedded WebApplicationContext

2018-05-31 18:19:53.303 INFO 25352 --- [ost-startStop-1] o.s.web.context.ContextLoader      : Root WebApplicationContext: initialization completed in 2162 ms 

这三行日志，就说明了什么呢？系统启动，是先spring boot启动，启动自己内嵌的tomcat容器，将自己作为一个web应用在tomcat容器中来启动 

2018-05-31 18:19:54.123 INFO 25352 --- [ost-startStop-1] o.s.b.w.servlet.FilterRegistrationBean  : Mapping filter: 'metricsFilter' to: [/*]

2018-05-31 18:19:54.124 INFO 25352 --- [ost-startStop-1] o.s.b.w.servlet.FilterRegistrationBean  : Mapping filter: 'characterEncodingFilter' to: [/*]

2018-05-31 18:19:54.124 INFO 25352 --- [ost-startStop-1] o.s.b.w.servlet.FilterRegistrationBean  : Mapping filter: 'hiddenHttpMethodFilter' to: [/*]

2018-05-31 18:19:54.124 INFO 25352 --- [ost-startStop-1] o.s.b.w.servlet.FilterRegistrationBean  : Mapping filter: 'httpPutFormContentFilter' to: [/*]

2018-05-31 18:19:54.124 INFO 25352 --- [ost-startStop-1] o.s.b.w.servlet.FilterRegistrationBean  : Mapping filter: 'requestContextFilter' to: [/*]

2018-05-31 18:19:54.125 INFO 25352 --- [ost-startStop-1] o.s.b.w.servlet.FilterRegistrationBean  : Mapping filter: 'webRequestTraceFilter' to: [/*]

2018-05-31 18:19:54.125 INFO 25352 --- [ost-startStop-1] o.s.b.w.servlet.FilterRegistrationBean  : Mapping filter: 'servletContainer' to urls: [/eureka/*]

2018-05-31 18:19:54.125 INFO 25352 --- [ost-startStop-1] o.s.b.w.servlet.FilterRegistrationBean  : Mapping filter: 'applicationContextIdFilter' to: [/*]

2018-05-31 18:19:54.125 INFO 25352 --- [ost-startStop-1] o.s.b.w.servlet.ServletRegistrationBean : Mapping servlet: 'dispatcherServlet' to [/] 

'servletContainer' to urls: [/eureka/*]，从这一行就可以看出来什么呢？就是在spring cloud eureka server中，绝对是将jersey的核心过滤器，ServletContainer注册到了tomcat中去作为一个过滤器，拦截的是/eureka/*这个模式的请求，跟eureka server发出的这个请求，都会走jersey的过滤器，然后这些请求，会被交给后端的XXXResource来处理，XXXResource其实就是jersey框架的controller 

'dispatcherServlet' to [/]，spring web mvc的核心servlet，拦截所有其他的这个请求组 

 Mapped "{[/health || /health.json],methods=[GET],produces=[application/vnd.spring-boot.actuator.v1+json ||，这种东西spring boot的监控提供的endpoint访问节点，可以让你比如请求/health，来看看应用的健康状况 

o.s.c.n.eureka.InstanceInfoFactory    : Setting initial instance status as: STARTING，将服务实例的信息设置为STARTING，正在启动中 

spring cloud整合eureka server，就是将原来人家BootStrap监听器里的初始化代码，放到spring boot auto configuration中去执行，在spring boot启动之后，然后来执行eureka server的初始化的代码 

2018-05-31 18:20:00.272 INFO 25352 --- [      main] com.netflix.discovery.DiscoveryClient  : Initializing Eureka in region us-east-1

2018-05-31 18:20:00.272 INFO 25352 --- [      main] com.netflix.discovery.DiscoveryClient  : Client configured to neither register nor query for data.

2018-05-31 18:20:00.285 INFO 25352 --- [      main] com.netflix.discovery.DiscoveryClient  : Discovery Client initialized at timestamp 1527762000285 with initial instances count: 0 

eureka server自己本身也是一个eureka client，所以这里很明显在构造自己的eureka client，构造DiscoveryClient 

Client configured to neither register nor query for data.是因为你设置了不要注册也不要抓取注册表，所以这里的意思就是不注册，也不抓取注册表 

2018-05-31 18:20:00.377 INFO 25352 --- [      main] c.n.eureka.DefaultEurekaServerContext  : Initializing ...，，很明显，在构造自己的EurekaServerContext 

2018-05-31 18:20:00.380 WARN 25352 --- [      main] c.n.eureka.cluster.PeerEurekaNodes    : The replica size seems to be empty. Check the route 53 DNS Registry，在初始化自己的PeerEurekaNodes，就是代表了eureka server集群 

2018-05-31 18:20:00.411 INFO 25352 --- [      main] c.n.e.registry.AbstractInstanceRegistry : Finished initializing remote region registries. All known remote regions: []，我们默认情况下，是没有所谓的region的概念的，所以你在看源码的时候，remote region的代码直接略过去，eureka代码的写的很烂，AWS、remote region模式这些代码跟核心的、普通的代码全部耦合在了一起，用了大量的if else语句来写。 

2018-05-31 18:20:00.412 INFO 25352 --- [      main] c.n.eureka.DefaultEurekaServerContext  : Initialized，EurekaSeverContext，很明显是初始化好了 

spring-cloud-starter-eureka，依赖已经过时了，现在都是用spring-cloud-starter-netflix-eureka 

2018-05-31 18:20:00.777 INFO 25352 --- [      main] o.s.c.n.e.s.EurekaServiceRegistry    : Registering application unknown with eureka with status UP，就是我给大家说过，spring cloud自己扩展了一个EurekaServiceRegistry的类，这个类的意思，就是不要按照原来的延迟40秒去注册，就是spreing boot 一旦启动，就立即进行一次注册 

2018-05-31 18:20:00.871 INFO 25352 --- [   Thread-11] o.s.c.n.e.server.EurekaServerBootstrap  : Setting the eureka configuration..

2018-05-31 18:20:00.872 INFO 25352 --- [   Thread-11] o.s.c.n.e.server.EurekaServerBootstrap  : Eureka data center value eureka.datacenter is not set, defaulting to default

2018-05-31 18:20:00.872 INFO 25352 --- [   Thread-11] o.s.c.n.e.server.EurekaServerBootstrap  : Eureka environment value eureka.environment is not set, defaulting to test

2018-05-31 18:20:00.894 INFO 25352 --- [   Thread-11] o.s.c.n.e.server.EurekaServerBootstrap  : isAws returned false

2018-05-31 18:20:00.896 INFO 25352 --- [   Thread-11] o.s.c.n.e.server.EurekaServerBootstrap  : Initialized server context 

这快是说是ServetContext初始化完成 

2018-05-31 18:20:00.897 INFO 25352 --- [   Thread-11] c.n.e.r.PeerAwareInstanceRegistryImpl  : Got 1 instances from neighboring DS node

2018-05-31 18:20:00.898 INFO 25352 --- [   Thread-11] c.n.e.r.PeerAwareInstanceRegistryImpl  : Renew threshold is: 1

2018-05-31 18:20:00.898 INFO 25352 --- [   Thread-11] c.n.e.r.PeerAwareInstanceRegistryImpl  : Changing status to UP 

这个的意思是说，从相邻的eureka server节点拉取了一个服务实例，就1个 

2018-05-31 18:20:00.905 INFO 25352 --- [   Thread-11] e.s.EurekaServerInitializerConfiguration : Started Eureka Server，完成eureka server的启动 

2018-05-31 18:21:00.899 INFO 25352 --- [a-EvictionTimer] c.n.e.registry.AbstractInstanceRegistry : Running the evict task with compensationTime 0ms

2018-05-31 18:22:00.899 INFO 25352 --- [a-EvictionTimer] c.n.e.registry.AbstractInstanceRegistry : Running the evict task with compensationTime 0ms

2018-05-31 18:23:00.900 INFO 25352 --- [a-EvictionTimer] c.n.e.registry.AbstractInstanceRegistry : Running the evict task with compensationTime 0ms

2018-05-31 18:24:00.900 INFO 25352 --- [a-EvictionTimer] c.n.e.registry.AbstractInstanceRegistry : Running the evict task with compensationTime 0ms

2018-05-31 18:25:00.900 INFO 25352 --- [a-EvictionTimer] c.n.e.registry.AbstractInstanceRegistry : Running the evict task with compensationTime 0ms

2018-05-31 18:26:00.901 INFO 25352 --- [a-EvictionTimer] c.n.e.registry.AbstractInstanceRegistry : Running the evict task with compensationTime 0ms

2018-05-31 18:27:00.902 INFO 25352 --- [a-EvictionTimer] c.n.e.registry.AbstractInstanceRegistry : Running the evict task with compensationTime 1ms

2018-05-31 18:28:00.903 INFO 25352 --- [a-EvictionTimer] c.n.e.registry.AbstractInstanceRegistry : Running the evict task with compensationTime 0ms

2018-05-31 18:29:00.904 INFO 25352 --- [a-EvictionTimer] c.n.e.registry.AbstractInstanceRegistry : Running the evict task with compensationTime 0ms

2018-05-31 18:30:00.385 WARN 25352 --- [eerNodesUpdater] c.n.eureka.cluster.PeerEurekaNodes    : The replica size seems to be empty. Check the route 53 DNS Registry

2018-05-31 18:30:00.904 INFO 25352 --- [a-EvictionTimer] c.n.e.registry.AbstractInstanceRegistry : Running the evict task with compensationTime 0ms

2018-05-31 18:31:00.904 INFO 25352 --- [a-EvictionTimer] c.n.e.registry.AbstractInstanceRegistry : Running the evict task with compensationTime 0ms

2018-05-31 18:32:00.904 INFO 25352 --- [a-EvictionTimer] c.n.e.registry.AbstractInstanceRegistry : Running the evict task with compensationTime 0ms

2018-05-31 18:33:00.905 INFO 25352 --- [a-EvictionTimer] c.n.e.registry.AbstractInstanceRegistry : Running the evict task with compensationTime 0ms

2018-05-31 18:34:00.905 INFO 25352 --- [a-EvictionTimer] c.n.e.registry.AbstractInstanceRegistry : Running the evict task with compensationTime 0ms 

evict task，EvictionTask，就是清理任务，每隔60s，每隔1分钟，后台线程会检查一次所有的服务注册表中的服务，如果在90 * 2 = 180s内，没有心跳过来，那么就认为这个服务实例挂了，就把这个服务实例给摘除 

咱们来调试一次eureka cilent注册的源码，其他的源码，如果你要在eclipse里面，结合你的hello world代码来打断点调试，都是一个意思 

instanceId: localhost:ServiceA:8080 

但是大家如果愿意的话，完全可以自己这么来玩儿一通 

你能够在eclipse里面粘贴源码，打断点，调试这个源码，是你在源码级别调试、定位和查找问题的一个非常重要的一个能力，以后如果说你的线上出了问题，是有给报错的异常，你可以定位到是哪一行代码，然后打一些断点，来从源码级别看看，到底为什么会出这个问题。 

甚至，你完全可以自己做源码的定制，你可以去修改spring cloud eureka源码，你可以去修改netflix eureka源码，你只要修改好了之后，将你自己的版本，发布到nexus私服，你可以做一个工程，依赖原生的spring cloud和eureka。但是你在自己的工程里，对他们的代码进行一个改造，发布成自己的工程。 

让你们公司的业务，都使用你们公司自己版本的eureka，都可以。

### 040_用一张思维导图来总结一下学习到的eureka知识体系

eureka入门
	服务注册和发现的基本原理
	基于eureka进行服务注册和发现的helloworld
	eureka集群的部署和实战
	eureka的其他特性
		自己实现的健康检查器
		心跳的间隔配置
		注册表的抓取配置
		自我保护的配置

eureka源码阅读环境的搭建
	spring cloud eureka和netflix eureka的关系
	netflix eureka的工程结构
	基于IntelliJ IDEA和gradle搭建了eureka源码阅读环境
	修改eureka自带的测试代码准备调试环境

eureka server启动源码剖析
	eureka server的工程结构
	环境初始化以及ConfigurationManager
		基于double check + volatile实现的单例模式
	配置文件的加载以及面向接口的配置项读取的设计思想
	基于构造器模式的InstanceInfo的构造
	eureka server内部的eureka client的初始化
	eureka server context的构造和初始化
	画图梳理了一下eureka server启动的流程
	eureka resources里带的jsp就可以看到控制台

eureka client启动源码剖析

服务注册源码剖析
	eureka client端的服务注册
	eureka server端的服务注册
		服务注册表是个map数据结构
	画图梳理服务注册的流程

注册表抓取源码剖析
	全量注册表抓取
		多级缓存机制
	增量注册包抓取
		一致性hash比对机制

服务续约（心跳）源码剖析
	保存最近一次心跳的时间戳

服务下线源码剖析
	eureka client端的服务下线
	eureka server端的服务下线

服务故障源码剖析
	后台定时线程检查
	eureka bug分析：90 * 2 = 180s没有心跳才算故障
	定时任务补偿时间的设计机制

自我保护源码剖析
	最近一分钟心跳次数统计机制
		MeasuredRate
		两个AtomicLong + 后台线程实现
	计算期望的最小每分钟心跳次数
		服务实例数量 * 2 * 0.85
	如果最近一分钟的心跳次数 < 每分钟期望的最少心跳次数
		自我保护机制触发
			不会摘除任何故障服务实例
			eureka控制台会看到一行红色的字

eureka server集群机制源码剖析
	eureka server启动时互相同步注册表
	注册、心跳、下线等消息的复制转发
	基于3层队列的任务批处理机制

spring cloud eureka源码剖析
	spring cloud eureka server
		spring boot auto configuration
		在系统启动之后拷贝人家原来BootStrap监听器里的代码
		在spring boot启动之后就完成eureka server的启动
	spring cloud eureka client
		spring boot auto configuration
		系统系统之后完成DiscoveryClient的构造
		额外的代码：系统一启动立马进行服务注册
	在eclipse中如何调试源码

###  041_大白话和一个简单的图来说说分布式系统中的负载均衡调用是啥？

分布式系统中的负载均衡的调用

![](C:\Users\zy199005\Desktop\中华石杉\images\java\06\04101.png) 

  

我们呢，之前给大家讲了一个eureka的这么一个东西，大白话+画图，eureka，服务注册和发现。为什么要服务注册和发现呢？分布式系统的环境里，特别拆分为了很多个服务，服务之间是互相调用的，可能一个请求过来，要多个服务互相调用，完成一个工作。 

就是说，服务A调用服务B，必须是得知道服务B部署在了哪些机器上，每台机器上接收请求的是哪个端口号？ 

eureka注册中心，服务注册+发现。每个服务注册过去，eureka里就包含了每个服务部署在哪些机器上？每台机器上有哪个端口可以接受请求。服务发现呢？你要调用一个服务，你就从eureka那边去拉取服务注册表，看看你要调用的那个服务部署在哪些机器上？监听的是哪个端口号？ 

spring cloud里面另外一个组件，ribbon。 

ribbon也是netflix公司搞出来的，spring cloud跟eureka一样，把人家netflix ribbon组件，搞自己这儿来了，基于别人的ribbon组件，做了一层薄薄的封装，主要还是用的人家的东西。。。 

ribbon -> 调用时的负载均衡 

ribbon -> load balancer，负载均衡 

100个请求过来，到服务B，服务B每次接收到一个请求，都会找ribbon，ribbon就会从服务A的server list选择一个服务器，让服务B去请求服务A的某个服务实例。ribbon会尽量确保说将所有的请求，均匀的分配到请求服务A的各台机器上去。。。 

假设服务B接收到了100个请求，服务A有5台机器，那么ribbon基本上会尽量确保说，服务A的每台机器是接收20个请求的 

微服务是干嘛的？把一个100万行代码的大系统，从原来就是100万行代码在一个eclipse工程里，每次部署上线，就是一个war包，放到线上机器，tomcat停止，把war包放进去，tomcat启动，ok了。 

100万行代码，拆分成100个微服务，每个微服务差不多有1万行代码，每个微服务是1个人来维护。原来是100个人维护一个100万行代码的工程，很恶心。。。。现在呢？是每个人维护一个1万行代码的这么一个服务，100个人，个个都很爽。。。 

一旦微服务之后，这个系统直接就变成了分布式系统。 

分布式 != 微服务，100万行代码的系统，你现在呢拆分3个系统， 每个系统30万行代码。一个请求过来，需要3个系统协作处理一个请求，系统A先处理一下，然后调用系统B处理一下，调用系统C处理一下，这个请求才完成。 

一个请求，需要多个部署在不同机器上的服务或者系统协作来处理，才能完成，你就可以认为你开发的是一个分布式系统。但是分布式系统不一定是微服务架构？胖服务，一个服务30万行代码。。。 

微服务，一定是分布式系统，一旦微服务了之后，必然，几乎是100%，一个请求过来，要多个部署在不同机器上的服务协作处理这个请求。

### 042_基于netflix ribbon组件来一个原生的负载均衡调用demo

spring cloud，他其实就是对很多东西进行了一个封装，说白了就是这样子 

ribbon，最好还是先来体验一把人家原始的API是怎么用的，怎么做负载均衡的。。。 

直接基于netflix的原生的ribbon API来做一把负载均衡的调用 

**1、开发一个web服务**

```
<dependency>
<groupId>org.springframework.boot</groupId>
<artifactId>spring-boot-starter-web</artifactId>
<version>1.5.13.RELEASE</version>
</dependency> 
```

```
@SpringBootApplication
public class GreetingServiceApplication {
public static void main(String[] args) {
SpringApplication.run(GreetingServiceApplication.class, args);
}
} 
```

application.yml:

```
server:
 port: 8080 
```

```
@RestController
@RequestMapping(“/greeting”)
public class GreetingController {
@GetMapping(“/sayHello/{name}”)
public String sayHello(@PathVariable(“name”) String name) {
return “hello, ” +name;
}
} 
```

用8080和8088两个端口号启动两个服务好了 

**2、开发一个调用服务的客户端（基于ribbon）** 

```
<dependency>
<groupId>com.netflix.ribbon</groupId>
<artifactId>ribbon</artifactId>
<version>2.2.5</version>
</dependency>
<dependency>
<groupId>com.netflix.ribbon</groupId>
<artifactId>ribbon-httpclient</artifactId>
<version>2.2.5</version>
</dependency>
```

```
public class GreetingClient {
public static void main(String[] args) throws Exception {
ConfigurationManager.getConfigInstance().setProperty(
“greeting-service.ribbon.listOfServers”, “localhost:8080,localhost:8088”);
RestClient client = (RestClient)ClientFactory.getNamedClient(“greeting-service”);
HttpRequest reuqest = HttpRequest.newBuilder().uri(“/greeting/sayHello/leo”).build();
for(int i = 0; i < 10; i++) {
HttpResponse response = client.executeWithLoadBalancer(request);
String result = response.getEntity(String.class);
System.out.println(result);
}
}
}
```

实验结果是什么呢？ribbon很棒，就是帮我们完成一个服务部署多个实例的时候，负载均衡的活儿，没问题，可以干到。10次请求，均匀分布在了两个服务实例上，每个服务实例承载了5次请求。

### 043_体验一下netflix ribbon的负载均衡器的原生接口以及内置的规则 

**1、原生的负载均衡器接口** 

```
ILoadBalancer balancer = new BaseLoadBalancer(); 
List<Server> servers = new ArrayList<Server>();
servers.add(new Server(“localhost”, 8080));
servers.add(new Server(“localhost”, 8088));
balancer.addServers(servers); 
for(int i = 0; i < 10; i++) {
Server server = balancer.chooseServer(null);
System.out.println(server);
} 
```

默认使用round robin轮询策略，直接从服务器列表里轮询 

RestClient内部，底层，就是基于默认的BaseLoadBalancer来选择一个server 

**2、自定义负载均衡的规则** 

ILoadBalancer负载均衡器，底层是基于IRule，负载均衡算法，规则，来从一堆服务器list中选择一个server出来 

负载均衡器是基于一个IRule接口指定的负载均衡规则，来从服务器列表里获取每次要请求的服务器的，所以可以自定义负载均衡规则 

```
public class MyRule implements IRule {
ILoadBalancerr balancer;
public MyRule() {
}

public MyRule(ILoadBalancer balancer) {
this.balancer = balancer;
}

public Server choose(Object key) {
List<Server> servers = balancer.getAllServers();
return servers.get(0);
} 
// getter和setter
}

ILoadBalancer balancer = new BaseLoadBalancer();
balancer.setRule(new MyRule(balancer));
List<Server> servers = new ArrayList<Server>();
servers.add(new Server(“localhost”, 8080));
servers.add(new Server(“lolcalhost”, 8088));
balancer.addServers(servers);
for(int i = 0; i < 10; i++) {
Server server = balancer.chooseServer(null);
System.out.println(server);
}
```

说真的，很少需要自己定制负载均衡算法的，除非是类似hash分发的那种场景，可以自己写个自定义的Rule，比如说，每次都根据某个请求参数，分发到某台机器上去。不过在分布式系统中，尽量减少这种需要hash分发的情况。 

说这个，主要是告诉你，负载均衡的一些底层API罢了，主要是ILoadBalancer和IRule 

但是如果在后面要把这里做的比较复杂的话，很有可能会站在一些内置的Rule的基础之上，吸收他们的源码，自己定制一个复杂的高阶的涵盖很多功能的负载均衡器 

**3、ribbon内置负载均衡规则**

RoundRobinRule：系统内置的默认负载均衡规范，直接round robin轮询，从一堆server list中，不断的轮询选择出来一个server，每个server平摊到的这个请求，基本上是平均的 

AvailabilityFilteringRule：这个rule就是会考察服务器的可用性 

如果3次连接失败，就会等待30秒后再次访问；如果不断失败，那么等待时间会不断边长

如果某个服务器的并发请求太高了，那么会绕过去，不再访问 

WeightedResponseTimeRule：带着权重的，每个服务器可以有权重，权重越高优先访问，如果某个服务器响应时间比较长，那么权重就会降低，减少访问 

ZoneAvoidanceRule：根据区域和服气来进行负载均衡，说白了，就是机房的意思 

BestAvailableRule：忽略那些连接失败的服务器，然后尽量找并发比较低的服务器来请求 

RandomRule：随机找一个服务器 

RetryRule：可以重试，就是通过round robin找到的服务器请求失败，可以重新找一个服务器 

ribbon主打的就是负载均衡，网络通信，别的一些东西，都是次要，只要是看ribbon提供的各种负载均衡的算法的实现，另外一个是看ribbon + eureka + spring cloud如何整合使用的，看看ribbon源码里面去找比较重要的一些配置的参数 

### 044_ribbon原生API中用于定时ping服务器判断其是否存活的接口 

负载均衡器里，就是ILoadBalancer里，有IRule负责负载均衡的规则，选择一个服务器；还有一个IPing负责定时ping每个服务器，判断其是否存活 

```
ILoadBalancer balancer = new BaseLoadBalancer(); 
List<Server> servers = new ArrayList<Server>();
servers.add(new Server(“localhost”, 8080));
servers.add(new Server(“localhost”, 8088));
balancer.addServers(servers); 
// http://localhost:8080/ 
balancer.setPing(new PingUrl());
balancer.setPingInterval(1); 
// 这里就会每隔1秒去请求那两个地址
Thread.sleep(5000);
for(int i = 0; i < 10; i++) {
Server server = balancer.chooseServer(null);
System.out.println(server);
} 
```

不过说实话，这块一般最好稍微做的那啥一点，用个类似/health的接口来表明自己的健康状况，可以自定义一个Ping组件 

```
pblic class MyPing implements IPing {
public boolean isAlive(Server server) {
return true;
}
} 
```

ribbon比较重要的几个API 

RestClient

ILoadBalancer、IRule、IPing 

### 045_回头看看spring cloud环境中ribbon的使用以及图解一下工作原理

spring cloud + ribbon + eureka整合的原理  

![](C:\Users\zy199005\Desktop\中华石杉\images\java\06\04501.png) 

  

大家还记得，要在一个服务里调用另外一个服务的写法吗？ 

```
@LoadBalanced
@Bean
public RestTemplate getRestTemplate() {
return new RestTemplate();
}
```

说白了，就是用一个RestTemplate来访问别的服务，RestTemplate本身很简单，就是一个http请求的组件，本身没什么负载均衡的功能，他就是指定一个url，就访问这个url就得了。但是这里用@LoadBalanced注解之后，默认底层就会用ribbon实现负载均衡了。 

大家用屁股想想，很简单的道理，这里肯定是RestTemplate底层会去基于ribbon来对一个服务的service list进行负载均衡式的访问。那service list是从哪儿拿到的？ribbon和eureka整合起来使用了，在这个ribbon里，肯定server list是从eureka client里拿到的，对吧，人家本地不是缓存了完整的注册表么？ 

然后呢，请求一个服务的时候，就找那个服务对应的server list，round robin轮询一下 

这里可以画个图来大家理解一下 

这块大概的原理我们先理解一下，后面可以看看源码 

如果要对ribbon装配自己的负载均衡规则和ping规则，就可以这样来搞： 

```
public class MyConfiguration {
@Bean
public IRule getRule() {
return new MyRule();
}

@Bean
public IPing getPing() {
return new MyPing();
} 
} 

@RibbonClient(name = “ServiceB”, configuration = MyConfiguration.class
public class ServiceBConfiguration {
}
```

### 046_站在ribbon源码的角度来画一张大体的流程图辅助大家理解

ribbon的大体流程图

![](C:\Users\zy199005\Desktop\中华石杉\images\java\06\04601.png) 

 

咱们这一讲开始，就进入spring cloud生态里面的ribbon组件的使用，eureka服务注册和发现，ribbon负载均衡。 

讲ribbon，改变讲解源码的方式，之前讲eureka源码，我自己个人读源码的一种方式，就是直接intellij idea里读静态源码，不调试。差多读完了之后，就开始在eclipse里，attach上各个开源项目的源码，然后就在eclipse调试一下demo的代码。中间，会不断的画图，画很多张图，通过画图来梳理这个源码。 

大家对这种方式跟不上，如果你以后真的成为所谓的技术高手之后，必须得习惯这样读源码的方式，你必须得锻炼自己硬看静态源码的能力。场景，比如说在公司里你用eureka发现有个报错。 

你以为这个时候你去调试这个源码，有用吗？？？没用，你那个报错根本可能在本地就复现不了。你就只能直接搜索静态源码，找一下那个异常在哪里，然后直接动用你的最强大脑，对静态源码进行分析。去分析为什么会产生这个异常？然后呢，你怎么来解决这个问题 

因为大家直接看静态源码，会觉得很坑，看不懂，跟不上，理解不了。 

从ribbon源码开始，读源码的方式，换成教学手法。尽量，如果有可能，上来先给你画图，然后你先看一张图之后，然后你脑子里就有一定的印象，大概的原理就清楚了；接着呢开始来读这个细节的源码，读源码不再读静态源码，直接在eclipse里断掉调试我们的demo程序，调试源码；一边调试源码，一边读懂源码，一边在源码里加入大量的注释，自己写大量的注释，有助于我们加深理解和思考；一边读源码，一边画图，要不然就是对之前的图细化一下，要不然就是画一些新的图。 

图 -> 调试源码 -> 写源码注释 -> 画图 

就是你读的源码已经太多太多，技术功底很深厚了，可以用我的那种方法，我的那种方法，就是技术层次和境界都不一样了，直接读静态源码的人很少，一边读可能都不用画图，脑子里图形就出来了。 

基于ribbon源码的层面，给大家大概来画一张图，让大家先明白一下ribbon的工作的基本的原理。。。。。。。。 

RestTemplate，请求：http://localhost:8080/sayHello，如果给：http://ServiceA/sayHello，RestTemplate绝对100%报错，因为你里面搞了一个ServiceA，他是一个服务名称，不是ip地址和主机名，也没有端口号，根本没法请求这个东西 

ILoadBalancer里面包含IRule和IPing，IRule负责从一堆server list中根据负载均衡的算法，选择出来某个server，关键是，server list从哪儿来？

### 047_ribbon源码探险开始：通过@LoadBalanced注解作为突破口来找找线索

@LoadBalanced注解初探

![](C:\Users\zy199005\Desktop\中华石杉\images\java\06\04701.png) 

​    

https://github.com/spring-cloud/spring-cloud-commons 

我平时读源码的习惯，就是我一般读源码，都是按照eureka那种方式来的，就是在intellij idea或者eclipse下面，把源码下载下来，导入IDE中，然后读静态源码，写注释，画图 

@LoadBalanced 

这个注解的意思，其实说什么呢？将一个RestTemplate标志为底层采用LoadBalancerClient来执行实际的http请求，支持负载均衡 

很多时候，我们看到这里就直接懵圈了，这个时候你就别懵，发挥：连蒙带猜。推测。。。基于你过往的经验，尝试去推测 

你看一下这个注解，在哪个包下面，

org.springframework.cloud.client.loadbalancer，推测的思路，就是说，我就去看看这个包下面有啥东西。。。。。一般来说，如果是spring cloud或者是spring boot相关的项目，一定会有一个XXAutoConfiguraiton的一个东西 

XXXAutoConfiguraiton的一个东西，会负责去触发个什么东西啊。。。或者干个什么事儿啊。。。 

spring-cloud-common，上面的那个包是在这个项目里面的，找找对应的包 

惊人的发现： 

AsyncLoadBalancerAutoConfiguration.class

LoadBalancerAutoConfiguration.class 

Async。。。。。我这里告诉大家，看到类似这样的情况，想都不用想，Async一定是下面的那个不带Async的一个特殊的变种，看类名就知道是支持异步请求负载均衡请求的，看类名和类体系，看看就知道了。。。。 

用屁股来猜想一下，Async相关的类体系，可能都是跟异步发起http请求以及负载均衡相关的一些东西，可能是这样的特殊的机制 

但是不带Async的一套类，可能就是走普通的同步的http请求 

肯定默认的肯定是普通的同步的http请求咯。。。 

LoadBalancerAutoConfiguration.class，Async相关的类可能根本都没用到 

LoadBalancerAutoConfiguration，看看这个类里是什么东西 

看看这个注释，写的直接就是专门为ribbon（负载均衡）搞的一个auto configuration类 

List<RestTemplate>这个东西。。。 

SmartInitializingSingleton，里面有一个afterSingletonsInstantiated()方法，看类名，连蒙带猜，看不懂任何源码的。。。SmartInitializingSingleton一看就是初始化相关的东西，就是在系统启动的时候，一定会在某个时机来执行的。。。。。。afterSingletonsInstantiated()这个方法，一看就是在spring singleton bean实例化完了之后来执行的 

拿到当前的RestTemplate list，遍历。。。对每个RestTemplate，又遍历一个Cutomizer（专门用来定制化RestTemplate的组件）。。。。用每个Customizer来定制每个RestTemplate 

连蒙带猜的思想，停一停。。。。RestTemplate list是从哪儿来的呢？ 

在Controller里面，new RestTemplate()，实例化了一个bean，实例化好的这个bean，一定会放入LoadBalancerAutoConfiguration的List<RestTemplate>里面去，你别问我是怎么放入的，连蒙带猜，底层的一些细节的代码，我自己当然看过的，因为我自己可以不用讲课，直接用我自己的方式，夸夸夸快速的看各种源码的细节，而且这里牵扯到很多地方的源码，包括spring源码，spring cloud，spring boot 

如果是我第一次来看这个ribbon的源码，也是这个思路，也是连蒙带猜，很多这个源码的实现的细节，其实是在后面，你可能要阅读多个项目的源码之后，才能迎刃而解，spring cloud、spring boot、甚至是spring很多源码之后，才能理解所有的100%的细节 

屁股想想，new RestTemplate()，一定是放到List<RestTemplate>里面去了 

而且，一定是每个RestTemplate都被Cusotomizer给定制化了 

抓大放小的看源码的思路和技巧，过。。。。说一个我N多年以前，中考的时候，初中升高中，我非常的紧张，我想考我们那儿最好的一个高中。N多年以前的名校都是很有实力的，没有水分的。。。。 

100分，物理题目难，我本来就是初中的年级前10名。第一遍做下来，直接发现50%的题目好像都不会做，做一道题目，一道题目不会做，我就不管，抓大放小，不会就不会吧，过。做到最后一题都做完了，发现自己放过了50%的题目。 

做了第一遍之后，我感觉上来了点，回过头去再次去做那些题目，结果就跟有如神助一样，结果后面再做第二遍，都会做了。。。。96分，几乎是接近满分，我们初中物理平均分是60多分。。。 

不会，直接过，别在卡着，结果你硬卡，卡在前面某个选择题上了，在钻牛角尖，结果考试都快结束了，你后面大量的题目还没做。心理素质不过关，有强迫症 

看源码的时候，过掉50%的细节，不影响你看后面的源码的 

RestTemplateCustomizer，一看就是专门对RestTemplate进行定制化的一个组件

```
@Bean
@ConditionalOnMissingBean
public RestTemplateCustomizer restTemplateCustomizer(
final LoadBalancerInterceptor loadBalancerInterceptor) {
return new RestTemplateCustomizer() {
@Override
public void customize(RestTemplate restTemplate) {
List<ClientHttpRequestInterceptor> list = new ArrayList<>(
restTemplate.getInterceptors());
list.add(loadBalancerInterceptor);
restTemplate.setInterceptors(list);
}
};
} 
```

看看定制化的逻辑是什么呢？list里放了一个ClientHttpRequestInterceptor，interceptor，拦截器，给RestTemplate设置了一个拦截器。。。。。

```
@Bean
public LoadBalancerInterceptor ribbonInterceptor(
LoadBalancerClient loadBalancerClient,
LoadBalancerRequestFactory requestFactory) {
return new LoadBalancerInterceptor(loadBalancerClient, requestFactory);
}     
```

设置的那个拦截器，很明显就是LoadBalancerInterceptor。。。。 

往后走，有一些Retry相关的代码，一看就是跟RetryTemplate相关联的，跟我们用的普通的RestTemplate是区别开来的，大胆的猜想一下，Retry相关的代码，先不用看了，因为我们没用过RetryTemplate，那些代码可能根本就用不着。。。。 

我们用的就是普通的RestTemplate。。。所以就关注上面的那些代码就ok了 

梳理一下这节课探索源码的思路： 

（1）@LoadBalanced注解入手，线索直接断掉

（2）给大家一个经验技巧，从这个注解所在的项目和包下面入手，来找找相关的东西，有什么线索

（3）spring boot和spring cloud相关的类，你别想多了，直接找XXXAutoConfiguraiton的类，就知道是怎么回事

（4）找到了这个LoadBalancerAutoConfiguration，在这个类里面就有了重大的突破

（5）里面有一个List<RestTemplate>，推测就是我们创建的那个RestTemplate会放到这里来

（6）用这个RestTemplateCustomizer对每个RestTemplate进行了定制化，给每个RestTemplate设置了interceptor

（7）具体是哪个interceptor呢？LoadBalancerInterceptor，拦截器 

强调一遍看源码的技巧： 

（1）一定要先理解在一块源码讲解之前的一幅图

（2）看我的视频讲解，看一点点，几秒，几十秒，几分钟，暂停一下

（3）暂停了以后，自己在自己本地去调试一下对应的源码，然后自己可以模仿我这样子，在自己的笔记本里写笔记、注释或者是分析的思路

（4）一边写这个笔记，一边开始画一幅小图，小图里是具体的对应的细节

（5）自己看完一个视频，首先视频里有讲解，很细致，能保证你听懂。你自己积累了一份笔记，在写笔记的过程中，自己有自己的思考。最后，你还画了一些图出来，通过图在自己脑子里加深了印象。人脑记住的是图形，不是文字 

perfect。。。这就是学习源码课程最完美的思路和方法

### 048_惊讶的发现spring cloud通过拦截器机制改变了RestTemplate的行为 

LoadBalancerInterceptor拦截器的原理 

![](C:\Users\zy199005\Desktop\中华石杉\images\java\06\04801.png) 

 LoadBalancerAutoConfiguration里面，通过RestTemplateCustomizer给我们自己创建的那个RestTemplate设置了一个拦截器（LoadBalancerInterceptor），我们这里可以开始继续大胆的猜想：

拦截器是干嘛用的。。。。

就是如果你对一个东西发起一个请求，那么会被拦截器给拦截掉，由拦截器先来处理一下

大胆的推测一下：如果我们对RestTemplate执行某个操作，比如说restTemplate.getForObject()操作，相当于是希望发起一个http请求，请求一个服务的接口，此时不会由RestTemplate自己原生的功能来实现

而是会由拦截器来实现这个请求http服务的一个功能

所以说，我们只要这节课来探索一下那个LoadBalancerInterceptor的源码，是不是就可以看到说，对RestTemplate发起的请求，在底层被拦截器拦截之后到底了干了些什么事情呢。。。。。。。。。

在LoadBalancerInterceptor拦截器里，找到了下面一坨代码

	@Override
	public ClientHttpResponse intercept(final HttpRequest request, final byte[] body,
			final ClientHttpRequestExecution execution) throws IOException {
		final URI originalUri = request.getURI();
		String serviceName = originalUri.getHost();
		Assert.state(serviceName != null, "Request URI does not contain a valid hostname: " + originalUri);
		return this.loadBalancer.execute(serviceName, requestFactory.createRequest(request, body, execution));
	}

别看别的，光是看这个方法名称，intercept()，拦截的意思

推测一下：在执行下面那行代码的时候，其实是将这个请求给封装了一下，将http://ServiceA/sayHello/封装到了HttpRequest里面去，然后将HttpRequest加上其他的一些组件和数据，比如说byte[] body（猜测一下是什么东西？如果你发送请求的时候，带上了一个json串，一定是放请求体里面的，请求体里面的json串就会作为byte[] body传进来），ClientHttpRequestExecution（猜测是负责底层的http通信的组件）

restTemplate.getForObject("http://ServiceA/sayHello/leo", String.class);

相当于是底层调用了拦截器里的intercept()方法，实际的这个请求的逻辑，不再由RestTemplate原来原生的默认的逻辑来实现，而是由intercept()拦截方法来实现了。。。。

final URI originalUri = request.getURI();
String serviceName = originalUri.getHost();

你感觉这两行代码是干嘛的？

request.getURI()，获取到的猜测就是：http://ServiceA/sayHello/leo
originalUri.getHost()，获取到的猜测就是：ServiceA

serviceName，服务名称，就是获取到的那个ServiceA

Assert.state(serviceName != null, "Request URI does not contain a valid hostname: " + originalUri);

如果你的获取到的服务名称是null，那么就打印异常日志，告诉你，你的请求的url地址里面没有包含合格的hostname主机名

在构造LoadBalancerInterceptor的时候，其实传进来了一个LoadBalancerClient，我们好奇，这个LoadBalancerClient，是从哪儿来的呢？

梳理清楚了一个东西：LoadBalancerInterceptor，拦截掉RestTemplate所有的执行的请求，这个内部就干一件事儿，就是从你的url地址里获取hostname作为服务名称，就是你要请求的服务的名称，就是找LoadBalancerClient去执行对应的负载均衡的请求，将解析出来的服务名称穿进去，还有就是基于RequestFactory创建出来的一个request

### 049_千辛万苦终于找到真正的请求入口：RibbonLoadBalancerClient

千辛万苦找到LoadBalancerClient的过程

![](C:\Users\zy199005\Desktop\中华石杉\images\java\06\04901.png) 

 实际上拦截器就是很薄很薄的一层，他是把请求交给LoadBalancerClient，这才是真正的重头戏，去执行实际的请求，首先呢interceptor自己肯定是不知道的，因为是构造他的时候，给传进来的LoadBalancerClient

LoadBalancerAutoConfiguration里面来，找一下构造LoadBalancerInterceptor的代码，看看是怎么给传进去的LoadBalancerClient？找不到，直接是在@Bean方法的入参，直接传递进来了一个LoadBalancerClient。。。。。

找遍了LoadBalancerAutoConfiguration类，都找不到在哪里有所谓的LoadBalancerClient

来看看，LoadBalancerClient到底是什么呢？是一个接口，execute()方法，看看注释，对一个服务实例来执行对应的请求，这个服务实例从哪儿来的呢？从LoadBalancer里面给返回的。。。。。

感觉上到了这里，线索就断了。。。。

发挥自己的连蒙带猜的技巧，推测，推测出来的都是准确的

既然是@Bean方法里传进来了一个LoadBalancerClient，肯定是LoadBalancerClient有个实现类，在别的地方，对这个实现类构造了一个实例，然后打成了一个@Bean，作为spring容器里可以管理的一个bean

只有这种可能，才可以在这里讲LoadBalancerClient传进来

LoadBalancerClient的实现类以及实例化成Bean的代码到底在哪儿呢？org.springframework.cloud.client.loadbalancer这个包里先找一下，发现肯定是没有的，当时我自己都找过了，你就不用去找了。。。。

spring-cloud-commons工程里去找一下，找找有没有对应的实例，你自己可以去找一下，发现也是没有的。。。。

脑洞一开，这个时候，肯定是将请求交给谁去处理的？肯定是交给ribbon的相关的类去处理的，而且在这里肯定找到的不是ribbon原生的api，肯定找的是spring cloud ribbon项目里面的类

RibbonLoadBalancerClient ==> 处理实际的请求

找了一通，发现说，原来是猜测，spring cloud ribbon项目里，有关联的东西，可以作为LoadBalancerClient，现在发现spring-cloud-starter-ribbon和spring-cloud-starter-netflix-ribbon中没有任何线索，仅仅发现说他们依赖了大量的netflix ribbon原生的jar包

找一下netflix ribbon原生的jar包里有没有线索

（1）ribbon-2.2.5.jar：理解为ribbon的内核级别的比较核心的一些组件
（2）ribbon-transport-2.2.5.jar：基于netty封装的特别底层的进行http、tcp、udp各种协议的网络通信的组件
（3）ribbon-core-2.2.5.jar：推测这是ribbon比较基础性的一些通用的代码组件
（4）ribbon-httpclient-2.2.5.jar：是ribbon底层的http网络通信的一些组件
（5）ribbon-loadbalancer-2.2.5.jar：都是ribbon最最核心的原生的API

猜测一下，可能会包含LoadBalancerClient的组件，有什么呢？

带着来学习如何看源码，大家要注意，我在这个过程中教给你的看源码的技巧和方法，大量的看源码实践之后得来的。。。。。

我们发现原生的ribbon里一定是没有的，所以还是得回到spring cloud ribbon相关的项目里再去看看。。。。

spring-cloud-starter-ribbon，这个里面是什么，引用了spring-cloud-starter-netflix-ribbon

spring-cloud-starter-netflix-ribbon，没一行代码，分析一下pom.xml，唯一找到的一个希望是这个项目：spring-cloud-netflix-core，只有他了，才有这个希望，可以找到所谓的ribbon的LoadBalancerClient

结果发现柳暗花明又一村，发现点开这个工程，一大坨代码，hystrix、zuul、feign、ribbon，这个里面很明显就是放了什么呢？放了spring cloud跟netflix相关的技术进行整合的胶水代码

为什么这里没有eureka整合相关的代码呢？

spring-cloud-netflix-eureka-client
spring-cloud-netflix-eureka-server

我们到ribbon相关的包下面去找找，有没有对应的LoadBalancerClient。。。

找到了什么呢？RibbonLoadBalancerClient，这个东东就是实际的请求执行的入口。已经知道了用的是哪个LoadBalancerClent，但是现在另外一个问题来了？如何将这个RibbonLoadBalancerClient创建为一个Bean的呢？

连蒙带猜，是不是什么AutoConfiguration相关的类，或者是Configuration相关的类，或者是Config相关的类，初始化了一个RibbonLoadBalancerClient的Bean呢？好玩儿，特别有意思。。。。

@AutoConfigureAfter(name = "org.springframework.cloud.netflix.eureka.EurekaClientAutoConfiguration")
@AutoConfigureBefore({LoadBalancerAutoConfiguration.class, AsyncLoadBalancerAutoConfiguration.class})

上面明确说明了，这个RibbonAutoConfiguraion，是在EurekaClientAutoConfiguration之后来执行的，也就是说eureka必须先初始化完，才会轮到ribbon来初始化。。。。

这个RibbonAutoConfiguration，必须在之前看的那个LoadBalancerAutoConfiguration之前来执行，LoadBalancerAutoConfiguration触发的一些列的代码，是依赖于LoadBalancerClient的，但是LoadBalancerClient的初始化是在RibbonAutoConfiguration里执行的，所以必须是RibbonAutoConfiguraiton先执行，先初始化一个RibbonLoadBalancerClient才可以。。。

@Bean
	@ConditionalOnMissingBean(LoadBalancerClient.class)
	public LoadBalancerClient loadBalancerClient() {
		return new RibbonLoadBalancerClient(springClientFactory());
	}

完美定位，找到了，LoadBalancerClient是哪儿来的？其实是这儿来的，这儿直接是创建了一个对应的LoadBalancerClient：RibbonLoadBalancerClient。。。。。。

最终你会发现说，在LoadBalancerInterceptor拦截器里，会将RestTemplate的方法和请求转发给RibbonLoadBalancerClient.execute()方法去执行

### 050_对spring cloud整合ribbon完成服务请求的核心流程初步尝试下源码调试

我们已经找到了那个执行请求的入口，正儿八经的一个RibbonLoadBalancerCient，是他来负责进行请求的处理的，初步的尝试一下源码的调试，将一个比较粗的ServiceB访问部署两个实例的ServiceA的请求流程，给调试通过 

分析一下，eureka为什么在测试环境，会很容易就进入保护模式，如果你没看过源码就是什么都不懂。。。。renews threshold的意思就是说，期待的每一分钟的最少的心跳次数，服务实例 * 2 * 0.85 = 6次 

计算出来是一个6次的话，除非是4 * 2 * 0.85 = 6.8 约等于 6，期望的最少的心跳次数是6 

这个就是有问题的了，如果是3个服务实例，3 * 2 * 0.85 = 5.1 约等于5，期望的最少的心跳次数应该是5，当然还有一种可能，有可能是eureka server用的数学的函数不太对，比如算出来3个服务实例，是5.1，四舍五入到了6，也有这种可能 

这些问题，全部要通过源码层面来解决，我们要在eureka的源码里加入对应的日志，或者是断点，解决对应的参数错误的一些问题，测试环境容易进入保护模式 

renews last min：上一分钟，发送过来的心跳次数是6次 

结果renew last min = renews threshold，导致什么呢？他还是显示和处于保护模式下。。。 

留点悬念，在后面我们用spring cloud来改造电商系统的时候，都会来解决这些问题的。。。。 

我们在RibbonLoadBalancer里面打了一个断点，请求的时候，本来是走RestTempalte的，结果直接进RibbonLoadBalancer了，所以可以说明，我们之前的推测，100%正确 

serviceId：服务名称，ServiceA 

通过这个服务名称，获取了一个ILoadBalancer，ribbon的核心API和组件，负载均衡器，ILoadBalancer接口，就是ribbon的原生的接口 

getServer()方法，一看就是通过ILoadBalancer去对ServiceA对应的server list，通过自己的负载均衡的算法，选择一个server出来

 

发现一个奇怪的现象。。。。为什么通过源码断点调试，发现每次请求的都是一个server呢？没有实现负载均衡的效果啊。。。所以我们才要后面去研究人家的源码啊。。。如果你轻易的就懂了，那就你是神 

我们会发现，如果就是用默认的一些行为，也许说不定上线之后，就会出一些问题。。。eureka万一动不动就进入保护模式，你怎么办？进入保护模式以后就代表着服务实例故障自动摘除的功能就失效了。。。。ribbon负载均衡的算法失效了，怎么办？ 

必须得懂源码啊。。。。。 

debug模式下，可能会因为debug导致系统运行的不太正常，代码一直hang在那儿，就会导致一些代码的运转不太对，正常模式下，ribbon负载均衡是ok的

### 051_找一找spring cloud与ribbon整合时的默认ILoadBalancer是谁

获取LoadBalancer的这个过程 

![](C:\Users\zy199005\Desktop\中华石杉\images\java\06\05101.png)    

这块儿我们通过源码调试的方式，来开始一步一步的研究ribbon底层的源码，核心入口：RibbonLoadBalancerClient，我们这一讲，先来研究第一步：如何创建ILoadBalancer的，使用功能的是哪个ILoadBalancer呢？ 

ILoadBalancer loadBalancer = getLoadBalancer(serviceId); 

我根据一个服务名，serviceId，类似ServiceA这样的一个服务名称，是如何找到对应的LoadBalancer的？我们默认使用的是哪个LoadBalancer呢？ 

居然是通过SpringClientFactory来获取对应的LoadBalancer的。。。。 

SpringClientFactory不是spring的包下的，是spring cloud与ribbon整合代码的包下的： 

org.springframework.cloud.netflix.ribbon 

这块一定是对spring进行了一定程度上的封装，封装了一些东西，从spring里面获取bean的入口，都变成了这个spring cloud ribbon自己的SpringClientFactory 

我来给大家解释一下，他的意思，就是说，对每个服务名称，你要调用的每个服务，对应着服务名称，都有一个对应的spring的ApplicationContext容器，ServiceA对应着一个自己的独立的spring的ApplicationContext容器 

然后呢？比如说要获取这个ServiceA服务的LoadBalancer，那么就从ServiceCA服务对应的自己的ApplicationContext容器中去获取自己的LoadBalancer即可 

如果是另外一个ServiceC服务，那么又是另外的一个spring APplicationContext，然后从里面获取到的LoadBalancer都是自己的容器里的LoadBalancer 

如果你被提示说，需要spring-cloud-context相关的源码，你就将我们之前弄好的那个spring-cloud-commons那个源码，粘贴进去即可，因为spring-cloud-context就是在spring-cloud-commons下面的 

name：ServiceA

type：ILoadBalancer接口 

很明确了，在SpringClientFactory里面，一个服务（比如说ServiceA） => 对应着一个独立的ApplicationContext，里面包含了自己这个服务的独立的一堆的组件，比如说LoadBalancer。如果要获取一个服务对应的LoadBalancer，其实就是在自己的那个ApplicationContext里面去获取那个LoadBalancer即可。根据ILoadBalancer接口类型，获取一个ILoadBalancer接口类型的实例化的bean即可。 

RibbonClientConfiguration：在这个里面可以找到对应的ILoadBalancer的实例bean 

如果你要找一个bean，要么就在XXAutoConfiguration里面找，要么就是在XXConfiguration里面找。。。spring cloud或者是spring boot的项目的一个特点，去找bean

```
@Bean
@ConditionalOnMissingBean
public ILoadBalancer ribbonLoadBalancer(IClientConfig config,
ServerList<Server> serverList, ServerListFilter<Server> serverListFilter,
IRule rule, IPing ping, ServerListUpdater serverListUpdater) {
if (this.propertiesFactory.isSet(ILoadBalancer.class, name)) {
return this.propertiesFactory.get(ILoadBalancer.class, config, name);
}
return new ZoneAwareLoadBalancer<>(config, rule, ping, serverList,
serverListFilter, serverListUpdater);
}   
```

人家创建的就是：ZoneAwareLoadBalancer，这就是所谓的我们在spring cloud整合ribbon的环境下，使用的默认的LoadBalancer 

https://github.com/Netflix/ribbon 

ZoneAwareLoadBalancer的父类是：DynamicServerListLoadBalancer，他的父类又是：BaseLoadBalancer 

下集预告：ZoneAwareLoadBalancer（属于ribbon）到底是如何与eureka整合，通过eureka client获取到对应的注册表的呢？如何感知到ServiceA服务对应的server list的呢？拿到了这个服务的注册表之后，后续是如何不断的刷新注册表的呢？

### 052_研究一下ribbon是如何与eureka整合获取服务注册列表的

ribbon如何与eureka整合获取到服务注册的列表

![](C:\Users\zy199005\Desktop\中华石杉\images\java\06\05201.png)   

看到了这个所谓的LoadBalancer，ZoneAwareLoadBalancer 

诧异一个问题，LoadBalancer内部，必须要去获取到当前要访问的这个服务的server list。访问一个服务，那么就要获取一个LoadBalancer实例，在LoadBalancer实例内部，必须是有这个服务的server list。 

这样的话，才知道如何对这个服务进行负载均衡的访问 

ServiceA，server list 

ZoneAwareLoadBalancer里面，貌似是什么都没有的。。。。很坑爹。直接找父类的构造函数，DynamicServerListLoadBalancer，一开始没看到什么线索，但是往下找，在一个restOfInit()方法里，貌似找到了蛛丝马迹。。。。 

```
void restOfInit(IClientConfig clientConfig) {
boolean primeConnection = this.isEnablePrimingConnections();
// turn this off to avoid duplicated asynchronous priming done in BaseLoadBalancer.setServerList()
this.setEnablePrimingConnections(false);
enableAndInitLearnNewServersFeature();
updateListOfServers();
if (primeConnection && this.getPrimeConnections() != null) {
this.getPrimeConnections().primeConnections(getReachableServers());
}
this.setEnablePrimingConnections(primeConnection);
LOGGER.info("DynamicServerListLoadBalancer for client {} initialized: {}", clientConfig.getClientName(), this.toString());
}
```

enableAndInitLearnNewServersFeature();，连蒙带猜，启用和初始化学习新的server的能力，好像感觉上是，如果后续ServiceA有新的服务实例加入进来了，那么我们需要能够感知到那些新加入进来的服务实例 

updateListOfServers();，连蒙带猜，更新server list。。。。发现了宝藏一样，可能就是在创建ZoneAwareLoadBalancer实例的时候，通过调用其父类DynamicServerListLoadBalancer的构造函数，调用了restOfInit()方法，调用了updateListOfServers()方法，==> 通过这个方法，从eureka client那里获取到ServiceA的server list 

filter：这个先别管他了，ribbon支持的一个feature，就是你可以从一个服务中过滤掉某些server，不要去访问那些server 

我现在需要去找ServerList是什么东东？他的getXXX的方法的实现，估计就是从erueka那儿获取服务的注册列表的实现代码 

发现是在构造ZoneAwareLoadBalancer的时候，从构造函数里传入进来的，那么就得回到RibbonClientConfiguraiton那儿去找一下，构造的时候，传递了什么ServerList进来？？？ServerList本身，是从@Bean方法入参传入进来的，所以可以推测，一定是在其他的某个XXXAutoConfiguration里，或者是XXXConfiguration里，实例化了一个ServerList的bean，才可以在这里给传入进来。。。

```
@Bean
@ConditionalOnMissingBean
@SuppressWarnings("unchecked")
public ServerList<Server> ribbonServerList(IClientConfig config) {
if (this.propertiesFactory.isSet(ServerList.class, name)) {
return this.propertiesFactory.get(ServerList.class, config, name);
}
ConfigurationBasedServerList serverList = new ConfigurationBasedServerList();
serverList.initWithNiwsConfig(config);
return serverList;
}  
```

在RibbonClientConfiguration里，我们找到了这坨代码，就是初始化了一个ServerList，心中一顿狂喜，说天堂有路你不走，地狱无门闯进来。ConfigurationBasedServerList ，这个东西，是不是就是我们要找的那个ServerList呢？泼了一盆冷水。。。 

看代码就知道，绝对不对啊，那个代码，ConfigurationBasedServerList ，从配置文件中，或者是代码的配置中，读取了一个listOfServers的配置项，如果我们手动配置了server list，才是走的这个东西，来初始化server list。。。 

这个绝对不是我们要的东西啊。。。。 

线索断了，百思不得其解，柳暗花明又一村，读源码的技巧，ServerList，肯定是代表了服务的server list。肯定是从eureka里去读的，那如果从eureka里去读，是不是肯定是得通过一个带着Eureka的类名，或者是Eureka相关的工程下的ServerList去读取的？ 

肯定不是通过ConfigurationBasedServerList 去读取的，肯定是某个跟eureka关联的ServerList去读取的。。。。 

先考虑考虑，从sprnig-cloud-netflix-core工程里，有没有eureka关联的ServerList呢？ 

org.springframework.cloud.netflix.ribbon只有这个包里有这个可能，没有Eureka相关的这个东西，在两个配置类里找了一下，也没找到eureka相关联的这个东西啊，那到底是在哪儿呢？？？ 

ribbon和eureka关联在一起的这个工程，比如说类似spring-cloud-ribbon-eureka之类的工程。。。。ribbon-eureka-2.2.5.jar。。。。确实，是有一些erueka相关联的一些类。。ServerList，但是有个问题，我们必须找到实例化ServerList为一个bean的代码 

之前我们已经看过了，ribbon相关的工程，没找到eureka相关的代码 

再去找纯就是eureka相关的工程，找找有没有ribbon相关的代码，spring-cloud-starter-netflix-eureka-client，这个工程里，我们要去看一下，到底怎么样。。。。也没什么东西。。。spring-cloud-netflix-eureka-client工程，柳暗花明又一村，ribbon.eureka包。。。。。一看就是用来将eureka于ribbon进行整合的 

EurekaRibbonClientConfiguration

```
@Bean
@ConditionalOnMissingBean
public ServerList<?> ribbonServerList(IClientConfig config, Provider<EurekaClient> eurekaClientProvider) {
if (this.propertiesFactory.isSet(ServerList.class, serviceId)) {
return this.propertiesFactory.get(ServerList.class, config, serviceId);
}
DiscoveryEnabledNIWSServerList discoveryServerList = new DiscoveryEnabledNIWSServerList(
config, eurekaClientProvider);
DomainExtractingServerList serverList = new DomainExtractingServerList(
discoveryServerList, config, this.approximateZoneFromHostname);
return serverList;
}   
```

人家eureka和ribbon整合相关的代码，提供的一个ServerList 

发现说，实际上跟eureka整合的ServerList提供的getUpdatedServerList()方法，是调用的DiscoveryEnabledNIWSServerList的getUpdatedServerList()方法：

```
@Override
public List<DiscoveryEnabledServer> getUpdatedListOfServers(){
return obtainServersViaDiscovery();
} 
```

就在obtainServersViaDiscovery()方法里面，我们发现了一堆euerka的代码，从eureka client中获取到注册表，从注册表里可以获取到当前这个服务的ServiceA对应的server list，vipAddress，连蒙带猜，服务名，ServiceA。 

spring-cloud-netflix-eureka-client，这个项目里，有个eureka整合ribbon的代码

### 053_那么ribbon第一次从eureka获取到注册表之后后续如何持续更新呢？

ribbon如何持续的从eureka中获取注册表

![](C:\Users\zy199005\Desktop\中华石杉\images\java\06\05301.png) 

  

eureka client自己本身，是不断的去从eureka server每隔30秒更新一次注册表，拉取增量注册表，大家还记得吗？所以说ribbon和eureka整合的机制里，肯定得有一个组件，负责每隔一定的时间，从本地的eureka client里刷新一下服务的注册表到LoadBalancer中。。。。 

enableAndInitLearnNewServersFeature(); 

从方法名，连蒙带猜，启用和初始化学习新的服务实例的能力 

我们就要找一下ServerListUpdater是谁呢？回到哪儿ZoneAwareLoadBalancer初始化构造的时候去看一下，传入的一个ServerListUpdater是谁呢？PollingServerListUpdater。。。。之前在日志里还看到了呢。。。 

给PollingServerListUpdater的start()方法传入了一个UpdateAction，代表的是实际的更新注册表的行为。。。其实呢，每次PollingServerListUpdater定时更新注册表的时候，执行的实际的行为，就是上一讲看到的那个updateListOfServers()方法 

上一讲的那个方法，其实就是从eureka client里去获取一下注册表，重新更新到LoadBalancer中去。。。。 

在PollingServerListUpdater中，创建了一个Runnable线程，里面就是执行UpdateAction的行为。。。在延迟一定的时间过后，每隔一定的时间就执行一下那个Runnable线程，就会执行UpdateAction中的操作来刷新注册表，从eureka client中获取注册表，然后刷新到LoadBalancer中去。。。 

默认的是1秒钟过后，会第一次执行那个Runnable线程，以后是每隔30秒执行一下那个Runnable线程，就去从eureka client刷新注册表到自己的ribbon的LoadBalancer中来。

### 054_spring cloud与ribbon整合时的默认负载均衡算法如何选择一个server？

spring cloud与ribbon整合时的一个默认的负载均衡算法

![](C:\Users\zy199005\Desktop\中华石杉\images\java\06\05401.png)

通过LoadBalancer从一个服务对应的server list中选择一个server出来，保持负载均衡，将请求均匀的打到各个服务器上去 

LoadBalancer的chooseServer()方法，通过自己内置的负载均衡算法，选择一个server出来 

ZoneAwareLoadBalancer，Zone根本不用管他，因为我们这里暂时没有Zone的概念，机房的概念，多机房的话，他这里可以感知到多机房的，将一个机房里的请求，转发给自己这个机房里部署的其他的服务实例 

除非是一些大公司，或者是基于阿里云的环境，否则一般都是单机房部署的，上了一些规模了，有些中小型的公司系统比较成熟了，也会做双机房的环境 

ZoneAwareLoadBalancer.chooseServer()方法，在这里对服务的server list选择了一个出来 

内部，一定是对每个zone，对每个机房都搞了一个LoadBalancer 

所以呢ZoneAwareLoadBalancer内部还是基于BaseLoadBalander在工作的，封装了多个机房，对每个机房的请求，都找每个机房自己对应的一个BaseLoadBalancer，直接调用了BaseLoadBalancer的chooseServer()方法选择了一个server出来 

BaseLoadBalancer的chooseServer()方法中，直接就是用的IRule来选择了一台服务器 

找到，IRule到底是哪个Rule？IRule就代表了封装好的负载均衡的算法

用的是RibbonClientConfiguraiton中实例化的一个ZoneAvoidanceRule，调用了他的choose()方法来选择一个server，其实是用的父类，PredicateBasedRule.choose()方法，先执行过滤规则，过滤掉一批server，根据你自己指定的filter规则，然后用round robin轮询算法，依次获取下一个server 

1 % 2 = 1

2 % 2 = 0 

干说，大家有点不好理解，我们这边的话呢，就来源码调试一下，你就什么都懂了 

举个例子， 

192.168.31.107:8080

192.168.31.121:8080 

round robin ==> 不管你有几台机器，就是从第一台开始，每台机器访问一次，依次循环往复 

其实在ZoneAwareLoadBalancer的chooseServer()方法中，会发现当前只有一个zone，就是只有一个机房，所以会走另外一个逻辑 

modulo：2，代表的是当地前有几台机器 

2 % 2 = 0 

将0设置给nextIndex，会判断一下current是否小于modulo，正常情况下，一定是小于的 

返回的是8088这台机器 

modulo = 2

current = 0

next = 1

nextIndex = 1 

返回的是current = 0，选择的是两台机器中的第0台，第1台，从list里选择的时候走的是index 

这次返回的是8080这台机器 

modulo = 2

current = 1

next = 0

nextIndex = 0 

返回的是current = 1，选择的是两台机器中的第1台，第2台，lits的index是从1开始的，所以是第二台 

这次返回的是8088这台机器 

最最核心的方法，在AbstractServerPredicate的incrementAndGetModulo()方法，每次都是采用上面的round robin轮询算法，来依次遍历选择server list中的每一台server 

```
for (;;) {
int current = nextIndex.get();
int next = (current + 1) % modulo;
if (nextIndex.compareAndSet(current, next) && current < modulo)
return current;
} 
```

核心算法，round robin轮询算法

### 055_拿到了负载均衡算法选出来的server如何发起一个真正的网络请求

实际执行http请求的流程 

![](C:\Users\zy199005\Desktop\中华石杉\images\java\06\05501.png) 

猜测一下

		RibbonLoadBalancerContext context = this.clientFactory
				.getLoadBalancerContext(serviceId);

这边是从SpringClientFactory中，获取ServiceA对应的ApplicationContext容器，然后再从这个容器中获取对应的RibbonLoadBalancerContext bean

我们需要去找一下LoadBalancerRequest是什么东西？

在LoadBalancerInterceptor中，可以找到调用RibbonLoadBalancerClient.execute()方法的地方，那里去找一下LoadBalancerRequest是什么东西？

	return new LoadBalancerRequest<ClientHttpResponse>() {
	@Override
			public ClientHttpResponse apply(final ServiceInstance instance)
					throws Exception {
				HttpRequest serviceRequest = new ServiceRequestWrapper(request, instance, loadBalancer);
				if (transformers != null) {
					for (LoadBalancerRequestTransformer transformer : transformers) {
						serviceRequest = transformer.transformRequest(serviceRequest, instance);
					}
				}
				return execution.execute(serviceRequest, body);
			}
	
		};

LoadBalancerRequest，是一个匿名内部类的实例，就是在这里定义的

T returnVal = request.apply(serviceInstance);

在RibbonLoadBalancerClient的execute()方法中，调用了上面的那行代码，调用了那个LoadBalancerRequest的apply()方法，在这个方法中，传入了选择出来的server，意思就是，对这台server发起一个指定的一个请求

http://ServiceA/sayHello/leo，这个URL地址是封装在LoadBalancerRequest中的

将LoadBalancerRequest和server再次封装为了一个WrapperHttpRequest


将这个ServiceRequestWrappter交给了ClientHttpRequestExecution

再往下的话呢，其实就是走到spring-web的源码里去了，其实就是说是spring-web下的负责底层的http请求的组件，从ServiceRequestWrapper中获取出来了对应的真正的请求URL地址，然后发起了一次请求

所以，奥秘，不在于说spring-web的底层的http的源码，不看也罢

ServiceRequestWrapper中，因为你用屁股想想，spring-web的ClientHttpRequestExecution肯定是从ServiceRequestWrapper中，获取出来了对应的请求URL地址，这个请求URL地址的替换，是最最重要的

	@Override
	public URI getURI() {
		URI uri = this.loadBalancer.reconstructURI(
				this.instance, getRequest().getURI());
		return uri;
	}

ServiceRequestWrapper里面的getURI()方法重写了，基于自己的逻辑重写了，这个里面，调用了RibbonLoadBalancerClient的reconstructURI()方法，基于选择出来的server的地址，重构了请求URI

传入进去了负载均衡算法选择出来的一个server，getRequest().getURI() => http://ServiceA/sayHello/leo ==> 进行重构和替换，就是将ServiceA给替换成了实际选择出来的server对应的hostname:port

http://localhost:8080/sayHello/leo

就用这个请求，基于底层的ClientHttpRequestExecution发起一次http请求 

### 056_spring cloud中的ping服务器的机制来检查服务实例是否存活有效吗？ 

之前给大家说过，原生的ribbon有一个ping机制，就是有一个IPing的组件，会自己时不时的ping一下服务器，看看服务器是否存活，让自己仅仅请求存活的服务器即可 

我们来看看人家这个spring cloud整合ribbon使用的场景下，IPing组件是什么个工作机制？

```
@Bean
@ConditionalOnMissingBean
public IPing ribbonPing(IClientConfig config) {
if (this.propertiesFactory.isSet(IPing.class, name)) {
return this.propertiesFactory.get(IPing.class, config, name);
}
return new DummyPing();
} 
```

直接就发现spring cloud环境下，使用的IPing组件，是所谓的一个DummyPing组件

```
public class DummyPing extends AbstractLoadBalancerPing {
public DummyPing() {
}
public boolean isAlive(Server server) {
return true;
}
@Override
public void initWithNiwsConfig(IClientConfig clientConfig) {
}
} 
```

这个里面，什么都没有。。。。 

所以给大家说一下，spring cloud环境下， 默认的情况下，IPing组件是不生效的，不用ribbon自己去判断server是否存活，eureka去玩儿的。。。erueka自己会有故障发现和服务实例摘除的机制，如果某个服务实例挂了，eureka server会发现，然后摘除这个服务实例，然后所有的eureka client都会得到一个通知，eureka client本地的ribbon，不是有一个PollingServerListUpdater组件，每隔30秒去从自己本地的eureka client去拉取注册表 

ribbon通过与eureka的整合，自动就有一套服务实例故障自动摘除的机制 

ServiceA -> 发现机器从原来的3台变成现在的2台了 

下次再请求的时候，就不会找原来的那个故障的服务器去请求了 

疏忽，这块不是在RibbonClientConfiguration中定义的这个DummyPing，默认的ping，但是ribbon和eureka整合起来使用之后，使用的是人家eureka那个项目中定义的一个IPing组件。。。。EurekaRibbonClientConfiguration中 

NIWSDiscoveryPing，这个IPing组件，干的是什么事儿呢？其实非常简单的，他就是说将每个server list中的server，都检查一下这个server对应的一个eureka中的InstanceInfo的状态，看看这个InstanceInfo，服务实例的status是否是正常的

```
boolean isAlive = true;
if (server!=null && server instanceof DiscoveryEnabledServer){
DiscoveryEnabledServer dServer = (DiscoveryEnabledServer)server;        
InstanceInfo instanceInfo = dServer.getInstanceInfo();
if (instanceInfo!=null){          
InstanceStatus status = instanceInfo.getStatus();
if (status!=null){
isAlive = status.equals(InstanceStatus.UP);
}
}
}
return isAlive; 
```

这块其实跟我之前讲的是差不都的，在ribbon和eureka整合之后，ribbon最主要的就是三剑客，ILoadBalancer、IRule、IPing。IPing就将本地持有的server list中的每个server都执行一下isAlive()方法，看看那个server对应的eureka的InstanceInfo的status。。。 

eureka的InstanceInfo的status不是也是靠着我们之前说过的那个ribbon和eureka整合的机制一层一层刷新过来的吗？？？ 

不是说靠你自己发送个http请求ping一下对方的服务器的接口 

最后找一个源码，就是在ZoneAwareLoadBalancer实例构造的时候，一定会有一个地方，去启动一个定时调度的任务，这个定时调度的任务，一定会每隔一定的时间，就用IPing组件对server list中的每个server都执行一下isAlive()方法。。。 

BaseLoadBalancer.initWithConfig()方法中，有一个setPingInterval()方法，连蒙带猜，用屁股想想，这个方法一定跟Ping组件定时调度有关系。。。setupPingTask()方法，一看就是很容易猜想到是在启动定时ping server list的定时调度任务 

​    lbTimer = new ShutdownEnabledTimer("NFLoadBalancer-PingTimer-" + name, true);

​    lbTimer.schedule(new PingTask(), 0, pingIntervalSeconds * 1000); 

默认的是每隔30秒执行一下那个PingTask调度任务，里面会去执行一个Pinger()的东西，这个里面会去执行SerialPingStrategy 

results = pingerStrategy.pingServers(ping, allServers); 

用IPing组件对每个server都执行一下isAlive()方法。。。。 

另外我可以告诉大家，网上找ribbon的ping机制，我曾今就看到过一篇博客，是说ribbon的ping机制，是每隔10秒钟ping一下

### 057_对ribbon自己原生的另外几种负载均衡算法的IRule源码初探一下

默认的负载均衡算法可能存在的问题

 ![](C:\Users\zy199005\Desktop\中华石杉\images\java\06\05701.png)   

没什么好太多说的 

你要相信一点，就是spring cloud的设计的哲学和思想，尽量就是说开箱即用 

无论是zuul、eureka、feign、ribbon、hystrix，尽量刚开始上的时候，都用默认的参数就可以了，所以呢，你会发现一个问题，如果按照原生的一个round robin的负载均衡算法，会有一个问题 

在刚才的源码里，我们可以看到，他就是非常简单的去进行一个选择这样子，就是不断的从自己本地的server list中去round robin轮询选择一个server去请求 

他的问题就是说，可能会不断的请求一个已经不存在的，故障的服务实例，请求失败 

spring cloud的哲学，对于这个问题，是通过后面的hystrix来解决，通过hystrix来做资源隔离，熔断和降级，对这个请求失败的服务实例，就走降级机制，可能就是这样子，可以保证某个服务实例故障了，不会因为请求他失败，而影响当前的这个服务 

一遍来说，也不太建议大家在生产环境随意的自己更改负载均衡的算法 

给大家简单的看看，其他的一些ribbon支持的负载均衡算法的IRule的源码 

RoundRobinRule：系统内置的默认负载均衡规范，直接round robin轮询，从一堆server list中，不断的轮询选择出来一个server，每个server平摊到的这个请求，基本上是平均的 

这个算法，说白了是轮询，就是一台接着一台去请求，是按照顺序来的 

AvailabilityFilteringRule：这个rule就是会考察服务器的可用性 

如果3次连接失败，就会等待30秒后再次访问；如果不断失败，那么等待时间会不断边长

如果某个服务器的并发请求太高了，那么会绕过去，不再访问 

用屁股猜想，先用round robin算法，轮询依次选择一台server，如果判断这个server是存活的可用的，如果这台server是不可以访问的，那么就用round robin算法再次选择下一台server，依次循环往复，10次。还是不行 

WeightedResponseTimeRule：带着权重的，每个服务器可以有权重，权重越高优先访问，如果某个服务器响应时间比较长，那么权重就会降低，减少访问 

ZoneAvoidanceRule：根据机房和服务器来进行负载均衡，说白了，就是机房的意思，看了源码就是知道了，这个就是所谓的spring cloud ribbon环境中的默认的Rule 

BestAvailableRule：忽略那些请求失败的服务器，然后尽量找并发比较低的服务器来请求 

RandomRule：随机找一个服务器，尽量将流量分散在各个服务器上 

RetryRule：可以重试，就是通过round robin找到的服务器请求失败，可以重新找一个服务器

### 058_如果在spring cloud环境下就用ribbon来做服务调用会咋样？ 

比如说我们原来，其实就用了spring cloud里面的两个项目，一个是eureka，服务注册与发现；另外一个是ribbon，起码是得用的，因为要用ribbon来支持负载均衡；RestTemplate，spring-web里面的一个发送http请求的一个类库 

比较核心的一个问题，如果仅仅是使用RestTemplate + ribbon的方式来进行服务间的这个调用，会导致我们每次去调用人家一个接口，都要单独写一些代码。。。。 

我们追求一下极致，看看有没有办法，可以让我们不用写代码，直接用一些接口和注解一下子就可以完成对其他服务的调用呢？ 

答案：feign，就可以完成声明式的服务调用。。。我们不用写代码去调用一个接口 

我们如果仅仅是用ribbon，服务间的调用会长啥样？我们再来看看，如果用feign来调用服务，大概会长啥样？我们发现一个问题，ribbon这里，如果仅仅使用ribbon来进行服务间的调用，很麻烦，对ServiceA每个接口，都需要在本地定义一个对应的接口的方法，在方法里写代码来调用人家的接口 

也就是说，ServiceB调用ServiceA是有编码的成本的。。。。 

假如说，我们用feign，我们理想中的情况，应该是怎么玩儿的呢？ 

我们正儿八经在公司里做N多个服务的微服务架构的系统的时候，都是让比如ServiceA他要对外提供什么接口，那么ServiceA要提供一个jar包出来，然后ServiceB是一点编码都不做的，不能为了ServiceA去编码的 

ServiceB要调用ServiceA，那么ServiceA就提供一个jar包出来，里面包含了自己提供的接口，包括接口如何调用自己的，ServiceB直接引用一个jar包即可，然后直接就调用ServiceA提供的一堆接口

### 059_基于spring cloud feign来开发声明式接口调用的CRUD demo 

**1、给ServiceA加几个接口**

```
@RestController
@RequestMapping("/user") 
public class ServiceAController {
@RequestMapping(value = "/sayHello/{id}", method = RequestMethod.GET)
public String sayHello(@PathVariable("id") Long id, 
@RequestParam("name") String name, 
@RequestParam("age") Integer age) {   
System.out.println("打招呼，id=" + id + ", name=" + name + ", age=" + age);  
return "{'msg': 'hello, " + name + "'}"; 
}
@RequestMapping(value = "/", method = RequestMethod.POST)
public String createUser(@RequestBody User user) {
System.out.println("创建用户，" + user); 
return "{'msg': 'success'}";
}
@RequestMapping(value = "/{id}", method = RequestMethod.PUT)
public String updateUser(@PathVariable("id") Long id, @RequestBody User user) {
System.out.println("更新用户，" + user); 
return "{'msg': 'success'}";
}
@RequestMapping(value = "/{id}", method = RequestMethod.DELETE)
public String deleteUser(@PathVariable("id") Long id) {
System.out.println("删除用户，id=" + id);
return "{'msg': 'success'}"; 
}
@RequestMapping(value = "/{id}", method = RequestMethod.GET)
public User getById(@PathVariable("id") Long id) {
System.out.println("查询用户，id=" + id);
return new User(1L, "张三", 20);
}
} 
```

**2、重构一下ServiceB基于feign来调用ServiceA**

```
<dependency>
<groupId>org.springframework.cloud</groupId>
<artifactId>spring-cloud-starter-feign</artifactId>
</dependency>
```

在Application上加入：@EnableFeignClients

```
@FeignClient(“ServiceA”)
public interface ServiceAClient {
@RequestMapping(value = “/sayHello/{id}”, method = RequestMethod.GET)
String sayHello(@PathVariable(“id”) Long id,
@RequestParam(“name”) String name,
@RequestParam(“age”) Integer age);
@RequestMapping(value = “/user”, method = RequestMethod.POST)
String createUser(@RequestBody User user)
@RequestMapping(value = “/user/{id}”, method = RequestMethod.PUT)
String updateUser(@PathVariable(“id”) Long id, 
@RequestBody User user)
@RequestMapping(value = “/user/{id}, method = RequestMethod.DELETE)
String deleteUser(@PathVariable(“id”) Long id)
@RequestMapping(value = “/user/{id}, method = RequestMethod.GET”)
User getById(@PathVariable(“id”) Long id)
} 
```

feign默认就是集成了ribbon实现了负载均衡的，所以自己试下就ok了，用着很简单 

**3、feign继承特性** 

（1）单独定义一个工程，叫做service-a-api，定义统一对外暴露的接口以及实体类 

```
<distributionManagement>
<repository>
<id>nexus-releases</id>
<name>Nexus Release Repository</name>
<url>http://localhost:8081/repository/maven-releases/</url>
</repository>
<snapshotRepository>
<id>nexus-snapshots</id>
<name>Nexus Snapshot Repository</name>
<url>http://localhost:8081/repository/maven-snapshots/</url>
</snapshotRepository>
</distributionManagement>
<dependency>
<groupId>org.springframework.boot</groupId>
<artifactId>spring-boot-starter-web</artifactId>
<version>1.5.13.RELEASE</version>
</dependency>
```

```
@RequestMapping("/user") 
public interface ServiceAInterface {
@RequestMapping(value = "/sayHello/{id}", method = RequestMethod.GET)
String sayHello(@PathVariable("id") Long id, 
@RequestParam("name") String name,  @RequestParam("age") Integer age);
@RequestMapping(value = "/", method = RequestMethod.POST)
String createUser(@RequestBody User user);
@RequestMapping(value = "/{id}", method = RequestMethod.PUT)
String updateUser(@PathVariable("id") Long id, @RequestBody User user);
@RequestMapping(value = "/{id}", method = RequestMethod.DELETE)
String deleteUser(@PathVariable("id") Long id);
@RequestMapping(value = "/{id}", method = RequestMethod.GET)
User getById(@PathVariable("id") Long id);
}
```

```
public class User {
private Long id;
private String name;
private Integer age;
public User() {
}
public User(Long id, String name, Integer age) {
this.id = id;
this.name = name;
this.age = age;
}
public Long getId() {
return id;
}
public void setId(Long id) {
this.id = id;
}
public String getName() {
return name;
}
public void setName(String name) {
this.name = name;
}
public Integer getAge() {
return age;
}
public void setAge(Integer age) {
this.age = age;
}
@Override
public String toString() {
return "User [id=" + id + ", name=" + name + ", age=" + age + "]";
}
} 
```

（2）ServiceA中对定义好的接口实现业务逻辑

```
<dependency>
<groupId>com.zhss.demo</groupId>
<artifactId>service-a-api</artifactId>
<version>0.0.1-SNAPSHOT</version>
</dependency>
```

```
@RestController
public class ServiceAController implements ServiceAInterface {
public String sayHello(@PathVariable("id") Long id, 
@RequestParam("name") String name, 
@RequestParam("age") Integer age) {   
System.out.println("打招呼，id=" + id + ", name=" + name + ", age=" + age);  
return "{'msg': 'hello, " + name + "'}"; 
}
public String createUser(@RequestBody User user) {
System.out.println("创建用户，" + user); 
return "{'msg': 'success'}";
}
public String updateUser(@PathVariable("id") Long id, @RequestBody User user) {
System.out.println("更新用户，" + user); 
return "{'msg': 'success'}";
}
public String deleteUser(@PathVariable("id") Long id) {
System.out.println("删除用户，id=" + id);
return "{'msg': 'success'}"; 
}
public User getById(@PathVariable("id") Long id) {
System.out.println("查询用户，id=" + id);
return new User(1L, "张三", 20);
}
}
```

（3）改造ServiceB依赖ServiceA的接口jar包 

```
<dependency>
<groupId>com.zhss.demo</groupId>
<artifactId>service-a-api</artifactId>
<version>0.0.1-SNAPSHOT</version>
</dependency>
```

```
@FeignClient("ServiceA")
public interface ServiceAClient extends ServiceAInterface { 
}  
```

负载均衡了，而且整个服务之间的调用，做的就比较有模有样了，比较企业级了 

后面我们基于spring cloud本身去改造我们的阶段一的系统，没什么很大的难度，我们自己正儿八经做一个比较复杂的分布式系统，微服务架构的话，谁提供什么接口，定义一个单独的xx-service-api的工程，部署到私服，人家依赖你的jar包，基于你提供的接口来开发，就可以了，直接调用你的服务的接口

### 060_在spring cloud环境下使用feign的时候进行自定义bean 

feign就跟ribbon一样，内部都包含了很多的核心组件 

ribbon，三剑客，ILoadBalancer、IRule、IPing，这几个东东是最重要的，ServerList，也属于他的核心组件，也是有Builder的 

feign，也是一样的，也有很多核心的组件： 

（1）编码器和解码器：Encoder和Decoder，如果调用接口的时候，传递的参数是个对象，feign需要将这个对象进行encode，编码，搞成json序列化，就是把一个对象转成json的格式，Encoder干的事儿；Decoder，解码器，就是说你收到了一个json以后，如何来处理这个东西呢？如何将一个json转换成本地的一个对象。。 

（2）Logger：打印日志的，feign是负责接口调用，发送http请求，所以feign是可以打印这个接口调用请求的日志的 

（3）Contract：比如一般来说feign的@FeignClient注解和spring web mvc支持的@PathVariable、@RequestMapping、@RequestParam等注解结合起来使用了。feign本来是没法支持spring web mvc的注解的，但是有一个Contract组件之后，契约组件，这个组件负责解释别人家的注解，让feign可以跟别人家的注解结合起来使用 

（4）Feign.Builder：FeignClient的一个实例构造器，各种设计模式的使用，构造器，演示过，就是复杂对象的构造，非常适合，用了构造器模式之后，代码是很优雅的。 

（5）FeignClient：就是我们使用feign最最核心的入口，就是要构造一个FeignClient，里面包含了一系列的组件，比如说Encoder、Decoder、Logger、Contract，等等吧。。。 

1、sprin cloud对feign的默认组件 

Decoder：ResponseEntityDecoder 

Encoder：SpringEncoder 

Logger：Slf4jLogger 

Contract（这个是用来翻译第三方注解的，比如说对feign使用spring mvc的注解）：SpringMvcContract 

Feign实例构造器：HystrixFeign.Builder => Hystrix其实也是跟Feign整合在一起使用的，spring cloud几个核心的组件，eureka、ribbon、feign、hystrix、zuul，其实eureka是独立部署server的，但是feign + hystrix + ribbon + eureka client整合在一起使用的。我之前已经给大家说过ribbon和eureka是如何整合的 

Feign客户端：LoadBalancerFeignClient => 负载均衡，通过LoadBalancerFeignClient，底层是跟ribbon整合起来使用的 

2、自定义bean

```
@FeignClient(name = “ServiceA”, configuration = MyConfiguration.class)
public interface ServiceAClient {
}
public class MyConfiguration {
@Bean
public RequestInterceptor requestInterceptor() {
return new MyRequestInterceptor();
}
}
```

feign的拦截器的使用，就是说我们可以实现对feign的请求进行拦截的拦截器，实现一个接口即可，RequestInterceptor，然后所有的请求发送之前都会被我们给拦截，你看这里不就是拦截器模式，interceptor模式

### 061_在spring cloud中使用feign的时候如何自定义一些参数配置 

比如说我们吧，在做这个微服务架构的系统的时候，不用上来就胡乱配置太多的东西，很多时候，默认配置就ok，不要说你觉得自己很牛，胡乱调整配置，很可能就调错了。除了极其少数的关键的几个配置，要配置以外；然后在测试的环节，看看有没有什么问题，如果有可以调整配置；在压力测试的环节，可以看看有没有什么问题，如果有可以调整配置；如果在线上发生了生产环境的问题，那么可以调整配置 

普通参数配置

压缩配置

日志配置 

1、feign配置的格式 

feign:

 client:

  config:

   ServiceA:

​    connectTimeout: 5000

​    readTimeout: 5000

​    loggerLevel: full

​    decode404: false

 

feign:

 client:

  config:

   default:

​    connectTimeout: 5000

​    readTimeout: 5000

​    loggerLevel: full 

2、启用feign的压缩 

feign.compression.request.enabled: true

feign.compression.request.mime-types: text/xml,application/xml,application/json

feign.compression.request.min-request-size: 2048

feign.compression.response.enabled: true 

3、启用请求日志 

这块其实在日志这里，一般不要在生产开这个日志吧，开这个日志的话，量很大，比如说你每天要发送几亿次请求，这些请求日志你都要？？？除非是收集这些日志在大数据平台进行日志的分析。。。。 

关于log的打印，最好是用统一的日志组件，要自己设计和研发大型的日志中心，然后我们将log打印到日志中心里去，基于ELK、Kafka那套技术栈来做的日志中心 

可以建议大家比如说在测试环境里打开，辅助你debug，调试测试，测试环境里请求不会很多，请求日志都记录下来感觉还可以 

logger level：none，basic，headers，full

logging.level.com.zhss.service.ServiceAClient: DEBUG 

@Configuration

public class MyConfiguration {

  @Bean

  Logger.Level feignLoggerLevel() {

​    return Logger.Level.FULL;

  }

} 

2018-06-11 17:24:41.088 DEBUG 31004 --- [nio-9090-exec-1] com.zhss.service.ServiceAClient      : [ServiceAClient#getById] <--- HTTP/1.1 200 (632ms)

2018-06-11 17:24:41.088 DEBUG 31004 --- [nio-9090-exec-1] com.zhss.service.ServiceAClient     : [ServiceAClient#getById] content-type: application/json;charset=UTF-8

2018-06-11 17:24:41.088 DEBUG 31004 --- [nio-9090-exec-1] com.zhss.service.ServiceAClient     : [ServiceAClient#getById] date: Mon, 11 Jun 2018 09:24:41 GMT

2018-06-11 17:24:41.088 DEBUG 31004 --- [nio-9090-exec-1] com.zhss.service.ServiceAClient     : [ServiceAClient#getById] transfer-encoding: chunked

2018-06-11 17:24:41.088 DEBUG 31004 --- [nio-9090-exec-1] com.zhss.service.ServiceAClient     : [ServiceAClient#getById] 

2018-06-11 17:24:41.090 DEBUG 31004 --- [nio-9090-exec-1] com.zhss.service.ServiceAClient     : [ServiceAClient#getById] {"id":1,"name":"张三","age":20}

2018-06-11 17:24:41.090 DEBUG 31004 --- [nio-9090-exec-1] com.zhss.service.ServiceAClient     : [ServiceAClient#getById] <--- END HTTP (33-byte body)

2018-06-11 17:24:41.909 INFO 31004 --- [erListUpdater-0] c.netflix.config.ChainedDynamicProperty : Flipping property: ServiceA.ribbon.ActiveConnectionsLimit to use NEXT property: niws.loadbalancer.availabilityFilteringRule.activeConnectionsLimit = 2147483647 

### 062_老规矩：咱们画一张很大的图来捋一捋feign的核心工作流程

feign的核心功能流程

![](C:\Users\zy199005\Desktop\中华石杉\images\java\06\06201.png) 

   

用屁股想一想，你就定义了一个ServiceAClient的接口，凭啥说，你就@Autowried注入一个ServiceAClient接口的实例，就可以去调用接口的方法，然后直接http请求就发出去了？用屁股想一想，一定是feign在运行的时候，针对我们打了@FeignClient的注解的接口，在运行的时候动态生成了一个动态代理。。。。 

接口是没有实现的，是不能调用的。。。 

我们用屁股想想，feign一定是整合了ribbon的，因为必须基于ribbon来进行负载均衡，因为每个服务都是部署多台机器的，必须有负载均衡的机制，所以feign肯定不会自己去干负载均衡的事情，ribbon都干的很好了 

feign + ribbon + eureka，ServiceA服务名称 => server list，必须结合eureka来，从eureka获取到对应的服务的server list

### 063_从@EnableFeignClients入手来找一找扫描@FeignClient的入口在哪儿

扫描@FeignClient注解的入口

![](C:\Users\zy199005\Desktop\中华石杉\images\java\06\06301.png)   

就得进入一下feign的源码的剖析，尤其是要剖析spring cloud环境下的feign的源码和工作机制，那么我们考虑一下，研究spring cloud环境下的feign的源码，入口在哪儿啊？？能够让我们研究的入口就俩： 

第一个入口：Application启动类的@EnableFeignClients注解 

第二个入口：我们自定义的接口的，比如说ServiceAClient接口，上面打的这个@FeignClient注解 

这块，先不看注解的源码，先用屁股来猜想，屁股猜想论，我给大家一个大胆的假设：我觉得我们用@FeignClient标注了自定义的接口，作用就是给feign的一个核心机制来扫描的，feign核心机制一定会去扫描所有打了@FeignClient注解的接口 

feign核心机制，扫描到那些打了@FeignClient注解的接口之后，就会针对这些接口，生成自己的feign动态代理，以及解析和处理接口上打的那些spring web mvc的注解，比如@RequestMapping，@PathVarialbe，@RequestParam，基于spring web mvc的注解，来生成接口对应的http请求 

一个问题来了，谁来扫描@FeignClient注解的接口呢？？？ 

大胆的猜想一下：Application启动类的@EnableFeignClients注解，这个注解一定会作为一个全局的东东，一旦你加了这个注解之后，就会触发对应的Feign的核心机制，那个被触发的feign核心机制，就会去扫描所有包下面的@FeignClient注解的接口 

这一讲，我们来看看这俩注解的源码 

@FeignClient注解的解释: 

你用这个@FeignClient注解标注了一个接口，这个接口会被创建为一个REST client（发送restful请求的客户端），然后可以将这个REST client注入其他的组件（比如说ServiceBController），如果启用了ribbon的话，就会采用负载均衡的方式，来进行http请求的发送，你可以用@RibbonClient标注一个配置类，在那个配置类里可以自定义自己的ribbon的ILoadBalancer。。。 

@RibbonClient的名称，要跟@FeignClient的名称，一样的 

public class MyConfiguration { 

@Bean

public IRule getRule() {

return new MyRule();

} 

@Bean

public IPing getPing() {

return new MyPing();

} 

} 

@RibbonClient(name = “ServiceA”, configuration = MyConfiguration.class)

public class ServiceAConfiguration { 

} 

所以说，通过@FeignClient的注解，都可以看得出来，人家都说的很明确了，你用这个注解标注一个接口，就是让feign对这个接口创建一个对应的动态代理出来，这个动态代理就是所谓的REST client，发送rest请求的客户端 

@FeignClient注解的源码中，定义了一堆方法，那些方法就是说，可以在这个注解中指定哪些参数。。。value和name表达的意思是一样的，都是指代的你要调用的那个服务名称；url，一看就是说，如果你不用ribbon的话，那么就没法做负载均衡了，你可以就用url地址指定你要请求的地址，比如说：http://localhost:9090；decode404的意思，就是说用404替代抛出FeignException异常，替代为404异常；configurtation指定一个配置类，可以在里面自定义自己的Encoder、Decoder、Contract。。。 

@EnableFeignClients，极为关键，扫描那些标注了@FeignClient注解的接口，这里有一些参数，就是指定你要扫描哪些包下面的@FeignClient注解的接口。。。 

有一个极为重要的东西：@Import(FeignClientsRegistrar.class) 

这个@Import其实就是负责扫描@FeignClient注解的极为关键的一个入口，导入了一个FeignClientRegistrar类。。。我们猜测一下，FeignClientRegistrar是什么东西？屁股猜想论。。。负责FeignClient注册的一个组件 

我们猜想的就是：这个FeignClientRegistrar组件，负责扫描所有包下面的@FeignClient注解的接口，然后触发后面所有的处理流程 

FeignClientRegistrar实现了一堆接口，XXXAware，不用问，一定是实现了这个接口，持有了对应的引用，然后让spring给他注入一堆东西，XXX 

​     @Override

​     public void registerBeanDefinitions(AnnotationMetadata metadata,

​               BeanDefinitionRegistry registry) {

​          registerDefaultConfiguration(metadata, registry);

​          registerFeignClients(metadata, registry);

​     } 

你看到这个方法，有没有觉得有点奇怪？？？ 

​          registerDefaultConfiguration(metadata, registry);

​          registerFeignClients(metadata, registry); 

注册默认的配置：这个是什么意思？一看就是解析相关的一些配置，注册到自己身体里去 

注册FeignClients：我猜测，这个方法就是最最核心的，扫描各个包下面的@FeignClient注解，然后生成@FeignClient的动态代理，注册这些@FeignClient 

猜测registerBeanDefinitions()方法，是feign的核心的入口方法，这个方法是什么时候会调用呢？？？？分析一下他的实现接口，ImportBeanDefinitionRegistrar，这个接口，发现说是spring-context项目里带的 

我们屁股猜想一下，肯定是在spring boot启动的时候，spring容器初始化的时候，一定会在某个时间点，会对实现这个接口的类的registerBeanDefinitions()方法会来调用，让你来实例化一些bean，注册到spring容器里去。。。 

所以我们的spring boot启动的时候，FeignClientRegistrar.registerBeanDefinitions()方法，将会作为扫描@FeignClient注解的入口，也就是我们研究spring cloud环境下的feign的源码的一个关键的入口

### 064_牛刀小试：跑起来服务环境然后打断点初步调试一下feign的入口源码 

FeignClientsRegistrar.registerBeanDefinitions()方法，打个断点 

启动ServiceB服务，debug模式进去，直接就可以进去feign去扫描@FeignClient注解的入口的源码，可以初步的简单调试一下 

我们这一讲，就以registerDefaultConfiguration()方法为例，来先初步调试一下feign的源码 

大概猜测一下，metadata（AnnotationMetadata）可能是注解相关的一些元数据，BeanDefinitionRetistry（bean实例的注册器） 

​          Map<String, Object> defaultAttrs = metadata

​                    .getAnnotationAttributes(EnableFeignClients.class.getName(), true); 

这行代码，屁股看看都明白，其实就是获取了@EnableFeignClients这个注解的所有属性的值 

​            String name;

​               if (metadata.hasEnclosingClass()) {

​                    name = "default." + metadata.getEnclosingClassName();

​               }

​               else {

​                    name = "default." + metadata.getClassName();

​               } 

获取Aplication启动类的全限定名：default.com.zhss.service.ServiceBApplication 

registerClientConfiguration() ==> 方法 

BeanDefinitionBuilder，这个是什么东东？spring cloud的源码，比netflix公司的源码，水平高了几个档次，毕竟netflix的源码只是写公司内部使用的，只不过影响力大了以后，融入了spring cloud。但是人家spring cloud的源码，都是开放给全世界使用的，这个代表了全世界的这个领域的专家的最高水平了，所以spring cloud的源码，人家是肯定不会瞎写的 

看spring cloud的源码，就感觉非常的舒服 

BeanDefinitionBuilder，bean定义的构造器，连蒙带猜，抓大放小，别去管他是什么东西 

抓大放小，认真你就输了

我们可以想到，就是将之前搞出来的启动类的全限定名的name，以及defaultConfiguration（空的），这两个东西作为，addConstructorArgValue，将name和defaultConfiguration作为构造某个bean的构造函数的入参。。。。 

可能接下来要用BeanDefinitionBuilder构造某个bean，构造这个bean的时候，需要往构造函数中传入两个入参，就是我们上面解析出来的name和defaultConfiguration 

​          BeanDefinitionBuilder builder = BeanDefinitionBuilder

​                    .genericBeanDefinition(FeignClientSpecification.class);

​          builder.addConstructorArgValue(name);

​          builder.addConstructorArgValue(configuration);

​          registry.registerBeanDefinition(

​                    name + "." + FeignClientSpecification.class.getSimpleName(),

​                    builder.getBeanDefinition()); 

认真你就输了，别去管他了，抓大放小，屁股猜想论，基于default.com.zhss.service.ServiceBApplication.FeignClientSpecification，之前构造出来的beanDefinition，注册到了BeeanDefinictionRegistry里面去，再往里走就别走了，是spring-beans工程的，读源码读到spring源码里去了 

这里搞出来的一些关键的东西，就是： 

（1）Application启动类的全限定类名：default.com.zhss.service.ServiceBApplication

（2）解析了一下@EnableFeignClients注解的attrs属性值，defaultConfiguration

（3）基于上面两块东西，在一个叫做BeanDefinicitonRegistry（spring-beans项目）的东西里注册了一下 

小试牛刀，告诉你feign的源码是可以调试的，就ok了 

屁股猜想论来猜想一下：

（1）registerFeignClients()方法，这个方法的话，在这个方法里会对所有的包进行扫描，专门扫描包含了@FeignClient注解的接口

（2）registerFeignClient()方法，最终应该是基于这个方法完成了扫描出来的@FeignClient相关接口的注册 

那么所以，我们下一讲，就来调试一下registerFeignClients()方法里的代码

### 065_终于找到了feign核心机制的入口：来看看如何扫描包下面的@FeignClient注解

扫描@FeignClient注解的机制

![](C:\Users\zy199005\Desktop\中华石杉\images\java\06\06501.png) 

​    

看看feign核心机制，如何扫描所有包下面的@FeignClient注解的接口 

获取了一个scanner，你看看这个scanner，是：ClassPathScanningCandidateComponentProvider 

看类名，屁股猜想一下就知道：在classpath中扫描候选的组件的provider类，这个类就是复杂在指定的路径中，扫描你指定的条件的相关的bean，类，接口 

Set<String> basePackages; 

​          Map<String, Object> attrs = metadata

​                    .getAnnotationAttributes(EnableFeignClients.class.getName());

​          AnnotationTypeFilter annotationTypeFilter = new AnnotationTypeFilter(

​                    FeignClient.class);

​          final Class<?>[] clients = attrs == null ? null

​                    : (Class<?>[]) attrs.get("clients");

​          if (clients == null || clients.length == 0) {

​               scanner.addIncludeFilter(annotationTypeFilter);

​               basePackages = getBasePackages(metadata);

​          }

​          else {

​               final Set<String> clientClasses = new HashSet<>();

​               basePackages = new HashSet<>();

​               for (Class<?> clazz : clients) {

​                    basePackages.add(ClassUtils.getPackageName(clazz));

​                    clientClasses.add(clazz.getCanonicalName());

​               }

​               AbstractClassTestingTypeFilter filter = new AbstractClassTestingTypeFilter() {

​                    @Override

​                    protected boolean match(ClassMetadata metadata) {

​                         String cleaned = metadata.getClassName().replaceAll("\\$", ".");

​                         return clientClasses.contains(cleaned);

​                    }

​               };

​               scanner.addIncludeFilter(

​                         new AllTypeFilter(Arrays.asList(filter, annotationTypeFilter)));

​          } 

如果是有经验的码农，一看这个代码就知道，这一大坨代码，其实都是在处理要扫描的包路径，在确定到底要扫描哪些包里面的@FeignClient注解标注的接口呢？ 

先是去获取了@EnableFeignClients里面的属性，因为这个属性里是可以配置basePackages，就是可以自己指定要扫描的包路径的 

​          AnnotationTypeFilter annotationTypeFilter = new AnnotationTypeFilter(

​                    FeignClient.class); 

这行代码，极为关键，AnnotationTypeFilter，就是一个根据注解的类型进行过滤的过滤器，传入进去的是@FeignClient注解的类型，一看就是什么呢？用于过滤出来@FeignClient注解类型的过滤器  

final Class<?>[] clients = attrs == null ? null

​                    : (Class<?>[]) attrs.get("clients");

​          if (clients == null || clients.length == 0) {

​               scanner.addIncludeFilter(annotationTypeFilter);

​               basePackages = getBasePackages(metadata);

​          } 

clients，在正常情况下，都是空的，为啥？因为我们一般不会在@EnableFeignClients注解中来配置clients属性，所以可以默认一般都是空的 

如果clients是空的，就会给组件扫描器添加一个注解过滤器，之前搞的那个专门过滤@FeignClient注解的注解过滤器，就会加入组件扫描器中 

basePackages = getBasePackages(metadata);，一看就是极为关键的代码，看名字，屁股猜猜，都知道，先是尝试从@EnableFeingClients注解中去获取要扫描的basePackages包路径。结果没有发现，肯定是在你@EnableFeignClients注解没有配置basePackages属性的时候，就会去自动生成一堆basePackages 

发现关键的逻辑，如果你的@EnableFefignClients中没有配置要扫描的包路径，那么默认就是你的Application启动类所在的包，com.zhss.service 

不常走的源码逻辑，别去看了，抓大放小，看常走的源码逻辑，常用的东西，就可以了 

此时就会发现我们要扫描的包路径，就是com.zhss.service包 

else {

​               final Set<String> clientClasses = new HashSet<>();

​               basePackages = new HashSet<>();

​               for (Class<?> clazz : clients) {

​                    basePackages.add(ClassUtils.getPackageName(clazz));

​                    clientClasses.add(clazz.getCanonicalName());

​               }

​               AbstractClassTestingTypeFilter filter = new AbstractClassTestingTypeFilter() {

​                    @Override

​                    protected boolean match(ClassMetadata metadata) {

​                         String cleaned = metadata.getClassName().replaceAll("\\$", ".");

​                         return clientClasses.contains(cleaned);

​                    }

​               };

​               scanner.addIncludeFilter(

​                         new AllTypeFilter(Arrays.asList(filter, annotationTypeFilter)));

​          } 

else里的代码没走，一般也不常走，除非你配置了@EnableFeignClients中的clients属性才会走，所以别看了 

​               Set<BeanDefinition> candidateComponents = scanner

​                         .findCandidateComponents(basePackage); 

这行代码，极为关键：使用了组件扫描器（搭载了@FeignClient注解过滤器），在com.zhss.service包中扫描，包含了@FeignClient注解的接口。。。扫描出来了一堆BeanDefinition 

return new ClassPathScanningCandidateComponentProvider(false, this.environment) { 

​               @Override

​               protected boolean isCandidateComponent(

​                         AnnotatedBeanDefinition beanDefinition) {

​                    if (beanDefinition.getMetadata().isIndependent()) {

​                         // TODO until SPR-11711 will be resolved

​                         if (beanDefinition.getMetadata().isInterface()

​                                   && beanDefinition.getMetadata()

​                                             .getInterfaceNames().length == 1

​                                   && Annotation.class.getName().equals(beanDefinition

​                                             .getMetadata().getInterfaceNames()[0])) {

​                              try {

​                                   Class<?> target = ClassUtils.forName(

​                                             beanDefinition.getMetadata().getClassName(),

​                                             FeignClientsRegistrar.this.classLoader);

​                                   return !target.isAnnotation();

​                              }

​                              catch (Exception ex) {

​                                   this.logger.error(

​                                             "Could not load target class: "

​                                                       \+ beanDefinition.getMetadata().getClassName(),

​                                             ex);

​                              }

​                         }

​                         return true;

​                    }

​                    return false; 

​               }

​          }; 

看看这段代码，创建组件扫描器时候的一段代码，里面自己覆盖了isCandidateComponent()方法，看名字，屁股猜猜都知道，这个组件扫描器，干的活儿，一定是在指定的com.zhss.service包下去扫描所有的类，每次扫到一个类，就交给这个isCandidateComponent()方法，判断一下，是否是我们需要的那个类？？？ 

推测一下，大概这个东西的意思是什么呢？ 

看看所谓组件扫描器我们能到的内部逻辑的工作原理 

我们可以看到给这个组件扫描器的isCandidateComponent()方法传入进来的，居然就是我们用@FeignClient标注的那个ServiceAClient接口。。。而且可以获取到我们定义的ServiceAClient接口继承的那个ServiceAInterface接口 

beanDefinition.getMetadata().getInterfaceNames()[0] 

很明显，这个东西是什么啊？就是刚才说的那个ServiceAInterface接口的名字，这个东西是否跟Annotation.class.getName()一致，如果一致才会往下走；如果不一致直接返回true 

对于我们的这个情况，传入进来了一个ServiceAClient，继承了ServiceAInterface，在这个方法中，是直接返回ture的，直接就符合candicateComponent的要求 

这个组件扫描器的逻辑就已经出来了。。。 

组件扫描器，scanner，我们之前给设置了一个@FeignClient注解的过滤器，这样的话呢，scanner会将com.zhss.service包下面的@FeignClient标注的接口扫描出来，然后交给isCandidateComponent()方法来处理，默认都是返回true 

感慨一下，看spring cloud相关的源码，真的比netflix原生自己公司写的源码，舒服太多太多了，写的好的代码，极为清晰，看代码很容易就看懂了 

所谓的candicateComponent就是我们的标注了@FeignClient的接口，ServiceAClient接口 

if (candidateComponent instanceof AnnotatedBeanDefinition) {

} 

这个if判断就是说，你这个候选bean，必须是被注解打标注的bean，我们肯定是如何的，因为@FeignClient标注了 

​                         Assert.isTrue(annotationMetadata.isInterface(),

​                                   "@FeignClient can only be specified on an interface"); 

这里都说了，@FeignClient注解必须标注在接口上，这是要求的 

​                         Map<String, Object> attributes = annotationMetadata

​                                   .getAnnotationAttributes(

​                                             FeignClient.class.getCanonicalName()); 

这块，就是说，拿到@FeignClient注解里，我们加入的属性，比如说我们，就加入了一个value，一个是configuration属性，最主要的就是获取我们的@FeignClient指定的要访问的那个服务的名称 

​                         registerClientConfiguration(registry, name,

​                                   attributes.get("configuration"));

一看就是什么呢？将name（服务名称） + @FeignClient的配置属性 => 在BeanDefinitionRegistry中注册一下，这个我们现在看不懂，也没必要去看懂，抓大放小 

registerFeignClient(registry, annotationMetadata, attributes); 

下集预告，就是来分析这个方法，这个registreFeignClient的方法，一看就是对扫描出来的@FeignClient接口去进行注册

### 066_来看看将@FeignClient接口构造为bean的过程以及是如何注册到容器里的

扫描@FeignClient注解的机制续

![](C:\Users\zy199005\Desktop\中华石杉\images\java\06\06601.png)   

接着上一讲，继续来看的。。 

registerFeignClient() 

这边一看就是在构造构造一个BeanDefiniction的东西，这个东西的话，构造的过程，其实就是用了构造器模式，这个构造器模式呢，就会将@FeignClient注解的属性以及ServiceAClient相关的东西，都放到这个BeanDefinition中去 

​          BeanDefinitionBuilder definition = BeanDefinitionBuilder

​                    .genericBeanDefinition(FeignClientFactoryBean.class); 

这行代码，非常关键：FeignClientFactoryBean，一般这种东西，都是极为关键的一个组件，就是用来创建核心的FeignClient组件的一个工厂bean 

name：@FeignClient(value = “ServiceA”)，服务名称 

attributes，大家自己回过头去看看，就是@FeignClient里面的属性，value和configuration两个属性 

AbstractBeanDefinition beanDefinition = definition.getBeanDefinition(); 

就是通过构造器模式完成了@FeignClient标注的ServiceAClient接口对应的BeanDefinition的构造的过程，成功构造出来了一个BeanDefinition，里面包含了@FeignClient注解和ServicewAClient接口相关的所有信息 

基于接口类名（ServiceAClient接口的类名），alias（ServiceAFeignClient），刚刚构造好的BeanDefinition，构造了一个BeanDefinitionHolder 

就基于BeanDefinitionRegistry和BeanDefinitionHolder，完成了BeanDefinition的注册，注册的逻辑就不要看了，走的是spring-beans项目的源码了 

很多疑问，BeanDefinition到底是啥？？？BeanDefinitionHolder到底是啥？？？BeanDefinitionRegistry到底是啥？？？ 

抓大放小，不要去卡这种细节。。。 

屁股猜想论，大胆的设想一下 ======> spring boot系统启动的时候，刚启动，就跑到这段代码里来了，这段代码，其实是在扫描包路径下的@FeignClient标注的接口都有哪些？？然后将@FeignClient注解的属性和我们自定义的ServiceAClient接口的信息封装为了BeanDefinition，注册到了一个所谓的BeanDefinitionRegistry的地方 

大胆的推测一下，其实就是在系统刚启动的时候，这里就是单纯的完成包的扫描，以及信息的解析，将这些东西存储到spring框架中去，留待后面来使用。。。 

通过那张大图的理解，下一步，其实就是应该去基于扫描出来的@FeignClient注解和ServiceAClident接口的信息，然后去创建实现ServiceAClient接口的动态代理，feign核心的动态代理，将动态代理作为一个bean，注入给ServiceBControler，然后ServiceBController后面调用的都是这个feign动态代理。。。 

你感觉，创建这个动态代理应该是在哪儿呢？？？ 

​          BeanDefinitionBuilder definition = BeanDefinitionBuilder

​                    .genericBeanDefinition(FeignClientFactoryBean.class); 

注意到了吗？FeignClientFactoryBean，一看就是靠的是这个东西作为一个工厂，在后面spring容器初始化的某个阶段，根据之前扫描出来的信息完成ServiceAClient的feign动态代理的构造。。。 

惊讶的发现，FeignClientFactoryBean中，居然保存了@FeignClient注解的所有属性的值！！！必须得有啊！因为要根据这些属性的值，来完成feign动态代理的构造。。。 

我们明显就是在FeignClientFactoryBean中，发现了一大坨构造FeignClient的代码，所以很明显是我们的推测是这样子的：前面仅仅是扫描@FeignClient和接口信息，后面其实会在FeignClientFactoryBean中，在spring容器初始化的某个过程中，调用这个工厂bean的某个方法，创建和获取到ServiceAClient对应的feign动态代理，放到spring容器中去 

后面ServiceBController就是直接注入刚才创建好的那个动态代理

### 067_先来冷静的分析一下FeignClientFactoryBean中有哪些东西和操作？ 

扫描包下面的@FeignClient的注解，以及搞完了，扫描到内存里来了，形成了BeanDefinition 

下面一步，其实就是在spring容器初始化的时候，一定是会根据扫描出来的@FeignClient的信息，去构造一个原生的feign的FeignClient出来，然后基于这个FeignClient来构造一个ServiceAClient接口的动态代理 

也就是说ServiceAClient接口调用的时候，一定是会走这个动态代理的 

FeignClientFactoryBean里面去，我们其实在这里找到了相关的一些构造FeignClient的过程 

FeignClientFactoryBean包含了@FeignClient注解中的所有的属性的值，所以肯定是根据你定义的@FeignClient注解的属性，来进行FeignClient的生成 

​     @Override

​     public void setApplicationContext(ApplicationContext context) throws BeansException {

​          this.applicationContext = context;

​     } 

比如这个东西就是无关紧要的，一看就是在注入spring容器 

​     protected Feign.Builder feign(FeignContext context) {

​          FeignLoggerFactory loggerFactory = get(context, FeignLoggerFactory.class);

​          Logger logger = loggerFactory.create(this.type); 

​          // @formatter:off

​          Feign.Builder builder = get(context, Feign.Builder.class)

​                    // required values

​                    .logger(logger)

​                    .encoder(get(context, Encoder.class))

​                    .decoder(get(context, Decoder.class))

​                    .contract(get(context, Contract.class));

​          // @formatter:on 

​          configureFeign(context, builder); 

​          return builder;

​     } 

这个方法是干什么的？？看起来直接就是再构造Feign.Builder，FeignBuilder构造好了以后，就可以基于这个Feign.Builder来构造对应的FeignClient来使用了。getObject()这个方法里，会去调用feign()方法，所以说，feign()方法肯定是被别人调用的，不是我们要找的一个入口方法 

configureFeign()方法，看着就是像是对Feign.Builder进行配置，发现这个方法是被feign()方法来调用的，更加不是入口的。两个configureUsingConfiguration()方法，这个方法的话，一看就是也是对Feign.Builder进行配置的，发现是configureFeign()方法在调用这两个方法，更加不是所谓的入口了 

getOrInstantiate()方法，也不是入口方法，居然是给configureUsingConfiguration()来调用的，人家只是拆的比较碎，比较散而已；get()方法，也是被别人调用的；getOptional()方法，也是被别人调用的，一看也不是入口方法；loadBalance()方法，也是被别人调用的，不是入口方法 

@Override

​     public Object getObject() throws Exception {

​          FeignContext context = applicationContext.getBean(FeignContext.class);

​          Feign.Builder builder = feign(context); 

​          if (!StringUtils.hasText(this.url)) {

​               String url;

​               if (!this.name.startsWith("http")) {

​                    url = "http://" + this.name;

​               }

​               else {

​                    url = this.name;

​               }

​               url += cleanPath();

​               return loadBalance(builder, context, new HardCodedTarget<>(this.type,

​                         this.name, url));

​          }

​          if (StringUtils.hasText(this.url) && !this.url.startsWith("http")) {

​               this.url = "http://" + this.url;

​          }

​          String url = this.url + cleanPath();

​          Client client = getOptional(context, Client.class);

​          if (client != null) {

​               if (client instanceof LoadBalancerFeignClient) {

​                    // not lod balancing because we have a url,

​                    // but ribbon is on the classpath, so unwrap

​                    client = ((LoadBalancerFeignClient)client).getDelegate();

​               }

​               builder.client(client);

​          }

​          Targeter targeter = get(context, Targeter.class);

​          return targeter.target(this, builder, context, new HardCodedTarget<>(

​                    this.type, this.name, url));

​     } 

这段代码，getObject()方法，引起我注意的是，@Override注解，如果有这个注解，一般是实现的接口或者父类定义的抽象方法，这种@Override的方法，一般是给别人来调用的，很可能是一个入口方法。而且这个getObject()方法，是没有人调用他的，只有他去调用别人，所以说非常可能就是一个入口方法 

也就是我们大胆的猜测一下：FeignClientFactoryBean，很可能入口方法就是getObject()方法，如果你有比较丰富的经验的话，Targeter一类的东西，一遍就代表的是动态代理。。。很可能说这个getObject()方法，就是在spring容器初始化的时候，被作为入口来调用，然后在这个里面，创建了一个ServiceAClient的动态代理，然后返回给spring容器，注册到Spring容器里去。。。。。 

然后。。。@FeignCilent标注的ServiceAClient接口，就有动态代理实现的bean了 

然后。。。这个动态代理bean就可以注入的ServiceBController里面去了。。。。

### 068_Feign.Builder的构造过程：spring cloud环境下默认组件以及配置参数

feign动态代理的构造过程

![](C:\Users\zy199005\Desktop\中华石杉\images\java\06\06801.png)   

这一讲开始的话，我们可以就是从getObject()方法作为一个入口，打上断电，来调试，看feign动态代理构造的过程，这堂课，其实就是分析一下Feign.Builder的构造过程，spring cloud环境下给feign提供的一些默认的bean组件，都有了；还有我们对feign自定义的spring cloud环境下的参数配置，都有了 

我们推测，spring容器初始化的时候，就会来调用FeignClientFactoryBean的getObject()方法 

FeignContext context = applicationContext.getBean(FeignContext.class); 

这行代码是啥意思？我们来猜测一下，屁股猜想论：FeignContext是什么呢？我给大家一个大胆的设想，ribbon吗？ribbon里面，是有个一SpringClientFactory，就是对每个服务的调用，都有一个独立的ILoadBalancer，IoadBalancer里面的IRule、IPing都是独立的组件，也就是说当时ribbon用了一个SpringclientFactory，每个服务都对应一个独立的spring容器，从那个独立的spring容器中，可以取出这个服务关联的属于自己的LoadBalancer之类的东西 

FeignContext是什么呢？我们如果要调用一个服务的话，ServiceA，那么那个服务（ServiceA）就会关联一个独立的spring容器，FeignContext（代表了一个独立的容器），关联着自己独立的一些组件，比如说独立的Logger组件，独立的Decoder组件，独立的Encoder组件，都是某个服务自己独立的 

因为对不同的服务调用的@FeignClient，都是可以自定义不同的Configuration的。。。 

给大家说一下spring cloud整合feign相关的胶水代码，之前给大家都讲过了，就在spring-cloud-netflix-core项目里，在FeignAutoConfiguration中，就定义好了一个FeignContext，这个FeignContext内部是负责来对每个服务都维护一个对应的spring容器的，这里维护一个map，就是一个服务对应一个spring容器： 

​     @Bean

​     public FeignContext feignContext() {

​          FeignContext context = new FeignContext();

​          context.setConfigurations(this.configurations);

​          return context;

​     } 

FeignLoggerFactory loggerFactory = get(context, FeignLoggerFactory.class); 

​     protected <T> T get(FeignContext context, Class<T> type) {

​          T instance = context.getInstance(this.name, type);

​          if (instance == null) {

​               throw new IllegalStateException("No bean found of type " + type + " for "

​                         \+ this.name);

​          }

​          return instance;

​     } 

比如说获取这个FeignLoggerFactory，是怎么获取的呢？？ 

使用了get()方法，干了什么呢？根据服务名称（ServiceA）去FeignContext里面去获取对应的FeignLoggerFactory，这里的逻辑，就会是根据ServiceA服务名称，先获取对应的spring容器，然后从那个spring容器中，获取自己独立的一个FeignLoggerFactory 

通过FeignLoggerFactory创建了一个Logger，这个Logger其实就是feign关联的一个记录日志的组件。。。我们有一个问题，那么默认用的是哪个FeignLoggerFactory呢？直接就在spring-cloud-netflix-core里面找到了DefaultFeignLoggerFactory。。。默认创建的是一个Slf4jLogger。。。 

Feign.Builder builder = get(context, Feign.Builder.class)，这行代码极为关键，一看这个代码，就知道，是从FeignContext中获取Feign.Builder对应的一个bean。。 

先找找XXXAutoConfiguration里面还有没有？结果在FeignAutoConfiguraiton里没找到。。。然后呢？在XXXConfiguration里再找找。。。FeignClientsConfiguration再找找，找到了两个Feign.Builder的一个实现 

一个是Hystrix相关的，另外一个是Retryer相关的 

一个是跟Hystrix熔断降级相关的一个Feign.Builder，另外一个是跟Retryer（请求超时、失败重试）相关的一个Feign.Builder 

直接断点往下走，看看创建出来的是谁？？ 

给Builder设置了logger，Slf4jLogger，设置给了Feign.Builder 

直接从FeignContext中，获取了预定义好的Encoder、Decoder、Contract，设置给了Feign.Builder。这个几个组件的默认是谁？在FeignClientsConfiguraiton中去找找：SpringEncoder、ResponseEntityDecoder、SpringMvcContract。。。 

​     @Configuration

​     @ConditionalOnClass({ HystrixCommand.class, HystrixFeign.class })

​     protected static class HystrixFeignConfiguration {

​          @Bean

​          @Scope("prototype")

​          @ConditionalOnMissingBean

​          @ConditionalOnProperty(name = "feign.hystrix.enabled", matchIfMissing = false)

​          public Feign.Builder feignHystrixBuilder() {

​               return HystrixFeign.builder();

​          }

​     } 

默认情况下的FeignBuilder，是走的是HystrixFeign.Builder，因为默认情况下，feign就是跟hystrix整合在一起使用的。。。 

configureFeign()，一看就是使用我们在application.yml中配置的参数，来设置Feign.Builder 

FeignClientPropeties一看就是在读取application.yml中的feign.client打头的一些参数，包括了connectionTimeout、readTimeout之类的参数，屁股想想，都是在初始化的时候，去读取application.yml中的参数，然后放在自己身体里。。。。 

一开始读取的application.yml中的是空，因为我们本来就什么都没配置，所以直接是全部使用的默认的参数配置；然后就是读取我们自定义的MyConfiguration中配置的一些bean，比如说Logger.Level，日志等级，我们设置为了FULL，就在这里给读出来了 

默认情况下是从不重试，请求是没有重试的 

Request.Options，请求相关的参数，connectTimeout = 10s，readTimeout = 60s，直接用默认的。。。 

请求拦截器，都是可以自定义 

applicaton.yml中，也可以配置上面的那些东西，如果配置了，会覆盖MyConfiguration中的配置，优先级更高 

​           configureUsingProperties(properties.getConfig().get(properties.getDefaultConfig()), builder);

​     configureUsingProperties(properties.getConfig().get(this.name), builder); 

第一行，是说，采用的是application.yml中针对所有feign client配置的参数；第二行，是说，针对的是当前的这个服务进行的feign client的配置，当前服务的配置优先级最高 

到这一步为止，Feign.Builder，全部完成，全部配置完毕 

下一讲，就是去看看如何用Feign.Builder构造一个FeignClient出来。。。。那是Feign的核心组件

### 069_关键组件！找一找Feign.Client用的是谁以及居然在这里就跟ribbon关联了！

feign动态代理的构造过程

![](C:\Users\zy199005\Desktop\中华石杉\images\java\06\06901.png)   

Feign.Builder，构造出来一个Feign.Client。。。。 

​          FeignContext context = applicationContext.getBean(FeignContext.class);

​          Feign.Builder builder = feign(context);

分析完了底层的源码，就是用各种默认的bean、配置的bean、配置的参数，构造了一个Feign.Builder，接下来就是基于这个Feign.Builder，还得在这个Builder里放一个Feign.Client进去。。。 

如果你在@FeignClient上，没有配置url属性，也就是你没有自己指定服务的url地址，那么就会自动跟ribbon关联起来，采用ribbon来进行负载均衡，直接就开始为ribbon来准备对应的url地址了：http://ServiceA 

你在这里，看源码，就可以看到@FeignClient注解的path属性是怎么用的 

如果你要访问的是这个ServiceA服务的某一类接口，@FeignClient(value = “ServiceA”, path = “/user”)，跟你拼接请求URL地址的时候，就会拼接成：http://ServiceA/user 

调用了loadbalance()方法，猜测一下，这个loadBalance()方法是干嘛的？？用了ribbon的支持负载均衡的这么一个东西，可能就是一个基于ribbon进行负载均衡的动态代理 

https://github.com/OpenFeign/feign 

先是构造了一个HardCodedTarget，硬编码的Target，里面包含了接口类型（com.zhss.service.ServiceAClient）、服务名称（ServiceA）、url地址（http://ServiceA），跟Feign.Builder、FeignContext，一起，传入了loadBalance()方法里去 

Feign.Client，从FeignContext里面获取Feign.Client，如何获取呢？默认定义的在哪儿呢？你如果在FeignAutoConfiguration、FeignClientsConfiguration中去找，Feign.Client，是没有的。。。屁股来想想，这边Feign一定是跟ribbon整合起来使用的，那么我们是不是应该到feign和ribbon相关的包下面去找找？ 

org.springframework.cloud.netflix.feign.ribbon 

这个包，一看就是feign和ribbon关联起来的，有关系的东西都在这里 

FeignRibbonClientAutoConfiguration，这个类，一看就是feign和ribbon整合起来的东西 

​     @Bean

​     @ConditionalOnMissingBean

​     public Request.Options feignRequestOptions() {

​          return LoadBalancerFeignClient.DEFAULT_OPTIONS;

​     } 

但是呢，遗憾的是，在这里找到的唯一有关系的，就是这个东东，Request.Options，人家用的是默认的配置，XXXAutoConfiguration找不到，那就找XXXConfiguration。。一不小心找到了三个东西： 

DefaultFeignLoadBalancedConfiguration.class

HttpClientFeignLoadBalancedConfiguration.class

OkHttpFeignLoadBalancedConfiguration.class 

那么如果出现这种情况，想都不用想，直接默认肯定是Default的，肯定是用默认的 

HttpClientFeignLoadBalancedConfiguration.class，要求的是feign.httpclient.enabled属性设置为true 

OkHttpFeignLoadBalancedConfiguration.class，要求的是feign.okhttp.enabled属性设置为true 

DefaultFeignLoadBalancedConfiguration.class，默认的是这里返回的Feign.Client 

@Configuration

class DefaultFeignLoadBalancedConfiguration {

​     @Bean

​     @ConditionalOnMissingBean

​     public Client feignClient(CachingSpringLoadBalancerFactory cachingFactory,

​                                    SpringClientFactory clientFactory) {

​          return new LoadBalancerFeignClient(new Client.Default(null, null),

​                    cachingFactory, clientFactory);

​     }

} 

默认的就是这里返回的LoadBalancerFeignClient。。。 

下集预告，下一讲直接就是，如何基于feign的核心机制，来创建接口的动态代理，Targeter

### 070_我们得仔细看看核心中的核心：针对一个接口创建feign动态代理的实现细节

feign动态代理的构造过程（3）

![](C:\Users\zy199005\Desktop\中华石杉\images\java\06\07001.png)  

如何来基于Feign.Builder和HardCodedTarget，来最终基于feign的动态代理的机制，针对一个接口创建出来动态代理呢？？？ 

所以我们现在的任务，就是要去找找Targeter 

FeignAutoConfiguration中，找到了Targeter是如何创建的，bean构造的逻辑来看的话 

如果有feign.hystrix.HystrixFeign这个类的话，那么就会构造一个HystrixTargeter出来；如果没有feign.hystrix.HystrixFeign这个类的话，那么就会构造一个DefaultTargeter出来 

feign.hystrix.HystrixFeign这个类会存在于哪里呢？？ 

我们在feign-core-9.5.0.jar里找了下，没有啊，没有这个包啊。。。 

我们想想，有没有一个feign-hystrix之类的东东？如果有的话，会不会存在那个feign.hystrix.HystrixFeign呢？？？真的找到了一个feign-hystrix-9.5.0.jar。。。所以说在classpath路径下，可以找到feign.hystrix.HystrixFeign 

所以说，在上面，绝对是用了HystrixTargeter的。。。 

​     @Configuration

​     @ConditionalOnClass(name = "feign.hystrix.HystrixFeign")

​     protected static class HystrixFeignTargeterConfiguration {

​          @Bean

​          @ConditionalOnMissingBean

​          public Targeter feignTargeter() {

​               return new HystrixTargeter();

​          }

​     } 

屁股想想都知道，HystrixTargeter一看就是用来跟feign和hystrix整合使用的，在发送请求的时候基于hystrix可以实现熔断、限流、降级 

我记混了，因为在生产环境里，我们一般都是启用feign.hystrix.enabled一定是启用的，feign一定是跟hystrix整合起来用的，结果在我们没设置这个的时候，默认的情况下，Feign.Builder用的就是feign自己原生的这个Feign.Builder，是不跟hystrix有关系的 

Map<String, MethodHandler> nameToHandler = targetToHandlersByName.apply(target); 

这行代码，极为关键，其实是基于我们配置的Contract、Encoder等一堆组件，加上Target对象（知道是ServiceAClient接口），去进行接口的所有的spring mvc的注解的解析，以及接口中各个方法的一些解析，获取了这个接口中有哪些方法？？？ 

sayHello、createUser、等等。。。。 

这里就是遍历ServiceAClient接口中的每个方法，包括sayHello()等方法，通过反射来的了 

methodToHandler.put(method, nameToHandler.get(Feign.configKey(target.type(), method))); 

将ServiceAClient接口中的每个方法，加上对应的nameToHandler中存放的对应的SynchronousMethodHandler（异步化的方法代理处理组件），放到一个map中去，methodToHandler 

nameToHandler：就是接口中的每个方法的名称，对应一个处理这个方法的SynchronousMethodHandler 

methodToHandler：就是接口中的每个方法对应的Method对象，对应一个处理这个方法的SynchronousMethodHandler 

InvocationHandler handler = factory.create(target, methodToHandler); 

这行代码，是基于一个factory工厂，创建了一个InvocationHandler，如果学习过JDK的动态代理的话，就会知道，InvocationHandler就是JDK中的动态代理 

 static final class Default implements InvocationHandlerFactory { 

  @Override

  public InvocationHandler create(Target target, Map<Method, MethodHandler> dispatch) {

   return new ReflectiveFeign.FeignInvocationHandler(target, dispatch);

  }

 } 

T proxy = (T) Proxy.newProxyInstance(target.type().getClassLoader(), new Class<?>[]{target.type()}, handler); 

这块就是核心的，基于JDK的动态代理，创建出来了一个动态代理，Proxy，这个Proxy是实现了ServiceAClient接口的 

new Class<?>[]{target.type()}，这个就是ServiceAClient接口，意思就是说，基于JDK动态代理的机制，创建一个实现了ServiceAClient接口的动态代理 

handler，InvocationHandler的意思，就是说，对上面创建的那个proxy动态代理，所有对接口方法的调用，都会走这个InvocationHandler的拦截方法，由这个InvocationHandler中的一个方法来提供所有方法的一个实现的逻辑 

JDK动态代理极其简单的一个东西，基础的东西，入门级的知识，4个月培训班儿里都会教JDK动态代理 

### 071_停一停脚步：结合feign动态代理的生成原理来画图剧透一下feign请求处理机制

feign基于动态代理处理请求的机制 

![](C:\Users\zy199005\Desktop\中华石杉\images\java\06\07101.png)   

我们已经明白了feign动态代理的机制 

那么这一讲我们结合画图来说一下，对feign动态代理进行请求的时候会干什么 

除非你在@FeignClient里配置一个url属性，指定你要访问的服务的url地址，才会走我们没看的一段源码逻辑，否则的话，直接是走loadBalance()方法来生成动态代理 

targetToHandlersByName.apply(target); 

这行代码，其实很关键，他其实是对我们定义的ServiceAClient接口进行解析，解析里面有哪些方法，然后为每个方法创建一个SynchronousMethodHandler出来，也就是说那个MethodHandler专门用来处理那个方法的请求调用 

target.type()，这个就是ServiceAClient接口 

JDK动态代理，你可以认为他动态生成了一个类，没有名字的，匿名类，这个类是实现了ServiceAClient接口，基于这个匿名的类创建了一个对象，T proxy，他就是所谓的动态代理，对这个T proxy对象所有接口方法的调用，都会交给InvocationHandler来处理

### 072_被遗忘的细节：MethodHandler创建以及Contract解析spring mvc注解

接口方法与MethodHandler映射map的生成机制

![](C:\Users\zy199005\Desktop\中华石杉\images\java\06\07201.png)   

回顾一下细节 

targetToHandlersByName，包含了Decoder、Encoder、Contract等feign的核心组件 

List<MethodMetadata> metadata = contract.parseAndValidatateMetadata(key.type()); 

key：HardCodedTarget(type=ServiceAClient, name=ServiceA, url=http://ServiceA) 

key.type()：可以获取到的就是HardCodedTarget类型 

SpringMvcContract，他是负责解析我们在接口上打的各种spring mvc的注解的，@RequestMappinng、@PathVariable、RequestParam，默认情况下，feign是不理解spring mvc的这些注解的，feign是不知道如何处理的 

所以全都靠feign的Contract组件，来解析接口上的spring mvc的注解 

List<MethodMetadata>是什么东西啊？屁股猜猜，ServiceAClient接口里的每个方法，都会被SpringMvcContract组件来解析，最后对每个方法都生成一个MethodMetadata，代表了这个方法的一些元数据 

MethodMetadata里面放了什么呢？ 

以这个deleteUser()这个接口来举例，其实获取到了方法的相关的方方面面的所有的东西 

（1）方法的定义：ServiceAClient#deleteUser(Long)

（2）方法的返回类型：class java.lang.String

（3）发送HTTP请求的模板：DELETE /user/{id} HTTP/1.1 

@RequestMapping(value = "/{id}", method = RequestMethod.DELETE)

String deleteUser(@PathVariable("id") Long id); 

我们定义的接口长的是这个样子的 

DELETE /user/{id} HTTP/1.1 

发送HTTP请求的模板，这个模板，不就是靠的是SpringMvcContract组件解析spring mvc的注解，才能解析出来这个HTTP请求的模板 

我们用屁股猜想一下： 

（1）SpringMvcContract组件的工作原理，解析@RequestMapping注解，看看里面的method属性是谁？一看发现要发送的请求方法是DELETE，所以在HTTP template里就加了一个DELETE 

（2）找到了ServiceAINterface上定义的@RequestMapping注解，解析里面的value值，就可以拿到/user，此时HTTP template变成：DELETE /user 

（3）再次解析deleteUser()方法上的@RequestMapping注解，找到里面的value，获取到/{id}，拼接到HTTP template里去：DELETE /user/{id} 

（4）直接硬编码拼死一个HTTP协议，http 1.1，HTTP template：DELETE /user/{id} HTTP/1.1 

（5）indexToName：我们猜想这个是说，解析的是@PathVariable注解，就可以知道什么呢？第一个占位符（index是0）要替换成方法入参里的id这个参数的值。。。，0 -> id 

（6）假如后面来调用这个deleteUser()方法，传递进来的id = 1.那么此时就会拿出之前解析好的HTTP template：DELETE /user/{id} HTTP/1.1。然后用传递进来的id = 1替换掉第一个占位符的值，DELETE /user/1 HTTP/1.1。。。合情合理的猜想 

基本上给大家就剖析清楚 

下一步的话呢，我们要考虑一下，SpringMvcContract他的原理，其实不出意外，就跟我上面说的是一样的，但是我们还是可以快速的看一下SpringMvcContract的源码，这里都是琐碎的代码，说白了，就是处理各种注解的，提取信息，拼接发送HTTP的请求模板template org.springframework.cloud.netflix.feign.support 

   SynchronousMethodHandler.Factory synchronousMethodHandlerFactory =

​     new SynchronousMethodHandler.Factory(client, retryer, requestInterceptors, logger,

​                        logLevel, decode404);

   ParseHandlersByName handlersByName =

​     new ParseHandlersByName(contract, options, encoder, decoder,

​                 errorDecoder, synchronousMethodHandlerFactory);

   return new ReflectiveFeign(handlersByName, invocationHandlerFactory); 

在这里，创建RefrectiveFeign的时候，就创建了一个SynchronousMethodHandler.Factory，穿进去了发送请求相关的LoadBalancerFeignClient、Retryer（负责请求重试）、请求拦截器、日志打印的东西，等等 

   return new SynchronousMethodHandler(target, client, retryer, requestInterceptors, logger,

​                     logLevel, md, buildTemplateFromArgs, options, decoder,

​                     errorDecoder, decode404); 

通过这个源码，你就可以看到，对每个方法都创建了一个对应的SynchronousMethodHandler，同步方法处理器，这个SynchronousMethodHandler里面包含了后面发送请求需要的所有的组件，LoadBalancerFeignClient、Retryer（负责请求重试）、请求拦截器、日志打印的东西，等等

### 073_初步发送一个请求来源码调试一下feign动态代理是怎么接收和处理请求的 

到了这一讲为止，我们终于把@FeignClient注解的扫描、动态代理的生成、MethodHandler的创建，这些东西已经全部捋顺了，调试了源码、分析了源码、画了大量的图，已经所有的细节都搞通了 

我们要在feign生成的动态代理里面去打一个断点，看看发送请求的时候，feign动态代理是如何接收到这个请求，以及如何处理的，先来初步的看一看 

JDK动态代理，之前已经跟大家说过很多遍了，就是说人家就是创建一个T proxy出来 

T proxy是一个匿名类的对象，这个类是动态生成的，是没有名字的，这个类是实现了ServiceAClient接口的，然后我们访问ServiceBController，都是在调用T proxy，对T proxy的调用都会交给InvocationHandler 

所以如果我们要研究动态代理是如何处理请求的，那么就在之前看到的那个InvocationHandler里面打一个断点，然后对ServiceBController发送请求。我们找到ReflectiveFeign.FeignInvocationHandler，invoke()方法 

如果我们对动态代理发起请求，都会交给FeignInvocationHandler的invoke()方法来处理，我们在invoke()方法里打一个断点，就ok，就可以接收到我们发起的所有的请求 

args：你传递进来的参数 

dispatch，methodToHandler，map，里面包含的就是每个方法名称 => MethodHandler 

找到方法对应的MethodHandler，将args参数交给他来处理请求 

RequestTemplate template = buildTemplateFromArgs.create(argv); 

args：id=1，name=张三，age=20 

你觉得这行代码在干嘛？？？ 

GET /user/sayHello/1?name=%E5%BC%A0%E4%B8%89&age=20 HTTP/1.1 

还记不记得，之前的时候，我们用SpringMvcContract解析spring mvc的注解，最终拿到的是一个什么东西？ 

GET /user/sayHello/{id} HTTP/1.1 

生成一个要访问的接口，我们之前是不是有@RequestParam注解，我们一定是基于SpringMvcContract也会去解析@RequestParam注解，将方法的入参，绑定到http请求参数里去了。。。 

GET /user/sayHello/1?name=张三&age=20 HTTP/1.1

### 074_feign处理请求的核心：LoadBalancerFeignClient的工作流程

feign处理请求的机制（1）

![](C:\Users\zy199005\Desktop\中华石杉\images\java\06\07401.png)  

  上一讲的话，我们初步源码调试了处理请求的流程 

  for (RequestInterceptor interceptor : requestInterceptors) {

   interceptor.apply(template);

} 

遍历请求拦截器，将每个请求拦截求都应用到RequestTemplate请求模板上面去，也就是让每个请求拦截器对请求进行处理 

其实就是基于RequestTemplate，创建了一个Request出来，这个Request是基于之前的那个HardCodedTarget（包含了目标请求服务信息的一个Target），处理了RequestTemplate，生成了一个Request 

http://ServiceA，是包含在HardCodedTarget中的 

LoadBalancerFeignClient，将请求的参数传入了进去，连接超时时间是10s，读超时时间是60s 

我们其实是基于LoadBalancerFeignClient完成了请求的处理和发送，在这个里面，就是肯定是将http请求发送到了对方的ServiceA的某个server上去，同时获取了response响应，下面的代码都是在处理response了 

从请求url地址中，取出来了要访问的服务的名称，ServiceA，然后将请求url中的服务名称给干掉了 

接下来基于去除了服务名称的uri地址，创建了一个适合ribbon请求 

然后又搞了一个IClientConfig，这个东西一看就是ribbon相关的一些配置 

接着就是根据服务名称，去获取对应的FeignLoadBalancer，然后初步查看这个源码，我们其实就发现了一个问题，就是在这个源码中，我们其实是创建了一个FeignLoadBalancer，然后最最重要的一点，是在FeignLoadBalancer里封装了ribbon的ILoadBalancer。。。。。 

ribbon最核心的就是ILoadBalancer，选用的是哪个，以及是如何跟eureka整合起来的 

下集预告：feign、ribbon、eureka是如何整合起来的？ 

feign用的是哪个ribbon的ILoadBalancer？ribbon的那个ILoadBalancer内部有一个ServerList是如何跟eureka整合起来去拉取注册表的？

### 075_抓紧看重点：feign又是如何与ribbon以及eureka整合起来的呢？

feign处理请求的机制（2）

![](C:\Users\zy199005\Desktop\中华石杉\images\java\06\07501.png) 

 feign是用的哪个ribbon的LoadBalancer，ribbon的那个LoadBalancer内部的ServerList有没有去eureka那儿抓注册表

我们通过源码的调试，就会发现说，feign的源码就跟之前看到的那个ribbon的源码的流程，一模一样了，其实人家ribbon的话呢，就会初始化这个ZoneAwareLoadBalancer

RibbonClientConfiguraiton，就一样的，就是初始化这个ZoneAwareLoadBalancer，内部是持有的跟eureka进行整合的DomainExtractingServerList

所以说，在spring boot启动，要去获取一个ribbon的ILoadBalancer的时候，会去获取到那个服务对应的一个独立的spring容器，从这个容器里面去获取对应的独立的ZoneAwareLoadBalancer，人家自己里面就有DomainExtractingServerList，DomainExtractingServerList这个东西自己会去eureka的注册表里去抓取服务对应的注册表，server list

答案，全部，真相大白

已经完全看到了feign、ribbon、eureka是如何整合的，ribbon的哪个ILoadBalancer，ZoneAwareLoadBalancer，就无所谓了

FeignLoadBalancer里面就封装了这个ZoneAwareLoadBalancer

下一讲，我们要看看，feign是如何基于ribbon的ZoneAwareLoadBalancer来进行负载均衡，从一个server list中选择出来一个server的？

### 076_奇怪的代码发生了：FeignLoadBalancer是如何负载均衡选择server的？

feign处理请求的机制（3）

![](C:\Users\zy199005\Desktop\中华石杉\images\java\06\07601.png)   

上一讲的 

lbClient(clientName)，其实就是去看看FeignLoadBalancer里面是什么？里面包含了一个ribbon的ZoneAwareLoadBalancer，负载均衡算法、跟eureka如何整合，都清楚了 

executeWithLoadBalancer(ribbonRequest, requestConfig).toResponse(); 

看一看，这坨东西里面是什么玩意儿？ 

LoadBalancerCommand<T> command = buildLoadBalancerCommand(request, requestConfig); 

这一块的话，大家会发现非常的奇怪，这个代码，什么玩意儿啊？一个command 

我告诉大家，XXXCommand是跟hystirx技术相关的，基于XXXCommand可以做隔离、限流、熔断、降级。。。 

这个LoadBalancerCommand刚刚创建的时候，你发现里面的server是null，就是还没确定是要对哪个server发起请求呢。。。 

屁股来猜测一下，假如说你也不懂Hystrix是什么东西，那么LoadBalancerCommand是什么呢？？？你觉得呢？大概是一个负责发送请求的一个组件吧。。。 

command.submit(

​        new ServerOperation<T>() {

​          @Override

​          public Observable<T> call(Server server) {

​            URI finalUri = reconstructURIWithServer(server, request.getUri());

​            S requestForServer = (S) request.replaceUri(finalUri);

​            try {

​              return Observable.just(AbstractLoadBalancerAwareClient.this.execute(requestForServer, requestConfig));

​            } 

​            catch (Exception e) {

​              return Observable.error(e);

​            }

​          }

​        })

​        .toBlocking()

​        .single(); 

这坨代码，来看一下，看着很蹊跷 

call()方法里面，很明显就是发送物理请求最终的一块代码，直接构造出来了具体的http请求的地址，然后呢基于底层的http通信组件，发送出去了这个请求 

ServerOperation包含了call()方法，是被提交到LoadBalancerCommand里面去的 

然后调用了一个toBlocking().single()方法，看着就是阻塞式同步执行，然后获取一个响应结果的这么一个意思 

大胆的猜测一下，估计应该是ServerOperation封装了一下，对负载均衡选择出来的这个server，然后直接基于这个server替换掉请求URL中的ServiceA，然后直接拼接出来最终的请求URL地址，然后基于底层的http组件发送请求 

由LoadBalancerCommand来执行这段逻辑，LoadBalancerCommand肯定是在某个地方先使用ribbon的ZoneAwareLoadBalancer负载均衡选择出来了一个server，然后将这个server，交给SeerverOpretion中的call()方法去处理 

我们在LoadBalancerCommand里，找到了下面一坨代码： 

private Observable<Server> selectServer() {

​    return Observable.create(new OnSubscribe<Server>() {

​      @Override

​      public void call(Subscriber<? super Server> next) {

​        try {

​          Server server = loadBalancerContext.getServerFromLoadBalancer(loadBalancerURI, loadBalancerKey);  

​          next.onNext(server);

​          next.onCompleted();

​        } catch (Exception e) {

​          next.onError(e);

​        }

​      }

​    });

} 

我们来推测一下，LoadBalancerCommand一定是在某个时机，就是去执行了上面的那段selectServer()方法，在这个方法中，就是基于我们之前搞出来的那个ribbon的ZoneAwareLoadBalancer的chooseServer()方法，通过负载均衡机制选择了一个server出来 

其实我们在LoadBalancerCommand的源码中，就可以看到，在submit()方法中，就会去调用selectServer()方法，通过ribbon负载均衡选择一个server出来 

选择了一个server出来以后，才可以去调用ServerOperation.call()方法，由call()方法根据server发送http请求 

源码层面有很多的细节，就是LoadBalancerCommand这一块，都是跟hystrix相关的，但是目前你先不用过多的关注他，我们先考虑我们自己的一些核心的逻辑就可以了，selectServer()方法来选择server，调用了ServerOperation.call()方法来对server发送请求就ok了

### 077_纠正一个讲解中的小错误：老是潜意识里把feign和hystrix混在一起  

FeignLoadBalancer的executeWithLoadBalancer()方法中 

创建了一个LoadBalancerCommand，来执行这个请求，结果我当时跟大家说的是这个Command是跟Hystrix相关的，结果我发现自己还是犯了个错误 

因为是spring cloud的早期版本里面，feign默认是启用hystrix的，另外一个，其实在生产环境中，feign一定是跟hystrix合在一起用的，所以潜意识里老是这样子 

先是基于原生的feign来讲的，跟hystrix还没整合在一起 

rx也是一个编程框架，这个东西就是独立的一个东西 

RXJava这么一个编程框架，响应式的编程框架，大量的给你实现了观察者模式的一些东西 

LoadBalancerCommand，跟hystrix半毛钱关系都没有 

你就认为，他就是一个feign自己原生实现的一个用来发送请求的一个组件

### 078_最终发出去的请求是长啥样的以及http组件是如何发送请求的呢？

feign处理请求的机制

 ![](C:\Users\zy199005\Desktop\中华石杉\images\java\06\07801.png)

 源码调试，就到了临门一脚，就差发送请求

ServerOperation.call()方法里的源码来调试一下，看看里面是怎么发送请求的

http://localhost:8080/user/sayHello/1?name=张三&age=20

我们之前讲过，LoadBalancerCommand的selectServer()方法中选择出来了一个server，然后将这个server给放到了ServerOperation.call()方法中去

在这个方法中，第一件事情，就是根据之前处理好的请求URL

GET http:///user/sayHello/1?name=张三&age=20 HTTP/1.1

加上我们选择出来的那个server的地址：localhost:8080，拼接在一起就ok了

http://localhost:8080/user/sayHello/1?name=张三&age=20，最终的请求URL地址

接着就是调用FeignLoadBalancer的execute()方法，向上面的请求URL地址发送一个http请求，这里有一个很关键的点

其实就是发送请求的超时时间，这个是极为关键的一个参数

因为你做微服务系统的时候，哪怕你不配置重试、降级，你起码得配置这个超时，你请求一个接口多久必须得超时，一遍来说我们要求任何一个接口，请求时间最好不要超过200ms，一般接口最好是在几十ms，经历了很多层服务的转发之后，用户在浏览器上发起的一个操作，一般在几百毫秒，一定给人家返回了

结果最终的在发起实际的http请求的时候，这个超时的时间，默认发现原来都是1000毫秒，也就是1秒钟

		Response response = request.client().execute(request.toRequest(), options);

这块就是在发送物理的http请求

将相应结果封装为RibbonResponse就ok了

### 079_那么feign在接收到了服务返回的响应结果之后是如何处理的呢？

feign处理请求的机制

![](C:\Users\zy199005\Desktop\中华石杉\images\java\06\07901.png)   

比如说我们发送一个请求 

GET http://localhost:8080/user/1 HTTP/1.1 

人家服务返回的是一个json，此时这个json串肯定是在哪儿呢？Response的body属性里 

​     return decode(response); 

decode方法，就是会用到我们之前所说的那个Decoder组件，来对返回的json串给他反序列化为我们指定的一个类型，默认的是ResponseEntityDecoder，用他来反序列化json串为一个user 

   return decoder.decode(response, metadata.returnType()); 

response里，包含了人家返回的一个json串：{"id":1,"name":"张三","age":20} 

metadata.returnType()：class com.zhss.demo.User 

把这两个东西交给ResponseEntityDecoder，他就会将json给转化为User对象

### 080_feign整合ribbon的连接超时以及失败重试的配置参数以及源码分析 

超时 

微服务架构的系统中，起码你得配置一个超时的时间，timeout，一个服务调用另外一个服务，你起码得有个超时的时间。总不能说服务B调用服务A，楞是等了5分钟还没返回？？？起码得设置一个时间，服务B调用服务A，最多等待1s，还没返回的话，直接就判定这次请求失败了。 

重试 

服务B，调用服务A，服务A部署了3台机器 

现在服务B通过负载均衡的算法，调用到了服务A的机器1，结果呢，因为服务A的机器1宕机了，请求超时了，服务B这个时候咋办？？？你可以让服务B再次尝试一下请求服务A的机器1，如果还是不行的话，那么可以让服务B去尝试服务A的机器2，如果还是不行，可以去尝试服务A的机器3 

超时、重试、隔离、限流、熔断、降级 

spring cloud的feign和ribbon整合的这一块儿，如果要配置超时和重试，大概是下面这样子 

spring:

 cloud:

loadbalancer:

 retry:

  enabled: true 

ribbon:

 ConnectTimeout: 1000

 ReadTimeout: 1000

 OkToRetryOnAllOperations: true

 MaxAutoRetries: 1

 MaxAutoRetriesNextServer: 3 

这些东西，他在源码层面都体现在了哪里呢？ 

FeignLoadBalancer.getRequestSpecificRetryHandler()方法中，就会读取你配置的几个参数：OkToRetryOnAllOperations、MaxAutoRetries、MaxAutoRetriesNextServer 

LoadBalancerCommand.submit()方法中，也就是在执行请求逻辑的时候，读取RetryHandler中配置的参数，会根据请求的情况，是否报错，是否报异常，进行重试的控制 

FeignLoadBalancer.execute()，发送实际的http请求的时候，就会传入你设置的超时的参数  

retry:enabled，其实是控制之前有一个组件，叫做Retryer，默认是NoRetryer，但是如果启用了那个参数之后，就会打开这个重试，会使用一个支持重试的Retryer，Retryer在两个地方有使用 

SynchronousMethodHandler.invoke()方法里面，如果抛了异常的话，也会默认根据Retryer进行重试 

源码调试 

（1）FeignLoadBalancer.getRequestSpecificRetryHandler()，打一个断点，看看几个参数是否被读取

（2）LoadBalancerCommand.submit()，打一些断点，我们要模拟出来，某个server他是宕机的情况，然后让他去重试

（3）模拟ServiceA某个机器上的接口响应时间超时，测试我们的超时时间

（4）超时之后，就报异常，然后就进行重试，同样的一台机器，重试1次不行，就开始尝试其他的机器 

ServiceA在8080 端口启动的实例，sayHello()接口会延迟5秒钟；在8088端口启动的实例，是好的，sayHello()接口是没有延迟的 

直接请求进来 

（1）FeignLoadBalancer.getRequestSpecificRetryHandler()：就是在读取我们配置的重试的参数，okToRetryOnAllErrors和okToRetryOnConnectErrors设置为true生效了，retrySameServer设置为1，retryNextServer设置为3 

（2）LoadBalancerCommand.submit()：maxRetrysSame和maxRetrysNext都是我们之前设置的1和3 

（3）FeignLoadBalancer.execute()方法中，发起请求的超时时间，都是1000毫秒，就是我们设置的 

（4）第一次负载均衡是请求8088端口，所以肯定是不会超时的 

（5）第二次负载均衡就是请求8080端口，很明显出问题了，就是说，请求超时了，1秒钟没有返回结果直接就超时了 

（6）超时之后，就会跳入那个LoadBalancerCommand.retryPolicy()的一个方法中，判断是否要进行重试，重试次数是否大于设置的retrySameServer，第一次重试肯定是1=1，不是1>1，RequestSpecificRetryHandler.isRetriableException()，判断当前出现的这个问题，是否需要重试，此时只要你设置了okToRetryOnAllErrors这个参数是true，全部会认为是要进行重试的 

（7）发现直接LoadBalancerCommand自动给你进行重试了，自动执行ServerOperation.call()方法，重试的还是8080这台机器，发现再次超时，又开始判断是否要进行重试，但是此时tryCount是2，trySameServer是1，也就是说我们设置的是最多同一台机器重试1次，但是此时已经到第二次重试了，此时会判断不要再重试这台机器了 

（8）直接代码会进到LoadBalancerCommand的判断是否要重试其他机器的代码里，此时会判断是否要重试其他机器，肯定是可以重试其他机器的 

（9）此时又进入了ServerOption.call()方法，发现此时重试的所谓的其他机器，还是8080这台机器，此时肯定还是超时，又会去判断是否要重试，retryPolicy()方法中。如果开始重试其他机器了，第一次还是在重试当前这台机器 

（10）此时你会觉得非常的离奇，你会很尴尬，你说，咋整的？我告诉你，这个就是所谓的源码出真知，必须在源码里看那些参数是怎么用的 

（11）然后第二次重试其他机器的时候，就会去重试8088机器了，此时就ok了 

总结一下： 

MaxAutoRetries: 1

MaxAutoRetriesNextServer: 3 

比如你请求8080机器，第一次超时或者报错了，重试1次，再次请求1次 

如果第二次请求，还是超时或者报错的话，那么就会尝试其他的机器，比如说8088 

但是第一次尝试其他机器的时候，其实还是访问的是8080，而且对8080是访问1次，重试1次，如果还是不行，尝试下一台机器 

此时才会尝试8088这台机器 

你可以多搞几台机器试一试，8088还是不行，会去尝试下一台，留个作业，ServiceA启动5个实例，然后就用上面两个参数去试一下 

打招呼，id=1, name=张三, age=20

进入漫长的等待。。。。。。。。

业务逻辑处理完毕。。。。。。。。

2018-06-15 11:19:00.166 INFO 35440 --- [trap-executor-0] c.n.d.s.r.aws.ConfigClusterResolver   : Resolving eureka endpoints via configuration

打招呼，id=1, name=张三, age=20

进入漫长的等待。。。。。。。。

业务逻辑处理完毕。。。。。。。。

2018-06-15 11:24:00.167 INFO 35440 --- [trap-executor-0] c.n.d.s.r.aws.ConfigClusterResolver   : Resolving eureka endpoints via configuration

打招呼，id=1, name=张三, age=20

进入漫长的等待。。。。。。。。

业务逻辑处理完毕。。。。。。。。

2018-06-15 11:29:00.167 INFO 35440 --- [trap-executor-0] c.n.d.s.r.aws.ConfigClusterResolver   : Resolving eureka endpoints via configuration

打招呼，id=1, name=张三, age=20

进入漫长的等待。。。。。。。。

业务逻辑处理完毕。。。。。。。。 

OkToRetryOnAllOperations: true

这个参数的意思，就是无论是请求的时候有什么异常，超时、报错，都会触发重试 

spring:

 cloud:

loadbalancer:

 retry:

  enabled: true 

你如果去网上或者一些书上去看的话，重试这开，网上和书上没有一个地方是说清楚的，我觉得国内，就在feign这块，重试机制这块，只有我们的这个feign的这个源码的课程的最后一讲，结合源码来调试，才搞清楚了，feign的这些重试相关的参数的使用 

很多人都会告诉你，必须得启用上面那坨东西，才可以启用feign的重试机制，其实不是，没关系，但是我给你看下这个东西是用来干嘛的就可以了 

ServiceA在请求的时候，我们比如要对某个server发起这个请求，直接将那个server的实例给停掉，发起请求的时候一定是访问不通的 

我一般现在的习惯，都是直接看静态源码，就是不调试，因为很多时候，你在线上如果发现了问题以后，你在自己本地，要调试出来，要模拟一个环境，很难很难 

结果这次突然之间进ok了 

哪怕是你没有设置重试，但是如果ServiceA的两个实例都是设置了5秒的延迟，我们能看到他自动也会在一台机器请求超时了，会去找另外一台机器，如果也超时，此时就会认为失败了。。。 

此时就会报错 

2018-06-15 11:53:10.609 DEBUG 34852 --- [io-9090-exec-10] com.zhss.service.ServiceAClient      : [ServiceAClient#sayHello] <--- ERROR SocketTimeoutException: Read timed out (3086ms)

2018-06-15 11:53:10.639 DEBUG 34852 --- [io-9090-exec-10] com.zhss.service.ServiceAClient     : [ServiceAClient#sayHello] java.net.SocketTimeoutException: Read timed out

​     at java.net.SocketInputStream.socketRead0(Native Method)

​     at java.net.SocketInputStream.socketRead(SocketInputStream.java:116)

​     at java.net.SocketInputStream.read(SocketInputStream.java:171)

​     at java.net.SocketInputStream.read(SocketInputStream.java:141)

​     at java.io.BufferedInputStream.fill(BufferedInputStream.java:246)

​     at java.io.BufferedInputStream.read1(BufferedInputStream.java:286)

​     at java.io.BufferedInputStream.read(BufferedInputStream.java:345)

​     at sun.net.www.http.HttpClient.parseHTTPHeader(HttpClient.java:735)

​     at sun.net.www.http.HttpClient.parseHTTP(HttpClient.java:678)

​     at sun.net.www.protocol.http.HttpURLConnection.getInputStream0(HttpURLConnection.java:1587)

​     at sun.net.www.protocol.http.HttpURLConnection.getInputStream(HttpURLConnection.java:1492)

​     at java.net.HttpURLConnection.getResponseCode(HttpURLConnection.java:480)

​     at feign.Client$Default.convertResponse(Client.java:152)

​     at feign.Client$Default.execute(Client.java:74)

​     at org.springframework.cloud.netflix.feign.ribbon.FeignLoadBalancer.execute(FeignLoadBalancer.java:80)

​     at org.springframework.cloud.netflix.feign.ribbon.FeignLoadBalancer.execute(FeignLoadBalancer.java:48)

​     at com.netflix.client.AbstractLoadBalancerAwareClient$1.call(AbstractLoadBalancerAwareClient.java:104)

​     at com.netflix.loadbalancer.reactive.LoadBalancerCommand$3$1.call(LoadBalancerCommand.java:303)

​     at com.netflix.loadbalancer.reactive.LoadBalancerCommand$3$1.call(LoadBalancerCommand.java:287)

​     at rx.internal.util.ScalarSynchronousObservable$3.call(ScalarSynchronousObservable.java:231)

​     at rx.internal.util.ScalarSynchronousObservable$3.call(ScalarSynchronousObservable.java:228)

​     at rx.Observable.unsafeSubscribe(Observable.java:10151)

​     at rx.internal.operators.OnSubscribeConcatMap$ConcatMapSubscriber.drain(OnSubscribeConcatMap.java:286)

​     at rx.internal.operators.OnSubscribeConcatMap$ConcatMapSubscriber.onNext(OnSubscribeConcatMap.java:144)

​     at com.netflix.loadbalancer.reactive.LoadBalancerCommand$1.call(LoadBalancerCommand.java:185)

​     at com.netflix.loadbalancer.reactive.LoadBalancerCommand$1.call(LoadBalancerCommand.java:180)

​     at rx.Observable.unsafeSubscribe(Observable.java:10151)

​     at rx.internal.operators.OnSubscribeConcatMap.call(OnSubscribeConcatMap.java:94)

​     at rx.internal.operators.OnSubscribeConcatMap.call(OnSubscribeConcatMap.java:42)

​     at rx.Observable.unsafeSubscribe(Observable.java:10151)

​     at rx.internal.operators.OperatorRetryWithPredicate$SourceSubscriber$1.call(OperatorRetryWithPredicate.java:127)

​     at rx.internal.schedulers.TrampolineScheduler$InnerCurrentThreadScheduler.enqueue(TrampolineScheduler.java:73)

​     at rx.internal.schedulers.TrampolineScheduler$InnerCurrentThreadScheduler.schedule(TrampolineScheduler.java:52)

​     at rx.internal.operators.OperatorRetryWithPredicate$SourceSubscriber.onNext(OperatorRetryWithPredicate.java:79)

​     at rx.internal.operators.OperatorRetryWithPredicate$SourceSubscriber.onNext(OperatorRetryWithPredicate.java:45)

​     at rx.internal.util.ScalarSynchronousObservable$WeakSingleProducer.request(ScalarSynchronousObservable.java:276)

​     at rx.Subscriber.setProducer(Subscriber.java:209)

​     at rx.internal.util.ScalarSynchronousObservable$JustOnSubscribe.call(ScalarSynchronousObservable.java:138)

​     at rx.internal.util.ScalarSynchronousObservable$JustOnSubscribe.call(ScalarSynchronousObservable.java:129)

​     at rx.internal.operators.OnSubscribeLift.call(OnSubscribeLift.java:48)

​     at rx.internal.operators.OnSubscribeLift.call(OnSubscribeLift.java:30)

​     at rx.internal.operators.OnSubscribeLift.call(OnSubscribeLift.java:48)

​     at rx.internal.operators.OnSubscribeLift.call(OnSubscribeLift.java:30)

​     at rx.internal.operators.OnSubscribeLift.call(OnSubscribeLift.java:48)

​     at rx.internal.operators.OnSubscribeLift.call(OnSubscribeLift.java:30)

​     at rx.Observable.subscribe(Observable.java:10247)

​     at rx.Observable.subscribe(Observable.java:10214)

​     at rx.observables.BlockingObservable.blockForSingle(BlockingObservable.java:444)

​     at rx.observables.BlockingObservable.single(BlockingObservable.java:341)

​     at com.netflix.client.AbstractLoadBalancerAwareClient.executeWithLoadBalancer(AbstractLoadBalancerAwareClient.java:112)

​     at org.springframework.cloud.netflix.feign.ribbon.LoadBalancerFeignClient.execute(LoadBalancerFeignClient.java:63)

​     at feign.SynchronousMethodHandler.executeAndDecode(SynchronousMethodHandler.java:97)

​     at feign.SynchronousMethodHandler.invoke(SynchronousMethodHandler.java:76)

​     at feign.ReflectiveFeign$FeignInvocationHandler.invoke(ReflectiveFeign.java:103)

​     at com.sun.proxy.$Proxy82.sayHello(Unknown Source)

​     at com.zhss.service.ServiceBController.greeting(ServiceBController.java:36)

​     at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)

​     at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)

​     at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)

​     at java.lang.reflect.Method.invoke(Method.java:498)

​     at org.springframework.web.method.support.InvocableHandlerMethod.doInvoke(InvocableHandlerMethod.java:205)

​     at org.springframework.web.method.support.InvocableHandlerMethod.invokeForRequest(InvocableHandlerMethod.java:133)

​     at org.springframework.web.servlet.mvc.method.annotation.ServletInvocableHandlerMethod.invokeAndHandle(ServletInvocableHandlerMethod.java:97)

​     at org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.invokeHandlerMethod(RequestMappingHandlerAdapter.java:827)

​     at org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.handleInternal(RequestMappingHandlerAdapter.java:738)

​     at org.springframework.web.servlet.mvc.method.AbstractHandlerMethodAdapter.handle(AbstractHandlerMethodAdapter.java:85)

​     at org.springframework.web.servlet.DispatcherServlet.doDispatch(DispatcherServlet.java:967)

​     at org.springframework.web.servlet.DispatcherServlet.doService(DispatcherServlet.java:901)

​     at org.springframework.web.servlet.FrameworkServlet.processRequest(FrameworkServlet.java:970)

​     at org.springframework.web.servlet.FrameworkServlet.doGet(FrameworkServlet.java:861)

​     at javax.servlet.http.HttpServlet.service(HttpServlet.java:635)

​     at org.springframework.web.servlet.FrameworkServlet.service(FrameworkServlet.java:846)

​     at javax.servlet.http.HttpServlet.service(HttpServlet.java:742)

​     at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:231)

​     at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166)

​     at org.apache.tomcat.websocket.server.WsFilter.doFilter(WsFilter.java:52)

​     at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193)

​     at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166)

​     at org.springframework.web.filter.RequestContextFilter.doFilterInternal(RequestContextFilter.java:99)

​     at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107)

​     at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193)

​     at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166)

​     at org.springframework.web.filter.HttpPutFormContentFilter.doFilterInternal(HttpPutFormContentFilter.java:109)

​     at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107)

​     at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193)

​     at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166)

​     at org.springframework.web.filter.HiddenHttpMethodFilter.doFilterInternal(HiddenHttpMethodFilter.java:81)

​     at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107)

​     at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193)

​     at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166)

​     at org.springframework.web.filter.CharacterEncodingFilter.doFilterInternal(CharacterEncodingFilter.java:197)

​     at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107)

​     at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193)

​     at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166)

​     at org.apache.catalina.core.StandardWrapperValve.invoke(StandardWrapperValve.java:198)

​     at org.apache.catalina.core.StandardContextValve.invoke(StandardContextValve.java:96)

​     at org.apache.catalina.authenticator.AuthenticatorBase.invoke(AuthenticatorBase.java:496)

​     at org.apache.catalina.core.StandardHostValve.invoke(StandardHostValve.java:140)

​     at org.apache.catalina.valves.ErrorReportValve.invoke(ErrorReportValve.java:81)

​     at org.apache.catalina.core.StandardEngineValve.invoke(StandardEngineValve.java:87)

​     at org.apache.catalina.connector.CoyoteAdapter.service(CoyoteAdapter.java:342)

​     at org.apache.coyote.http11.Http11Processor.service(Http11Processor.java:803)

​     at org.apache.coyote.AbstractProcessorLight.process(AbstractProcessorLight.java:66)

​     at org.apache.coyote.AbstractProtocol$ConnectionHandler.process(AbstractProtocol.java:790)

​     at org.apache.tomcat.util.net.NioEndpoint$SocketProcessor.doRun(NioEndpoint.java:1468)

​     at org.apache.tomcat.util.net.SocketProcessorBase.run(SocketProcessorBase.java:49)

​     at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)

​     at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)

​     at org.apache.tomcat.util.threads.TaskThread$WrappingRunnable.run(TaskThread.java:61)

​     at java.lang.Thread.run(Thread.java:748) 

at org.springframework.cloud.netflix.feign.ribbon.FeignLoadBalancer.execute(FeignLoadBalancer.java:80) 

这块这个类，是不是很熟悉，就是最终发送请求，就是在FeignLoadBalancer中发的，报错也是在这里报出来的 

ServiceB中去掉重试的配置，保留超时的配置，期望的是接口调用超时 

feign-core项目的SynchronousMethodHandler，打断点 

如果一旦说，整个哪怕上面的所有的重试都没生效，请求都失败了，就会报错，就会进入SynchronousMethodHandler的try catch中，去处理这个异常 

此时就会调用一个retryer的方法，这个retryer默认情况下是不重试的，但是如果你开启了这坨东西： 

spring:

 cloud:

loadbalancer:

 retry:

  enabled: true 

那么此时retryer就会工作，就默认的feign的重试机制 

源码出真知，一调试源码，发现我又记错了一个细节，LoadBalancerCommand当成hystrix的东西，人的脑子里会有一些惯性和错觉，spring cloud版本也一直在变，参数也一直在变，可能确实有的时候会记错一些东西 

​     @Bean

​     public Retryer feignRetryer() {

​          return new Retryer.Default();

​     } 

启用你自定义的一个Retryer，feign的Retryer才可以，默认情况下是没有重试，NO_RETRY，直接是报错 

人家Retryer.DEFAULT，默认是自动重试5次，每次重试的时候，会停留一段时间，这里是150ms，就会重试一次 

每次重试，都会依次访问ServiceA的每台机器，每台机器都会发现是超时了，再次休眠225ms，再次重试，每次重试的时间都是不一样的，都会不断的增加 

依次循环往复，来这么个5次，休眠时间变成了337ms 

feign的retryer，其实是需要自己去自定义的，跟我们上面说的那坨参数的重试之间的关系是什么呢？ 

ribbon:

 ConnectTimeout: 1000

 ReadTimeout: 1000

 OkToRetryOnAllOperations: true

 MaxAutoRetries: 1

 MaxAutoRetriesNextServer: 3 

其实他们俩没关系，各重试各的，LoadBalancerCommand里面会去进行各种重试 

自定义Retryer的话，在SynchronousMethodHandler层面，执行LoadBalancerCommand里面会去进行各种重试，如果还是不行个，就会到SynchronousMethodHandler层面去进行这么一个重试，最多又会重试5轮 

我们就发现说，如果去掉了下面那坨配置，就会发现说，ServiceA的每个服务实例，都反复请求了6次，然后才会报错 

spring:

 cloud:

loadbalancer:

 retry:

  enabled: true

如果加上了上面的那段配置之后，就会发现说，是ServiceA的每个服务实例，都会请求1次，然后就会报错，然后就会走feign的Retryer的重试机制  

我们后面在讲spring cloud技术运用到项目里去的时候，还会做大量的测试，验证，然后才会确定生产项目的各种参数如何来配置 

spring:

 cloud:

loadbalancer:

 retry:

  enabled: true 

ribbon:

 ConnectTimeout: 1000

 ReadTimeout: 1000

 OkToRetryOnAllOperations: true

 MaxAutoRetries: 1

 MaxAutoRetriesNextServer: 3 

Retryer 

外层的这个Retryer到底有没有必要。。。。 

我们生产环境里面，外层的Retryer一般不用，我们其实就是针对某个服务实例发起的请求的时候，配置超时+报错，自己配置重试的策略

### 081_解释一下netflix hystrix的学习为什么采用龙果的公开课

hystrix是干嘛的

![](C:\Users\zy199005\Desktop\中华石杉\images\java\06\08101.png)   

spring cloud三个组件：eureka（服务注册与发现），ribbon（客户端负载均衡），feign（声明式服务调用），下一个要学习的组件，就是hystrix 

科普一下，hystrix是干嘛的，有一堆服务 

隔离、熔断、降级 

备用方案 

hystrix本身其实是netflix开源的 

netflix hystrix原生的技术本身的学习课程 

直接采用我之前录制过的一个课程，大家直接看就ok了

### 082_在电商详情页背景下的hystrix高可用技术实战的课程介绍

### 083_hystrix与高可用系统架构：资源隔离+限流+熔断+降级+运维监控

前半部分，专注在高并发这一块，缓存架构，承载高并发，在各种高并发导致的令人崩溃/异常的场景下，运行着

缓存架构，高可用性，在各种系统的各个地方有乱七八糟的异常和故障的情况下，整套缓存系统还能继续健康的run着

HA，HAProxy，主备服务间的切换，这就做到了高可用性，主备实例，多冗余实例，高可用最最基础的东西

什么样的情况下，可能会导致系统的崩溃，以及系统不可用，针对各种各样的一些情况，然后我们用什么技术，去保护整个系统处于高可用的一个情况下

1、hystrix是什么？

netflix（国外最大的类似于，爱奇艺，优酷）视频网站，五六年前，也是，感觉自己的系统，整个网站，经常出故障，可用性不太高

有时候一些vip会员不能支付，有时候看视频就卡顿，看不了视频。。。

影响公司的收入。。。

五六年前，netflix，api team，提升高可用性，开发了一个框架，类似于spring，mybatis，hibernate，等等这种框架

高可用性的框架，hystrix

hystrix，框架，提供了高可用相关的各种各样的功能，然后确保说在hystrix的保护下，整个系统可以长期处于高可用的状态，100%，99.99999%

最理想的状况下，软件的故障，就不应该说导致整个系统的崩溃，服务器硬件的一些故障，服务的冗余

唯一有可能导致系统彻底崩溃，就是类似于之前，支付宝的那个事故，工人施工，挖断了电缆，导致几个机房都停电

不可用，和产生一些故障或者bug的区别

2、高可用系统架构

资源隔离、限流、熔断、降级、运维监控

资源隔离：让你的系统里，某一块东西，在故障的情况下，不会耗尽系统所有的资源，比如线程资源

我实际的项目中的一个case，有一块东西，是要用多线程做一些事情，小伙伴做项目的时候，没有太留神，资源隔离，那块代码，在遇到一些故障的情况下，每个线程在跑的时候，因为那个bug，直接就死循环了，导致那块东西启动了大量的线程，每个线程都死循环

最终导致我的系统资源耗尽，崩溃，不工作，不可用，废掉了

资源隔离，那一块代码，最多最多就是用掉10个线程，不能再多了，就废掉了，限定好的一些资源

限流：高并发的流量涌入进来，比如说突然间一秒钟100万QPS，废掉了，10万QPS进入系统，其他90万QPS被拒绝了

熔断：系统后端的一些依赖，出了一些故障，比如说mysql挂掉了，每次请求都是报错的，熔断了，后续的请求过来直接不接收了，拒绝访问，10分钟之后再尝试去看看mysql恢复没有

降级：mysql挂了，系统发现了，自动降级，从内存里存的少量数据中，去提取一些数据出来

运维监控：监控+报警+优化，各种异常的情况，有问题就及时报警，优化一些系统的配置和参数，或者代码

3、如何讲解这块内容？

（1）如何将eshop-cache，核心的缓存服务改造成高可用的架构
（2）hystrix中的一部分内容，单拉出来，做成一个免费的小课程，作为福利发放出去
（3）eshop-cache，写代码，eshop-cache-ha，业务场景，跟之前衔接起来，重新去写代码
（4）hystrix做服务高可用这一块的内容，讲解成只有一个业务背景，重新写代码，独立


eshop-cache，在各级缓存数据都失效的情况下，会重新从源系统中调用接口，依赖源系统去查询mysql数据库去重新获取数据

如果你的各种依赖的服务有了故障，那么很可能会导致你的系统不可用

hystrix对系统进行各种高可用性的系统加固，来应对各种不可用的情况


缓存雪崩那一块去讲解，redis肯定挂，mysql有较大概率挂掉，在风雨飘摇中

我之前做的一个项目，我们多个项目都用了公司里公用的缓存的存储，缓存彻底挂了，雪崩了，导致各种业务系统全部崩溃，崩溃了好几个小时

导致公司损失了大量的资金的损失

其中导致公司损失最大的负责人，受到了很大的处分 

### 084_hystrix要解决的分布式系统可用性问题以及其设计原则

什么是分布式系统以及其中的故障和hystrix

![](C:\Users\zy199005\Desktop\中华石杉\images\java\06\08401.png)  

依赖服务的故障导致服务被拖垮以及故障的蔓延

![](C:\Users\zy199005\Desktop\中华石杉\images\java\06\08402.png) 

资源隔离如何保护依赖服务的故障不要拖垮整个系统 

![](C:\Users\zy199005\Desktop\中华石杉\images\java\06\08403.png) 

 高可用性这个topic，然后咱们会用几讲的时间来讲解一下如何用hystrix，来构建高可用的服务的架构

咱们会用一个真实的项目背景，作为业务场景，来带出来在这个特定的业务场景下，可能会产生哪些各种各样的可用性的一些问题

针对这些问题，我们用hystrix的解决方案和原理是什么

带着大家，纯手工将所有的服务的高可用架构的代码，全部纯手工自己敲出来

形成高可用服务架构的项目实战的一个课程

1、Hystrix是什么？

在分布式系统中，每个服务都可能会调用很多其他服务，被调用的那些服务就是依赖服务，有的时候某些依赖服务出现故障也是很正常的。

Hystrix可以让我们在分布式系统中对服务间的调用进行控制，加入一些调用延迟或者依赖故障的容错机制。

Hystrix通过将依赖服务进行资源隔离，进而组织某个依赖服务出现故障的时候，这种故障在整个系统所有的依赖服务调用中进行蔓延，同时Hystrix还提供故障时的fallback降级机制

总而言之，Hystrix通过这些方法帮助我们提升分布式系统的可用性和稳定性

2、Hystrix的历史

hystrix，就是一种高可用保障的一个框架，类似于spring（ioc，mvc），mybatis，activiti，lucene，框架，预先封装好的为了解决某个特定领域的特定问题的一套代码库

框架，用了框架之后，来解决这个领域的特定的问题，就可以大大减少我们的工作量，提升我们的工作质量和工作效率，框架

hystrix，高可用性保障的一个框架

Netflix（可以认为是国外的优酷或者爱奇艺之类的视频网站），API团队从2011年开始做一些提升系统可用性和稳定性的工作，Hystrix就是从那时候开始发展出来的。

在2012年的时候，Hystrix就变得比较成熟和稳定了，Netflix中，除了API团队以外，很多其他的团队都开始使用Hystrix。

时至今日，Netflix中每天都有数十亿次的服务间调用，通过Hystrix框架在进行，而Hystrix也帮助Netflix网站提升了整体的可用性和稳定性

3、初步看一看Hystrix的设计原则是什么？

hystrix为了实现高可用性的架构，设计hystrix的时候，一些设计原则是什么？？？

（1）对依赖服务调用时出现的调用延迟和调用失败进行控制和容错保护
（2）在复杂的分布式系统中，阻止某一个依赖服务的故障在整个系统中蔓延，服务A->服务B->服务C，服务C故障了，服务B也故障了，服务A故障了，整套分布式系统全部故障，整体宕机
（3）提供fail-fast（快速失败）和快速恢复的支持
（4）提供fallback优雅降级的支持
（5）支持近实时的监控、报警以及运维操作

调用延迟+失败，提供容错
阻止故障蔓延
快速失败+快速恢复
降级
监控+报警+运维

完全描述了hystrix的功能，提供整个分布式系统的高可用的架构

4、Hystrix要解决的问题是什么？

在复杂的分布式系统架构中，每个服务都有很多的依赖服务，而每个依赖服务都可能会故障

如果服务没有和自己的依赖服务进行隔离，那么可能某一个依赖服务的故障就会拖垮当前这个服务

举例来说，某个服务有30个依赖服务，每个依赖服务的可用性非常高，已经达到了99.99%的高可用性

那么该服务的可用性就是99.99%的30次方，也就是99.7%的可用性

99.7%的可用性就意味着3%的请求可能会失败，因为3%的时间内系统可能出现了故障不可用了

对于1亿次访问来说，3%的请求失败，也就意味着300万次请求会失败，也意味着每个月有2个小时的时间系统是不可用的

在真实生产环境中，可能更加糟糕

上面也就是说，即使你每个依赖服务都是99.99%高可用性，但是一旦你有几十个依赖服务，还是会导致你每个月都有几个小时是不可用的

画图分析说，当某一个依赖服务出现了调用延迟或者调用失败时，为什么会拖垮当前这个服务？以及在分布式系统中，故障是如何快速蔓延的？

5、再看Hystrix的更加细节的设计原则是什么？

（1）阻止任何一个依赖服务耗尽所有的资源，比如tomcat中的所有线程资源
（2）避免请求排队和积压，采用限流和fail fast来控制故障
（3）提供fallback降级机制来应对故障
（4）使用资源隔离技术，比如bulkhead（舱壁隔离技术），swimlane（泳道技术），circuit breaker（短路技术），来限制任何一个依赖服务的故障的影响
（5）通过近实时的统计/监控/报警功能，来提高故障发现的速度
（6）通过近实时的属性和配置热修改功能，来提高故障处理和恢复的速度
（7）保护依赖服务调用的所有故障情况，而不仅仅只是网络故障情况

调用这个依赖服务的时候，client调用包有bug，阻塞，等等，依赖服务的各种各样的调用的故障，都可以处理

6、Hystrix是如何实现它的目标的？

（1）通过HystrixCommand或者HystrixObservableCommand来封装对外部依赖的访问请求，这个访问请求一般会运行在独立的线程中，资源隔离
（2）对于超出我们设定阈值的服务调用，直接进行超时，不允许其耗费过长时间阻塞住。这个超时时间默认是99.5%的访问时间，但是一般我们可以自己设置一下
（3）为每一个依赖服务维护一个独立的线程池，或者是semaphore，当线程池已满时，直接拒绝对这个服务的调用
（4）对依赖服务的调用的成功次数，失败次数，拒绝次数，超时次数，进行统计
（5）如果对一个依赖服务的调用失败次数超过了一定的阈值，自动进行熔断，在一定时间内对该服务的调用直接降级，一段时间后再自动尝试恢复
（6）当一个服务调用出现失败，被拒绝，超时，短路等异常情况时，自动调用fallback降级机制
（7）对属性和配置的修改提供近实时的支持

画图分析，对依赖进行资源隔离后，如何避免依赖服务调用延迟或失败导致当前服务的故障

### 085_电商网站的商品详情页缓存服务业务背景以及框架结构说明

小型电商网站的静态化方案

![](C:\Users\zy199005\Desktop\中华石杉\images\java\06\08501.png) 

大型电商网站的详情页系统的架构 

![](C:\Users\zy199005\Desktop\中华石杉\images\java\06\08502.png) 

 我们这个课程，基于hystrix，如何来构建高可用的分布式系统的架构，项目实战

模拟真实业务的这么一个小型的项目，来全程贯穿，用这个项目中的业务场景去一个一个的讲解hystrix高可用的每个技术

纯讲hystrix，脱离实际的业务背景，听起来有点枯燥，大家学完了hystrix以后，可能没法完全感受到技术是如何融入我们的项目中的

大背景：电商网站，首页，商品详情页，搜索结果页，广告页，促销活动，购物车，订单系统，库存系统，物流系统

小背景：商品详情页，如何用最快的结果将商品数据填充到一个页面中，然后将页面显示出来

分布式系统：商品详情页，缓存服务，+底层源数据服务，商品信息服务，店铺信息服务，广告信息服务，推荐信息服务，综合起来组成一个分布式的系统

1、电商网站的商品详情页系统架构

（1）小型电商网站的商品详情页系统架构（不是我们要讲解的）

（2）大型电商网站的商品详情页系统架构

（3）页面模板

举个例子

将数据动态填充/渲染到一个html模板中，是什么意思呢？

<html>
	<title>#{name}的页面</title>
	<body>
		商品的价格是：#{price}
		商品的介绍：#{description}
	</body>
</html>

上面这个就可以认为是一个页面模板，里面的很多内容是不确定的，#{name}，#{price}，#{description}，这都是一些模板脚本，不确定里面的值是什么？

将数据填充/渲染到html模板中，是什么意思呢？

{
	"name": "iphone7 plus（玫瑰金+32G）",
	"price": 5599.50
	"description": "这个手机特别好用。。。。。。"
}

<html>
	<title>iphone7 plus（玫瑰金+32G）的页面</title>
	<body>
		商品的价格是：5599.50
		商品的介绍：这个手机特别好用。。。。。。
	</body>
</html>

上面这个就是一份填充好数据的一个html页面

2、缓存服务

缓存服务，订阅一个MQ的消息变更，如果有消息变更的话，那么就会发送一个网络请求，调用一个底层的对应的源数据服务的接口，去获取变更后的数据

将获取到的变更后的数据填充到分布式的redis缓存中去

高可用这一块儿，最可能出现说可用性不高的情况，是什么呢？就是说，在接收到消息之后，可能在调用各种底层依赖服务的接口时，会遇到各种不稳定的情况

比如底层服务的接口调用超时，200ms，2s都没有返回; 底层服务的接口调用失败，比如说卡了500ms之后，返回一个报错

在分布式系统中，对于这种大量的底层依赖服务的调用，就可能会出现各种可用性的问题，一旦没有处理好的话

可能就会导致缓存服务自己本身会挂掉，或者故障掉，就会导致什么呢？不可以对外提供服务，严重情况下，甚至会导致说整个商品详情页显示不出来

缓存服务接收到变更消息后，去调用各个底层依赖服务时的高可用架构的实现

我们刚才讲解的整套大型电商网站的商品详情页的缓存架构，完整的那个流程，《亿级流量电商详情页系统的大型高并发与高可用缓存架构实战》

3、框架结构

围绕着缓存服务去拉取各种底层的源数据服务的数据，调用其接口时，可能出现的系统不可用的问题

从简

spring boot，微服务的非常快速，非常好用的技术框架，脱胎于spring，具体的东西就不讲解，直接带着大家上手搭建一个spring boot的框架

2个服务，缓存服务，商品服务，缓存服务依赖于商品服务

模拟各种商品服务可能接口调用时出现的各种问题，导致系统不可用的场景，然后用hystrix完整的各种技术点全部贯穿在里面

解决了一大堆设计业务背景下的系统不可用问题，hystrix整个技术体系，知识体系，也就讲解完了

消息队列，redis，咱们都不搞了

分布式系统，微服务，dubbo，不用dubbo，目前比较明显的一个趋势是，行业里，未来主要还是spring boot，spring cloud，主流的开源技术，去构建微服务的分布式系统

基于dubbo，官方很久之前就停止更新了，支持也不是太好

spring boot + http client + hystrix

### 086_基于spring boot快速构建缓存服务以及商品服务

1、pom.xml

<parent>
    <groupId>org.springframework.boot</groupId>
    <artifactId>spring-boot-starter-parent</artifactId>
    <version>1.2.5.RELEASE</version>
</parent>

<properties>
	<project.build.sourceEncoding>UTF-8</project.build.sourceEncoding>
	<java.version>1.8</java.version>
</properties>

<dependencies>
	<dependency>
        <groupId>org.springframework.boot</groupId>
        <artifactId>spring-boot-starter-web</artifactId>
    </dependency>
    <dependency>
        <groupId>org.springframework.boot</groupId>
        <artifactId>spring-boot-starter-thymeleaf</artifactId>
    </dependency>
    <dependency>
        <groupId>org.springframework.boot</groupId>
        <artifactId>spring-boot-starter-jdbc</artifactId>
    </dependency>
    <dependency>
        <groupId>org.springframework.boot</groupId>
        <artifactId>spring-boot-starter-actuator</artifactId>
    </dependency>
    <dependency>
        <groupId>org.mybatis</groupId>
        <artifactId>mybatis-spring</artifactId>
        <version>1.2.2</version>
    </dependency>
    <dependency>
        <groupId>org.mybatis</groupId>
        <artifactId>mybatis</artifactId>
        <version>3.2.8</version>
    </dependency>
    <dependency>
        <groupId>org.apache.tomcat</groupId>
        <artifactId>tomcat-jdbc</artifactId>
    </dependency>
    <dependency>
        <groupId>mysql</groupId>
        <artifactId>mysql-connector-java</artifactId>
    </dependency>
    <dependency>
        <groupId>com.alibaba</groupId>
        <artifactId>fastjson</artifactId>
        <version>1.1.43</version>
    </dependency>
</dependencies>	
<build>
    <plugins>
        <plugin>
            <groupId>org.springframework.boot</groupId>
            <artifactId>spring-boot-maven-plugin</artifactId>
        </plugin>
    </plugins>
</build>

<repositories>
    <repository>
        <id>spring-milestone</id>
        <url>https://repo.spring.io/libs-release</url>
    </repository>
</repositories>

<pluginRepositories>
    <pluginRepository>
        <id>spring-milestone</id>
        <url>https://repo.spring.io/libs-release</url>
    </pluginRepository>
</pluginRepositories>

你实际在你本地去搭建这个工程的时候，你首先就会发现说，你一修改这个pom.xml，发现下载各种spring boot依赖包，下载巨慢巨慢

北京，宽带，100M，联通，还是下载的巨慢

手工下载依赖，并安装到本地maven仓库

（1）在maven中央仓库搜索jar包，如果没有找到，就得手动在百度里面找，下载jar下来
（2）根据jar对应的group id，artifact id，找到自己本地的maven仓库，对应的目录，将jar包拷贝到那个目录里面去

jmxtool，groupId=com.sun.jdmk，artifactId=jmxtools，version=1.2.1
com\sun\jdmk\jmxtools\1.2.1

（3）手工执行mvn install:install-file的命令，在本地仓库中安装这个依赖

mvn install:install-file -Dfile=E:\apache-maven-3.0.5\mvn_repo\com\sun\jdmk\jmxtools\1.2.1\jmxtools-1.2.1.jar -DgroupId=com.sun.jdmk -DartifactId=jmxtools -Dversion=1.2.1 -Dpackaging=jar

（4）强制kill掉你的eclipse

（5）重新再进入eclips，这个时候肯定是会报很多的错误的，重新加载maven依赖

（6）反复循环，手工下载了，十几个到二十个依赖，然后最终所有的依赖全部成功下载到了本地，工程部报错

2、配置文件（src/main/resources）

Application.properties

server.port=8081
spring.datasource.url=jdbc:mysql://192.168.31.85:3306/eshop
spring.datasource.username=eshop
spring.datasource.password=eshop
spring.datasource.driver-class-name=com.mysql.jdbc.Driver

说明：我已经在一个虚拟机中，安装好了一个mysql数据库，大家需要自己在自己本地安装一个mysql，配置好对应的url连接串，还有对应的用户名和密码就可以了

怎么安装mysql，大家自己网上查一下吧，java工程师，大学的学生，自己在本地安装一个mysql还是可以搞定的吧

mybatis/UserMappper.xml

templates/hello.html

3、Application

    @EnableAutoConfiguration
    @SpringBootApplication
    @ComponentScan
    @MapperScan("com.roncoo.eshop.cache.mapper")
    public class Application {
    @Bean
    @ConfigurationProperties(prefix="spring.datasource")
    public DataSource dataSource() {
        return new org.apache.tomcat.jdbc.pool.DataSource();
    }
    
    @Bean
    public SqlSessionFactory sqlSessionFactoryBean() throws Exception {
        SqlSessionFactoryBean sqlSessionFactoryBean = new SqlSessionFactoryBean();
        sqlSessionFactoryBean.setDataSource(dataSource());
        PathMatchingResourcePatternResolver resolver = new PathMatchingResourcePatternResolver();
        sqlSessionFactoryBean.setMapperLocations(resolver.getResources("classpath:/mybatis/*.xml"));
        return sqlSessionFactoryBean.getObject();
    }
     
    @Bean
    public PlatformTransactionManager transactionManager() {
        return new DataSourceTransactionManager(dataSource());
    }
    
    public static void main(String[] args) {
        SpringApplication.run(Application.class, args);
    }
    }

4、HelloController

5、完成两个服务的构建

### 087_快速完成缓存服务接收数据变更消息以及调用商品服务接口的代码编写

快速将核心的功能流程，用代码来实现

从下一讲开始，然后我们其实就针对这里面的一些东西，来给大家讲解哪些地方可能会有可用性的问题，如何用hystrix来解决这些可用性的问题

1、接收数据变更的消息，订阅一个MQ的topic，但是我们这里就简化一下，采取提供一个http接口

2、往http接口发送一条消息，就认为是通知缓存服务，有一个商品的数据变更了

<dependency>
	<groupId>org.apache.httpcomponents</groupId>
	<artifactId>httpclient</artifactId>
	<version>4.4</version>
</dependency>

/**
 * HttpClient工具类
 * @author lixuerui
 *
 */
@SuppressWarnings("deprecation")
public class HttpClientUtils {
	
	/**
	 * 发送GET请求
	
	 * @param url 请求URL
	
	 * @return 响应结果
	 */
	@SuppressWarnings("resource")
	public static String sendGetRequest(String url) {
		String httpResponse = null;
		
		HttpClient httpclient = null;
		InputStream is = null;
		BufferedReader br = null;
		
		try {
			// 发送GET请求
			httpclient = new DefaultHttpClient();
			HttpGet httpget = new HttpGet(url);  
			HttpResponse response = httpclient.execute(httpget);	
		
		​	// 处理响应
		​	HttpEntity entity = response.getEntity();
		​	if (entity != null) {
		​	is = entity.getContent();
		​	br = new BufferedReader(new InputStreamReader(is)); 
		
		​	StringBuffer buffer = new StringBuffer("");       
		​    String line = null;
		
		​    while ((line = br.readLine()) != null) {  
		​    		buffer.append(line + "\n");      
	    ​    }  
	    
		​	httpResponse = buffer.toString();      
		
		}     
		
		} catch (Exception e) {  
			e.printStackTrace();  
		} finally {
			try {
				if(br != null) {
					br.close();
				}
				if(is != null) {
					is.close();
				}
			} catch (Exception e2) {
				e2.printStackTrace();  
			}
		}
	
	 return httpResponse;
	 }
	
	/**
	 * 发送post请求
	
	 * @param url URL
	
     * @param map 参数Map
    
     * @return
     */
    @SuppressWarnings({ "rawtypes", "unchecked", "resource" })
    public static String sendPostRequest(String url, Map<String,String> map){  
    	HttpClient httpClient = null;  
        HttpPost httpPost = null;  
        String result = null;  
        
        try{  
            httpClient = new DefaultHttpClient();  
            httpPost = new HttpPost(url);  
            //设置参数  
        	List<NameValuePair> list = new ArrayList<NameValuePair>();  
        	Iterator iterator = map.entrySet().iterator();  
        	while(iterator.hasNext()){  
            	Entry<String,String> elem = (Entry<String, String>) iterator.next();  
            	list.add(new BasicNameValuePair(elem.getKey(), elem.getValue()));  
        	}
        
        ​	if(list.size() > 0){  
        ​    UrlEncodedFormEntity entity = new UrlEncodedFormEntity(list, "utf-8");    
        ​    httpPost.setEntity(entity);  
        ​	} 	
        
        ​	HttpResponse response = httpClient.execute(httpPost);  
        ​	if(response != null){  
        ​    HttpEntity resEntity = response.getEntity();  
        ​    if(resEntity != null){  
        ​        result = EntityUtils.toString(resEntity, "utf-8");    
        ​    }  
        ​	}   
        
	    } catch(Exception ex){  
	        ex.printStackTrace();  
	    } finally {	
	    }
	    
	    return result;  
	}  
	

}

3、缓存服务接收到这条消息之后，就会去通过http调用商品服务的一个接口，获取到商品变更后的最新数据

### 088_商品服务接口故障导致的高并发访问耗尽缓存服务资源的场景分析

商品服务接口导致缓存服务资源耗尽的问题

![](C:\Users\zy199005\Desktop\中华石杉\images\java\06\08801.png)

1、商品服务接口调用故障，导致缓存服务资源耗尽

2、hystrix针对一个一个的具体的业务场景，去开发高可用的架构

### 089_基于hystrix的线程池隔离技术进行商品服务接口的资源隔离

资源隔离生效的讲解

![](C:\Users\zy199005\Desktop\中华石杉\images\java\06\08901.png)

1、pom.xml

<dependency>
    <groupId>com.netflix.hystrix</groupId>
    <artifactId>hystrix-core</artifactId>
    <version>1.5.12</version>
</dependency>

2、将商品服务接口调用的逻辑进行封装

hystrix进行资源隔离，其实是提供了一个抽象，叫做command，就是说，你如果要把对某一个依赖服务的所有调用请求，全部隔离在同一份资源池内

对这个依赖服务的所有调用请求，全部走这个资源池内的资源，不会去用其他的资源了，这个就叫做资源隔离

hystrix最最基本的资源隔离的技术，线程池隔离技术

对某一个依赖服务，商品服务，所有的调用请求，全部隔离到一个线程池内，对商品服务的每次调用请求都封装在一个command里面

每个command（每次服务调用请求）都是使用线程池内的一个线程去执行的

所以哪怕是对这个依赖服务，商品服务，现在同时发起的调用量已经到了1000了，但是线程池内就10个线程，最多就只会用这10个线程去执行

不会说，对商品服务的请求，因为接口调用延迟，将tomcat内部所有的线程资源全部耗尽，不会出现了

    public class CommandHelloWorld extends HystrixCommand<String> {
    private final String name;
    
    public CommandHelloWorld(String name) {
        super(HystrixCommandGroupKey.Factory.asKey("ExampleGroup"));
        this.name = name;
    }
    
    @Override
    protected String run() {
        return "Hello " + name + "!";
    }
    }

不让超出这个量的请求去执行了，保护说，不要因为某一个依赖服务的故障，导致耗尽了缓存服务中的所有的线程资源去执行

3、开发一个支持批量商品变更的接口

HystrixCommand：是用来获取一条数据的
HystrixObservableCommand：是设计用来获取多条数据的

    public class ObservableCommandHelloWorld extends HystrixObservableCommand<String> {
    private final String name;
    
    public ObservableCommandHelloWorld(String name) {
        super(HystrixCommandGroupKey.Factory.asKey("ExampleGroup"));
        this.name = name;
    }
    
    @Override
    protected Observable<String> construct() {
        return Observable.create(new Observable.OnSubscribe<String>() {
            @Override
            public void call(Subscriber<? super String> observer) {
                try {
                    if (!observer.isUnsubscribed()) {
                        observer.onNext("Hello " + name + "!");
                        observer.onNext("Hi " + name + "!");
                        observer.onCompleted();
                    }
                } catch (Exception e) {
                    observer.onError(e);
                }
            }
         } ).subscribeOn(Schedulers.io());
    }
    }
4、command的四种调用方式

同步：new CommandHelloWorld("World").execute()，new ObservableCommandHelloWorld("World").toBlocking().toFuture().get()

如果你认为observable command只会返回一条数据，那么可以调用上面的模式，去同步执行，返回一条数据

异步：new CommandHelloWorld("World").queue()，new ObservableCommandHelloWorld("World").toBlocking().toFuture()

对command调用queue()，仅仅将command放入线程池的一个等待队列，就立即返回，拿到一个Future对象，后面可以做一些其他的事情，然后过一段时间对future调用get()方法获取数据

    // observe()：hot，已经执行过了
    // toObservable(): cold，还没执行过
    Observable<String> fWorld = new CommandHelloWorld("World").observe();
    assertEquals("Hello World!", fWorld.toBlocking().single());
    fWorld.subscribe(new Observer<String>() {
    @Override
    public void onCompleted() {
    
    }
    
    @Override
    public void onError(Throwable e) {
        e.printStackTrace();
    }
    
    @Override
    public void onNext(String v) {
        System.out.println("onNext: " + v);
    }
    });

    Observable<String> fWorld = new ObservableCommandHelloWorld("World").toObservable();
    assertEquals("Hello World!", fWorld.toBlocking().single());
    fWorld.subscribe(new Observer<String>() {
    @Override
    public void onCompleted() {
    }
    @Override
    public void onError(Throwable e) {
        e.printStackTrace();
    }
    
    @Override
    public void onNext(String v) {
        System.out.println("onNext: " + v);
    }
    });

5、如何解决刚才的问题

画图讲解资源隔离后的效果

### 090_基于hystrix的信号量技术对地理位置获取逻辑进行资源隔离与限流

线程池隔离和信号量隔离的原理以及区别

![](C:\Users\zy199005\Desktop\中华石杉\images\java\06\09001.png)

信号量的资源隔离与限流的说明

![](C:\Users\zy199005\Desktop\中华石杉\images\java\06\09002.png)

1、线程池隔离技术与信号量隔离技术的区别

hystrix里面，核心的一项功能，其实就是所谓的资源隔离，要解决的最最核心的问题，就是将多个依赖服务的调用分别隔离到各自自己的资源池内

避免说对某一个依赖服务的调用，因为依赖服务的接口调用的延迟或者失败，导致服务所有的线程资源全部耗费在这个服务的接口调用上

一旦说某个服务的线程资源全部耗尽的话，可能就导致服务就会崩溃，甚至说这种故障会不断蔓延

hystrix，资源隔离，两种技术，线程池的资源隔离，信号量的资源隔离

信号量，semaphore

信号量跟线程池，两种资源隔离的技术，区别到底在哪儿呢？

2、线程池隔离技术和信号量隔离技术，分别在什么样的场景下去使用呢？？

线程池：适合绝大多数的场景，99%的，线程池，对依赖服务的网络请求的调用和访问，timeout这种问题

信号量：适合，你的访问不是对外部依赖的访问，而是对内部的一些比较复杂的业务逻辑的访问，但是像这种访问，系统内部的代码，其实不涉及任何的网络请求，那么只要做信号量的普通限流就可以了，因为不需要去捕获timeout类似的问题，算法+数据结构的效率不是太高，并发量突然太高，因为这里稍微耗时一些，导致很多线程卡在这里的话，不太好，所以进行一个基本的资源隔离和访问，避免内部复杂的低效率的代码，导致大量的线程被hang住

3、在代码中加入从本地内存获取地理位置数据的逻辑

业务背景里面， 比较适合信号量的是什么场景呢？

比如说，我们一般来说，缓存服务，可能会将部分量特别少，访问又特别频繁的一些数据，放在自己的纯内存中

一般我们在获取到商品数据之后，都要去获取商品是属于哪个地理位置，省，市，卖家的，可能在自己的纯内存中，比如就一个Map去获取

对于这种直接访问本地内存的逻辑，比较适合用信号量做一下简单的隔离

优点在于，不用自己管理线程池拉，不用care timeout超时了，信号量做隔离的话，性能会相对来说高一些

4、采用信号量技术对地理位置获取逻辑进行资源隔离与限流

super(Setter.withGroupKey(HystrixCommandGroupKey.Factory.asKey("ExampleGroup"))
        .andCommandPropertiesDefaults(HystrixCommandProperties.Setter()
               .withExecutionIsolationStrategy(ExecutionIsolationStrategy.SEMAPHORE)));

### 091_hystrix的线程池+服务+接口划分以及资源池的容量大小控制

线程池+queue的工作原理

![](C:\Users\zy199005\Desktop\中华石杉\images\java\06\09101.png)

资源隔离，两种策略，线程池隔离，信号量隔离

对资源隔离这一块东西，做稍微更加深入一些的讲解，告诉你，除了可以选择隔离策略以外，对你选择的隔离策略，可以做一定的细粒度的一些控制

1、execution.isolation.strategy

指定了HystrixCommand.run()的资源隔离策略，THREAD或者SEMAPHORE，一种是基于线程池，一种是信号量

线程池机制，每个command运行在一个线程中，限流是通过线程池的大小来控制的

信号量机制，command是运行在调用线程中，但是通过信号量的容量来进行限流

如何在线程池和信号量之间做选择？

默认的策略就是线程池

线程池其实最大的好处就是对于网络访问请求，如果有超时的话，可以避免调用线程阻塞住

而使用信号量的场景，通常是针对超大并发量的场景下，每个服务实例每秒都几百的QPS，那么此时你用线程池的话，线程一般不会太多，可能撑不住那么高的并发，如果要撑住，可能要耗费大量的线程资源，那么就是用信号量，来进行限流保护

一般用信号量常见于那种基于纯内存的一些业务逻辑服务，而不涉及到任何网络访问请求

netflix有100+的command运行在40+的线程池中，只有少数command是不运行在线程池中的，就是从纯内存中获取一些元数据，或者是对多个command包装起来的facacde command，是用信号量限流的

// to use thread isolation
HystrixCommandProperties.Setter()
   .withExecutionIsolationStrategy(ExecutionIsolationStrategy.THREAD)
// to use semaphore isolation
HystrixCommandProperties.Setter()
   .withExecutionIsolationStrategy(ExecutionIsolationStrategy.SEMAPHORE)

2、command名称和command组

线程池隔离，依赖服务->接口->线程池，如何来划分

你的每个command，都可以设置一个自己的名称，同时可以设置一个自己的组

private static final Setter cachedSetter = 
    Setter.withGroupKey(HystrixCommandGroupKey.Factory.asKey("ExampleGroup"))
        .andCommandKey(HystrixCommandKey.Factory.asKey("HelloWorld"));    

public CommandHelloWorld(String name) {
    super(cachedSetter);
    this.name = name;
}

command group，是一个非常重要的概念，默认情况下，因为就是通过command group来定义一个线程池的，而且还会通过command group来聚合一些监控和报警信息

同一个command group中的请求，都会进入同一个线程池中

3、command线程池

threadpool key代表了一个HystrixThreadPool，用来进行统一监控，统计，缓存

默认的threadpool key就是command group名称

每个command都会跟它的threadpool key对应的thread pool绑定在一起

如果不想直接用command group，也可以手动设置thread pool name

public CommandHelloWorld(String name) {
    super(Setter.withGroupKey(HystrixCommandGroupKey.Factory.asKey("ExampleGroup"))
            .andCommandKey(HystrixCommandKey.Factory.asKey("HelloWorld"))
            .andThreadPoolKey(HystrixThreadPoolKey.Factory.asKey("HelloWorldPool")));
    this.name = name;
}

command threadpool -> command group -> command key

command key，代表了一类command，一般来说，代表了底层的依赖服务的一个接口

command group，代表了某一个底层的依赖服务，合理，一个依赖服务可能会暴露出来多个接口，每个接口就是一个command key

command group，在逻辑上去组织起来一堆command key的调用，统计信息，成功次数，timeout超时次数，失败次数，可以看到某一个服务整体的一些访问情况

command group，一般来说，推荐是根据一个服务去划分出一个线程池，command key默认都是属于同一个线程池的

比如说你以一个服务为粒度，估算出来这个服务每秒的所有接口加起来的整体QPS在100左右

你调用那个服务的当前服务，部署了10个服务实例，每个服务实例上，其实用这个command group对应这个服务，给一个线程池，量大概在10个左右，就可以了，你对整个服务的整体的访问QPS大概在每秒100左右

一般来说，command group是用来在逻辑上组合一堆command的

举个例子，对于一个服务中的某个功能模块来说，希望将这个功能模块内的所有command放在一个group中，那么在监控和报警的时候可以放一起看

command group，对应了一个服务，但是这个服务暴露出来的几个接口，访问量很不一样，差异非常之大

你可能就希望在这个服务command group内部，包含的对应多个接口的command key，做一些细粒度的资源隔离

对同一个服务的不同接口，都使用不同的线程池

command key -> command group

command key -> 自己的threadpool key

逻辑上来说，多个command key属于一个command group，在做统计的时候，会放在一起统计

每个command key有自己的线程池，每个接口有自己的线程池，去做资源隔离和限流

但是对于thread pool资源隔离来说，可能是希望能够拆分的更加一致一些，比如在一个功能模块内，对不同的请求可以使用不同的thread pool

command group一般来说，可以是对应一个服务，多个command key对应这个服务的多个接口，多个接口的调用共享同一个线程池

如果说你的command key，要用自己的线程池，可以定义自己的threadpool key，就ok了

4、coreSize

设置线程池的大小，默认是10

HystrixThreadPoolProperties.Setter()
   .withCoreSize(int value)

一般来说，用这个默认的10个线程大小就够了

5、queueSizeRejectionThreshold

控制queue满后reject的threshold，因为maxQueueSize不允许热修改，因此提供这个参数可以热修改，控制队列的最大大小

HystrixCommand在提交到线程池之前，其实会先进入一个队列中，这个队列满了之后，才会reject

默认值是5

HystrixThreadPoolProperties.Setter()
   .withQueueSizeRejectionThreshold(int value)

6、execution.isolation.semaphore.maxConcurrentRequests

设置使用SEMAPHORE隔离策略的时候，允许访问的最大并发量，超过这个最大并发量，请求直接被reject

这个并发量的设置，跟线程池大小的设置，应该是类似的，但是基于信号量的话，性能会好很多，而且hystrix框架本身的开销会小很多

默认值是10，设置的小一些，否则因为信号量是基于调用线程去执行command的，而且不能从timeout中抽离，因此一旦设置的太大，而且有延时发生，可能瞬间导致tomcat本身的线程资源本占满

HystrixCommandProperties.Setter()
   .withExecutionIsolationSemaphoreMaxConcurrentRequests(int value)

### 092_深入分析hystrix执行时的8大流程步骤以及内部原理

hystrix执行时的8大流程以及内部原理

![](C:\Users\zy199005\Desktop\中华石杉\images\java\06\09201.png)

之前几讲，我们用实际的业务背景给了一些可用性的问题

然后借着那些最最基础的可用性的问题，然后讲解了hystrix最基本的支持高可用的技术，资源隔离+限流

创建command，执行这个command，配置这个command对应的group和线程池，以及线程池/信号量的容量和大小

我们要去讲解一下，你开始执行这个command，调用了这个command的execute()方法以后，hystrix内部的底层的执行流程和步骤以及原理是什么呢？

在讲解这个流程的过程中，我们会带出来hystrix其他的一些核心以及重要的功能

画图分析整个8大步骤的流程，然后再对每个步骤进行细致的讲解

1、构建一个HystrixCommand或者HystrixObservableCommand

一个HystrixCommand或一个HystrixObservableCommand对象，代表了对某个依赖服务发起的一次请求或者调用

构造的时候，可以在构造函数中传入任何需要的参数

HystrixCommand主要用于仅仅会返回一个结果的调用
HystrixObservableCommand主要用于可能会返回多条结果的调用

HystrixCommand command = new HystrixCommand(arg1, arg2);
HystrixObservableCommand command = new HystrixObservableCommand(arg1, arg2);

2、调用command的执行方法

执行Command就可以发起一次对依赖服务的调用

要执行Command，需要在4个方法中选择其中的一个：execute()，queue()，observe()，toObservable()

其中execute()和queue()仅仅对HystrixCommand适用

execute()：调用后直接block住，属于同步调用，直到依赖服务返回单条结果，或者抛出异常
queue()：返回一个Future，属于异步调用，后面可以通过Future获取单条结果
observe()：订阅一个Observable对象，Observable代表的是依赖服务返回的结果，获取到一个那个代表结果的Observable对象的拷贝对象
toObservable()：返回一个Observable对象，如果我们订阅这个对象，就会执行command并且获取返回结果

K             value   = command.execute();
Future<K>     fValue  = command.queue();
Observable<K> ohValue = command.observe();         
Observable<K> ocValue = command.toObservable();    

execute()实际上会调用queue().get().queue()，接着会调用toObservable().toBlocking().toFuture()

也就是说，无论是哪种执行command的方式，最终都是依赖toObservable()去执行的

3、检查是否开启缓存

从这一步开始，进入我们的底层的运行原理啦，了解hysrix的一些更加高级的功能和特性

如果这个command开启了请求缓存，request cache，而且这个调用的结果在缓存中存在，那么直接从缓存中返回结果

4、检查是否开启了短路器

检查这个command对应的依赖服务是否开启了短路器

如果断路器被打开了，那么hystrix就不会执行这个command，而是直接去执行fallback降级机制

5、检查线程池/队列/semaphore是否已经满了

如果command对应的线程池/队列/semaphore已经满了，那么也不会执行command，而是直接去调用fallback降级机制

6、执行command

调用HystrixObservableCommand.construct()或HystrixCommand.run()来实际执行这个command

HystrixCommand.run()是返回一个单条结果，或者抛出一个异常
HystrixObservableCommand.construct()是返回一个Observable对象，可以获取多条结果

如果HystrixCommand.run()或HystrixObservableCommand.construct()的执行，超过了timeout时长的话，那么command所在的线程就会抛出一个TimeoutException

如果timeout了，也会去执行fallback降级机制，而且就不会管run()或construct()返回的值了

这里要注意的一点是，我们是不可能终止掉一个调用严重延迟的依赖服务的线程的，只能说给你抛出来一个TimeoutException，但是还是可能会因为严重延迟的调用线程占满整个线程池的

即使这个时候新来的流量都被限流了。。。

如果没有timeout的话，那么就会拿到一些调用依赖服务获取到的结果，然后hystrix会做一些logging记录和metric统计

7、短路健康检查

Hystrix会将每一个依赖服务的调用成功，失败，拒绝，超时，等事件，都会发送给circuit breaker断路器

短路器就会对调用成功/失败/拒绝/超时等事件的次数进行统计

短路器会根据这些统计次数来决定，是否要进行短路，如果打开了短路器，那么在一段时间内就会直接短路，然后如果在之后第一次检查发现调用成功了，就关闭断路器

8、调用fallback降级机制

在以下几种情况中，hystrix会调用fallback降级机制：run()或construct()抛出一个异常，短路器打开，线程池/队列/semaphore满了，command执行超时了

一般在降级机制中，都建议给出一些默认的返回值，比如静态的一些代码逻辑，或者从内存中的缓存中提取一些数据，尽量在这里不要再进行网络请求了

即使在降级中，一定要进行网络调用，也应该将那个调用放在一个HystrixCommand中，进行隔离

在HystrixCommand中，上线getFallback()方法，可以提供降级机制

在HystirxObservableCommand中，实现一个resumeWithFallback()方法，返回一个Observable对象，可以提供降级结果

如果fallback返回了结果，那么hystrix就会返回这个结果

对于HystrixCommand，会返回一个Observable对象，其中会发返回对应的结果
对于HystrixObservableCommand，会返回一个原始的Observable对象

如果没有实现fallback，或者是fallback抛出了异常，Hystrix会返回一个Observable，但是不会返回任何数据

不同的command执行方式，其fallback为空或者异常时的返回结果不同

对于execute()，直接抛出异常
对于queue()，返回一个Future，调用get()时抛出异常
对于observe()，返回一个Observable对象，但是调用subscribe()方法订阅它时，理解抛出调用者的onError方法
对于toObservable()，返回一个Observable对象，但是调用subscribe()方法订阅它时，理解抛出调用者的onError方法

9、不同的执行方式

execute()，获取一个Future.get()，然后拿到单个结果
queue()，返回一个Future
observer()，立即订阅Observable，然后启动8大执行步骤，返回一个拷贝的Observable，订阅时理解回调给你结果
toObservable()，返回一个原始的Observable，必须手动订阅才会去执行8大步骤

### 093_基于request cache请求缓存技术优化批量商品数据查询接口

request cache的原理

![](C:\Users\zy199005\Desktop\中华石杉\images\java\06\09301.png)

我们上一讲讲解的那个图片，顺着那个图片的流程，来一个一个的讲解hystrix的核心技术

1、创建command，2种command类型
2、执行command，4种执行方式
3、查找是否开启了request cache，是否有请求缓存，如果有缓存，直接取用缓存，返回结果

首先，有一个概念，叫做reqeust context，请求上下文，一般来说，在一个web应用中，hystrix

我们会在一个filter里面，对每一个请求都施加一个请求上下文，就是说，tomcat容器内，每一次请求，就是一次请求上下文

然后在这次请求上下文中，我们会去执行N多代码，调用N多依赖服务，有的依赖服务可能还会调用好几次

在一次请求上下文中，如果有多个command，参数都是一样的，调用的接口也是一样的，其实结果可以认为也是一样的

那么这个时候，我们就可以让第一次command执行，返回的结果，被缓存在内存中，然后这个请求上下文中，后续的其他对这个依赖的调用全部从内存中取用缓存结果就可以了

不用在一次请求上下文中反复多次的执行一样的command，提升整个请求的性能


HystrixCommand和HystrixObservableCommand都可以指定一个缓存key，然后hystrix会自动进行缓存，接着在同一个request context内，再次访问的时候，就会直接取用缓存

用请求缓存，可以避免重复执行网络请求

多次调用一个command，那么只会执行一次，后面都是直接取缓存

对于请求缓存（request caching），请求合并（request collapsing），请求日志（request log），等等技术，都必须自己管理HystrixReuqestContext的声明周期

在一个请求执行之前，都必须先初始化一个request context

HystrixRequestContext context = HystrixRequestContext.initializeContext();

然后在请求结束之后，需要关闭request context

context.shutdown();

一般来说，在java web来的应用中，都是通过filter过滤器来实现的

    public class HystrixRequestContextServletFilter implements Filter {
    public void doFilter(ServletRequest request, ServletResponse response, FilterChain chain) 
     throws IOException, ServletException {
        HystrixRequestContext context = HystrixRequestContext.initializeContext();
        try {
            chain.doFilter(request, response);
        } finally {
            context.shutdown();
        }
    }
    }
@Bean
public FilterRegistrationBean indexFilterRegistration() {
    FilterRegistrationBean registration = new FilterRegistrationBean(new IndexFilter());
    registration.addUrlPatterns("/");
    return registration;
}

结合咱们的业务背景，我们做了一个批量查询商品数据的接口，在这个里面，我们其实通过HystrixObservableCommand一次性批量查询多个商品id的数据

但是这里有个问题，如果说nginx在本地缓存失效了，重新获取一批缓存，传递过来的productId都没有进行去重，1,1,2,2,5,6,7

那么可能说，商品id出现了重复，如果按照我们之前的业务逻辑，可能就会重复对productId=1的商品查询两次，productId=2的商品查询两次

我们对批量查询商品数据的接口，可以用request cache做一个优化，就是说一次请求，就是一次request context，对相同的商品查询只能执行一次，其余的都走request cache

    public class CommandUsingRequestCache extends HystrixCommand<Boolean> {
    private final int value;
    
    protected CommandUsingRequestCache(int value) {
        super(HystrixCommandGroupKey.Factory.asKey("ExampleGroup"));
        this.value = value;
    }
    
    @Override
    protected Boolean run() {
        return value == 0 || value % 2 == 0;
    }
    
    @Override
    protected String getCacheKey() {
        return String.valueOf(value);
    }
    }

    @Test
    public void testWithCacheHits() {
        HystrixRequestContext context = HystrixRequestContext.initializeContext();
        try {
            CommandUsingRequestCache command2a = new CommandUsingRequestCache(2);
            CommandUsingRequestCache command2b = new CommandUsingRequestCache(2);
    	assertTrue(command2a.execute());
        // this is the first time we've executed this command with
        // the value of "2" so it should not be from cache
        assertFalse(command2a.isResponseFromCache());
    
        assertTrue(command2b.execute());
        // this is the second time we've executed this command with
        // the same value so it should return from cache
        assertTrue(command2b.isResponseFromCache());
    } finally {
        context.shutdown();
    }
    
    // start a new request context
    context = HystrixRequestContext.initializeContext();
    try {
        CommandUsingRequestCache command3b = new CommandUsingRequestCache(2);
        assertTrue(command3b.execute());
        // this is a new request context so this 
        // should not come from cache
        assertFalse(command3b.isResponseFromCache());
    } finally {
        context.shutdown();
    }
    }
缓存的手动清理

    public static class GetterCommand extends HystrixCommand<String> {
    private static final HystrixCommandKey GETTER_KEY = HystrixCommandKey.Factory.asKey("GetterCommand");
    private final int id;
    
    public GetterCommand(int id) {
        super(Setter.withGroupKey(HystrixCommandGroupKey.Factory.asKey("GetSetGet"))
                .andCommandKey(GETTER_KEY));
        this.id = id;
    }
    
    @Override
    protected String run() {
        return prefixStoredOnRemoteDataStore + id;
    }
    
    @Override
    protected String getCacheKey() {
        return String.valueOf(id);
    }
    
    /**
     * Allow the cache to be flushed for this object.
     * 
     * @param id
     *            argument that would normally be passed to the command
     */
    public static void flushCache(int id) {
        HystrixRequestCache.getInstance(GETTER_KEY,
                HystrixConcurrencyStrategyDefault.getInstance()).clear(String.valueOf(id));
    }
    }

    public static class SetterCommand extends HystrixCommand<Void> {
    private final int id;
    private final String prefix;
    
    public SetterCommand(int id, String prefix) {
        super(HystrixCommandGroupKey.Factory.asKey("GetSetGet"));
        this.id = id;
        this.prefix = prefix;
    }
    
    @Override
    protected Void run() {
        // persist the value against the datastore
        prefixStoredOnRemoteDataStore = prefix;
        // flush the cache
        GetterCommand.flushCache(id);
        // no return value
        return null;
    }
    }
### 094_开发品牌名称获取接口的基于本地缓存的fallback降级机制

1、创建command
2、执行command
3、request cache
4、短路器，如果打开了，fallback降级机制

1、fallback降级机制

hystrix调用各种接口，或者访问外部依赖，mysql，redis，zookeeper，kafka，等等，如果出现了任何异常的情况

比如说报错了，访问mysql报错，redis报错，zookeeper报错，kafka报错，error

对每个外部依赖，无论是服务接口，中间件，资源隔离，对外部依赖只能用一定量的资源去访问，线程池/信号量，如果资源池已满，reject

访问外部依赖的时候，访问时间过长，可能就会导致超时，报一个TimeoutException异常，timeout

上述三种情况，都是我们说的异常情况，对外部依赖的东西访问的时候出现了异常，发送异常事件到短路器中去进行统计

如果短路器发现异常事件的占比达到了一定的比例，直接开启短路，circuit breaker

上述四种情况，都会去调用fallback降级机制

fallback，降级机制，你之前都是必须去调用外部的依赖接口，或者从mysql中去查询数据的，但是为了避免说可能外部依赖会有故障

比如，你可以再内存中维护一个ehcache，作为一个纯内存的基于LRU自动清理的缓存，数据也可以放入缓存内

如果说外部依赖有异常，fallback这里，直接尝试从ehcache中获取数据

比如说，本来你是从mysql，redis，或者其他任何地方去获取数据的，获取调用其他服务的接口的，结果人家故障了，人家挂了，fallback，可以返回一个默认值

两种最经典的降级机制：纯内存数据，默认值

run()抛出异常，超时，线程池或信号量满了，或短路了，都会调用fallback机制

给大家举个例子，比如说我们现在有个商品数据，brandId，品牌，一般来说，假设，正常的逻辑，拿到了一个商品数据以后，用brandId再调用一次请求，到其他的服务去获取品牌的最新名称

假如说，那个品牌服务挂掉了，那么我们可以尝试本地内存中，会保留一份时间比较过期的一份品牌数据，有些品牌没有，有些品牌的名称过期了，Nike++，Nike

调用品牌服务失败了，fallback降级就从本地内存中获取一份过期的数据，先凑合着用着

    public class CommandHelloFailure extends HystrixCommand<String> {
    private final String name;
    
    public CommandHelloFailure(String name) {
        super(HystrixCommandGroupKey.Factory.asKey("ExampleGroup"));
        this.name = name;
    }
    
    @Override
    protected String run() {
        throw new RuntimeException("this command always fails");
    }
    
    @Override
    protected String getFallback() {
        return "Hello Failure " + name + "!";
    }
    }

@Test
public void testSynchronous() {
    assertEquals("Hello Failure World!", new CommandHelloFailure("World").execute());
}

HystrixObservableCommand，是实现resumeWithFallback方法

2、fallback.isolation.semaphore.maxConcurrentRequests

这个参数设置了HystrixCommand.getFallback()最大允许的并发请求数量，默认值是10，也是通过semaphore信号量的机制去限流

如果超出了这个最大值，那么直接被reject

HystrixCommandProperties.Setter()
   .withFallbackIsolationSemaphoreMaxConcurrentRequests(int value)

### 095_深入理解hystrix的短路器执行原理以及模拟接口异常时的短路实验

短路器深入的工作原理

1、如果经过短路器的流量超过了一定的阈值，HystrixCommandProperties.circuitBreakerRequestVolumeThreshold()

举个例子，可能看起来是这样子的，要求在10s内，经过短路器的流量必须达到20个；在10s内，经过短路器的流量才10个，那么根本不会去判断要不要短路

2、如果断路器统计到的异常调用的占比超过了一定的阈值，HystrixCommandProperties.circuitBreakerErrorThresholdPercentage()

如果达到了上面的要求，比如说在10s内，经过短路器的流量（你，只要执行一个command，这个请求就一定会经过短路器），达到了30个；同时其中异常的访问数量，占到了一定的比例，比如说60%的请求都是异常（报错，timeout，reject），会开启短路

3、然后断路器从close状态转换到open状态

4、断路器打开的时候，所有经过该断路器的请求全部被短路，不调用后端服务，直接走fallback降级

5、经过了一段时间之后，HystrixCommandProperties.circuitBreakerSleepWindowInMilliseconds()，会half-open，让一条请求经过短路器，看能不能正常调用。如果调用成功了，那么就自动恢复，转到close状态

短路器，会自动恢复的，half-open，半开状态

6、circuit breaker短路器的配置

（1）circuitBreaker.enabled

控制短路器是否允许工作，包括跟踪依赖服务调用的健康状况，以及对异常情况过多时是否允许触发短路，默认是true

HystrixCommandProperties.Setter()
   .withCircuitBreakerEnabled(boolean value)

（2）circuitBreaker.requestVolumeThreshold

设置一个rolling window，滑动窗口中，最少要有多少个请求时，才触发开启短路

举例来说，如果设置为20（默认值），那么在一个10秒的滑动窗口内，如果只有19个请求，即使这19个请求都是异常的，也是不会触发开启短路器的

HystrixCommandProperties.Setter()
   .withCircuitBreakerRequestVolumeThreshold(int value)

（3）circuitBreaker.sleepWindowInMilliseconds

设置在短路之后，需要在多长时间内直接reject请求，然后在这段时间之后，再重新导holf-open状态，尝试允许请求通过以及自动恢复，默认值是5000毫秒

HystrixCommandProperties.Setter()
   .withCircuitBreakerSleepWindowInMilliseconds(int value)

（4）circuitBreaker.errorThresholdPercentage

设置异常请求量的百分比，当异常请求达到这个百分比时，就触发打开短路器，默认是50，也就是50%

HystrixCommandProperties.Setter()
   .withCircuitBreakerErrorThresholdPercentage(int value)

（5）circuitBreaker.forceOpen

如果设置为true的话，直接强迫打开短路器，相当于是手动短路了，手动降级，默认false

HystrixCommandProperties.Setter()
   .withCircuitBreakerForceOpen(boolean value)

（6）circuitBreaker.forceClosed

如果设置为ture的话，直接强迫关闭短路器，相当于是手动停止短路了，手动升级，默认false

HystrixCommandProperties.Setter()
   .withCircuitBreakerForceClosed(boolean value)

7、实战演练

配置一个断路器，流量要求是20，异常比例是50%，短路时间是5s

在command内加入一个判断，如果是productId=-1，那么就直接报错，触发异常执行

写一个client测试程序，写入50个请求，前20个是正常的，但是后30个是productId=-1，然后继续请求，会发现

### 096_深入理解线程池隔离技术的设计原则以及动手实战接口限流实验

1、command的创建和执行：资源隔离
2、request cache：请求缓存
3、fallback：优雅降级
4、circuit breaker：短路器，快速熔断（一旦后端服务故障，立刻熔断，阻止对其的访问）

把一个分布式系统中的某一个服务，打造成一个高可用的服务

资源隔离，优雅降级，熔断

5、判断，线程池或者信号量的容量是否已满，reject，限流

限流，限制对后端的服务的访问量，比如说你对mysql，redis，zookeeper，各种后端的中间件的资源，访问，其实为了避免过大的流浪打死后端的服务，线程池，信号量，限流

限制服务对后端的资源的访问

1、线程池隔离技术的设计原则

Hystrix采取了bulkhead舱壁隔离技术，来将外部依赖进行资源隔离，进而避免任何外部依赖的故障导致本服务崩溃

线程池隔离，学术名称：bulkhead，舱壁隔离

外部依赖的调用在单独的线程中执行，这样就能跟调用线程隔离开来，避免外部依赖调用timeout耗时过长，导致调用线程被卡死

Hystrix对每个外部依赖用一个单独的线程池，这样的话，如果对那个外部依赖调用延迟很严重，最多就是耗尽那个依赖自己的线程池而已，不会影响其他的依赖调用

Hystrix选择用线程池机制来进行资源隔离，要面对的场景如下：

（1）每个服务都会调用几十个后端依赖服务，那些后端依赖服务通常是由很多不同的团队开发的
（2）每个后端依赖服务都会提供它自己的client调用库，比如说用thrift的话，就会提供对应的thrift依赖
（3）client调用库随时会变更
（4）client调用库随时可能会增加新的网络请求的逻辑
（5）client调用库可能会包含诸如自动重试，数据解析，内存中缓存等逻辑
（6）client调用库一般都对调用者来说是个黑盒，包括实现细节，网络访问，默认配置，等等
（7）在真实的生产环境中，经常会出现调用者，突然间惊讶的发现，client调用库发生了某些变化
（8）即使client调用库没有改变，依赖服务本身可能有会发生逻辑上的变化
（9）有些依赖的client调用库可能还会拉取其他的依赖库，而且可能那些依赖库配置的不正确
（10）大多数网络请求都是同步调用的
（11）调用失败和延迟，也有可能会发生在client调用库本身的代码中，不一定就是发生在网络请求中

简单来说，就是你必须默认client调用库就很不靠谱，而且随时可能各种变化，所以就要用强制隔离的方式来确保任何服务的故障不能影响当前服务

我不知道在学习这个课程的学员里，有多少人，真正参与过一些复杂的分布式系统的开发，不是说一个team，你们五六个人，七八个人，去做的

在一些大公司里，做一些复杂的项目的话，广告计费系统，特别复杂，可能涉及多个团队，总共三四十个人，五六十个人，一起去开发一个系统，每个团队负责一块儿

每个团队里的每个人，负责一个服务，或者几个服务，比较常见的大公司的复杂分布式系统项目的分工合作的一个流程

线程池机制的优点如下：

（1）任何一个依赖服务都可以被隔离在自己的线程池内，即使自己的线程池资源填满了，也不会影响任何其他的服务调用
（2）服务可以随时引入一个新的依赖服务，因为即使这个新的依赖服务有问题，也不会影响其他任何服务的调用
（3）当一个故障的依赖服务重新变好的时候，可以通过清理掉线程池，瞬间恢复该服务的调用，而如果是tomcat线程池被占满，再恢复就很麻烦
（4）如果一个client调用库配置有问题，线程池的健康状况随时会报告，比如成功/失败/拒绝/超时的次数统计，然后可以近实时热修改依赖服务的调用配置，而不用停机
（5）如果一个服务本身发生了修改，需要重新调整配置，此时线程池的健康状况也可以随时发现，比如成功/失败/拒绝/超时的次数统计，然后可以近实时热修改依赖服务的调用配置，而不用停机
（6）基于线程池的异步本质，可以在同步的调用之上，构建一层异步调用层

简单来说，最大的好处，就是资源隔离，确保说，任何一个依赖服务故障，不会拖垮当前的这个服务

线程池机制的缺点：

（1）线程池机制最大的缺点就是增加了cpu的开销

除了tomcat本身的调用线程之外，还有hystrix自己管理的线程池

（2）每个command的执行都依托一个独立的线程，会进行排队，调度，还有上下文切换
（3）Hystrix官方自己做了一个多线程异步带来的额外开销，通过对比多线程异步调用+同步调用得出，Netflix API每天通过hystrix执行10亿次调用，每个服务实例有40个以上的线程池，每个线程池有10个左右的线程
（4）最后发现说，用hystrix的额外开销，就是给请求带来了3ms左右的延时，最多延时在10ms以内，相比于可用性和稳定性的提升，这是可以接受的


我们可以用hystrix semaphore技术来实现对某个依赖服务的并发访问量的限制，而不是通过线程池/队列的大小来限制流量

sempahore技术可以用来限流和削峰，但是不能用来对调研延迟的服务进行timeout和隔离

execution.isolation.strategy，设置为SEMAPHORE，那么hystrix就会用semaphore机制来替代线程池机制，来对依赖服务的访问进行限流

如果通过semaphore调用的时候，底层的网络调用延迟很严重，那么是无法timeout的，只能一直block住

一旦请求数量超过了semephore限定的数量之后，就会立即开启限流

2、接口限流实验

假设，一个线程池，大小是15个，队列大小是10个，timeout时长设置的长一些，5s

模拟发送请求，然后写死代码，在command内部做一个sleep，比如每次sleep 1s，10个请求发送过去以后，直接被hang死，线程池占满

再发送请求，就会堵塞在缓冲队列，queue，10个，20个，10个，后10个应该就直接reject，fallback逻辑

15 + 10 = 25个请求，15在执行，10个缓冲在队列里了，剩下的流量全部被reject，限流，降级

withCoreSize：设置你的线程池的大小
withMaxQueueSize：设置的是你的等待队列，缓冲队列的大小
withQueueSizeRejectionThreshold：如果withMaxQueueSize<withQueueSizeRejectionThreshold，那么取的是withMaxQueueSize，反之，取得是withQueueSizeRejectionThreshold

线程池本身的大小，如果你不设置另外两个queue相关的参数，等待队列是关闭的

queue大小，等待队列的大小，timeout时长

先进去线程池的是10个请求，然后有8个请求进入等待队列，线程池里有空闲，等待队列中的请求如果还没有timeout，那么就进去线程池去执行

10 + 8 = 18个请求之外，7个请求，直接会被reject掉，限流，fallback

withExecutionTimeoutInMilliseconds(20000)：timeout也设置大一些，否则如果请求放等待队列中时间太长了，直接就会timeout，等不到去线程池里执行了
withFallbackIsolationSemaphoreMaxConcurrentRequests(30)：fallback，sempahore限流，30个，避免太多的请求同时调用fallback被拒绝访问

### 097_基于timeout机制来为商品服务接口的调用超时提供安全保护

一般来说，在调用依赖服务的接口的时候，比较常见的一个问题，就是超时

超时是在一个复杂的分布式系统中，导致不稳定，或者系统抖动，或者出现说大量超时，线程资源hang死，吞吐量大幅度下降，甚至服务崩溃

超时最大的一个问题

你去调用各种各样的依赖服务，特别是在大公司，你甚至都不认识开发一个服务的人，你都不知道那个人的水平怎么样，不了解

比尔盖茨说过一句话，在互联网的另外一头，你都不知道甚至坐着一条狗

分布式系统，大公司，多个团队，大型协作，服务是谁的，不了解，很可能说那个哥儿们，实习生都有可能

在一个复杂的系统里，可能你的依赖接口的性能很不稳定，有时候2ms，200ms，2s

如果你不对各种依赖接口的调用，做超时的控制，来给你的服务提供安全保护措施，那么很可能你的服务就被各种垃圾的依赖服务的性能给拖死了

大量的接口调用很慢，大量线程就卡死了，资源隔离，线程池的线程卡死了，超时的控制

（1）execution.isolation.thread.timeoutInMilliseconds

手动设置timeout时长，一个command运行超出这个时间，就被认为是timeout，然后将hystrix command标识为timeout，同时执行fallback降级逻辑

默认是1000，也就是1000毫秒

HystrixCommandProperties.Setter()
   .withExecutionTimeoutInMilliseconds(int value)

（2）execution.timeout.enabled

控制是否要打开timeout机制，默认是true

HystrixCommandProperties.Setter()
   .withExecutionTimeoutEnabled(boolean value)

让一个command执行timeout，然后看是否会调用fallback降级

### 098_基于hystrix的高可用分布式系统架构项目实战课程的总结

已经学到的东西

hystrix的核心知识

1、hystrix内部工作原理：8大执行步骤和流程
2、资源隔离：你如果有很多个依赖服务，高可用性，先做资源隔离，任何一个依赖服务的故障不会导致你的服务的资源耗尽，不会崩溃
3、请求缓存：对于一个request context内的多个相同command，使用request cache，提升性能
4、熔断：基于短路器，采集各种异常事件，报错，超时，reject，短路，熔断，一定时间范围内就不允许访问了，直接降级，自动恢复的机制
5、降级：报错，超时，reject，熔断，降级，服务提供容错的机制
6、限流：在你的服务里面，通过线程池，或者信号量，限制对某个后端的服务或资源的访问量，避免从你的服务这里过去太多的流量，打死某个资源
7、超时：避免某个依赖服务性能过差，导致大量的线程hang住去调用那个服务，会导致你的服务本身性能也比较差

学会了这些东西以后，我们特意设置了大电商背景，商品详情页系统，缓存服务的业务场景，尽量的去结合一些仿真的业务，去学习hystrix的各项技术

这个东西做起来没那么容易，尽量做了，学习效果更好一些，兴趣也会更好一些

已经可以快速利用hystrix给自己开发的服务增加各种高可用的保障措施了，避免你的系统因为各种各样的异常情况导致崩溃，不可用

hystrix的高阶知识

1、request collapser，请求合并技术
2、fail-fast和fail-slient，高阶容错模式
3、static fallback和stubbed fallback，高阶降级模式
4、嵌套command实现的发送网络请求的降级模式
5、基于facade command的多级降级模式
6、request cache的手动清理
7、生产环境中的线程池大小以及timeout配置优化经验
8、线程池的自动化动态扩容与缩容技术
9、hystrix的metric高阶配置
10、基于hystrix dashboard的可视化分布式系统监控
11、生产环境中的hystrix工程运维经验

### 099_基于request collapser请求合并技术进一步优化批量查询

hystrix，高级的技术，request collapser，请求合并技术，collapser折叠

优化过一个批量查询的接口了，request cache来做优化，可能有相同的商品就可以直接取用缓存了

多个商品，需要发送多次网络请求，调用多次接口，才能拿到结果

可以使用HystrixCollapser将多个HystrixCommand合并到一起，多个command放在一个command里面去执行，发送一次网络请求，就拉取到多条数据

用请求合并技术，将多个请求合并起来，可以减少高并发访问下需要使用的线程数量以及网络连接数量，这都是hystrix自动进行的

其实对于高并发的访问来说，是可以提升性能的

请求合并有很多种级别

（1）global context，tomcat所有调用线程，对一个依赖服务的任何一个command调用都可以被合并在一起，hystrix就传递一个HystrixRequestContext

（2）user request context，tomcat内某一个调用线程，将某一个tomcat线程对某个依赖服务的多个command调用合并在一起

（3）object modeling，基于对象的请求合并，如果有几百个对象，遍历后依次调用每个对象的某个方法，可能导致发起几百次网络请求，基于hystrix可以自动将对多个对象模型的调用合并到一起

请求合并技术的开销有多大

使用请求合并技术的开销就是导致延迟大幅度增加，因为需要一定的时间将多个请求合并起来

发送过来10个请求，每个请求本来大概是2ms可以返回，要把10个请求合并在一个command内，统一一起执行，先后等待一下，5ms

所以说，要考量一下，使用请求合并技术是否合适，如果一个请求本来耗费的时间就比较长，那么进行请求合并，增加一些延迟影响并不大


请求合并技术，不是针对那种访问延时特别低的请求的，比如说你的访问延时本身就比较高，20ms，10个请求合并在一起，25ms，这种情况下就还好

好处在哪里，大幅度削减你的线程池的资源耗费，线程池，10个线程，一秒钟可以执行10个请求，合并在一起，1个线程执行10个请求，10个线程就可以执行100个请求

增加你的吞吐量

减少你对后端服务访问时的网络资源的开销，10个请求，10个command，10次网络请求的开销，1次网络请求的开销了


每个请求就2ms，batch，8~10ms，延迟增加了4~5倍

每个请求本来就30ms~50ms，batch，35ms~55ms，延迟增加不太明显


将多个command请求合并到一个command中执行

请求合并时，可以设置一个batch size，以及elapsed time（控制什么时候触发合并后的command执行）

有两种合并模式，一种是request scope，另一种是global scope，默认是rquest scope，在collapser构造的时候指定scope模式

request scope的batch收集是建立在一个request context内的，而global scope的batch收集是横跨多个request context的

所以对于global context来说，必须确保能在一个command内处理多个requeset context的请求

在netflix，是只用request scope请求合并的，因为默认是用唯一一个request context包含所有的command，所以要做合并，肯定就是request scope

一般请求合并技术，对于那种访问同一个资源的command，但是参数不同，是很有效的


批量查询，HystrixObservableCommand，HystrixCommand+request cache，都是每个商品发起一次网络请求

一个批量的商品过来以后，我们还是多个command的方式去执行，request collapser+request cache，相同的商品还是就查询一次，不同的商品合并到一起通过一个网络请求得到结果


timeout问题解释：开发机上，特别慢，第一次请求的时候，几百毫秒，默认的timeout时长比较短

第二次的时候，访问的速度会快很多，就不会超时了

反应在系统上，第一次启动的时候，会有个别的超时，但是后面就好了，手动将timeout时长设置的大一些

（1）maxRequestsInBatch

控制一个Batch中最多允许多少个request被合并，然后才会触发一个batch的执行

默认值是无限大，就是不依靠这个数量来触发执行，而是依靠时间

HystrixCollapserProperties.Setter()
   .withMaxRequestsInBatch(int value)

（2）timerDelayInMilliseconds

控制一个batch创建之后，多长时间以后就自动触发batch的执行，默认是10毫秒

HystrixCollapserProperties.Setter()
   .withTimerDelayInMilliseconds(int value)

super(Setter.withCollapserKey(HystrixCollapserKey.Factory.asKey("GetProductInfosCollapser"))
				.andCollapserPropertiesDefaults(HystrixCollapserProperties.Setter()
						   .withMaxRequestsInBatch(100)
						   .withTimerDelayInMilliseconds(20))); 

### 100_hystirx的fail-fast与fail-silient两种最基础的容错模式

fail-fast，就是不给fallback降级逻辑，HystrixCommand.run()，直接报错，直接会把这个报错抛出来，给你的tomcat调用线程

fail-silent，给一个fallback降级逻辑，如果HystrixCommand.run()，报错了，会走fallback降级，直接返回一个空值，HystrixCommand，就给一个null

HystrixObservableCommand，Observable.empty()

很少会用fail-fast模式，比较常用的可能还是fail-silent，特别常用，既然都到了fallback里面，肯定要做点降级的事情

### 101_为商品服务接口调用增加stubbed fallback降级机制

stubbed fallback，残缺的降级

用请求中的部分数据拼装成结果，然后再填充一些默认值，返回

比如说你发起了一个请求，然后请求中可能本身就附带了一些信息，如果主请求失败了，走到降级逻辑

在降级逻辑里面，可以将这个请求中的数据，以及部分本地缓存有的数据拼装在一起，再给数据填充一些简单的默认值

然后尽可能将自己有的数据返回到请求方

stubbed，残缺了，比如说应该查询到一个商品信息，里面包含20个字段

请求参数搂出来一两个字段，从本地的少量缓存中比如说，可以搂出来那么两三个字段，最终的话返回的字段可能就五六个，其他的字段都是填充的默认值

数据有残缺

我们主要是演示一下这种模式的使用，你硬要我拿最真实的业务和代码去演示，不可能的

公司真实的项目，真实的业务代码，都极其的复杂

我做过的真实的项目，简化，抽象，仿真，拿出来模拟的业务场景，给大家来讲解

效果肯定是比你纯粹一点业务都没有，全都是一些最基础的demo代码，业务的feel，是怎么用的s

在你自己的项目里去用的话，你就必须结合你自己的业务场景，去思考，stubbed fallback，从请求参数里尽可能提取一些数据，请求参数多给一些

你要考虑到可以将哪些量比较少的数据保存在内存中，提取部分数据

默认的值怎么设置，看起来能稍微靠谱一些

### 102_基于双层嵌套command开发商品服务接口的多级降级机制

多级降级

先降一级，尝试用一个备用方案去执行，如果备用方案失败了，再用最后下一个备用方案去执行

command嵌套command

尝试从备用服务器接口去拉取结果


给大家科普一下，常见的多级降级的做法，有一个操作，要访问MySQL数据库

mysql数据库访问报错，降级，去redis中获取数据

如果说redis又挂了，然后就去从本地ehcache缓存中获取数据

hystrix command fallback语义，很容易就可以实现多级降级的策略


商品服务接口，多级降级的策略

command，fallback，又套了一个command，第二个command其实是第一级降级策略

第二个command的fallback是第二级降级策略


第一级降级策略，可以是

storm，我们之前做storm这块，第一级降级，一般是搞一个storm的备用机房，部署了一套一模一样的拓扑，如果主机房中的storm拓扑挂掉了，备用机房的storm拓扑定顶上

如果备用机房的storm拓扑也挂了

第二级降级，可能就降级成用mysql/hbase/redis/es，手工封装的一套，按分钟粒度去统计数据的系统

第三季降级，离线批处理去做，hdfs+spark，每个小时执行一次数据统计，去降级

特别复杂，重要的系统，肯定是要搞好几套备用方案的，一个方案死了，立即上第二个方案，而且要尽量做到是自动化的


商品接口拉取

主流程，访问的商品服务，是从主机房去访问的，服务，如果主机房的服务出现了故障，机房断电，机房的网络负载过高，机器硬件出了故障

第一级降级策略，去访问备用机房的服务

第二级降级策略，用stubbed fallback降级策略，比较常用的，返回一些残缺的数据回去

### 103_基于facade command开发商品服务接口的手动降级机制

手动降级

你写一个command，在这个command它的主流程中，根据一个标识位，判断要执行哪个流程

可以执行主流程，command，也可以执行一个备用降级的command

一般来说，都是去执行一个主流程的command，如果说你现在知道有问题了，希望能够手动降级的话，动态给服务发送个请求

在请求中修改标识位，自动就让command以后都直接过来执行备用command

3个command，套在最外面的command，是用semaphore信号量做限流和资源隔离的，因为这个command不用去care timeout的问题，嵌套调用的command会自己去管理timeout超时的


商品服务接口的手动降级的方案

主流程还是去走GetProductInfoCommand，手动降级的方案，比如说是从某一个数据源，自己去简单的获取一些数据，尝试封装一下返回

手动降级的策略，就比较low了，调用别人的接口去获取数据的，业务逻辑的封装

主流程有问题，那么可能你就需要立即自己写一些逻辑发布上去，从mysql数据库的表中获取一些数据去返回，手动调整一下降级标识，做一下手动降级

### 104_生产环境中的线程池大小以及timeout超时时长优化经验总结

timeout和线程池的超时关系

![](C:\Users\zy199005\Desktop\中华石杉\images\java\06\10401.png)

生产环境里面，一个是线程池的大小怎么设置，timeout时长怎么

不合理的话，问题还是很大的


在生产环境中部署一个短路器，一开始需要将一些关键配置设置的大一些，比如timeout超时时长，线程池大小，或信号量容量

然后逐渐优化这些配置，直到在一个生产系统中运作良好

（1）一开始先不要设置timeout超时时长，默认就是1000ms，也就是1s
（2）一开始也不要设置线程池大小，默认就是10
（3）直接部署hystrix到生产环境，如果运行的很良好，那么就让它这样运行好了
（4）让hystrix应用，24小时运行在生产环境中
（5）依赖标准的监控和报警机制来捕获到系统的异常运行情况
（6）在24小时之后，看一下调用延迟的占比，以及流量，来计算出让短路器生效的最小的配置数字
（7）直接对hystrix配置进行热修改，然后继续在hystrix dashboard上监控
（8）看看修改配置后的系统表现有没有改善

下面是根据系统表现优化和调整线程池大小，队列大小，信号量容量，以及timeout超时时间的经验

假设对一个依赖服务的高峰调用QPS是每秒30次

一开始如果默认的线程池大小是10

我们想的是，理想情况下，每秒的高峰访问次数 * 99%的访问延时 + buffer = 30 * 0.2 + 4 = 10线程，10个线程每秒处理30次访问应该足够了，每个线程处理3次访问

此时，我们合理的timeout设置应该为300ms，也就是99.5%的访问延时，计算方法是，因为判断每次访问延时最多在250ms（TP99如果是200ms的话），再加一次重试时间50ms，就是300ms，感觉也应该足够了

因为如果timeout设置的太多了，比如400ms，比如如果实际上，在高峰期，还有网络情况较差的时候，可能每次调用要耗费350ms，也就是达到了最长的访问时长

那么每个线程处理2个请求，就会执行700ms，然后处理第三个请求的时候，就超过1秒钟了，此时会导致线程池全部被占满，都在处理请求

这个时候下一秒的30个请求再进来了，那么就会导致线程池已满，拒绝请求的情况，就会调用fallback降级机制

因此对于短路器来说，timeout超时一般应该设置成TP99.5，比如设置成300ms，那么可以确保说，10个线程，每个线程处理3个访问，每个访问最多就允许执行300ms，过时就timeout了

这样才能保证说每个线程都在1s内执行完，才不会导致线程池被占满，然后后续的请求过来大量的reject

对于线程池大小来说，一般应该控制在10个左右，20个以内，最少5个，不要太多，也不要太少


大家可能会想，每秒的高峰访问次数是30次，如果是300次，甚至是3000次，30000次呢？？？

30000 * 0.2 = 6000 + buffer = 6100，一个服务器内一个线程池给6000个线程把

如果你一个依赖服务占据的线程数量太多的话，会导致其他的依赖服务对应的线程池里没有资源可以用了

6000 / 20 = 300台虚拟机也是ok的

虚拟机，4个cpu core，4G内存，虚拟机，300台

物理机，十几个cpu core，几十个G的内存，5~8个虚拟机，300个虚拟机 = 50台物理机


你要真的说是，你的公司服务的用户量，或者数据量，或者请求量，真要是到了每秒几万的QPS，

3万QPS，60 * 3 = 180万访问量，1800，1亿8千，1亿，10个小时，10亿的访问量，app，系统

几十台服务器去支撑，我觉得很正常

QPS每秒在几千都算多的了

### 105_生产环境中的线程池自动扩容与缩容的动态资源分配经验

可能会出现一种情况，比如说我们的某个依赖，在高峰期，需要耗费100个线程，但是在那个时间段，刚好其他的依赖的线程池其实就维持一两个就可以了

但是，如果我们都是设置死的，每个服务就给10个线程，那就很坑，可能就导致有的服务在高峰期需要更多的资源，但是没资源了，导致很多的reject

但是其他的服务，每秒钟就易一两个请求，结果也占用了10个线程，占着茅坑不拉屎

做成弹性的线程资源调度的模式

刚开始的时候，每个依赖服务都是给1个线程，3个线程，但是我们允许说，如果你的某个线程池突然需要大量的线程，最多可以到100个线程

如果你使用了100个线程，高峰期过去了，自动将空闲的线程给释放掉

（1）coreSize

设置线程池的大小，默认是10

HystrixThreadPoolProperties.Setter()
   .withCoreSize(int value)

（2）maximumSize

设置线程池的最大大小，只有在设置allowMaximumSizeToDivergeFromCoreSize的时候才能生效

默认是10

HystrixThreadPoolProperties.Setter()
   .withMaximumSize(int value)

（5）keepAliveTimeMinutes

设置保持存活的时间，单位是分钟，默认是1

如果设置allowMaximumSizeToDivergeFromCoreSize为true，那么coreSize就不等于maxSize，此时线程池大小是可以动态调整的，可以获取新的线程，也可以释放一些线程

如果coreSize < maxSize，那么这个参数就设置了一个线程多长时间空闲之后，就会被释放掉

HystrixThreadPoolProperties.Setter()
   .withKeepAliveTimeMinutes(int value)

（6）allowMaximumSizeToDivergeFromCoreSize

允许线程池大小自动动态调整，设置为true之后，maxSize就生效了，此时如果一开始是coreSize个线程，随着并发量上来，那么就会自动获取新的线程，但是如果线程在keepAliveTimeMinutes内空闲，就会被自动释放掉

默认是fales

HystrixThreadPoolProperties.Setter()
   .withAllowMaximumSizeToDivergeFromCoreSize(boolean value)


生产环境中，这块怎么玩儿的

也是根据你的服务的实际的运行的情况切看的，比如说你发现某个服务，平时3个并发QPS就够了，高峰期可能要到30个

那么你就可以给设置弹性的资源调度


因为你可能一个服务会有多个线程池，你要计算好，每个线程池的最大的大小加起来不能过大，30个依赖，30个线程池，每个线程池最大给到30,900个线程，很坑的


还有一种模式，就是说让多个依赖服务共享一个线程池，我们不推荐，多个依赖服务就做不到资源隔离，互相之间会影响的

1，coreSize

### 106_hystrix的metric统计相关的各种高阶配置讲解

1、为什么需要监控与报警？

HystrixCommand执行的时候，会生成一些执行耗时等方面的统计信息。这些信息对于系统的运维来说，是很有帮助的，因为我们通过这些统计信息可以看到整个系统是怎么运行的。hystrix对每个command key都会提供一份metric，而且是秒级统计粒度的。

这些统计信息，无论是单独看，还是聚合起来看，都是很有用的。如果将一个请求中的多个command的统计信息拿出来单独查看，包括耗时的统计，对debug系统是很有帮助的。聚合起来的metric对于系统层面的行为来说，是很有帮助的，很适合做报警或者报表。hystrix dashboard就很适合。

2、hystrix的事件类型

对于hystrix command来说，只会返回一个值，execute只有一个event type，fallback也只有一个event type，那么返回一个SUCCESS就代表着命令执行的结束

对于hystrix observable command来说，多个值可能被返回，所以emit event代表一个value被返回，success代表成功，failure代表异常

（1）execute event type

EMIT					observable command返回一个value
SUCCESS 				完成执行，并且没有报错
FAILURE					执行时抛出了一个异常，会触发fallback
TIMEOUT					开始执行了，但是在指定时间内没有完成执行，会触发fallback
BAD_REQUEST				执行的时候抛出了一个HystrixBadRequestException
SHORT_CIRCUITED			短路器打开了，触发fallback
THREAD_POOL_REJECTED	线程成的容量满了，被reject，触发fallback
SEMAPHORE_REJECTED		信号量的容量满了，被reject，触发fallback

（2）fallback event type

FALLBACK_EMIT			observable command，fallback value被返回了
FALLBACK_SUCCESS		fallback逻辑执行没有报错
FALLBACK_FAILURE		fallback逻辑抛出了异常，会报错
FALLBACK_REJECTION		fallback的信号量容量满了，fallback不执行，报错
FALLBACK_MISSING		fallback没有实现，会报错

（3）其他的event type

EXCEPTION_THROWN		command生命自周期是否抛出了异常
RESPONSE_FROM_CACHE		command是否在cache中查找到了结果
COLLAPSED				command是否是一个合并batch中的一个

（4）thread pool event type

EXECUTED				线程池有空间，允许command去执行了
REJECTED 				线程池没有空间，不允许command执行，reject掉了

（5）collapser event type

BATCH_EXECUTED			collapser合并了一个batch，并且执行了其中的command
ADDED_TO_BATCH			command加入了一个collapser batch
RESPONSE_FROM_CACHE		没有加入batch，而是直接取了request cache中的数据

3、metric storage

metric被生成之后，就会按照一段时间来存储，存储了一段时间的数据才会推送到其他系统中，比如hystrix dashboard

另外一种方式，就是每次生成metric就实时推送metric流到其他地方，但是这样的话，会给系统带来很大的压力

hystrix的方式是将metric写入一个内存中的数据结构中，在一段时间之后就可以查询到

hystrix 1.5x之后，采取的是为每个command key都生成一个start event和completion event流，而且可以订阅这个流。每个thread pool key也是一样的，包括每个collapser key也是一样的。

每个command的event是发送给一个线程安全的RxJava中的rx.Subject，因为是线程安全的，所以不需要进行线程同步

因此每个command级别的，threadpool级别的，每个collapser级别的，event都会发送到对应的RxJava的rx.Subject对象中。这些rx.Subject对象接着就会被暴露出Observable接口，可以被订阅。

5、metric统计相关的配置

（1）metrics.rollingStats.timeInMilliseconds

设置统计的rolling window，单位是毫秒，hystrix只会维持这段时间内的metric供短路器统计使用

这个属性是不允许热修改的，默认值是10000，就是10秒钟

HystrixCommandProperties.Setter()
   .withMetricsRollingStatisticalWindowInMilliseconds(int value)

（2）metrics.rollingStats.numBuckets

该属性设置每个滑动窗口被拆分成多少个bucket，而且滑动窗口对这个参数必须可以整除，同样不允许热修改

默认值是10，也就是说，每秒钟是一个bucket

随着时间的滚动，比如又过了一秒钟，那么最久的一秒钟的bucket就会被丢弃，然后新的一秒的bucket会被创建

HystrixCommandProperties.Setter()
   .withMetricsRollingStatisticalWindowBuckets(int value)

（3）metrics.rollingPercentile.enabled

控制是否追踪请求耗时，以及通过百分比方式来统计，默认是true

HystrixCommandProperties.Setter()
   .withMetricsRollingPercentileEnabled(boolean value)

（4）metrics.rollingPercentile.timeInMilliseconds

设置rolling window被持久化保存的时间，这样才能计算一些请求耗时的百分比，默认是60000，60s，不允许热修改

相当于是一个大的rolling window，专门用于计算请求执行耗时的百分比

HystrixCommandProperties.Setter()
   .withMetricsRollingPercentileWindowInMilliseconds(int value)

（5）metrics.rollingPercentile.numBuckets

设置rolling percentile window被拆分成的bucket数量，上面那个参数除以这个参数必须能够整除，不允许热修改

默认值是6，也就是每10s被拆分成一个bucket

HystrixCommandProperties.Setter()
   .withMetricsRollingPercentileWindowBuckets(int value)

（6）metrics.rollingPercentile.bucketSize

设置每个bucket的请求执行次数被保存的最大数量，如果再一个bucket内，执行次数超过了这个值，那么就会重新覆盖从bucket的开始再写

举例来说，如果bucket size设置为100，而且每个bucket代表一个10秒钟的窗口，但是在这个bucket内发生了500次请求执行，那么这个bucket内仅仅会保留100次执行

如果调大这个参数，就会提升需要耗费的内存，来存储相关的统计值，不允许热修改

默认值是100

HystrixCommandProperties.Setter()
   .withMetricsRollingPercentileBucketSize(int value)

（7）metrics.healthSnapshot.intervalInMilliseconds

控制成功和失败的百分比计算，与影响短路器之间的等待时间，默认值是500毫秒

HystrixCommandProperties.Setter()
   .withMetricsHealthSnapshotIntervalInMilliseconds(int value)

### 107_hystrix dashboard可视化分布式系统监控环境部署

1、安装metrics stream

<dependency>
    <groupId>com.netflix.hystrix</groupId>
    <artifactId>hystrix-metrics-event-stream</artifactId>
    <version>1.4.10</version>
</dependency>

@Bean
public ServletRegistrationBean indexServletRegistration() {
    ServletRegistrationBean registration = new ServletRegistrationBean(new HystrixMetricsStreamServlet());
    registration.addUrlMappings("/hystrix.stream");
    return registration;
}

2、安装gradle

类似于maven，一种java里面的打包和构建的工具，hystrix是用gradle去管理打包和构建的

配置环境变量，GRADLE_HOME
配置PATH，%GRADLE_HOME%/bin

gradle -v

3、下载tomcat7

解压缩

4、下载hystrix-dashboard的war包

cp hystrix-dashboard-*.war apache-tomcat-7.*/webapps/hystrix-dashboard.war

5、下载turbin

下载并解压缩

cp turbine-web/build/libs/turbine-web-*.war ./apache-tomcat-7.*/webapps/turbine.war

在/WEB-INF/classes下放置配置文件

config.properties

turbine.ConfigPropertyBasedDiscovery.default.instances=localhost
turbine.instanceUrlSuffix=:8081/hystrix.stream

turbin是用来监控一个集群的，可以将一个集群的所有机器都配置在这里

6、启动我们的服务

7、启动tomcat中的hystrix dashboard和turbin

localhost:8080/hystrix-dashboard

http://localhost:8081/hystrix.stream，监控单个机器
http://localhost:8080/turbine/turbine.stream，监控整个集群

8、发送几个请求，看看效果

9、hystrix dashboard

hystrix的dashboard可以支持实时监控metric

netflix开始用这个dashboard的时候，大幅度优化了工程运维的操作，帮助节约了恢复系统的时间。大多数生产系统的故障持续时间变得很短，而且影响幅度小了很多，主要是因为hystrix dashborad提供了可视化的监控。

截图说明，dashboard上的指标都是什么？

圆圈的颜色和大小代表了健康状况以及流量，折线代表了最近2分钟的请求流量

集群中的机器数量，请求延时的中位数以及平均值

最近10秒内的异常请求比例，请求QPS，每台机器的QPS，以及整个集群的QPS

断路器的状态

最近一分钟的请求延时百分比，TP90，TP99，TP99.5

几个有颜色的数字，代表了最近10秒钟的统计，以1秒钟为粒度

成功的请求数量，绿颜色的数字; 短路的请求数量，蓝色的数字; timeout超时的请求数量，黄色的数字; 线程池reject的请求数量，紫色的数字; 请求失败，抛出异常的请求数量，红色的数字

### 108_生产环境中的hystrix分布式系统的工程运维经验总结

如果发现了严重的依赖调用延时，先不用急着去修改配置，如果一个command被限流了，可能本来就应该限流

在netflix早期的时候，经常会有人在发现短路器因为访问延时发生的时候，去热修改一些皮遏制，比如线程池大小，队列大小，超时时长，等等，给更多的资源，但是这其实是不对的

如果我们之前对系统进行了良好的配置，然后现在在高峰期，系统在进行线程池reject，超时，短路，那么此时我们应该集中精力去看底层根本的原因，而不是调整配置

为什么在高峰期，一个10个线程的线程池，搞不定这些流量呢？？？代码写的太烂了，异步，更好的算法

千万不要急于给你的依赖调用过多的资源，比如线程池大小，队列大小，超时时长，信号量容量，等等，因为这可能导致我们自己对自己的系统进行DDOS攻击

疯狂的大量的访问你的机器，最后给打垮

举例来说，想象一下，我们现在有100台服务器组成的集群，每台机器有10个线程大小的线程池去访问一个服务，那么我们对那个服务就有1000个线程资源去访问了

在正常情况下，可能只会用到其中200~300个线程去访问那个后端服务

但是如果再高峰期出现了访问延时，可能导致1000个线程全部被调用去访问那个后端服务，如果我们调整到每台服务器20个线程呢？

如果因为你的代码等问题导致访问延时，即使有20个线程可能还是会导致线程池资源被占满，此时就有2000个线程去访问后端服务，可能对后端服务就是一场灾难

这就是断路器的作用了，如果我们把后端服务打死了，或者产生了大量的压力，有大量的timeout和reject，那么就自动短路，一段时间后，等流量洪峰过去了，再重启访问

简单来说，让系统自己去限流，短路，超时，以及reject，直到系统重新变得正常了


就是不要随便乱改资源配置，不要随便乱增加线程池大小，等待队列大小，异常情况是正常的

### 109_在spring cloud环境中使用hystrix进行高可用保护的demo 

我们其实在spring cloud的环境中，肯定是结合feign来使用hystrix的，我们肯定不会直接自己手动去创建一个HystrixCommand 

**pom.xml** 

<dependency>

<groupId>org.springframework.cloud</groupId>

<artifactId>spring-cloud-starter-hystrix</artifactId>

</dependency> 

**application.yml** 

feign:

 hystrix:

enabled: true 

**Application启动类** 

@EnableCircuitBreaker 

**在feign接口中加入hystrix的降级机制** 

@FeignClient(name = “ServiceA”, fallback = ServiceAFallback.class)

public interface ServiceAClient extends ServiceAInterface { 

static class ServiceAFallback implements ServiceAClient { 

public String sayHello() {

// 降级机制

} 

} 

} 

在application.yml中加入hystrix的配置 

hystrix:

 command:

default:

 execution:

  isolation:

   thread:

​    timeoutInMilliseconds: 1000

 circuitBreaker:

  requestVolumeThreshold: 4 

默认情况下，hystrix的group name就是ServiceA这种服务名称，也就是说你要调用一个服务的话，那么针对每个服务就是一个线程池 

然后针对每个接口方法，对应都会有一个自动生成的Command，CommandKey是接口名称#接口方法名称 

测试一下： 

默认情况下，hystrix的timeout超时时间是100s，所以我们把ServiceA的接口设置延迟几秒钟 

发送个请求就会看到直接超时，然后接口调用走降级机制了 

我们设置了断路器打开的条件，是如果短时间内请求超过4次，而且50%都是失败的话，那么就会打开断路器 

就是spring cloud、spring boot这种东西，有一点很恶心，你如果公司里的生产版本，用了一个比较稳定的版本之后，轻易不要升级，很多时候一旦升级，哪怕就是从Edgware.SR1升级到Edgware.SR3也可能导致一些问题 

看到的一个现象 

我们发现说，默认情况下，重试机制，如果你不配置的话，人家默认也会给你进行重试，而且默认的重试机制是什么呢？就是我们之前在自定义配置中加入的一个Retryer，默认就会重试5次。我们要取消那个Retryer 

默认的情况，就是说发送一次请求，默认情况下（如果什么重试机制都没配置的话），就会发起仅仅一次请求，如果这次请求不ok，超时，就会走hystrix的降级机制 

如果短时间内，连续咔咔咔发送多个请求，都失败了，4次请求50%都失败了，那么就会走熔断，后面都不会去请求了，直接走降级。熔断，要满足熔断的要求，其实通过手工挺难演示的，咱们手速毕竟不快。 

熔断也不演示了，其实就是在后面我们先看看源码，看看熔断器是怎么工作的，看完熔断器的原理之后，我们看到哪些参数在里面进行控制，接着我们再来做这个实验 

**整合了feign和hystrix了** 

hystrix，隔离、熔断、降级 

超时 -> 降级 

隔离 -> 你每次调用一个接口，其实都是走的那个接口的一个自己的线程池，是根据什么的来的呢？@FeignClient里的value默认就是hystrix的groupName，就控制一个服务接口就会生成一个线程池，对那个服务里所有接口的调用，全部都是走这个服务自己的线程池的 

通过线程池就完成了隔离 

**打开hystrix的监控** 

我们希望能够有一个界面，可以看到你的hystrix相关的监控统计，比如请求数量、异常数量、每秒的请求数量 

在服务B中加入这个东西 

<dependency>

<groupId>org.springframework.boot</groupId>

<artifactId>spring-boot-starter-actuator</artifactId>

<version>1.5.13.RELEASE</version>

</dependency> 

此时访问一个url链接： 

http://localhost:9090/hystrix.stream，就可以看到hystrix输出的stream统计数据，就会返回这里面服务B的hystrix相关的一些统计信息，比如说调用次数之类的 

再搞一个hystrix-dashboard项目 

<dependency>

<groupId>org.springframework.cloud</groupId>

<artifactId>spring-cloud-starter-hystrix-dashboard</artifactId>

</dependency>

<dependency>

<groupId>org.springframework.cloud</groupId>

<artifactId>spring-cloud-starter-hystrix</artifactId>

</dependency>

<dependency>

<groupId>org.springframework.boot</groupId>

<artifactId>spring-boot-starter-actuator</artifactId>

<version>1.5.13.RELEASE</version>

</dependency>

 

@SpringBootApplication

@EnableHystrixDashboard

public class Application { 

public static void main(String[] args) { 

} 

} 

访问默认的hystrix dashboard地址，http://localhost:8082/hystrix 

看到了一个界面，让你输入要监控的服务实例的地址，你输入：http://localhost:9090/hystrix.stream即可 

解释一下这个仪表盘的意思： 

有个圆圈，那个是代表了服务的流量，如果圆圈越大，就代表了流量越大 

圆圈下面有一条线，是最近2分钟内的流量变化情况 

bad request，你要发送请求的时候，你发送的请求本身都是坏的，都是有问题的，就比如说你发送的请求的请求方法（PUT），人家接口接收的是GET 

有两排数字，左边一排，从上到下依次是：成功的请求数量、熔断的请求数量。右边一排，从上到小，依次是：超时请求数量、线程池拒绝的请求数量、异常的请求数量 

然后有一个百分比数字，那个是最近10秒钟的失败的请求所占的百分比 

Host：这个是服务实例的每秒的请求数量，也就是所谓的QPS了

Cluster：这个是服务的（包含所有服务实例的）的每秒的请求数量，看的是服务整体的QPS 

Circuit：这个是断路器的状态，打开或者关闭 

Hosts：这个是说一个服务有多少个服务实例 

Median（请求延时的中位数，请求的中位数延时是100ms）、Mean（请求延时的平均数，150ms）、90th（TP90，90%的请求都是50ms）、99th（TP99，99%的请求，190ms）、99.5th（TP99.5，99.5%的请求，300ms） 

Threadpool：这个是记录线程池内部的一些情况，服务B调用服务A的专用的线程池的一些配置和情况，这里就可以让我们去看到服务与服务之间的调用的很多关键的统计信息 

请求次数（流量大小）、QPS、请求时延、对其他服务的调用QPS 

**基于turbin来监控服务集群** 

如果你的服务B搞了一个集群的话，服务B部署多台机器的话，就会组成一个集群，直接用hystrix dashboard只能监控一台机器，如果一次性要监控一个集群的话，引入一个单独的聚合一个服务的集群中各个机器的统计信息的turbine服务 

<dependency>

<groupId>org.springframework.boot</groupId>

<artifactId>spring-boot-starter-actuator</artifactId>

<version>1.5.13.RELEASE</version>

</dependency> 

<dependency>

<groupId>org.springframework.cloud</groupId>

<artifactId>spring-cloud-starter-turbine</artifactId>

</dependency>

 

@SpringBootApplication

@EnableEurekaClient

@EnableTurbine

public class TurbineApplication {

  public static void main(String[] args) {

​    SpringApplication.run(TurbineApplication.class, args);

  }

} 

application.yml 

spring:

 application:

  name: hystrix-turbine 

server:

 port: 2002 

management:

 port: 2003 

eureka:

 instance:

  hostname: localhost

 client:

  serviceUrl:

   defaultZone: http://localhost:8761/eureka   

turbine:

 appConfig: ServiceB

 clusterNameExpression: "'default'"

打开hystrix监控的面板：输入这个turbine的地址，http://localhost:2002/turbine.stream
就是这个turbine服务，肯定是从eureka中加载注册表，然后的话呢，就可以根据我们配置的要监控的服务，对服务的各个机器的hystrix统计进行一个聚合 

### 110_全网稀缺的讲解：feign与hystrix整合的时候各种参数咋配置？

ribbon和hystrix整合的话，那么使用的是@HystrixCommand，这个东东里面可以放hystrix的各种配置，但是实际生产环境里，根本不这么玩儿，不会直接用ribbon + RestTemplate，feign 

feign + hystrix 

在哪儿去配置各个服务的hystrix相关的配置呢？？？ 

全网稀缺，feign + hystrix怎么配置，怎么玩儿，很多人没告诉你 

hystrix:

 command:

  ServiceAClient#sayHello(Long,String,Integer):

   execution:

​    isolation:

​     thread:

​      timeoutInMilliseconds: 100

​    circuitBreaker:

​     requestVolumeThreshold: 4 

回顾一遍，之前netflix hystrix的原生的相关的参数 

hystrix:

 command:

  default:

   execution:

​    isolation:

​     strategy: THREAD

​     thread:

​      timeoutInMilliseconds: 1000

​      interruptOnTimeout: true

​    semaphore:

​     maxConcurrentRequests: 10

​    timeout: 

​     enabled: true

   circuitBreaker:

​    enabled: true

​    requestVolumeThreshold: 20

​    sleepWindowInMilliseconds: 5000

​    errorThresholdPercentage: 50

线程池相关的参数

高峰期每秒的请求数量 / 1000毫秒 / TP99请求延时 + buffer空间

比如说处理一个请求，要50ms，TP99，99%的请求里处理一个请求耗时最长是50ms

我们给一点buffer空间，10ms，60ms

一秒钟一个线程可以处理多少个请求呢？1000 / 60 = 16，一个线程一秒钟可以处理16个请求

高峰期，每秒最多1200个请求，一个线程每秒可以处理16个请求，需要多少个线程才能处理每秒1200个请求呢？1200 / 16 = 75，最多需要75个线程，每个线程每秒处理16个请求，75个线程每秒才可以处理1200个请求

最多需要多少个线程，就是这样子算出来

服务B -> 服务A 

服务B调用服务A的线程池需要多少个线程呢？

高峰期，服务B最多要调用服务A每秒钟1200次，服务A处理一个请求是60ms，服务B每次调用服务A的时候，用一个线程发起一次请求，那么这个服务B的这个线程，要60ms才能返回

服务B而言，一个线程对服务A发起一次请求需要60ms，一个线程每秒钟可以请求服务A达到16次，但是现在服务B每秒钟需要请求服务A达到1200次，那么服务B就需要75个线程，在高峰期并发请求服务A，才可以完成每秒1200次的调用

服务B，部署多台机器，每台机器调用服务A的线程池有10个线程，比如说搞个10个线程，一共部署10台机器，那么服务B调用服务A的线程数量，一共有100个线程，轻轻松松可以支撑高峰期调用服务A的1200次的场景

每个线程调用服务A一次，耗时60ms，每个线程每秒可以调用服务A一共是16次，100个线程，每秒最多可以调用服务A是1600次，高峰的时候只要支持调用服务A的1200次就可以了，所以这个机器部署就绰绰有余了

我个人给大家一个建议，一般来说，hystrix的默认配置可以不用去修改，上生产环境，能不改就不改，最好是在线上跑一端时间之后，根据线上系统具体的负载去修改相关的配置

 hystrix.threadpool.default.coreSize：线程池大小，默认10
hystrix.threadpool.default.maximumSize：线程池最大大小，默认10
hystrix.threadpool.default.allowMaximumSizeToDivergeFromCoreSize：是否允许动态调整线程数量，默认false，只有设置为true了，上面的maximumSize才有效
hystrix.threadpool.default.keepAliveTimeMinutes ：默认是1，超出coreSize的线程，空闲1分钟后释放掉

hystrix.threadpool.default.maxQueueSize 默认－1，不能动态修改
hystrix.threadpool.default.queueSizeRejectionThreshold 可以动态修改，默认是5，先进入请求队列，然后再由线程池执行  

执行相关的属性： 

```
hystrix.command.default.execution.isolation.strategy：隔离策略，默认Thread，可以选择Semaphore信号量
 
hystrix.command.default.execution.isolation.thread.timeoutInMilliseconds：超时时间，默认1000ms
hystrix.command.default.execution.timeout.enabled：是否启用超时，默认ture
hystrix.command.default.execution.isolation.thread.interruptOnTimeout：超时的时候是否中断执行，默认true 
 
hystrix.command.default.execution.isolation.semaphore.maxConcurrentRequests：信号量隔离策略下，允许的最大并发请求数量，默认10
 
降级相关的属性
 
hystrix.command.default.fallback.enabled 默认true
 
熔断相关的属性
 
hystrix.command.default.circuitBreaker.enabled：是否启用熔断器默认true
hystrix.command.default.circuitBreaker.requestVolumeThreshold：10秒钟内，请求数量达到多少才能去尝试触发熔断，默认20
hystrix.command.default.circuitBreaker.errorThresholdPercentage：10秒钟内，请求数量达到20，同时异常比例达到50%，就会触发熔断，默认50
hystrix.command.default.circuitBreaker.sleepWindowInMilliseconds：触发熔断之后，5s内直接拒绝请求，走降级逻辑，5s后尝试half-open放过少量流量试着恢复，默认5000
hystrix.command.default.circuitBreaker.forceOpen：强制打开熔断器
hystrix.command.default.circuitBreaker.forceClosed：强制关闭熔断器
 
metric相关的属性
 
hystrix.threadpool.default.metrics.rollingStats.timeInMillisecond：线程池统计指标的时间，默认10000，就是10s
hystrix.threadpool.default.metrics.rollingStats.numBuckets：将rolling window划分为n个buckets，默认10
hystrix.command.default.metrics.rollingStats.timeInMilliseconds：command的统计时间，熔断器是否打开会根据1个rolling window的统计来计算。若rolling window被设为10000毫秒，则rolling window会被分成n个buckets，每个bucket包含success，failure，timeout，rejection的次数的统计信息。默认10000
hystrix.command.default.metrics.rollingStats.numBuckets 设置一个rolling window被划分的数量，若numBuckets＝10，rolling window＝10000，那么一个bucket的时间即1秒。必须符合rolling window % numberBuckets == 0。默认10
hystrix.command.default.metrics.rollingPercentile.enabled 执行时是否enable指标的计算和跟踪，默认true
hystrix.command.default.metrics.rollingPercentile.timeInMilliseconds 设置rolling percentile window的时间，默认60000
hystrix.command.default.metrics.rollingPercentile.numBuckets 设置rolling percentile window的numberBuckets。逻辑同上。默认6
hystrix.command.default.metrics.rollingPercentile.bucketSize 如果bucket size＝100，window＝10s，若这10s里有500次执行，只有最后100次执行会被统计到bucket里去。增加该值会增加内存开销以及排序的开销。默认100
hystrix.command.default.metrics.healthSnapshot.intervalInMilliseconds 记录health 快照（用来统计成功和错误绿）的间隔，默认500ms
 
 
高阶特性相关的参数
 
hystrix.command.default.requestCache.enabled 默true
 
hystrix.command.default.requestLog.enabled 记录日志到HystrixRequestLog，默认true
 
hystrix.collapser.default.maxRequestsInBatch 单次批处理的最大请求数，达到该数量触发批处理，默认Integer.MAX_VALUE
hystrix.collapser.default.timerDelayInMilliseconds 触发批处理的延迟，也可以为创建批处理的时间＋该值，默认10
hystrix.collapser.default.requestCache.enabled 是否对HystrixCollapser.execute() and HystrixCollapser.queue()的cache，默认true
```

### 111_spring cloud环境下的feign与hystrix整合的核心原理图

feign与hystrix整合的核心原理

![](C:\Users\zy199005\Desktop\中华石杉\images\java\06\11101.png) 

 

eureka + ribbon + feign 

eureka + ribbon：ribbon的ILoadBalancer里的ServerList会自动每隔30秒从eureka client里去获取本地的最新的注册表，根据注册表里的服务的server list，来进行负载均衡 

ribbon + feign：feign在发起一个请求之前，一定会使用ribbon的ILoadBalancer去进行负载均衡，从一堆server list中获取一个server，然后再针对哪个server发起请求 

feign + hystrix：feign发起请求的时候，会基于hystrix来进行各个服务的隔离、超时、异常、限流、降级、熔断 

hystrix + turbine + dashboard：来看到一个最最基础的微服务架构的仪表盘，请求次数、请求延时 

feign + hystrix整合的核心原理 

feign的核心原理是什么？？ 

@EnableFeignClients注解 -> 扫描 -> @FeignClient注解 -> 针对接口生成动态代理 -> 基于Contract解析spring mvc的注解 -> 请求都是基于feign动态代理 -> 使用ribbon进行负载均衡 -> 根据之前解析出来的spring mvc注解里的信息生成已给请求url -> 针对负载均衡选择出来的server发出一个http请求 

hystrix跟feign整合以后 

短路，熔断，circuit breaker 

大胆的猜测一下，feign和hystirx整合，feign动态代理里面一定是有一些hystrix相关的代码，然后请求走feign动态代理的时候，就会基于hystrix command发送请求，实现服务间调用的隔离、限流、超时、异常、降级、熔断、统计。 

hystirx的服务间调用的统计 -> dashboard进行可视化的监控

### 112_启用hystrix之后feign的动态代理创建的过程有什么变化呢？

启用hystrix之后生成feign动态代理的过程

![](C:\Users\zy199005\Desktop\中华石杉\images\java\06\11201.png)

我们来找一个生成feign动态代理的关键地方，打入断点，启动服务B，来观察，如果你启用hystrix之后，生成动态代理的时候有什么区别 

HystrixTargeter来入手，打一个断点，跟进去看看 

一边断点调试源码，一边在word里写源码的分析，一边在processon画图 

​          if (!(feign instanceof feign.hystrix.HystrixFeign.Builder)) {

​               return feign.target(target);

​          } 

之前给大家说过，如果没有启用hystirx的话，那么默认的Builder是原生的Feign.Builder，但是如果启用了hystrix之后呢？feign.hystrix.HystrixFeign，Builder就是HystrixFeign.Builder了。。。。 

fallback，我们之前其实没有设置，所以在这里的fallback就是一个空 

class com.zhss.service.ServiceAClient$ServiceAClientFallbackFactory 

我们设置的那个FallbackFactory，负责在每次超时、拒绝（线程池满）、异常的时候，create()方法返回一个降级机制的对象 

​          FallbackFactory<? extends T> fallbackFactory = (FallbackFactory<? extends T>)

​               getFromContext("fallbackFactory", feignClientName, context, fallbackFactoryClass, FallbackFactory.class); 

从服务（ServiceA）的独立的spring容器中取出来一个独立的FallbackFactory，调用每个服务的时候，他对应的FallbackFactory都是存在于那个服务关联的独立的spring容器中的 

​          /* We take a sample fallback from the fallback factory to check if it returns a fallback

​          that is compatible with the annotated feign interface. */

​          Object exampleFallback = fallbackFactory.create(new RuntimeException());

​          Assert.notNull(exampleFallback,

​               String.format(

​               "Incompatible fallbackFactory instance for feign client %s. Factory may not produce null!",

​                    feignClientName));

​    **if** (!target.type().isAssignableFrom(exampleFallback.getClass())) {

​      **throw** **new** IllegalStateException(

​                    String.format(

​                         "Incompatible fallbackFactory instance for feign client %s. Factory produces instances of '%s', but should produce instances of '%s'",

​                         feignClientName, exampleFallback.getClass(), target.type()));

​          } 

上来不管三七二十一，就是用你的FallbackFactory去创建一个Fallback对象出来，用来检查你自己定义的那个Fallback工厂是否ok，你的Fallback工厂是否返回了一个Fallback对象，不能为空的。。你定义的Fallback对象必须是实现了ServiceAClient接口的，检查你的Fallback对象的类型 

​          return builder.target(target, fallbackFactory); 

生成动态代理，Builder的target()方法，传入进去fallbackFactory 

HystrixFeign.Builder的target()方法 

   super.invocationHandlerFactory(new InvocationHandlerFactory() {

​    @Override public InvocationHandler create(Target target,

​      Map<Method, MethodHandler> dispatch) {

​     return new HystrixInvocationHandler(target, dispatch, setterFactory, nullableFallbackFactory);

​    }

   });

   super.contract(new HystrixDelegatingContract(contract));

   return super.build(); 

最终实际用来去处理这个请求的，其实是InvocationHandler，他是JDK动态代理的核心，基于JDK动态代理机制，生成一个动态代理的对象之后，对这个对象所有的方法调用，都会走关联的那个InvocationHandler 

return new HystrixInvocationHandler(target, dispatch, setterFactory, nullableFallbackFactory); 

target：你要调用的服务

dispatch：map，接口的每个方法的Method对象 -> SynchronousMethodHandler

setterFactory：空

nullableFallbackFactory：我们给的那个降级对象的工程，fallback工程 

HystrixInvocationHandler -> 包含了上面的4样东西 

super.contract(new HystrixDelegatingContract(contract)); 

也很关键，Contract，解析第三方注解的组件，设置为了HystrixDelegatingContract，顾名思义，就是说，设置了这个组件之后，后面就可以解析你在各个接口上打的这个@HystirxCommand以及其他的一些注解，hystrix相关的一些注解 

接着就调用了super.build()，HystrixFeign.Builder的父类，就是Feign.Builder，后面的构造动态代理的逻辑，几乎都是一样了 

这里就是说核心的一点，就是先生成dispatch map，名字也叫做methodToHandler 

基于这个dispatch创建出来了一个HystrixInvocationHandler，feign-hystrix-9.5.0.jar里面，有这个类，是feign和hystirx整合专用的 

就会将动态代理，注入给ServiceBController

### 113_HystrixInvocationHandler的请求入口：服务接口Setter的构造逻辑  

HystrixInvocationHandler，是在feign-hystirx-9.5.0.jar里面的 

InvocationHandler.invoke()方法是动态代理中最最核心的，相当于是T proxy注入ServiceBController，调用T proxy的时候，所有方法的调用，全部会走InvocationHandler.invoke()方法 

打断点，跟进去，就可以看到基于hystrix来处理请求的入口 

HystrixCommand<Object> hystrixCommand = new HystrixCommand<Object>(setterMethodMap.get(method)) {

   @Override

   protected Object run() throws Exception {

​    try {

​     return HystrixInvocationHandler.this.dispatch.get(method).invoke(args);

​    } catch (Exception e) {

​     throw e;

​    } catch (Throwable t) {

​     throw (Error) t;

​    }

   } 

   @Override

   protected Object getFallback() {

​    if (fallbackFactory == null) {

​     return super.getFallback();

​    }

​    try {

​     Object fallback = fallbackFactory.create(getExecutionException());

​     Object result = fallbackMethodMap.get(method).invoke(fallback, args);

​     if (isReturnsHystrixCommand(method)) {

​      return ((HystrixCommand) result).execute();

​     } else if (isReturnsObservable(method)) {

​      // Create a cold Observable

​      return ((Observable) result).toBlocking().first();

​     } else if (isReturnsSingle(method)) {

​      // Create a cold Observable as a Single

​       return ((Single) result).toObservable().toBlocking().first();

​     } else if (isReturnsCompletable(method)) {

​      ((Completable) result).await();

​      return null;

​     } else {

​      return result;

​     }

​    } catch (IllegalAccessException e) {

​     // shouldn't happen as method is public due to being an interface

​     throw new AssertionError(e);

​    } catch (InvocationTargetException e) {

​     // Exceptions on fallback are tossed by Hystrix

​     throw new AssertionError(e.getCause());

​    }

   }

}; 

果然，HystrixInvocationHandler，名副其实，就是一看就是里面肯定是基于hystrix的API来进行请求的执行的，构造了一个HystrixCommand 

setterMethodMap.get(method) 

在构造这个HystrixCommand的时候，传入进去了一个这个东西 

setterMethodMap是什么呢？ 

public abstract java.lang.String com.zhss.demo.ServiceAInterface.deleteUser(java.lang.Long)=com.netflix.hystrix.HystrixCommand$Setter@47c55779 

你要调用的每个方法的Method对象 -> HystrixCommand.Setter类 

HystrixCommand.Setter类是什么东西？大家还记得吗？ 

private static final Setter cachedSetter = 

  Setter.withGroupKey(HystrixCommandGroupKey.Factory.asKey("ExampleGroup"))

​    .andCommandKey(HystrixCommandKey.Factory.asKey("HelloWorld"));   

如果你要是去用hystrix command构造的时候，务必传入进去两个东西 

第一个东西，就是至关重要的groupKey，一般来说就是一个服务对应一个groupKey，服务名称就是一个groupKey，groupKey就对应着一个线程池。。。 

第二个东西，就是commandKey，一个commandKey对应服务的一个接口 

也就是说，一个服务对应一个groupKey，一个服务对应多个HystrixCommand，每个HystrixCommand对应一个commandKey，每个commandKey代表一个接口，但是多个接口属于同一个服务，也就是对应同一个groupKey 

一个groupKey对应一个线程池，一个服务对应一个线程池，比如就10个线程 

那么这个服务可能会有比如28个接口，就对应着28个HystrixCommand，28个commandKey，getById、createUser，但是这个服务的28个接口的28个HystrixCommand请求执行，全部都是基于一个服务的线程池，也就是只有10个线程来处理这个服务的所有28个接口的调用。。。。 

在HystrixInvocationHandler构造的时候，就会去根据dispatch包含了所有的接口的方法，对每个接口方法，都会生成一个Setter，这个Setter里面就包含了这个服务接口对应的groupKey和commandKey 

所以我们来简单的看一下这个Setter map的生成的过程，就可以从源码级别了解到feign整合hystrix的时候，对每个接口的调用，groupKey和commandKey分别是什么？ 

SetterFactory.create()方法，走的就是默认的逻辑 

   String groupKey = target.name();

   String commandKey = Feign.configKey(target.type(), method);

   return HystrixCommand.Setter

​     .withGroupKey(HystrixCommandGroupKey.Factory.asKey(groupKey))

​     .andCommandKey(HystrixCommandKey.Factory.asKey(commandKey)); 

groupKey -> target.name() -> ServiceA -> @FeignClient注解里设置的服务名称 

feign整合hystrix的时候，一个@FeignClient标注一个服务，这个服务的名称就会作为这个服务的每个接口的groupKey，一个服务对应一个groupKey，对应一个线程池，在这个服务中所有接口的调用，都走这个服务对应的线程池 

Feign.configKey()，静态方法，工具方法的意思，根据服务对应的Interface的类名 + Interface中的方法名，拼接成这个接口对应的commanKey -> ServiceAClient#sayHello(String,Integer,Long) -> commandKey 

setterMethodMap ->  

public abstract java.lang.String com.zhss.demo.ServiceAInterface.deleteUser(java.lang.Long)=com.netflix.hystrix.HystrixCommand$Setter@47c55779 

deleteUser(java.lang.Long) 

-> 

Setter(groupKey = ServiceA, commandKey = ServiceAClient#deleteUser(Long)) 

new HystrixCommand<Object>(setterMethodMap.get(method)) 

setterMethodMap.get(method) -> 获取到那个接口方法 -> Setter(groupKey, commandKey) -> 构造了一个HystrixCommand 

  if (isReturnsHystrixCommand(method)) {

   return hystrixCommand;

  } else if (isReturnsObservable(method)) {

   // Create a cold Observable

   return hystrixCommand.toObservable();

  } else if (isReturnsSingle(method)) {

   // Create a cold Observable as a Single

   return hystrixCommand.toObservable().toSingle();

  } else if (isReturnsCompletable(method)) {

   return hystrixCommand.toObservable().toCompletable();

}

return hystrixCommand.execute(); 

这坨逻辑，包含了HystrixCommand执行的逻辑

### 114_研究一下执行请求的HystrixCommand的构建过程以及组成结构  

我们这一讲的话呢，我们继续研究HystrixInvocationHandler里面的东西 

接口：Interface

服务接口：接口，Interface里面的一个方法 => 一个服务的一个接口 

看了一下请求处理的入口，HystrixInvocationHandler.invoke()跟进去，看了一个setterMethodMap，ServiceAClient里面的每个接口方法都有一个hystirx的Setter，包含了groupKey（服务名称，ServiceA），commandKey（接口名称，ServiceAClient#sayHello(Long,String,Integer)） 

基于这个被调用的方法的Setter，构造了一个HystrixCommand 

我们来研究一下HystrixCommand的组成结构 

   @Override

   protected Object run() throws Exception {

​    try {

​     return HystrixInvocationHandler.this.dispatch.get(method).invoke(args);

​    } catch (Exception e) {

​     throw e;

​    } catch (Throwable t) {

​     throw (Error) t;

​    }

   } 

   @Override

   protected Object getFallback() {

​    if (fallbackFactory == null) {

​     return super.getFallback();

​    }

​    try {

​     Object fallback = fallbackFactory.create(getExecutionException());

​     Object result = fallbackMethodMap.get(method).invoke(fallback, args);

​     if (isReturnsHystrixCommand(method)) {

​      return ((HystrixCommand) result).execute();

​     } else if (isReturnsObservable(method)) {

​      // Create a cold Observable

​      return ((Observable) result).toBlocking().first();

​     } else if (isReturnsSingle(method)) {

​       // Create a cold Observable as a Single

​      return ((Single) result).toObservable().toBlocking().first();

​     } else if (isReturnsCompletable(method)) {

​      ((Completable) result).await();

​      return null;

​     } else {

​      return result;

​     }

​    } catch (IllegalAccessException e) {

​     // shouldn't happen as method is public due to being an interface

​     throw new AssertionError(e);

​    } catch (InvocationTargetException e) {

​     // Exceptions on fallback are tossed by Hystrix

​     throw new AssertionError(e.getCause());

​    }

   } 

上面的那坨代码，要仔细研究，他就是HystrixCommand的组成结构 

   @Override

   protected Object run() throws Exception {

​    try {

​     return HystrixInvocationHandler.this.dispatch.get(method).invoke(args);

​    } catch (Exception e) {

​     throw e;

​    } catch (Throwable t) {

​     throw (Error) t;

​    }

   } 

run()方法，HystrixCommand的run方法里面是什么东东？command实际执行的时候，他的业务逻辑就封装在了这个里面 

对于我们来说，每个command的执行业务逻辑，就是根据ribbon进行负载均衡，选择一个server，生成针对那个server的http请求，发起一个http请求 

command核心的执行逻辑，就是下面那行代码 

return HystrixInvocationHandler.this.dispatch.get(method).invoke(args);

dispatch：map数据结构，接口里每个方法Method -> SynchronousMethodHandler 

SynchronousMethodHandler.invoke()，传入执行这个方法的实际的参数，args 

这个里面的执行逻辑，就跟我们之前讲解的feign的原生的请求执行逻辑是一样的了 

   @Override

   protected Object getFallback() {

​    if (fallbackFactory == null) {

​     return super.getFallback();

​    }

​    try {

​     Object fallback = fallbackFactory.create(getExecutionException());

​     Object result = fallbackMethodMap.get(method).invoke(fallback, args);

​     if (isReturnsHystrixCommand(method)) {

​      return ((HystrixCommand) result).execute();

​      } else if (isReturnsObservable(method)) {

​      // Create a cold Observable

​      return ((Observable) result).toBlocking().first();

​     } else if (isReturnsSingle(method)) {

​      // Create a cold Observable as a Single

​      return ((Single) result).toObservable().toBlocking().first();

​     } else if (isReturnsCompletable(method)) {

​      ((Completable) result).await();

​      return null;

​     } else {

​      return result;

​     }

​    } catch (IllegalAccessException e) {

​     // shouldn't happen as method is public due to being an interface

​     throw new AssertionError(e);

​    } catch (InvocationTargetException e) {

​     // Exceptions on fallback are tossed by Hystrix

​     throw new AssertionError(e.getCause());

​    }

   } 

你觉得这里的getFallback()方法被调用，应该是什么时候？ 

我告诉大家，就是在你的hystrix command执行发生问题的时候，会调用这个command的fallback逻辑，降级机制：熔断（断路器打开了，直接就会fallback）、拒绝（线程池满了，信号量满了）、超时（核心逻辑执行超时）、异常（如果核心逻辑执行报错，比如说远程接口报错，往外面抛异常） 

上述的情况下，会直接执行getFallback()方法，去获取一个Fallback object，降级对象，然后会调用这个fallback对象中的降级方法，来实现降级逻辑 

netflix hystrix的github上拉取源码，1.5.12 

如果fallbackFactory是null的话，直接会报错，就说你没有fallback降级逻辑，结果你的command还执行失败了，此时就会直接给你报错 

Object fallback = fallbackFactory.create(getExecutionException()); 

fallbackFactory去创建一个fallback对象出来，getExecutionException是什么东西？获取command执行的异常，熔断、拒绝、超时、报错，都会给你，你自己来决定，根据各种不同的异常，如何实现降级 

Object fallback：我们自己定义的实现ServiceAClient接口的匿名类的对象，里面包含了降级的逻辑 

Object result = fallbackMethodMap.get(method).invoke(fallback, args); 

fallbackMethodMap一看就是包含了接口的各种方法，根据你要调用的这个方法，获取一个方法对应的Method对象，然后对fallback object调用那个Method方法，传入args参数 

这一讲，咱们就剖析清楚了，在这里创建的这个HystrixCommand的结构 

run()，getFallback() 

run()：就是使用SynchronousMethodHandler来处理请求，逻辑跟之前是一模一样了 

getFallback()：就是如果command执行有任何的问题的话，就会直接获取一个fallback object，然后执行fallback object的降级逻辑

### 115_再继续打断点来对HystrixCommand的执行入口进行源码探秘

hystrix执行原理图

![](C:\Users\zy199005\Desktop\中华石杉\images\java\06\11501.png)    

HystrixInvocationHandler那儿去，断点本来就有 

就跑起来服务的环境，然后发送请求，来继续断点调试，看看人家的HystrixCommand的execute()方法，去执行一个请求的入口 

return HystrixCommand.class.isAssignableFrom(method.getReturnType()); 

method.getReturnType()：你要调用的接口方法的返回类型 

  if (isReturnsHystrixCommand(method)) {

   return hystrixCommand;

  } else if (isReturnsObservable(method)) {

   // Create a cold Observable

   return hystrixCommand.toObservable();

  } else if (isReturnsSingle(method)) {

   // Create a cold Observable as a Single

   return hystrixCommand.toObservable().toSingle();

  } else if (isReturnsCompletable(method)) {

   return hystrixCommand.toObservable().toCompletable();

} 

isReturnsHystrixCommand(method)：判断一下method的返回类型，是否是HystrixCommand类型 

isReturnsObservable(method)：判断一下method的返回类型，是否是Observable类型 

他会判断一下，你的接口方法 

HystrixCommand sayHello(Long id, String name, Integer age) 

sayHello()方法的返回类型是HystrixCommand的话，那么在这里，针对这个方法的调用，构造好了HystrixCommand之后，就不会去执行这个command，而是将这个command作为你的sayHello()方法的返回值，返回给你 

让你来决定，如何使用这个command 

大家通过源码的阅读，源码多有意思，可以非常深入、透彻的理解feign和hystirx整合的时候，应该怎么用 

execute()方法 ->  

return queue().get(); 

queue()方法，感觉这个queue()方法是什么东西啊？ 

从这个queue()方法开始，我们就要研究netflix hystrix的源码了 

queue()方法，是用来异步执行command业务逻辑的，他会将command扔到线程池里去执行，但是这个方法是不会等待这个线程执行完毕command的，他会拿到一个Future对象，通过Future对象去获取command执行完毕的响应结果 

​    /*

​     \* The Future returned by Observable.toBlocking().toFuture() does not implement the

​     \* interruption of the execution thread when the "mayInterrupt" flag of Future.cancel(boolean) is set to true;

​     \* thus, to comply with the contract of Future, we must wrap around it.

​     */

​    final Future<R> delegate = toObservable().toBlocking().toFuture(); 

toObservable()：Observable对象 

toObservable().toBlocking().toFuture()：此时这个command已经被扔到了线程池里去执行了，获取了一个线程池里执行线程对应的一个Future对象 

这里你获取到的这个Future对象，是不具备，因为一些异常的原因，中断这个线程执行的能力的，比如超时、异常，你没办法在异常情况下，终止future对应的线程的执行，所以说要对这里返回的delegate future进行包装 

​    final Future<R> f = new Future<R>() { 

​      @Override

​      public boolean cancel(boolean mayInterruptIfRunning) {

​        if (delegate.isCancelled()) {

​          return false;

​        } 

​        if (HystrixCommand.this.getProperties().executionIsolationThreadInterruptOnFutureCancel().get()) {

​          /*

​           \* The only valid transition here is false -> true. If there are two futures, say f1 and f2, created by this command

​           \* (which is super-weird, but has never been prohibited), and calls to f1.cancel(true) and to f2.cancel(false) are

​           \* issued by different threads, it's unclear about what value would be used by the time mayInterruptOnCancel is checked.

​           \* The most consistent way to deal with this scenario is to say that if *any* cancellation is invoked with interruption,

​           \* than that interruption request cannot be taken back.

​           */

​          interruptOnFutureCancel.compareAndSet(false, mayInterruptIfRunning);

​              } 

​        final boolean res = delegate.cancel(interruptOnFutureCancel.get()); 

​        if (!isExecutionComplete() && interruptOnFutureCancel.get()) {

​          final Thread t = executionThread.get();

​          if (t != null && !t.equals(Thread.currentThread())) {

​            t.interrupt();

​          }

​        } 

​        return res;

​               }

​      @Override

​      public boolean isCancelled() {

​        return delegate.isCancelled();

​               } 

​      @Override

​      public boolean isDone() {

​        return delegate.isDone();

​               } 

​      @Override

​      public R get() throws InterruptedException, ExecutionException {

​        return delegate.get();

​      } 

​      @Override

​      public R get(long timeout, TimeUnit unit) throws InterruptedException, ExecutionException, TimeoutException {

​        return delegate.get(timeout, unit);

​      }         

​    }; 

所以说这个新创建的future对象，其实包装了上面的原生的delegate future对象，这里的cancel()方法，就是说，可以支持将delegate future对象对应的thread线程interrupt中止掉，封装了一些isCanceled()、isDone()、get()等future相关的代码 

他搞两个future，最主要的是用第二个future，去包装第一个future，第一个future，原生的情况下，是不支持cancel()方法中止自己对应的那个在执行的线程的，所以搞第二个future包装一下，可以支持cancel()中止线程 

hystrix command对应着一个服务接口，属于一个服务，服务就是对应@FeignClient里的服务名称，ServiceA，一个服务是一个groupKey，对应一个线程池，一定是要基于服务的线程池来进行执行的 

​    if (f.isDone()) {

​      try {

​        f.get();

​        return f;

​      } catch (Exception e) {

​        Throwable t = decomposeException(e);

​        if (t instanceof HystrixBadRequestException) {

​          return f;

​        } else if (t instanceof HystrixRuntimeException) {

​          HystrixRuntimeException hre = (HystrixRuntimeException) t;

​          switch (hre.getFailureType()) {

​                         case COMMAND_EXCEPTION:

​                         case TIMEOUT:

​                              // we don't throw these types from queue() only from queue().get() as they are execution errors

​                              return f;

​                         default:

​                              // these are errors we throw from queue() as they as rejection type errors

​                              throw hre;

​                         }

​        } else {

​          throw Exceptions.sneakyThrow(t);

​        }

​      }

​    } 

f.isDone()，就是通过future判断对应的那个线程，是否完成了command的执行 

f.get()，这里会阻塞住，卡住，尝试去通过future获取对应的thread对command执行后返回的结果，这里会卡住 

如果这行代码，执行完毕了，那么就说明可以获取到thread执行command返回的结果 

此时就会直接返回future 

  public R execute() {

​    try {

​      return queue().get();

​    } catch (Exception e) {

​      throw Exceptions.sneakyThrow(decomposeException(e));

​    }

} 

queue()了以后，就会通过线程池去执行command，然后在queue()方法中，会等待线程执行结束，如果线程执行结束了，就会返回future；即使执行失败了，也会根据情况，返回future，要不就是抛异常 

在execute()方法中，一定会拿到future，然后直接调用future.get()方法，尝试去获取futrue对应的thread执行command的一个结果 

execute()方法和queue()方法，主要的执行逻辑和流程 

下一讲开始，我们重点要研究的是哪儿？ 

toObservable().toBlocking().toFuture() 

这行代码，才是重中之重，这行代码底层实现了hystirx几乎所有的核心逻辑，请求缓存、熔断、队列+线程池、线程异步执行、超时检测、异常处理、异常统计、熔断开关

### 116_深入研究hystirx的执行原理：toObservable()内的复杂代码

hystrix执行原理图

![](C:\Users\zy199005\Desktop\中华石杉\images\java\06\11601.png)

hystrix的源码，真正核心的机制和逻辑都在：toObservable().toBlocking().toFuture() 

我们这一讲的话呢，就是来研究这个toObservable()的方法 

toObservable()，其实是HystrixCommand的父类，AbstractCommand的方法。hystrix几乎所有的核心逻辑，请求缓存、线程池、超时检测、异常检测、熔断触发，都几乎在这个方法里作为入口 

Used for asynchronous execution of command with a callback by subscribing to the {@link Observable}. 

这句话的意思，就是在这里，会将comand使用异步的方式来执行，怎么异步呢？肯定是扔到一个线程池里异步去跑。扔comand到线程池异步去执行之后，在这里你肯定是可以拿到一个Observable对象，拿到这个对象之后，你如果要看这个command执行的一些状态和结果，你需要去订阅这个Observable对象 

你呢，类似于要提供一个回调接口，订阅Observable对象 

如果你command执行成功了、执行中断了、执行失败了，都会回过头来回调你提供的那些回调接口 

This lazily starts execution of the command once the {@link Observable} is subscribed to. 

这句话的意思是说，如果你获取了一个Observable对象之后，此时command其实还没立即开始执行的。。。。这个时候仅仅就是将command封装在Observable对象里面，什么都没干，返回给你一个Observable对象 

如果你订阅了那个Observable对象，提供了回调接口，才会触发Observable内部关联的comand会去执行，根据command执行的结果会去回调你提供的接口 

An eager {@link Observable} can be obtained from {@link #observe()}.

这句话的意思，如果你希望一旦获取到Observable对象，就立即让他去执行内部的command，那么不要调用toObservable()方法，你可以去调用observe()方法 

_cmd，其实就是之前在HystrixInvocationHandler里面创建出来的那个HystrixCommand（run()、getFallback()），就是内个匿名内部类的实例对象 

​    //doOnCompleted handler already did all of the SUCCESS work

​    //doOnError handler already did all of the FAILURE/TIMEOUT/REJECTION/BAD_REQUEST work 

doOnCompleted handler，处理说，如果你的command执行成功了之后，就会由他来处理 

doOnError handler，如果你的command执行过程中，出现了一些异常的情况，比如说，FAILURE（异常、报错）、TIMEOUT（超时）、REJECTION（线程池满，被拒绝）、BAT_REQUEST（错误的请求） 

final Action0 terminateCommandCleanup = new Action0() { 

​      @Override

​      public void call() {

​        if (_cmd.commandState.compareAndSet(CommandState.OBSERVABLE_CHAIN_CREATED, CommandState.TERMINAL)) {

​          handleCommandEnd(false); //user code never ran

​        } else if (_cmd.commandState.compareAndSet(CommandState.USER_CODE_EXECUTED, CommandState.TERMINAL)) {

​          handleCommandEnd(true); //user code did run

​        }

​      }

​    }; 

这坨东西，看着很奇怪，Action0的匿名内部类的对象 

terminateCommandCleanup：terminate，中止，command中止的时候，cleanup就是收尾的一些工作和逻辑 

​        if (_cmd.commandState.compareAndSet(CommandState.OBSERVABLE_CHAIN_CREATED, CommandState.TERMINAL)) {

​          handleCommandEnd(false); //user code never ran

​        } else if (_cmd.commandState.compareAndSet(CommandState.USER_CODE_EXECUTED, CommandState.TERMINAL)) {

​          handleCommandEnd(true); //user code did run

​        } 

（1）如果command的状态是OBSERVABLE_CHAIN_CREATED，就将状态设置为TERMINAL，同时执行handleCommandEnd(false)，如果是这种情况，说明之前user code，用户的代码，从来没有运行过，HystrixCommand.run() 

（2）如果command的状态是EXECUTED，就将状态设置为TERMINAL，同时执行handleCommandEnd(true)，这种情况，就是说user code已经运行过了，HystrixCommand.run()方法已经执行过了 

我们推测的话呢，是这样的，就是terminateCommandCleanup，应该是在HystrixCommand.run()尝试执行过后，执行完了以后来执行这个东西的，分两个情况，要不是HystrixCommand.run()执行成功了，要不是执行失败了 

unsubscribeCommandCleanup，我们会发现说，感觉好尴尬，都看不懂了 

教你一个看源码的技巧，此时只能多打一些断点，在这种明显用来回调的call()方法里面，都打上一个断点，如果我们现在去分析这些源码，还能看懂一点，但是都看不懂了，所以此时，直接抓大放小，连蒙带猜，过 

我们发现说，他在这里创建了一大堆很明显是用来被回调的接口的匿名内部类的对象 

terminateCommandCleanup 

unsubscribeCommandCleanup

applyHystrixSemantics

wrapWithAllOnNextHooks

fireOnCompletedHook 

​    return Observable.defer(new Func0<Observable<R>>() {

​      @Override

​      public Observable<R> call() {

​         /* this is a stateful object so can only be used once */

​        if (!commandState.compareAndSet(CommandState.NOT_STARTED, CommandState.OBSERVABLE_CHAIN_CREATED)) {

​          IllegalStateException ex = new IllegalStateException("This instance can only be executed once. Please instantiate a new instance.");

​          //TODO make a new error type for this

​          throw new HystrixRuntimeException(FailureType.BAD_REQUEST_EXCEPTION, _cmd.getClass(), getLogMessagePrefix() + " command executed multiple times - this is not permitted.", ex, null);

​        } 

​        commandStartTimestamp = System.currentTimeMillis(); 

​        if (properties.requestLogEnabled().get()) {

​          // log this command execution regardless of what happened

​          if (currentRequestLog != null) {

​            currentRequestLog.addExecutedCommand(_cmd);

​          }

​        } 

​        final boolean requestCacheEnabled = isRequestCachingEnabled();

​        final String cacheKey = getCacheKey(); 

​        /* try from cache first */

​        if (requestCacheEnabled) {

​          HystrixCommandResponseFromCache<R> fromCache = (HystrixCommandResponseFromCache<R>) requestCache.get(cacheKey);

​           if (fromCache != null) {

​            isResponseFromCache = true;

​            return handleRequestCacheHitAndEmitValues(fromCache, _cmd);

​          }

​        } 

​        Observable<R> hystrixObservable =

​            Observable.defer(applyHystrixSemantics)

​                .map(wrapWithAllOnNextHooks);

​        Observable<R> afterCache; 

​        // put in cache

​        if (requestCacheEnabled && cacheKey != null) {

​          // wrap it for caching

​          HystrixCachedObservable<R> toCache = HystrixCachedObservable.from(hystrixObservable, _cmd);

​          HystrixCommandResponseFromCache<R> fromCache = (HystrixCommandResponseFromCache<R>) requestCache.putIfAbsent(cacheKey, toCache);

​          if (fromCache != null) {

​            // another thread beat us so we'll use the cached value instead

​            toCache.unsubscribe();

​            isResponseFromCache = true;

​            return handleRequestCacheHitAndEmitValues(fromCache, _cmd);

​          } else {

​            // we just created an ObservableCommand so we cast and return it

​            afterCache = toCache.toObservable();

​          }

​        } else {

​          afterCache = hystrixObservable;

​        }

​        return afterCache

​            .doOnTerminate(terminateCommandCleanup)   // perform cleanup once (either on normal terminal state (this line), or unsubscribe (next line))

​            .doOnUnsubscribe(unsubscribeCommandCleanup) // perform cleanup once

​            .doOnCompleted(fireOnCompletedHook);

​      }

​    });

上面那一大坨，明显就是说创建了一个Observable对象，下面5个东西，之前创建好的，一些回调的接口，然后明显基于这5个回调的接口，然后创建了新的逻辑，Fun0，call()方法的实现逻辑，就是基于这5个回调接口来的 

terminateCommandCleanup 

unsubscribeCommandCleanup

applyHystrixSemantics

wrapWithAllOnNextHooks

fireOnCompletedHook 

然后就直接返回一个Observable对象了 

toObservable()：并没有真正的去执行我们的command，他其实就是基于command封装出来了一个Observable对象，然后直接返回这个Observable对象，command还没执行呢，除非你后面比如说去订阅Observable，才能出发他里面去执行command 

我们可以揣测，其实真正出发Observable里面的command的执行，肯定是这个toBlocking()方法里面去触发的，如果我们去看toBlocking()方法的源码，你觉得靠谱吗？我觉得不太靠谱，因为rxjava项目的源码 

我给大家说一个思路，类似于rxjava这种项目的源码，你不看也没关系，因为toBlocking()一旦调用之后，一定会触发Observable内部的一些执行的流程和逻辑，这些流程和逻辑，一定会依次的去调用之前的那5个东西提供的回调方法，call()方法 

我们不如不要跟进去看这个toBlocking()方法的源码，直接就全速前进，让源码在我们直接打的那5个东西的call()方法的断点里如果能进断点，我们来观察，那5个东西，在Observable执行的过程中，是怎么玩儿的 

先用屁股想一下 

toBlocking()方法一旦调用，一定会触发hystrix相关的所有核心逻辑的执行 

我们就去看一下，toBlocking()方法的源码我们不去看，rxjava的源码，我们直接点击全部前进，看看之前在那5个东东的call()方法里面打的断点，按照什么样的先后顺序会进去，如何执行，hystrix所有的核心逻辑，都集中在那5个东东的call()方法里了 

一旦全速前进之后，就会发现，果然开始进入到相关的call()方法里去了 

toBlocking()方法，首先触发的就是Func0的call()方法 

下一讲，我们来研究toBlocking()方法触发的Func0的call()方法，流程和逻辑

### 117_初步尝试探究Observable执行时的入口源码逻辑在干些什么？

hystrix执行原理图(2)

![](C:\Users\zy199005\Desktop\中华石杉\images\java\06\11701.png)

 

toObservable()方法的逻辑，这里面搞了5个东西，搞了一个Observable对象出来 

这一步，绝对是没有去执行command的 

Observable.toBlocking()方法的逻辑，其实就会开始去执行Observable里面的逻辑，按照顺序去执行之前搞的5个东西 

Func0.call()，这个是Observable执行command的源码逻辑的入口 

现在刚开始，command的state是NOT_STARTED，这么一个状态 

​        if (!commandState.compareAndSet(CommandState.NOT_STARTED, CommandState.OBSERVABLE_CHAIN_CREATED)) {

​          IllegalStateException ex = new IllegalStateException("This instance can only be executed once. Please instantiate a new instance.");

​          //TODO make a new error type for this

​          throw new HystrixRuntimeException(FailureType.BAD_REQUEST_EXCEPTION, _cmd.getClass(), getLogMessagePrefix() + " command executed multiple times - this is not permitted.", ex, null);

​        } 

刚开始做一个command状态的判断，如果说command的状态不是NOT_STARTED，他就认为说你已经执行过一次command了，这个时候就会很坑，他就不会让你重复执行一个command 

如果是command的状态是NOT_STARTED的话，那么就会将command的状态设置为OBSERVABLE_CHAIN_CREATED 

看到这里就明白了，Func0.call()，说白了，就是执行command的入口，Observable.toBlocking()方法触发的 

​        if (properties.requestLogEnabled().get()) {

​          // log this command execution regardless of what happened

​          if (currentRequestLog != null) {

​            currentRequestLog.addExecutedCommand(_cmd);

​           }

​        } 

feign也有请求日志，hystrix也搞请求日志，其实像这种日志，你不要也行，如果是正常的日志，对你的用处并不是很大。一般来说还是建议搞一个统一日志中心，全部自己在系统里自己打印日志，ELK去做的。 

默认情况，request log enabled是打开的，但是负责请求日志的对象，是null，所以这里什么都不会干 

默认情况下，request cache是不启用的 

​        Observable<R> hystrixObservable =

​            Observable.defer(applyHystrixSemantics)

​                .map(wrapWithAllOnNextHooks); 

基于applyHystrixSemantics和wrapWithAllOnNextHooks创建了一个hystrixObservable的东西，这俩东西是干嘛的？我们其实不知道 

​        return afterCache

​            .doOnTerminate(terminateCommandCleanup)   // perform cleanup once (either on normal terminal state (this line), or unsubscribe (next line))

​            .doOnUnsubscribe(unsubscribeCommandCleanup) // perform cleanup once

​            .doOnCompleted(fireOnCompletedHook); 

hystrixObservable，将之前搞的5个东西里，另外3个东西，也通过一些方法连续调用，设置给了这个Observable，到此为止的话呢，我们是不是就发现说，Observable，就是基于之前的5个东西来构造 

到此为止，我们就该再次全速前进了，因为之前发现，toObservable()创建的Observable.toBlocking()之后，就会触发Func0.call()方法执行，结果发现在这个Func0.call()方法里，没干啥，就是再次创建了一个hystrixObservable东西，将之前搞出来的5个东西给他塞了进去，返回这个hystirxObservable 

看看后面是如何对那5个东西进行调用的，我们能看到的代码逻辑，只有那5个东西，其他的我们都看不到 

果然全速前进之后，断点直接停留在applyHystrixSemantics.call()里面 

所以我们判断，其实真正执行command的代码，估计是在applyHystrixSemantics.call()里面去触发的 

​    executionHook.onStart(_cmd); 

ExecutionHookDeprecationWrapper => AbstractCommand的内部类，我们可以去看一下里面的代码逻辑是什么东西，这行代码，其实里面什么都没干，代码都是空的 

circuitBreaker是什么东西？短路器，熔断器 

​    if (circuitBreaker.attemptExecution()) { 

明显就是在找熔断器判断，尝试去执行，是否被熔断，如果熔断了就不让你执行command了，就执行走fallback降级逻辑了 

但是正常情况下，明显是让你执行的，熔断也明显是没有打开的 

applyHystrixSemantics()：基本涵盖了核心的hystirx的一套逻辑 

Observable.toBlocking()触发command执行的入口的源码逻辑就已经讲清楚了 

就是去看看，具体执行command的时候，到底是怎么去玩儿的

### 118_深入分析纷繁错乱的代码：尝试找到请求队列以及线程池的入口

hystrix执行原理图(3)

![](C:\Users\zy199005\Desktop\中华石杉\images\java\06\11801.png) 

我们其实现在是要去找，到底是如何执行我们的HystrixCommand.run()

applyHystrixSemantics()，关键方法，在这个里面包含了hystrix相关的核心代码 

如果要去执行command的话，其实内部肯定是需要基于一个等待队列+线程池，来执行的，肯定是将请求放入一个队列中，然后由线程池中的线程来执行 

我们现在就是要找一找，到底在哪儿可以去执行那个command呢？ 

等待队列 + 线程池，在哪儿呢？ 

​      final TryableSemaphore executionSemaphore = getExecutionSemaphore(); 

​    if (properties.executionIsolationStrategy().get() == ExecutionIsolationStrategy.SEMAPHORE) { 

如果说，我们设置的隔离策略，是基于semaphore（信号量），才会走下面的代码逻辑 

我们默认一般都是基于线程池来进行隔离的，不是基于semaphore，所以在这里拿到的这个所谓的TryableSemaphore，其实是一个什么都不干的东西 

​      final Action1<Throwable> markExceptionThrown = new Action1<Throwable>() {

​        @Override

​        public void call(Throwable t) {

​          eventNotifier.markEvent(HystrixEventType.EXCEPTION_THROWN, commandKey);

​        }

​      }; 

这个东西里的call()回调方法里，看起来是会在发生异常的时候，将这个异常发生的情况给发布一个event，事件通知 

private Observable<R> executeCommandAndObserve(final AbstractCommand<R> _cmd) 

这个方法，光是看名字，就差不离了，executeCommand，执行command.run()，andObserve，同时观察这个命令的执行结果 

markEmits

markCompleted

handleFallback

setRequestContext  

​      execution = executeCommandWithSpecifiedIsolation(_cmd)

​          .lift(new HystrixObservableTimeoutOperator<R>(_cmd)); 

executeCommandWithSpecifiedIsolation()，看名字，就是去基于线程池的隔离，来执行command，HystrixObservableTimeoutOperator（看起来像是负责监控command执行是否超时的这么一个东西） 

​    if (properties.executionIsolationStrategy().get() == ExecutionIsolationStrategy.THREAD) { 

如果隔离策略是thread，默认是 

接下来怎么办呢？ 

对源码全速前进一下，我们估计是什么呢？execution的Observable对象，此时源码全速前进，由人家rxjava自己本身的机制，就会确保说，按照一定的顺序来执行Observable对象的一些回调的函数（4个东西） 

下一讲，来看一下，到底是如何结合队列 + 线程池，来完成command的一个派对和执行的呢？？？

### 119_好不容易找到线程池相关的东西了：来深入看看具体怎么执行请求的？

hystrix执行原理图(4)

![](C:\Users\zy199005\Desktop\中华石杉\images\java\06\11901.png)   

这一讲，我们就要看到command到底是如何执行的，到底是如何结合线程池和等待队列去执行的 

​          if (!commandState.compareAndSet(CommandState.OBSERVABLE_CHAIN_CREATED, CommandState.USER_CODE_EXECUTED)) {

​            return Observable.error(new IllegalStateException("execution attempted while in state : " + commandState.get().name()));

​          } 

如果说，要执行command了，结果command的state不是OBSERVABLE_CHAIN_CREATED，那么就会说在一个错误的state之下在执行command，报错 

正常情况下，会将command state改成USER_CODE_EXECUTED 

threadpoolKey默认是跟groupKey是一样的，一个服务对应一个线程池 

​          if (isCommandTimedOut.get() == TimedOutStatus.TIMED_OUT) {

​            // the command timed out in the wrapping thread so we will return immediately

​            // and not increment any of the counters below or other such logic

​            return Observable.error(new RuntimeException("timed out before executing run()"));

​          } 

还没有执行HystrixCommand.run()之前，就直接宣告timed_out，我们在debug，所以就导致，进入到这里之前，就直接超时了 

我们尝试重新发送一次请求，这次我们快一些，直接进入execution Observable的Fun0.call()，直接去执行command 

必须得按照我们这样，直接在后面打一个断点，否则的话呢，在执行command之前，就直接给你timeout掉了，根本就没有机会去执行HystirxCommand.run()方法 

执行的时候，threadState：NOT_USING_THREAD 

大家看到这里的话，可以理解我之前为什么在eureka那一块，给大家说的是，一定要锻炼起来自己强大的阅读静态源码的能力，不要去依靠调试，debug调试很多时候有很多的坑，不一定可以让你调试出来的 

他是如何执行请求的，是如何将command放入一个queue，线程池里从queue里面去获取一个command来执行。。 

threadState -> STARTED 

​            endCurrentThreadExecutingCommand = Hystrix.startCurrentThreadExecutingCommand(getCommandKey()); 

​    final ConcurrentStack<HystrixCommandKey> list = currentCommand.get();

​    try {

​      list.push(key);

​    } catch (Exception e) {

​      logger.warn("Unable to record command starting", e);

​    }

​    return new Action0() { 

​      @Override

​      public void call() {

​        endCurrentThreadExecutingCommand(list);

​      } 

​    }; 

一看就是说将要执行的commandKey压入一个栈中 

​              executionHook.onThreadStart(_cmd);

​              executionHook.onRunStart(_cmd);

​              executionHook.onExecutionStart(_cmd); 

什么都没干 

​              return getUserExecutionObservable(_cmd); 

在这里会有实际执行command的这么一个逻辑 

​    return Observable.defer(new Func0<Observable<R>>() {

​      @Override

​       public Observable<R> call() {

​        try {

​          return Observable.just(run());

​        } catch (Throwable ex) {

​          return Observable.error(ex);

​        }

​      }

​    }).doOnSubscribe(new Action0() {

​      @Override

​      public void call() {

​        // Save thread on which we get subscribed so that we can interrupt it later if needed

​        executionThread.set(Thread.currentThread());

​      }

​    }); 

这里封装了一个Observable，里面的Func0.call()，就执行了我们自己写的那个run()方法 

咱们该打的断点，都打了，下一步就是直接全速前进，估计就是会去调用userObservable的Func0.call()方法，然后里面就会去执行我们的run()方法 

还记得一点儿，如果你要让一个Observable去执行的话，必须对这个Observable进行订阅，在这里的话呢，其实他内部先会搞一个Subscriber出来，订阅器出来，然后用这个Subscriber去订阅userObservable，然后才能出发userObservable的执行 

执行HystrixInvocationHandler里面的那个HystrixCommand.run() => SynchronousMethodHandler 

feign + ribbon + eureka的逻辑 

但是这里有一个很大的问题，还没看到如何在线程池里执行呢 

下一讲专门来找这个userObservable是如何在线程池里进行执行的。。。

### 120_弥补巨大的遗憾：迄今没找到的线程池的执行逻辑完成揭秘 

我们已经看到，command到底是怎么执行的了， 

rxjava -> 在国内不常用，结果在国外，netflix这种公司里面，rxjava、jersey，对我们来说，看源码，如果你为了hystrix，rxjava 

hystrix -> rxjava这种包，尽量采用读源码的技巧，对回调函数打一些断点，来看 

我个人的观点，hystrix这种框架让我来设计，站在我们国内码农的角度，我觉得不会大量的用rxjava的包，Observable 

rxjava -> Observable、Action0、Func0，各种回调函数 

源码里面，大量的充斥了这些东西，对源码的可读性，可维护性，不是特别好 

hystrix源码写的还可以，起码比eureka要好，rxjava，源码很绕，不是很直接，阅读起来稍微有点麻烦 

如果我来设计的话，我觉得不会采用这种设计思想，netflix的技术实力、技术影响力，非常的钦佩，我觉得是ok的，我对netflix立面，eureka -> 代码太烂，hystrix -> rxjava -> 可读性和可维护性不是很好 

ribbon和feign，我觉得代码写的水准很不错的，而且组件与组件之间的关系，很清晰 

hystrix，还没找到一点，线程池的使用逻辑到现在还没找到 

这就是我给大家说的一点，类似hystirx这样的底层的框架，我也设计过，基础架构的团队，微服务架构、分布式kv、基础框架 

从0到1，从1到10，从10到100，这么过程，用户量从0到上亿用户，业务系统，本身我就带过 

基础架构团队，基础框架、中间件、分布式系统 

高并发、高可用、高稳定性、安全性、海量数据 

hystrix这种框架，连一个线程池的使用，都很模糊，都找不到，我觉得真的不应该，这个就是大量使用rxjava这种响应式编程类库（观察者模式）的编程模式的缺点，rxjava这种类库，大量的都是在回调，这就导致整个系统的运行流程很模糊，很不直接，很不清晰 

就导致我们现在都找不到，最终执行command的那个逻辑是怎么被扔到线程池里去执行的‘

技巧 

hystirx，如果说是这样的话，我告诉大家怎么弄，你得在对应的类里面，我们去找一下threadPool，找一下threadPool是在哪里被使用的，那么应该在那块代码哪里，就会是通过线程池提交线程的这么一个入口这样子 

  protected final HystrixCircuitBreaker circuitBreaker;

protected final HystrixThreadPool threadPool; 

circuitBreaker：短路器

threadPool：线程池 

.subscribeOn(threadPool.getScheduler(new Func0<Boolean>() {

​        @Override

​        public Boolean call() {

​           return properties.executionIsolationThreadInterruptOnTimeout().get() && _cmd.isCommandTimedOut.get() == TimedOutStatus.TIMED_OUT;

​        }

​      })); 

会发现说，真正跟线程池有关系的核心逻辑，只有那里的一个地方 

我们在想， 作为一个突破口，我们是不是可以在这段代码里打一个断点，如果一会儿执行的话，我们可以跟进去看一看，线程池到底在干什么 

​    @Override

​    public Subscription schedule(Action0 action, long delayTime, TimeUnit unit) {

​      if (threadPool != null) {

​        if (!threadPool.isQueueSpaceAvailable()) {

​          throw new RejectedExecutionException("Rejected command because thread-pool queueSize is at rejection threshold.");

​        }

​      }

​      return worker.schedule(new HystrixContexSchedulerAction(concurrencyStrategy, action), delayTime, unit);

​    } 

​    @Override

​    public Subscription schedule(Action0 action) {

​      if (threadPool != null) {

​        if (!threadPool.isQueueSpaceAvailable()) {

​          throw new RejectedExecutionException("Rejected command because thread-pool queueSize is at rejection threshold.");

​        }

​      }

​      return worker.schedule(new HystrixContexSchedulerAction(concurrencyStrategy, action));

​    } 

看看上面的schedule()方法的实现逻辑，就是在判断线程池是否已满？如果已经满了，那么就会报一个reject的异常，还有的话，如果线程池没有满，那么就会去通过线程池进行调度。。。 

HystrixThreadPoolDefault：比较关键的一个类 

这个其实应该就是代表了默认的hystirx的线程池的实现： 

​    private final HystrixThreadPoolProperties properties;

​    private final BlockingQueue<Runnable> queue;

​    private final ThreadPoolExecutor threadPool;

​    private final HystrixThreadPoolMetrics metrics;

​    private final int queueSize; 

queue，BlockingQueue -> 用来排队的这么一个queue 

threadPool -> ThreadPoolExecutor -> JDK的线程池 

打了一大堆的断点，后面呢，我们重新启动serviceB，然后再次发起一个请求，然后我推测我们就可以看到完整的，线程池和队列如何初始化的 -> 最终的任务是如何提交给线程池进行执行的 -> 线程是如何执行我们的任务的 

可以相当于是，先教给大家一个读这种源码的技巧，告诉你，如果你没找到线程池相关的东西，怎么办呢。。。在源码里找，在对应的可能的地方，先打上断点，不是顺序执行的，hystrix -> rxjava -> 一大堆的回调函数，你得提前看源码，打上各种断点，然后才能在框架执行的时候，各种看到怎么回事 

通过源码的调试 -> 写分析 -> 完善的这个图

### 121_隐藏逻辑起底：hystrix线程池默认参数以及默认情况下构建的线程池

hystrix执行原理图(5)

![]()![12101](C:\Users\zy199005\Desktop\中华石杉\images\java\06\12101.png)

线程池是怎么初始化的，任务如何提交到线程池，如何检查线程池是否已满，如何基于线程池来执行一个HystrixCommand.run() 

在HystrixInvocationHandler构造HystrixCommand的时候，其实就会触发和完成线程池的一个初始化 

发送请求的时候，直接就是会先初始化这个线程池 

猜测，就是说，一个threadpoolKey会对应着一个线程池，每个HystrixCommand的threadpoolKey默认就是服务名称，ServiceA，所以说对每个服务都会初始化一个线程池 

​      // get the key to use instead of using the object itself so that if people forget to implement equals/hashcode things will still work

​      String key = threadPoolKey.name(); 

​      // this should find it for all but the first time

​      HystrixThreadPool previouslyCached = threadPools.get(key);

​      if (previouslyCached != null) {

​        return previouslyCached;

​      } 

​      // if we get here this is the first time so we need to initialize

​       synchronized (HystrixThreadPool.class) {

​        if (!threadPools.containsKey(key)) {

​          threadPools.put(key, new HystrixThreadPoolDefault(threadPoolKey, propertiesBuilder));

​        }

​      }

​      return threadPools.get(key); 

这段代码，就完美的印证了我们的猜测，就是在构造HystrixCommand的时候，同步会去初始化对应的服务的线程池，一个服务ServiceA -> threadPool 

从一个map里，根据ServiceA名字去获取一个threadPool，但是获取不到，就会新建一个放到map里去，下次就是直接复用了 

通过看源码，非常有意思，可以探秘几乎所有的秘密 

hystrix.threadpool.ServiceA.allowMaximumSizeToDivergeFromCoreSize = false

hystrix.threadpool.ServiceA.keepAliveTimeMinutes = 1

hystrix.threadpool.ServiceA.maximumSize = 10

hystrix.threadpool.ServiceA.coreSize = 10

hystrix.threadpool.ServiceA.maxQueueSize = -1

hystrix.threadpool.ServiceA.queueSizeRejectionThreshold = 5

hystrix.threadpool.ServiceA.metrics.rollingStats.numBuckets = 10

hystrix.threadpool.ServiceA.metrics.rollingStats.timeInMilliseconds = 10000 

HystrixConcurrencyStrategyDefault 

我们得去找一下ThreadPoolExecutor的构造逻辑 

queueSize = -1

ThreadPoolExecutor：这个线程池，就是 

​      return new ThreadFactory() {

​        private final AtomicInteger threadNumber = new AtomicInteger(0); 

​        @Override

​        public Thread newThread(Runnable r) {

​          Thread thread = new Thread(r, "hystrix-" + threadPoolKey.name() + "-" + threadNumber.incrementAndGet());

​          thread.setDaemon(true);

​          return thread;

​        } 

​      }; 

这个ThreadFactory，就是说，在线程池创建一个新的线程的时候，会基于这个ThreadFactory来创建，这里主要是窗机爱你出来一个Thread对象才能够，给这个Thread设置一个线程名称 

hystrix-ServiceA-1

hystrix-ServiceA-2

hystrix-ServiceA-3

hystrix-ServiceA-4 

​    final BlockingQueue<Runnable> workQueue = getBlockingQueue(maxQueueSize); 

初始化队列和线程池的逻辑 

maxQueueSize = -1 

​    if (maxQueueSize <= 0) {

​      return new SynchronousQueue<Runnable>();

​    } else {

​      return new LinkedBlockingQueue<Runnable>(maxQueueSize);

​    } 

源码给大家解密 

如果默认请款下，maxQueueSize = -1，是没有所谓的排队的效果的 

SynchronousQueue<Runnable>()，如果对线程池这块看不懂的话，请大家直接先去看面试突击第二季的线程池那块的讲解，当时那块知识我都讲解的很清晰了 

是没有排队的，一个请求过来了，就会直接创建一个新的线程，来执行这个请求，如果一旦线程池满了，没有新的线程可以了，那么此时就会尝试去创建更多的线程 

hystrix.threadpool.ServiceA.allowMaximumSizeToDivergeFromCoreSize = false

hystrix.threadpool.ServiceA.keepAliveTimeMinutes = 1

hystrix.threadpool.ServiceA.maximumSize = 10

hystrix.threadpool.ServiceA.coreSize = 10

hystrix.threadpool.ServiceA.maxQueueSize = -1 

一个请求过来，会找一个新的线程来处理这个请求，但是最多同时只能是coreSize指定的10个线程，同时处理10个请求 

如果10个线程都在繁忙中，此时来了第11个请求，直接就是线程池reject掉 

并没有所谓的排队的机制 

hystrix.threadpool.ServiceA.allowMaximumSizeToDivergeFromCoreSize = false

hystrix.threadpool.ServiceA.keepAliveTimeMinutes = 1

hystrix.threadpool.ServiceA.maximumSize = 10

hystrix.threadpool.ServiceA.coreSize = 10

hystrix.threadpool.ServiceA.maxQueueSize = 10 

一个队列，大小是10；线程池，10个线程 

此时会这样子，优先就是先用10个线程来处理请求，如果线程池满了，此时就会在队列里面排队，最多可以排10个请求，如果10个请求都满了，线程池里的10个线程也满了，还在繁忙中，此时maxsimumSize是10，无法增加新的线程，此时就会reject掉 

hystrix.threadpool.ServiceA.allowMaximumSizeToDivergeFromCoreSize = true

hystrix.threadpool.ServiceA.keepAliveTimeMinutes = 1

hystrix.threadpool.ServiceA.maximumSize = 20

hystrix.threadpool.ServiceA.coreSize = 10

hystrix.threadpool.ServiceA.maxQueueSize = 10 

先是用线程池里的10个线程来处理，如果10个线程都繁忙了，此时会进入队列排队，最多排10个请求，如果队列也满了，此时会创建新的线程，最多创建额外的10个线程，让线程池的综述，最多增加到20个。新增加出来的10个线程，如果处理完了请求，超过1分钟是空闲的，那么此时就会释放掉新增加出来的额外的10个线程。 

hystrix.threadpool.ServiceA.allowMaximumSizeToDivergeFromCoreSize = false

hystrix.threadpool.ServiceA.keepAliveTimeMinutes = 1

hystrix.threadpool.ServiceA.maximumSize = 10

hystrix.threadpool.ServiceA.coreSize = 10

hystrix.threadpool.ServiceA.maxQueueSize = -1 

​      return new ThreadPoolExecutor(dynamicCoreSize, dynamicCoreSize, keepAliveTime, TimeUnit.MINUTES, workQueue, threadFactory); 

全速前进，到这一步为止，线程池+队列，在哪个节点被初始化，默认的配置是什么，我们如何去调整指定服务的这么一个配置，线程池的初始化这块，完全ok了 

这一讲，源码层面搞清楚了hystrix的线程池的初始化 

下一讲，我们源码继续前进，来看看hystrix的线程池是如何被使用的

### 122_彻底扒开hystrix的核心执行逻辑：如何通过线程池来执行任务

hystrix执行原理图(6)

![](C:\Users\zy199005\Desktop\中华石杉\images\java\06\12201.png)

我们彻底明白了，在源码层面，看到了线程池是如何初始化的，这一讲，我们来源码，来看看线程池是如何提交的 

threadPool.getScheduler() 

touchConfig：默认情况下不会干什么事情，只有在你设置线程可以动态增长的时候，才会干一些事情 

HystrixContextScheduler

HystrixContextSchedulerWorker 

​        if (!threadPool.isQueueSpaceAvailable()) {

​          throw new RejectedExecutionException("Rejected command because thread-pool queueSize is at rejection threshold.");

​        } 

关键逻辑，判断线程池是否已满的核心逻辑 

queueSize = -1 

如果queueSize = -1的情况下，这个方法调用，永远是true 

queueSize = maxQueueSize = -1 

queueSize = maxQueueSize = 10，最多可以排队10个请求 

​      if (queueSize <= 0) {

​        // we don't have a queue so we won't look for space but instead

​        // let the thread-pool reject or not

​        return true;

​      } else {

​         return threadPool.getQueue().size() < properties.queueSizeRejectionThreshold().get();

​      } 

参数：queueSizeRejectionThreashold，默认值是5 

threadPool.getQueue().size() -> 当前你的线程池的队列里面排队了几个请求，比如说现在排队了3个请求，如果3个请求还是小于queueSizeRejectionThreashold（5），那么就是还是可以将请求扔进去的 

但是如果说，队列里面已经排队了5个请求，此时就是跟queueSizeRejectionThreashold（5）一样了，那么此时就会说已经没法排队了，空间已经满了 

hystrix.threadpool.ServiceA.allowMaximumSizeToDivergeFromCoreSize = false

hystrix.threadpool.ServiceA.keepAliveTimeMinutes = 1

hystrix.threadpool.ServiceA.maximumSize = 10

hystrix.threadpool.ServiceA.coreSize = 10

hystrix.threadpool.ServiceA.maxQueueSize = -1

hystrix.threadpool.ServiceA.queueSizeRejectionThreshold = 5 

hystrix.threadpool.ServiceA.allowMaximumSizeToDivergeFromCoreSize = false

hystrix.threadpool.ServiceA.keepAliveTimeMinutes = 1

hystrix.threadpool.ServiceA.maximumSize = 10

hystrix.threadpool.ServiceA.coreSize = 10

hystrix.threadpool.ServiceA.maxQueueSize = -1

hystrix.threadpool.ServiceA.queueSizeRejectionThreshold = 5 

他首先会将任务不断的给线程池，让线程池来处理，如果10个线程都满了，此时就会进入队列来排队 

如果此时队列里排队的请求是3个，那么此时就会判断说3 < 5，此时还可以继续送个请求过去，进行排队 

但是如果此时队列里排队的请求第5个，此时就会判断说5 = 5，5不小于5，此时就会报错：Rejected command because thread-pool queueSize is at rejection threshold. 

通过源码，各种参数是怎么用的，大家应该就全都清楚了吧？？？ 

面试突击里第二季，线程池 

HystrixContexSchedulerAction 

​      ThreadPoolExecutor executor = (ThreadPoolExecutor) threadPool.getExecutor();

​      FutureTask<?> f = (FutureTask<?>) executor.submit(sa);

​      sa.add(new FutureCompleterWithConfigurableInterrupt(f, shouldInterruptThread, executor)); 

这块就是将任务，提交到线程池里的核心逻辑了 

如果提交任务的时候，线程池已经满了，默认是会走abortPolicy， 

throw new RejectedExecutionException("Task " + r.toString() +

​                         " rejected from " +

​                         e.toString()); 

拒绝任务的提交，线程池已经满了，此时你就会看到这样的这么一个异常 

hystrix，核心的原理，通过一个图，就全都画清楚了

### 123_线程池中异步执行任务的时候如何进行超时检测以及中断线程的执行呢？

hystrix超时原理

![](C:\Users\zy199005\Desktop\中华石杉\images\java\06\12301.png)

 

hystrix最最核心的就是几块 

隔离+限流：线程池（结合面试突击第二季里的线程池），拒绝任务（队列满了，线程池满了） 

超时监测：如果执行的时候超时了，可以发现和中断执行 

异常：报错 

降级：如何执行降级的机制，fallback机制 

熔断：熔断器如何统计、如何打开、如何自动恢复 

请求缓存 

请求合并

executeCommandAndObserve() 

这个里面，可以看到施加了一个HystrixObservableTimeoutOperator的东西，都是一些rxjava包的一些用法，弄懂rxjava包的用法，精通rxjava东西的一个用法 

抓大放小，连蒙带猜 

​      TimerListener listener = new TimerListener() { 

​        @Override

​        public void tick() {

​          // if we can go from NOT_EXECUTED to TIMED_OUT then we do the timeout codepath

​          // otherwise it means we lost a race and the run() execution completed or did not start

​          if (originalCommand.isCommandTimedOut.compareAndSet(TimedOutStatus.NOT_EXECUTED, TimedOutStatus.TIMED_OUT)) {

​            // report timeout failure

​            originalCommand.eventNotifier.markEvent(HystrixEventType.TIMEOUT, originalCommand.commandKey); 

​            // shut down the original request

​            s.unsubscribe(); 

​            final HystrixContextRunnable timeoutRunnable = new HystrixContextRunnable(originalCommand.concurrencyStrategy, hystrixRequestContext, new Runnable() { 

​              @Override

​              public void run() {

​                child.onError(new HystrixTimeoutException());

​              }

​            }); 

​            timeoutRunnable.run();

​            //if it did not start, then we need to mark a command start for concurrency metrics, and then issue the timeout

​          }

​        } 

​        @Override

​        public int getIntervalTimeInMilliseconds() {

​          return originalCommand.properties.executionTimeoutInMilliseconds().get();

​        }

​      }; 

他其实是一个监听我们的command执行是否超时的这么一个监听器，如果command执行超时了，那么此时就会回调这个TimerListener里面的这个方法，将状态设置为TIMED_OUT，而且会抛出一个HystrixTimeoutException 

​      final Reference<TimerListener> tl = HystrixTimer.getInstance().addTimerListener(listener); 

HystrixTimer.getInstance()：这里明显是拿到了一个HystirxTimer的东西，在这个里面加入了上面的那个监听器，就是如果超时了，就会去回调那个监听器 

然后将这个HystrixTimer，给放到了command的里面去 

来做一个猜测，我们估计很可能是什么呢，HystrixTimer就是负责去监控command的执行是否超时的，超时的逻辑，很可能就在这个里面，如果超时了，就会去回调那个TimerListener。。。。。 

Timer used by {@link HystrixCommand} to timeout async executions 

注释都很清晰了，明确说明了HystrixTimer就是一个核心的组件，负责去将HystrixCommand的异步执行给超时掉 

coreSize：4，这个是代表的timer线程池的大小，跟我们之前说的执行的那个没关系 

​        threadFactory = new ThreadFactory() {

​          final AtomicInteger counter = new AtomicInteger();

​          @Override

​          public Thread newThread(Runnable r) {

​            Thread thread = new Thread(r, "HystrixTimer-" + counter.incrementAndGet());

​             thread.setDaemon(true);

​            return thread;

​          }

​        }; 

设置了timer线程的工厂，timer线程的名字叫做：HystirxTimer-1 

ScheduledThreadPoolExecutor：创建了一个用来进行调度的线程池，大小是4，最多只能同时调度4个线程 

​    Runnable r = new Runnable() { 

​      @Override

​      public void run() {

​        try {

​          listener.tick();

​        } catch (Exception e) {

​          logger.error("Failed while ticking TimerListener", e);

​        }

​      }

​    }; 

这个线程，就是在调用TimerListener的tick()方法 

​    ScheduledFuture<?> f = executor.get().getThreadPool().scheduleAtFixedRate(r, listener.getIntervalTimeInMilliseconds(), listener.getIntervalTimeInMilliseconds(), TimeUnit.MILLISECONDS); 

就是用之前创建好的线程池，来调度刚才创建的runnable线程，定时调度执行的 

hystrix.command.ServiceAClient#sayHello(Long,String,Integer).execution.isolation.thread.timeoutInMilliseconds = 3600000，1小时，默认是1s（1000ms） 

按照我们的设置，会每隔1小时去跑一次，但是默认情况下应该是每隔1秒钟去跑一次 

推测一下这个逻辑，正常情况下是，每隔一秒钟，会执行一次，执行的时候会判断，如果说人家都过了秒钟了，结果，坑爹的是，此时你的command的timeout状态还是NOT_EXECUTED，命令还没有执行，此时就会设置你为超时。。。。超时了就会设置为TIMEDOUT状态 

handleCommandEnd() 

很明显是在command执行结束之后被调用的，处理一些命令结束之后的事情，上来就是将这个command对应的那个检查timeout的任务给clean掉 

很多细节，很多代码在来回调用，很多细节，我就不去说了，大家抓大放小，而且很多代码调用，其实都没执行什么逻辑 

rxjava -> 这种模式的编程，观察者，少量运用，大量运用，会导致整个系统的运行流程很绕。。。

### 124_短路器打开、线程池拒绝、超时以及异常的时候降级机制是如何触发执行的呢？  

命令执行 

超时：有一个定时任务线程的不断的去检查状态，如果在超时时间之前，命令执行完了，此时会清理掉那个定时任务，命令的timeout state => COMPLETED 

异常：命令执行的过程中，报错了，抛异常了，异常肯定会不断的抛出来，给别人去处理 

拒绝：等待队列满，线程池，抛异常 

共同的一个特点，都是在抛出这个异常，我们想，抛出异常的话呢，肯定会让别人去处理，肯定有个人会去处理你异常的情况，然后执行你的fallback降级逻辑 

fallback降级逻辑是在哪儿执行的？？？ 

executeCommandAndObserve() 

​    final Func1<Throwable, Observable<R>> handleFallback = new Func1<Throwable, Observable<R>>() {

​      @Override

​      public Observable<R> call(Throwable t) {

​        circuitBreaker.markNonSuccess();

​        Exception e = getExceptionFromThrowable(t);

​        executionResult = executionResult.setExecutionException(e);

​        if (e instanceof RejectedExecutionException) {

​          return handleThreadPoolRejectionViaFallback(e);

​        } else if (t instanceof HystrixTimeoutException) {

​          return handleTimeoutViaFallback();

​        } else if (t instanceof HystrixBadRequestException) {

​          return handleBadRequestByEmittingError(e);

​        } else {

​          /*

​           \* Treat HystrixBadRequestException from ExecutionHook like a plain HystrixBadRequestException.

​           */

​          if (e instanceof HystrixBadRequestException) {

​            eventNotifier.markEvent(HystrixEventType.BAD_REQUEST, commandKey);

​            return Observable.error(e);

​          } 

​          return handleFailureViaFallback(e);

​        }

​      }

​    }; 

你会发现所有的异常，都会交给handleFallback来处理，针对不同的异常，reject、timeout、failure，拒绝、超时、失败，都会执行降级逻辑

### 125_线程池拒绝、超时以及异常的时候又是如何触发熔断开关的呢？

熔断器的工作原理

 ![](C:\Users\zy199005\Desktop\中华石杉\images\java\06\12501.png)  

在拒绝、超时、失败的时候，是如何处罚熔断器打开的

AbstractCommand里面，有一个东西，叫做HystrixCircuitBreaker，熔断器 

​      HystrixCircuitBreaker previouslyCached = circuitBreakersByCommand.get(key.name()); 

通过commandKey去获取一个command对应的熔断器 

ServiceAClient#sayHello(Long,String,Integer) => 自己的熔断器 

HystrixCircuitBreakerImpl 

​      Subscription s = subscribeToStream(); 

这行代码直接就是让熔断器监听了各种异常的统计信息，监听了拒绝、超时、失败的次数，如果说各种次数达到一定的范围内，此时就会触发熔断 

// check if we are past the statisticalWindowVolumeThreshold

​              if (hc.getTotalRequests() < properties.circuitBreakerRequestVolumeThreshold().get()) {

​                // we are not past the minimum volume threshold for the stat window,

​                // so no change to circuit status.

​                // if it was CLOSED, it stays CLOSED

​                // if it was half-open, we need to wait for a successful command execution

​                // if it was open, we need to wait for sleep window to elapse

​              } else {

​                if (hc.getErrorPercentage() < properties.circuitBreakerErrorThresholdPercentage().get()) {

​                  //we are not past the minimum error threshold for the stat window,

​                  // so no change to circuit status.

​                  // if it was CLOSED, it stays CLOSED

​                  // if it was half-open, we need to wait for a successful command execution

​                  // if it was open, we need to wait for sleep window to elapse

​                } else {

​                  // our failure rate is too high, we need to set the state to OPEN

​                  if (status.compareAndSet(Status.CLOSED, Status.OPEN)) {

​                    circuitOpened.set(System.currentTimeMillis());

​                  }

​                }

​              } 

这段代码，直接就实现了打开熔断的逻辑 

订阅了以后，每次如果有新的统计信息，就会来回调这个onNext()方法 

onNext()方法就会对统计信息进行各种检查，按照我们设置的一些参数，来完成对应的熔断的打开 

hc.getTotalRequests() < properties.circuitBreakerRequestVolumeThreshold().get() 

就是说在最近一个时间窗口内（10s），totalRequests（总请求数量）小于circuitBreakerRequestVolumeThreshold（默认是20），那么什么都不干 

反之，如果说totalRequests（总请求数量） >= circuitBreakerRequestVolumeThreshold（默认是20），那么就会进入下一步的尝试 

if (hc.getErrorPercentage() < properties.circuitBreakerErrorThresholdPercentage().get()) {

​                  //we are not past the minimum error threshold for the stat window,

​                  // so no change to circuit status.

​                  // if it was CLOSED, it stays CLOSED

​                  // if it was half-open, we need to wait for a successful command execution

​                  // if it was open, we need to wait for sleep window to elapse

​                } 

如果说最近一个时间窗口（默认是10s）内的异常的请求次数所占的比例（25次请求，5次，20%），< circuitBreakerErrorThresholdPercentage（异常比例，默认是50%），什么都不干。。。。 

但是反之，如果最近一个时间窗口内（默认是10s）内的异常的请求次数所占的比例（25次请求，20次，80%） > circuitBreakerErrorThresholdPercentage（默认是50%），此时就会打开熔断开关 

​                  if (status.compareAndSet(Status.CLOSED, Status.OPEN)) {

​                    circuitOpened.set(System.currentTimeMillis());

​                  } 

这段逻辑，就会将熔断器的状态设置为OPEN 

最近一个时间窗口（默认是10s） 

总的请求次数必须是 >= circuitBreakerRequestVolumeThreshold（默认是20次） 

异常请求的比例（一共25次，20次都失败了，拒绝、超时、失败，80%），>= circuitBreakerErrorThresholdPercentage（默认是50%），此时就会触发熔断开关

### 126_熔断开关一旦打开之后是如何对后续的请求直接走fallback逻辑的呢？

熔断器的工作原理(1)

 ![](C:\Users\zy199005\Desktop\中华石杉\images\java\06\12601.png)

如果说熔断器打开了，按理来说，就会在后面直接走fallback逻辑 

circuitBreaker.attemptExecution() 

这里是核心的逻辑，此处会去判断，是否打开了熔断器 

​      if (circuitOpened.get() == -1) {

​        return true;

​      } 

circuitOpened.get() == -1，就是可以执行请求，熔断器没有打开 

circuitOpened => 时间戳 

​    private boolean isAfterSleepWindow() {

​      final long circuitOpenTime = circuitOpened.get();

​      final long currentTime = System.currentTimeMillis();

​      final long sleepWindowTime = properties.circuitBreakerSleepWindowInMilliseconds().get();

​      return currentTime > circuitOpenTime + sleepWindowTime;

​    } 

circuitOpenTime => 20:00:00

sleepWindowTime => circuitBreakerSleepWindowInMilliseconds => 5000（5s） 

20:00:01 < 20:00:00 + 5s = 20:00:05 

如果熔断器被打开以后，还没有经过指定的（circuitBreakerSleepWindowInMilliseconds，默认是5s），那么就会直接attemptExecution返回false 

​    if (circuitBreaker.attemptExecution()) { 

如果是false的话，=> return handleShortCircuitViaFallback(); => 降级逻辑

### 127_熔断一段时间过后是如何自动尝试探查下游服务是否已经恢复的？

熔断器的工作原理(2)

![](C:\Users\zy199005\Desktop\中华石杉\images\java\06\12701.png) 

非常关键的一个参数 

circuitBreakerSleepWindowInMilliseconds 

默认是5秒钟，我们可以自己去修改，不修改也没事 

如果上次熔断打开的时间是：20:00:00 

此时当前的时间是20:00:06 > 20:00:00 + circuitBreakerSleepWindowInMilliseconds（5s） = 20:00:05 

当前时间比上一次熔断器打开的时间已经超过了5秒钟了 

熔断器状态会从OPEN -> HALF_OPEN 

如果尝试请求失败了，拒绝、超时、失败，handleFallback => circuitBreaker.markNonSuccess(); => 重新打开熔断器 

如果尝试请求成功了，会回调markEmits或者markOnCompleted => circuitBreaker.markSuccess() => 关闭熔断器 

hystirx核心的源码，全部结束 

执行、隔离、超时、失败、降级、熔断 

请求缓存、请求合并，两个小feature => 源码不讲都无所谓，在实际生产环境中，这两个高阶的功能，尽量不要用，缓存 => ehcache，请求合并 => 轻易不要用 => 自己做batch机制 => eureka（三层队列实现的batch提交的机制）

### 128_hystirx的请求缓存以及请求合并自学以及自行源码分析的作业 

hystrix的两个高级功能，请求缓存、请求合并 

关于feign整合hystrix之后，如何使用请求缓存和请求合并的功能，交给大家自己去研究，给你们留个作业，自己去学习即可 

在生产环境里，hystrix请求缓存，说实话不多见，我宁愿围绕feign来打造请求缓存的组件，也不愿意基于hystrix，hystrix的本质是一个熔断框架 

hystrix请求合并，我宁愿feign来打造，也不愿意围绕hystirx 

eureka：服务的注册与发现

ribbon：负载均衡

feign：声明式服务调用，发送请求

hystirx：隔离、降级、熔断

zuul：网关 

你可以自行去在学会如何使用之后，研究请求缓存和请求合并对应的源码

### 129_一张图告诉你为啥微服务架构里要搞个网关这个东西？

网关是用来干什么的？

![](C:\Users\zy199005\Desktop\中华石杉\images\java\06\12901.png) 

spring cloud这块的技术，eureka、ribbon、feign、hystrix，zuul，微服务架构里的网关 

网关是什么东西？为什么我们需要这个网关呢？ 

前后台分离，以前不都是ssm框架 + jsp/velocity/freemarker => ssm处理请求 -> 数据结果 -> 渲染到页面模板里面去，html => 浏览器来显示 

java后端工程师，就是写java代码，提供restful（不是也无所谓）的http的接口 

前端工程师，就是写js、html、css之类的代码，专门放在一个工程里，浏览器全部都是请求前端工程的，前端工程也是单独部署在服务器上的，比如说用这个node.js技术。前端工程比如用node.js发起类似ajax的请求，来请求我们的后端工程的api接口，http请求。 

前端工程一定会调用大量的，多达几十个，几百个后端的服务 

前端工程师要熟悉和维护几十个，甚至几百个后端的服务，在真正的工程开发里，非常的不靠谱和不现实，每个服务部署了几台机器，什么地址，叫什么名字 

设计模式，阶段一，facade门面思想，对于一套复杂的类体系和接口，全部暴露一个统一的门面，门面给别人调用即可，别人就不用去熟悉你几十个类和几百个接口，我要调用这个接口了，我还得去想想，我得找哪个类 

1、请求路由 

屏蔽复杂的后台系统的大量的服务，然后让前端工程师调用的时候非常的简单 

2、统一处理 

把所有后台服务都需要做的一些通用的事情，挪到网关里面去处理 

（1）统一安全认证

（2）统一限流

（3）统一降级

（4）统一异常处理

（5）统一请求统计

（6）统一超时处理

###  130_先来写第一个zuul的demo程序体验一把网关这个东西的使用 

spring cloud：eureka、ribbon、feign、hystrix、zuul 

创建一个工程：zuul-gateway 

<dependency>

<groupId>org.springframework.cloud</groupId>

<artifactId>spring-cloud-starter-zuul</artifactId>

</dependency>

<dependency>

<groupId>org.apache.httpcomponents</groupId>

<artifactId>httpclient</artifactId>

<version>4.5.3</version>

</dependency> 



@SpringBootApplication

@EnableZuulProxy

public class ZuulGatewayApplication { 

public static void main(String[] args) {

SpringApplication.run(ZuulGatewayApplication.class, args);

} 

} 

application.xml 

server:

 port: 9000

zuul:

 routes:

demo:

 url: http://localhost:9090 

这段配置的意思，就是说，如果你请求网关，比如：http://localhost:9000/demo/ServiceB/user/sayHello 

那么他会转发给：http://localhost:9090/ServiceB/user/sayHello 

就是这个意思 

大家从这里就可以看到，如果你的hystris不设置timeout时长，默认第一次请求，经常会超时，这个是不太合理的，所以超时的请求时长，可以稍微长一点，不设置长一些也无所谓，因为也就是这个服务刚启动，第一次请求会慢一些罢了 

http://localhost:9000/demo/ServiceB/user/sayHello/1?name=张三&age=20 

http://localhost:9090/ServiceB/user/sayHello/1?name=张三&age=20  

=> 直接来请求服务B

### 131_在spring cloud环境下来一把zuul的demo体验下怎么使用  

请求过来了，然后就是直接将请求转发给一个url地址

相当于是咱们就单独使用了zuul，但是我们现在要将zuul和ribbon、feign、hystrix、eureka整合起来使用，是如何使用的呢？ 

<dependency>

<groupId>org.springframework.cloud</groupId>

<artifactId>spring-cloud-starter-config</artifactId>

</dependency>

<dependency>

<groupId>org.springframework.cloud</groupId>

<artifactId>spring-cloud-starter-eureka</artifactId>

</dependency> 

application.yml 

spring:

 application:

name: zuul-gateway

eureka:

 instance:

hostname: localhost

 client:

serviceUrl:

 defaultZone: http://localhost:8761/eureka/

zuul:

 routes:

ServiceB:

 path: /demo/** 

上面的配置，就是说，所有针对http://localhost:9000/demo/**的请求，都会转发给服务B的其中一个服务，比如说转发给http://localhost:9090/ServiceB/user/sayHello 

http://localhost:9000/demo/ServiceB/user/sayHello 

http://localhost:9090/ServiceB/user/sayHello 

看过源码的人，就会发现说，哇塞，这个学习一个技术的使用，简单爆了，只是学习一个东西的使用，简单到不能再简单了，是一个开源技术背后的一些原理

### 132_zuul的核心工作原理图解：说白了就是责任链模式的各种过滤器

zuul的核心工作原理

![](C:\Users\zy199005\Desktop\中华石杉\images\java\06\13201.png) 

设计模式，其实在各种开源项目里，到处都是设计模式 

pre过滤器

-3：ServletDetectionFilter

-2：Servlet30WrapperFilter

-1：FromBodyWrapperFilter

1：DebugFilter

5：PreDecorationFilter 

routing过滤器 

10：RibbonRoutingFilter

100：SimpleHostRoutingFilter

500：SendForwardFilter 

post过滤器 

1000：SendResponseFilter 

error过滤器 

0：SendErrorFilter 

zuul的源码，其实非常简单的，一点都不复杂，zuul的源码，有可能是spring cloud几个核心组件里面，最简单的，ribbon差不多一个级别的简单

### 133_zuul最主要的功能：快速熟悉一下各种请求路由规则的配置

zuul：请求路由，他作为一个网关，接收到一个请求，然后将这个请求转发给其他的服务 

**1、简单路由** 

spring cloud在zuul的routing阶段，搞了几个过滤器，这几个过滤器会负责将请求转发到后面的服务里去，最基本的就是SimpleHostRoutingFilter，这个大概就是这么配置的： 

zuul:

 routes:

demo:

 path: /ServiceB/**

 url: http://localhost:9090/ServiceB 

zuul.host.maxTotalConnections：这是配置连接到目标主机的最大http连接数，是用来配置http连接池的，默认是200 

zuul.host.maxPerRouteConnections：就是每个主机的初始连接数，默认是20 

**2、跳转路由** 

SendForwardFilter负责进行跳转路由 

这个，就是在zuul-gateway工程里，搞一个controller，然后配置一下： 

zuul:

 routes:

demo:

 path: /test/**

 url: forward: /gateway/sayHello 

这个说白了就是自己跳转到自己网关工程里的一个接口 

**3、ribbon路由**

学习要有轻有重，最高效的学习，不是说拿到一个技术，然后一个功能点一个功能点的学，一个功能点一个功能点的练习，spring cloud，买一本spring cloud的技术书籍，一点一点跟着做，学习效率是很低的 

拿到一个技术，首先要投入精力搞懂的，就是他的核心的基础功能，可能就占到日常使用的80%的使用频率。spring，复杂，功能非常多，但是我们日常开发过程中，可能就用人家spring核心的10%的功能罢了。 

剩下这个技术会有一堆的配置、高级特性，你别一个一个的功能去做demo，主要讲解技术的使用，一个功能点一个功能点的读PPT、写demo，学习效率太低了。你只要了解即可，就是看一下，脑子里有印象就ok了。 

真正应该投入精力的，就是去看一个技术的源码，核心源码，围绕几个hello world的demo，把核心源码读通读懂。这个技术，学习一个技术的最好的方式。 

你在实际做项目的时候，设计架构的时候，你考虑的一些点，然后呢要不要去使用某个高级特性呢？ 

这个就是说基于ribbon + eureka，来转发请求到某个服务，使用ribbon来实现负载均衡 

zuul:

 routes:

ServiceB:

 path: /demo/**

 serviceId: ServiceB 

zuul:

 routes:

ServiceB:

 path: /demo/** 

下面那种写法是简化的写法 

**4、自定义路由规则** 

@Configuration

public class MyRouteRuleConfig { 

@Bean

public PatternServiceRouteMapper patternServiceRouteMapper() {

return new PatternServiceRouteMapper(“(zuul)-(?<test>.+)-(service)”, “${test}/**”);

} 

} 

请求：test/**的路径，转发给zuul-test-service 

**5、忽略路由** 

zuul:

 ignoredPatterns: /ServiceB/test

### 134_zuul的其他常见配置：请求头、路由映射、hystrix、ribbon等等 

**1、请求头配置** 

默认情况下，zuul有些敏感的请求头不会转发给后端的服务 

比如说：Cookie、Set-Cookie、Authorization，也可以自己配置敏感请求头 

zuul:

 sensitiveHeaders: accept-language, cookiei

 routes:

demo:

 sensitiveHeaders: cookie 

**2、路由映射信息** 

我们在zuul-gateway中引入actuator项目，然后在配置文件中，将management.security.enabled设置为false，就可以访问/routes地址，然后可以看到路由的映射信息 

**3、hystrix配置**

与ribbon整合转发时，会使用RibbonRoutingilter，转发会使用hystrix包裹请求，如果请求失败，会执行fallback逻辑 

public class ServiceBFallbackProvider implements ZuulFallbackProvider { 

public String getRoute() {

return “ServiceB”;

} 

public ClientHttpResponse fallbackResponse() {

return new ClientHttpResponse() { 

public InputStream getBody() throws IOException {

return new ByteArrayInputStream(“fallback”.getBytes());

} 

public HttpHeaders getHeaders() {

HttpHeaders headers = new HttpHeaders();

headers.setContentType(MediaType.TEXT_PLAIN);

return headers;

} 

public HttpStatus getStatusCode() throws IOException {

return HttpStatus.OK;

} 

public int getRawStatusCode() throws IOException {

return 200;

} 

public String getStatusText() throws IOException {

return “OK”;

} 

public void close() { 

} 

}

} 

} 

@Configuration

public class FallbackConfig { 

@Bean

public ZuulFallbackProvider fallbackProvider() {

return new ServiceBFallbackProvider();

} 

}

 

zuul:

 routes:

ServiceB:

 path: /ServiceB/** 

上面的代码就定义了ServiceB的降级逻辑 

但是一般不会针对某个服务搞降级，你最好是在getRoute()方法中，返回：*，这样子就是做一个全局的降级 

**4、ribbon客户端预加载**

默认情况下，第一次请求zuul才会初始化ribbon客户端，所以可以配置预加载 

zuul:

 ribbon:

eager-load:

 enabled: true 

**5、超时配置** 

人zuul也是用的hystrix + ribbon那套东西，所以说，超时这里要考虑hystrix和ribbon的，而且hystrix的超时要考虑ribbon的重试次数和单次超时时间 

hystrix的超时时间计算公式如下： 

(ribbon.ConnectTimeout + ribbon.ReadTimeout) * (ribbon.MaxAutoRetries + 1) * (ribbon.MaxAutoRetriesNextServer + 1) 

ribbon:

 ReadTimeout:100

 ConnectTimeout:500

 MaxAutoRetries:1

 MaxAutoRetriesNextServer:1 

如果不配置ribbon的超时时间，默认的hystrix超时时间是4000ms

### 135_再来搞一搞zuul的一些高级功能：过滤器优先级、自定义过滤器等等 

**1、过滤器优先级** 

pre过滤器 

-3：ServletDetectionFilter

-2：Servlet30WrapperFilter

-1：FromBodyWrapperFilter

1：DebugFilter

5：PreDecorationFilter 

routing过滤器 

10：RibbonRoutingFilter

100：SimpleHostRoutingFilter

500：SendForwardFilter 

post过滤器 

1000：SendResponseFilter

error过滤器 

0：SendErrorFilter 

**2、自定义过滤器** 

public class MyFilter extends ZuulFilter { 

public boolean shouldFilter() {

// 是否要执行过滤器

return true;

} 

publici Object run() {

System.out.println(“执行过滤器”);

return null;

} 

// 在哪个阶段执行

public String filterType() {

return FilterConstants.ROUTE_TYPE;

} 

// 这是过滤器的优先级

public int filterOrder() {

return 1;

} 

} 

@Configuration

public class FilterConfig { 

@Bean

public MyFilter myFilter() {

return new MyFilter();

} 

} 

**3、动态加载过滤器** 

<dependency>

<groupId>org.codehaus.groovy</groupId>

<artifactId>groovy-all</artifactId>

<version>2.4.12</version>

</dependency> 

在Application类里 

@PostConstruct

public void zuulInit() {

FilterLoader.getInstance().setCompiler(new GroovyCompiler()); 

String scriptRoot = System.getProperty(“zuul.filter.root”, “groovy/filters”);

String refreshInterval = System.getProperty(“zuul.filter.refreshInterval”, “5”); 

if(scriptRoot.length() > 0) {

scriptRoot = scriptRoot + File.separator;

} 

try {

FilterFileManager.setFilenameFilter(new GroovyFileFilter());

FilterFileManager.init(Integer.parseInt(refreshInterval), scriptRoot + “pre“, scriptRoot + “route”, scriptRoot + “post”);

} catch(Exception e) {

throw new RuntimeException(e);

} 

}

 

zuul:

 filter:

root: “groovy/filters”

refreshInterval: 5 

在src/main/java/groovy/filters中，放一个MyFilter.groovy 

class MyFilter extends ZuulFilter { 

public boolean shouldFilter() {

return true;

} 

public Object run() {

System.out.println(“过滤器”);

return null;

} 

public String filterType() {

return FilterConstants.ROUTE_TYPE;

} 

public int filterOrder() {

return 1;

} 

} 

先启动网关项目，然后将这个过滤器放到指定目录，过几秒钟就会生效 

**4、禁用过滤器** 

zuul:

 SendForwardFilter:

route:

 disable: true 

**5、RequestContext** 

在过滤器中，使用RequestContext.getCurrentContext()，可以获取到serviceId、requestURI等各种东西 

**6、@EnableZuulServer** 

这个的话，就是自动禁用掉PreDecorationFilter、RibbonRoutingFilter、SimpleHostRoutingFilter等过滤器。。。 

**7、error过滤器** 

在自定义过滤器里搞一个异常抛出来，ZuulException 

然后写一个MyErrorController，继承BasicErrorController，统一处理异常，打印一些信息，这就是统一异常处理 

统一异常处理

统一认证

统一限流

统一降级 

### 136_老规矩：先来一张很大的图说说zuul在spring cloud环境下的的核心原理

zuul的核心原理

![](C:\Users\zy199005\Desktop\中华石杉\images\java\06\13601.png)  

spring cloud的一些组件，他的顺序，都是有原因的，eureka、ribbon、feign、hystrix、zuul（eureka、ribbon、hystrix） 

用屁股想想，zuul的核心源码，没什么东西的，核心就在于说接收到一个url请求之后，如何来解析这个请求，如何根据我们在application.yml配置文件中的配置，来将这个url请求转换为针对某个服务的一个url请求 

依赖ribbon进行负载均衡，依赖eureka进行服务发现，依赖hystrix进行熔断降级

### 137_来观察一下spring cloud源码中的zuul过滤器所在的包

zuul源码级别原理图(1)

![](C:\Users\zy199005\Desktop\中华石杉\images\java\06\13701.png)

 

zuul，很有可能spring cloud核心组件里源码难度最低的一个组件，核心源码，以及核心功能，主要就是解析url，将解析后的url跟你的application.yml中的路由配置（route）匹配起来，对请求url选择对应的路由配置 

根据路由配置，将对应的请求封装一下，基于eureka + ribbon实现服务的负载均衡，基于hystirx包裹实际的请求，完成熔断降级 

zuul核心的代码都在一坨过滤器中 

在spring cloud源码中，zuul相关的过滤器在哪里呢？？？ 

pre过滤器 

-3：ServletDetectionFilter

-2：Servlet30WrapperFilter

-1：FromBodyWrapperFilter

1：DebugFilter

5：PreDecorationFilter 

routing过滤器 

10：RibbonRoutingFilter

100：SimpleHostRoutingFilter

500：SendForwardFilter 

post过滤器 

900：LocationRewriteFilter

1000：SendResponseFilter 

error过滤器 

0：SendErrorFilter

### 138_我们来分析一下@EnableZuulProxy注解以及zuul原生包

@EnableZuulProxy注解，一看就是非常核心的触发了zuul相关的过滤器的执行的这么一个注解，如果没有这个注解，很明显，zuul的一些功能就不会执行，包括zuul的各种过滤器，所以我们来以@EnableZuulProxy注解作为入口，来研究一下他在干什么 

这段话的意思，这个@EnableZuulProxy注解其实干了两件事情，第一件事情就是启用一个zuul server，这个东西可以接收所有的http请求，都会被他给拦截，所以这块我们可以想象一下，这里的zuul一定是搞了一个类似与servlet、filter、spring boot拦截器的东西 

这个东西一定会拦截所有的http请求，他来处理 

第二件事情，就是给那个zuul server（拦截器，servlet，filter）加入一些内置的filter，过滤器，就是我们之前看到的各种过滤器 

@EnableCircuitBreaker

@Target(ElementType.TYPE)

@Retention(RetentionPolicy.RUNTIME)

@Import(ZuulProxyMarkerConfiguration.class)

public @interface EnableZuulProxy {

} 

很明显上面的那个@Import引入了另外的一个Configuration类 

/**

 \* Responsible for adding in a marker bean to trigger activation of 

 \* {@link ZuulProxyAutoConfiguration}

 *

 \* @author Biju Kunjummen

 */ 

@Configuration

public class ZuulProxyMarkerConfiguration {

​     @Bean

​     public Marker zuulProxyMarkerBean() {

​          return new Marker();

​     } 

​     class Marker {

​     }

} 

看他的注释是什么意思啊？这个ZuulProxyMarkerConfiguration是用来触发ZuulProxyAutoConfiguration的执行的 

所以之前给大家说过，spring cloud、spring boot的源码，一定要注意，他的入口基本上就是各种各样的XXXAutoConfiguration一级XXXConfiguration。这里的zuul的入口，基本上就是ZuulProxyAutoConfiguration 

org.springframework.cloud.netflix.zuul 

这个包里一定就放了我们想要寻找的那些XXXAutoConfiguration或者是XXXConfiguration 

我们就来分析一下ZuulProxyAutoConfiguration，这个东西很明显就是zuul相关的组件的初始化的这么一个入口 

@ConditionalOnBean(ZuulProxyMarkerConfiguration.Marker.class) 

这个的意思，就是必须有ZuulProxyMarkerConfiguration里面的一个Marker作为spring容器中的bean，然后才能触发ZuulProxyAutoConfiguruation的执行，这个类里面大概来说，就是初始化了一系列的zuul的过滤器，以及其他七七八八的一些组件 

zuul-core-1.3.0.jar里，找到了一个比较核心的东西，一看就是我之前给大家说的zuul的核心入口，就是一个ZuulServletFilter，这个东西是java web原生的filter，会在java web应用，在tomcat这种容器里去注册，负责拦截所有的请求 

我们发现了另外一个非常核心的类，就是ZuulServlet，也是java web原生的servlet，我们理解，就是ZuulServletFilter和ZuulServlet加起来基于java web的原生API拦截了所有的请求，然后完成了整个zuul的入口的核心功能和代码 

一步一步的调试zuul的源码，一边写分析，一边画图 

zuul依赖eureka、ribbon、hystrix干了一些事情，他自己而言的话呢，没干什么事情，干的事情非常少

### 139_来给zuul原生的ZuulServlet打上断点分析一下请求入口的源码

zuul源码级别原理图

![](C:\Users\zy199005\Desktop\中华石杉\images\java\06\13901.png) 

zuul核心的入口一定是在他自己原生包里的filter和servlet，拦截所有的请求 

通过这个断点，直接发现，请求过来，直接进入ZuulServlet中的，你会发现原来zuul的核心请求是由ZuulServlet来作为一个入口来处理的 

RequestContext，这个东西会作为请求的上下文，在这个东西里面包含本次请求的所有相关的数据，他其实认为是一个类似与map的这么一个结构，首先这里就会将原生的ServletRequest放入其中 

​    ctx.setResponse(new HttpServletResponseWrapper(servletResponse)); 

HttpServletResponseWrapper，包裹了ServletResponse，装饰模式，包裹了之后，对某些功能可以进行增强，在Wrapper类里，可以保存response设置的一些status状态，方便我们取用status 

HttpServletResponseWrapper，包裹了原生的ServletResponse，都被放在了RequestContext中，里面放入了本次请求相关的所有内容，RequestContext我们用屁股想想，很适合用ThreadLocal来实现，本次请求就是一个线程在处理，对这个线程就可以使用ThreadLocal放入各种数据副本 

​    RequestContext ctx = RequestContext.getCurrentContext(); 

这个RequestContext，只要保证每次请求过来的时候，当前这个线程可以获取到一个独一无二的RequestContext就可以了，展现的是我分析源码的思路 

​      try {

​        preRoute();

​      } catch (ZuulException e) {

​        error(e);

​        postRoute();

​        return;

​      } 

preRoute()大概来说，就是去执行pre过滤器，如果pre过滤器中有任何一个过滤器执行失败了，那么会执行error(e) => 执行error过滤器，同时接着执行post过滤器 

​      try {

​        route();

​      } catch (ZuulException e) {

​        error(e);

​        postRoute();

​        return;

​      } 

如果pre过滤器都执行成功了，没有报错，然后就会执行route过滤器，但是如果执行route过滤器报错了，那么就会执行error过滤器，然后再执行post过滤器 

​      try {

​        postRoute();

​      } catch (ZuulException e) {

​        error(e);

​        return;

​      } 

postRoute()就是去执行post过滤器，如果route过滤器没有报错的话，那么就会执行post过滤器，如果post过滤器执行报错了，就会执行error过滤器 

​      RequestContext.getCurrentContext().unset(); 

本次请求执行完毕，直接清理掉RequestContext中的本次请求的RequestContext 

我们会发现一件事情，ZuulServletFilter没有执行，也挺好，说明入口主要就是ZuulServlet。其实ZuulServletFilter跟ZuulServelt是一回事儿，里面的代码逻辑几乎都是一样的，他们只是基于java web原生的api提供了两种不同形式的入口而已 

你可以基于servlet来启动zuul入口，也可以基于他的filter来启用zuul的入口 

默认情况下是使用zuul的ZuulServlet来作为请求入口的，ZuulServletFilter是不使用的

### 140_好了进入主题：先看看那些pre过滤器都干些什么乱七八糟的事情 

pre过滤器 

-3：ServletDetectionFilter

-2：Servlet30WrapperFilter

-1：FromBodyWrapperFilter

1：DebugFilter

5：PreDecorationFilter 

全部打上断点，然后我们来调试一下源码，主要看几块，第一是按照什么顺序来执行，第二是执行哪些过滤器，第三是每个过滤器在干什么 

​      runFilters("pre"); 

执行filter就是用的一个runFilters()方法，然后就传入pre字符串，通知要执行pre过滤器，起码得用一个常量吧，或者是最好是单独拉一个方法出来 

FilterProcessor，是一个单例类，专门用来执行各种过滤器的类 

​    boolean bResult = false; 

zuul的源码，一看代码，就知道写代码的人，这个代码功底不太ok 

​    List<ZuulFilter> list = FilterLoader.getInstance().getFiltersByType(sType); 

这行代码的意思，就是根据你指定的过滤器的类型，pre，来找到pre类型的过滤器，而且是按照过滤器的优先级来排序的，拿到了一个过滤器的list 

ServletDetectionFilter到底在干什么呢？ 

RequestContext：isDispatcherServletRequest = true 

Servlet30WrapperFilter 

​               ctx.setRequest(new Servlet30RequestWrapper(request)); 

Servlet30RequestWrapper类包裹了一下request，装饰模式 

​     /**

​      \* There is a bug in zuul 1.2.2 where HttpServletRequestWrapper.getRequest returns a wrapped request rather than the raw one.

​      \* @return the original HttpServletRequest

​      */

​     @Override

​     public HttpServletRequest getRequest() {

​          return this.request;

​     } 

在zuul 1.2.2里有一个bug，这个bug是什么呢？在zuul 1.2.2版本里，有一个类，叫做HttpServletRequestWrapper，当时实现的时候，那个getRequest()方法返回的不是原生的ServletRequest 

所以在zuul 1.3.0 版本里，其实修复了这个bug，就是搞了一个Servlet30Wrapper，是HttpServletReqeustWrapper子类，用这个东西来重写了一下getRequest()方法，这个方法会返回java web原生的一个ServletRequest类 

FromBodyWrapperFilter 

默认情况下不执行的，shouldFilter()方法里的逻辑，必须是APPLICATION_FORM_URLENCODED这种media type才会执行，或者是MULTIPART_FORM_DATA这种media type才会执行，默认情况下我们的media type肯定都不是这几种特殊的形式 

DebugFilter

你必须在http请求中加入一个参数，debug=true，然后才会执行DebugFilter，这个DebugFilter其实就是打开几个debug的标识，然后在后面的运行中会打印一些debug的日志 

PreDecocationFilter 

首先是解析了一下请求url，拿到了我们请求的url地址，/demo/ServiceB/user/sayHello/1 

​          final String requestURI = this.urlPathHelper.getPathWithinApplication(ctx.getRequest());

​          Route route = this.routeLocator.getMatchingRoute(requestURI); 

非常关键，他其实就是根据我们的请求url地址，去匹配我们的application.yml中的路由规则的配置，然后拿到了请求url对应的路由规则 

Route{id='ServiceB', fullPath='/demo/ServiceB/user/sayHello/1', path='/ServiceB/user/sayHello/1', location='ServiceB', prefix='/demo', retryable=false, sensitiveHeaders=[], customSensitiveHeaders=false, prefixStripped=true} 

zuul最核心的逻辑，在这个PreDecoration中就完成了，当然了，其实解析请求uri，以及完成请求uri和application.yml中的路由规则的匹配的事儿，是zuul最最核心的事儿，但是这个里面的源码是比较琐碎没任何技术含量的源码 

都是一些琐碎代码，体力活 

到此为止，pre过滤器都执行完了

### 141_终于找到zuul的核心代码：解析请求URI以及匹配路由规则

zuul源码级别原理图(2)

![](C:\Users\zy199005\Desktop\中华石杉\images\java\06\14101.png)

 上一讲给大家分析了pre过滤器的一些机制 

PreDecorationFilter才是最最核心的一坨逻辑，里面包含了请求的解析什么的，匹配路由规则，这块逻辑算是比较核心的逻辑，代码没什么技术含量的，就是一些琐碎的代码，体力活，解析，匹配 

就把PreDecorationFilter中的核心逻辑的源码来看一看 

UrlPathHelper是spring-web项目中的一个辅助类，工具类，其实就是解析请求URI，提取出来对应的请求URI的部分，这段源码不用看了，要看到spring-web中去了，也不是zuul的核心代码，人家只是用了别人的工具而已 

http://localhost:9000/demo/ServiceB/user/sayHello/1?name=张三&age=20 

/demo/ServiceB/user/sayHello/1 

​          Route route = this.routeLocator.getMatchingRoute(requestURI); 

这行代码，其实是根据解析出来的请求URI，去匹配application.yml文件中我们配置的路由规则，将路由规则封装成一个Route 

发现其实他里面只有一个DiscoveryClientRouteLocator，这个东西的话呢，我们没必要去搞清楚他是干什么的，只要知道他其实就是一个工具类，匹配路由规则的事情的 

​          if (log.isDebugEnabled()) {

​               log.debug("Finding route for path: " + path);

​          } 

如果你是调试模式的话，需要他打印很多debug日志，可以在请求里面加一个debug=true的参数，然后后面的各种debug日志都会打印出来，DebugFilter中会处理这个事情的 

zuul:

 routes:

  ServiceB:

   path: /demo/** 

Map<String, ZuulRoute> 

key = /demo/**

value = ZuulRoute(serviceId = “ServiceB”) 

/demo/**

/demo/ServiceB/user/sayHello/1 

是否匹配，如果匹配的话，就直接返回ZuulRoute，就是路由规则 

ZuulRoute{id='ServiceB', path='/demo/**', serviceId='ServiceB', url='null', stripPrefix=true, retryable=null, sensitiveHeaders=[], customSensitiveHeaders=false, } 

targetPath = /ServiceB/user/sayHello/1

prefix = /demo 

​          return new Route(route.getId(), targetPath, route.getLocation(), prefix,

​                    retryable,

​                    route.isCustomSensitiveHeaders() ? route.getSensitiveHeaders() : null, 

​                    route.isStripPrefix()); 

创建了一个Route对象，先搞到了一个ZuulRoute的这么一个东西，这个东西里面封装了一些基本的路由规则，然后对这个ZuulRoute再次进行了解析，以及一些转换，尤其是处理出来了几个数据，封装了一个Route对象 

Route{id='ServiceB', fullPath='/demo/ServiceB/user/sayHello/1', path='/ServiceB/user/sayHello/1', location='ServiceB', prefix='/demo', retryable=false, sensitiveHeaders=[], customSensitiveHeaders=false, prefixStripped=true} 

接下来就是将Route路由规则中的各种信息给放在了RequestContext中了，给下一个阶段route过滤器来使用

### 142_来初步看看route阶段的过滤器有哪几个大概都在干些什么呢

zuul源码级别原理图(3)

![](C:\Users\zy199005\Desktop\中华石杉\images\java\06\14201.png) 

routing过滤器 

10：RibbonRoutingFilter

100：SimpleHostRoutingFilter

500：SendForwardFilter 

​               ClientHttpResponse response = forward(commandContext); 

这行代码，他其实就是说基于ribbon完成了负载均衡，从ServiceB的几台机器中选择了一台出来，将请求封装在hystrix中来发送 

​      try {

​        route();

​      } catch (ZuulException e) {

​        error(e);

​        postRoute();

​        return;

​      } 

RibbonRoutingFilter => 将请求转发到服务的

SimpleHostRoutingFilter => 将请求转发到某个url地址的

SendForwardFilter => 将请求转发到zuul网关服务自己的一个接口上去

### 143_最核心的逻辑来了：RibbonRoutingFilter是如何将请求转发给服务的

zuul源码级别原理图(4)

![](C:\Users\zy199005\Desktop\中华石杉\images\java\06\14301.png) 

 

RequestContext 

{retryable=false, request=org.springframework.cloud.netflix.zuul.filters.pre.Servlet30RequestWrapper@5c66b301, ignoredHeaders=[authorization, set-cookie, cookie], originResponseHeaders=[com.netflix.util.Pair@abc01b78], zuulRequestHeaders={x-forwarded-host=localhost:9000, x-forwarded-proto=http, x-forwarded-prefix=/demo, x-forwarded-port=9000, x-forwarded-for=0:0:0:0:0:0:0:1}, zuulEngineRan=true, requestQueryParams={name=[张三], age=[20]}, requestURI=/ServiceB/user/sayHello/1, isDispatcherServletRequest=true, proxy=ServiceB, response=com.netflix.zuul.http.HttpServletResponseWrapper@7a0b1b0f, executedFilters=ServletDetectionFilter[SUCCESS][0ms], Servlet30WrapperFilter[SUCCESS][0ms], PreDecorationFilter[SUCCESS][17647ms], serviceId=ServiceB} 

RibbonCommandContext 

RibbonCommandContext{serviceId='ServiceB', method='GET', uri='/ServiceB/user/sayHello/1', retryable=false, headers={accept=[application/json], cache-control=[no-cache], user-agent=[Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/65.0.3325.181 Safari/537.36], content-type=[application/json], accept-language=[zh-CN,zh;q=0.9,en;q=0.8], x-forwarded-host=[localhost:9000], x-forwarded-proto=[http], x-forwarded-prefix=[/demo], x-forwarded-port=[9000], x-forwarded-for=[0:0:0:0:0:0:0:1], Accept-Encoding=[gzip]}, params={name=[张三], age=[20]}, requestEntity=com.netflix.zuul.http.ServletInputStreamWrapper@22453c1d, requestCustomizers=[], contentLength=-1, loadBalancerKey=null} 

info Map 

{method=GET, path=/ServiceB/user/sayHello/1, query=?name=%E5%BC%A0%E4%B8%89&age=20, remote=true, proxy=ServiceB, headers={request={accept=application/json, cache-control=no-cache, user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/65.0.3325.181 Safari/537.36, content-type=application/json, accept-language=zh-CN,zh;q=0.9,en;q=0.8, x-forwarded-host=localhost:9000, x-forwarded-proto=http, x-forwarded-prefix=/demo, x-forwarded-port=9000, x-forwarded-for=0:0:0:0:0:0:0:1, Accept-Encoding=gzip}}} 

HttpClientRibbonCommand（继承自HystrixCommand），里面实现了run()逻辑，实现了这个command要发送的请求的核心逻辑，后面的话呢，大家自己去回头看一看hystirx的源码逻辑，在里面，会初始化线程池，搞一堆Observable，提交一个任务到线程池里去执行，熔断、超时、拒绝、异常、降级，这些逻辑都是在HystrixCommand里面来控制的 

HttpClientRibbonCommand，他核心的一点就是自己设置的那个run()方法，封装了自己核心的业务逻辑，发送一个请求出去 

feign，feign执行到最后也是类似的逻辑，我这里就不展开分析了，在这里的意思是一样的，就是他会先调用selectServer()方法，通过ribbon的ILoadBalancer负载均衡选择一个server出来，然后执行实际的请求

### 144_简单看看剩下的route阶段两个过滤器的源码是干嘛的就行  

SimpleHostRoutingFilter 

如果你要转发给某个url地址，就是这个过滤器来干，源码非常简单，很少用 

其实就是处理一下请求头、请求参数、请求体（json数据），然后交给底层的http组件，将这个请求发给指定的主机名:端口号，就ok了 

SendForwardFilter 

​               RequestDispatcher dispatcher = ctx.getRequest().getRequestDispatcher(path); 

你参加那种4个月的培训班儿，就会学这个，java web的最最基础和原生的api，RequestDispacher进行请求转发，将这个请求转发给本地其他的这个接口来处理

### 145_再来看看post阶段的过滤器是如何将服务返回结果发送给浏览器的

zuul源码级别原理图(5)

![](C:\Users\zy199005\Desktop\中华石杉\images\java\06\14501.png) 

 LocationRewriteFilter 

这个filter默认情况下没跑，看看说响应结果是否是要进行请求重定向，如果是的话才会执行，但是这里默认一般不是 

SendResponseFilter 

​               is = context.getResponseDataStream();

​               InputStream inputStream = is; 

context.getResponseDataStream()，会是什么呢？你的服务返回的是一个json串，此时这个stream就是那个json串读取的流 

​          OutputStream outStream = servletResponse.getOutputStream(); 

ServletResponse是原生的servletResponse，获取到了针对浏览器的一个输出流，outStream就是一个输出流 

inputStream是服务B返回的json串读取的输入流，outStream是针对浏览器的一个输出流，你觉得他在这里会干骂呢？他其实就是会从inputStream输入流中读取json串，然后写到outStream输出流中，写给浏览器 

​          byte[] bytes = buffers.get();

​          int bytesRead = -1;

​          while ((bytesRead = zin.read(bytes)) != -1) {

​               out.write(bytes, 0, bytesRead);

​          } 

4个月培训班儿的同学，绝对知道，基础的不能再基础的一些东西了，java web的一些东西

### 146_最后一讲我们来看一下error阶段的过滤器是如何显示报错的

SendErrorFilter 

我们不用来调试源码，直接看一下源码就ok了 

之前的pre阶段、route阶段、post阶段，任何一个阶段抛出了异常，都会执行SendErrorFilter 

​               if (dispatcher != null) {

​                    ctx.set(SEND_ERROR_FILTER_RAN, true);

​                    if (!ctx.getResponse().isCommitted()) {

​                         ctx.setResponseStatusCode(exception.nStatusCode);

​                         dispatcher.forward(request, ctx.getResponse());

​                    }

​               } 

我之前给大家讲过，我们可以自己写一个controller，专门来处理zuul的所有异常报错，继承另外一个controller的基类就可以了，这样的话就可以实现统一的异常处理 

默认情况下，如果有异常，打印出异常日志，在控制台，将异常信息输出到浏览器中去 

BasicErrorController