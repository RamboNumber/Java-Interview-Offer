# 从 0 开始带你成为消息中间件实战高手

### 开篇词 工程师们学习技术的痛点：纯理论、不知道如何实战！

**1、为什么我们必须要不停的学习？**

相信只要对技术有追求的朋友都会不停地学习，因为技术领域发展非常快速，要想不被淘汰，就得不停学，甚至终身学习，不断迭代更新自己的技术能力。否则有些人虽然做着工程师的工作，但是仅仅满足于完成基本工作任务，那么技术能力会一直停滞不前。

最后，当整个行业的技术发展到一定程度时，你若是没跟上这些技术的发展，就会被行业淘汰。

举个简单的例子，如果一直以来你在线上生产环境部署时，都是采用的把项目打成一个war包，然后放到线上机器的Tomcat中，再重启Tomcat这种方式。

那么当你有一天出去面试时，突然发现外面的公司都是采用持续集成、自动化测试、全链路测试、自动化部署、灰度发布、容器化部署的方式在进行系统的开发、测试以及发布，此时你内心是什么感受？

不用说，你的内心一定是崩溃的，因为你发现自己已经被这个行业给淘汰掉了，出去找工作，没有人认可你的技术和经历，你也极度的没有自信。

绝大部分工程师，其实都明白上述道理，只有不停的学习，更新自己的技术体系，保持自己的核心竞争力，才能长久的在行业中生存下去。

**2、学习技术的痛点：纯理论，无实战！**

而绝大多数朋友在学习时，往往会采取以下几类方式：

- 阅读技术书籍。特别是趁着促销季大量囤书，然后一本本的啃。
- 网上关注一些公众号的文章或者是博客文章
- 购买一些技术专栏或一些技术视频课程

我发现身边很多朋友都是通过上述方式进行技术学习的，但是也经常听到有人跟我吐槽，感觉是学了很多东西，看了很多书、专栏和视频，但是觉得仅仅学会了一些理论性的东西

正因为如此，无论是自己在工作里用这个技术，还是出去面试跟人聊起这个技术的时候，自己也只能说出理论的东西。

似乎很多人都觉得自己对技术缺乏实战性的经验和积累？

没错，这就是行业工程师们学习技术的痛点，绝大多数资料都止步于纯理论，对技术的实战落地没有任何的经验输出，导致工程师们也没法学习到具有实战意义的东西。

**3、我们这个专栏的特点**

因此我们这个专栏，就是希望能够在消息中间件这个技术的学习上，改变过往这种纯理论无实战思路的学习方式。

以前的工程师出去找工作，只要你会Spring、MyBatis之类的技术框架，就可以找一份工作。

但是现在跳槽面试，要求会高很多，比如像消息中间件（MQ）这样的技术是一定会被问到的，无论是互联网行业还是传统软件行业。

很多工程师因此都会对消息中间件技术进行一定的学习，但是现在网上无论是书籍、专栏还是一些视频课程，几乎都是偏向理论的资料

比如下面一些问题，很多人即使自己学习了消息中间件技术，依然不明所以：

1. 消息中间件技术到底在生产环境是解决哪些系统业务问题的？
2. 到底如何用消息中间件技术来解决这些问题？
3. 如何根据生产情况去设计消息中间件的技术方案？
4. 在真正把消息中间件技术落地到项目中的时候，到底应该考虑哪些问题？

因此，我们这个专栏的设计思路，就是希望以实战的方式带着大家来学习消息中间件技术。

我会从一个**真实的日均百万交易量的订单系统架构**的技术痛点出发，反向驱动来学习消息中间件（mq）技术。

我会让你先明白在这个系统架构中有哪些技术痛点，然后再去思考一个技术有哪些功能，如何解决我们的这些痛点。

然后我会带着你思考：

- 如果要在生产环境中去落地这个技术方案，需要考虑哪些因素？
- 这个技术真正在生产环境中运行的时候可能会有哪些影响生产系统的问题？
- 该如何解决这些问题呢？
- 是不是可以对开源的技术做一些定制改造，进而让他更好的为我们的生产系统进行服务？

整个专栏都将以这种生产实战的思维出发，反过来带着大家学习消息中间件技术，而且会以现在行业中最流行和最常用的RocketMQ技术去学习。

你将会看到，我不会简单机械的给你讲一个一个的RocketMQ的原理和功能。

我会先告诉你，生产环境有这个需求和痛点，那么基于RocketMQ的某个功能如何来解决这个问题。

当你学完整个专栏之后，你会发现，你真的掌握了一种能力和思维：

- 当你在工作中遇到一些技术难题的时候，你知道如何用消息中间件技术去解决这些问题

- 当你出去找工作的时候，你可以跟人侃侃而谈，对消息中间件技术，你在生产环境中落地会考虑的一些问题是什么

**4、授人以鱼不如授人以渔**

另外，本专栏一个非常大的特点，就是希望真正让大家掌握捕鱼的能力，而不是直接把一些鱼送给你吃。

也就是说，在专栏中，对于每一个知识点，我都会反过来引导你去思考：

- 在你自己负责的系统中有没有类似的技术痛点和问题？
- 如果要让你在自己的系统中去解决类似的问题，你应该怎么做？

当你把这些问题都思考清楚之后，你会发现自己真正掌握了一个技术在生产中进行落地实战的思路和思维

同时你出去面试的时候，可以结合自己的系统情况，跟面试官聊一下技术在你们系统中落地实战的经验和思路。

**5、提问、答疑和互动**

当然在学习以及思考的过程中，一定会有很多的问题，这个非常正常。要学好一个东西，必须要勤于思考，在思考的时候就一定会产生问题。

当你学习过程中遇到问题时，尽情的在专栏中**每篇文章对应的评论区**提出你的问题，每天我都会对评论区中的问题进行答疑，跟你进行互动。

提问、答疑和互动的过程，相当于是你的第二次学习，你的很多问题会迎刃而解，真正让你的学习畅通无阻。

**6、专栏是如何更新的？**

我们的专栏是每周的一、三、五，进行更新，每次更新2篇文章，会包含一篇技术相关的讲解，还有一个“授人以渔”的环节。

此外，定期会有阶段性的思维导图总结和复习，帮助你温故知新。

**End**

### 01 一个真实电商订单系统的整体架构、业务流程及负载情况

正文开始：

**1、专栏主人公介绍**

**小猛**：应届毕业Java工程师，刚刚通过校招进入一家互联网公司工作，一个职场新人，对很多技术都不是太熟悉，还需要有资深的工程师带着，讲解系统业务和架构，同时安排和布置任务给他

**明哥**：10年工作经验的Java架构师，常年在国内各个一线互联网公司工作，有丰富的互联网公司的核心系统的设计、开发与运维经验，目前独立带领一个团队负责公司的订单系统，小猛就是他团队中的校招应届生，由他亲自带。

**说明**：这个专栏会从较为真实的职场环境出发，以两个主人公在工作中的一些对话作为核心的主体内容，带着大家去熟悉一个电商订单系统的架构以及各种技术痛点。

然后会由主人公之一的明哥带着职场新人小猛去熟悉消息中间件技术，为他布置各种任务去完成系统中的一些架构优化的工作。

相信这样的一种方式，会让大家学习起来更有代入感，而且更加有趣味性。

**2、一个订单系统的业务流程**

小猛从学校毕业后正式入职这家公司已经有1周了，在第一周里，主要是熟悉一下公司的开发环境、开发规范，跟团队里的同事熟悉熟悉，参加一下公司统一为新人提供的入职培训，同时参加团队的一些会议，熟悉一下工作方式。

一周过后，小猛就要开始正式接手一些实际的开发任务了。今天团队leader明哥带着小猛找了一个小会议室，打算给小猛进行为期几天的1对1培训

而培训的目的，主要是让小猛熟悉一下团队负责的订单系统的核心业务流程、整体架构设计以及当前系统面临的一些技术上的难点和痛点。

**明哥**：小猛，今天我来给你讲讲咱们团队负责的订单系统的业务流程以及整体架构。

**小猛**：好的，明哥，没问题，我会仔细听做好笔记的。

接着明哥就开始在白板上一边画图，一边讲起公司订单系统的业务流程。

**明哥**：订单系统可以说是公司最核心的业务系统之一，因为用户要在公司的APP中购买商品，首先会在APP中浏览各种各样的商品

接着就会将喜欢的商品加入到购物车中，然后下订单进行支付后就可以购买这些商品了，你看我下面画的这个图：

![picture.png](http://wechatapppro-1252524126.file.myqcloud.com/apppuKyPtrl1086/image/ueditor/27795700_1575426435.png)

所以在这个电商购物的流程中，订单系统是其中非常关键的一环，而我们团队就是负责整个订单系统的。

那订单系统在下订单这个核心的业务流程中，他自身的业务流程又是什么样的呢？

简单来说，当用户对购物车中选中的一批商品确认下单的时候，会先出来一个确认订单的界面

用户得先确认这个订单中的商品、价格、运费无误，而且在这个过程中可以选择是否要使用优惠券、促销活动的。

另外，用户还应该在这个界面中确认自己的快递方式，收件地址，是否要开发票以及发票的抬头是什么。

当用户完成这些信息确认之后，就可以确定下单。

此时我们的订单系统最核心的一个环节就出现了，就是要根据APP端传递过来的种种信息，完成订单的创建，此时需要在数据库中创建对应的订单记录，整个过程，就像下面这个图一样：

![picture.png](http://wechatapppro-1252524126.file.myqcloud.com/apppuKyPtrl1086/image/ueditor/50107200_1575426435.png)

接着当你正式确认下单之后，除了在数据库中创建这个订单之外，还会跳转到支付界面，让你通过选择好的支付方式完成这个订单的支付

比如跳转到支付宝或者微信，让你在支付宝或者微信中完成支付，看我下面的图：

![picture.png](http://wechatapppro-1252524126.file.myqcloud.com/apppuKyPtrl1086/image/ueditor/69549700_1575426435.png)

在完成了支付之后，一般来说，支付宝或者微信之类的支付系统，会反过来回调我们的一个接口，通知我们本次支付已经成功。

当我们收到支付成功的通知之后，就需要安排给用户进行配送发货。除此之外，我们的订单系统需要负责给用户发放优惠券一类的东西。

因为一般电商APP都经常会做一些鼓励用户购买的活动，比如你购买之后送一些优惠券，下次购买可以抵用5块钱，或者给你发一个几块钱的现金红包。

此外，还会给你发送一个push推送，通知你支付成功准备发货，这个推送很多时候是通过短信通知的。

我们看下面的图，在下面的图中就有支付完订单之后要做的一些事情：

![picture.png](http://wechatapppro-1252524126.file.myqcloud.com/apppuKyPtrl1086/image/ueditor/92051200_1575426435.png)

明哥说到这里，休息了一下，问道：怎么样小猛，对上面说的订单系统的核心业务流程都搞明白了吗？

**小猛**：嗯嗯，差不多明白了，因为平时就经常会用一些电商APP去进行购物，所以对整个业务流程结合自己平时的使用体验，还是很容易搞懂的。

**3、订单系统的非核心业务流程**

**明哥**点点头：好的，看来上面的核心业务流程没什么问题了。但是一个订单系统可不光是这么简单的一些业务而已

实际上订单系统在运行的过程中可能会跟底层的营销系统、购物车系统、商品系统、配送系统等大量的系统进行复杂的交互。当然，现在你不用一下子都搞的那么清楚，一步一步来。

现在给你讲讲订单系统在运行时的一些非核心业务流程。

首先订单系统在完成核心的下单业务流程之后，用户一定会查询自己的订单，那么订单系统务必要提供对应的**订单查询功能**。

我们看下面的图，在这个图里画出了订单系统需要具备的一个功能模块

下单模块主要是用于创建订单，异步模块主要是在支付成功之后发优惠券、红包和推送，查询模块主要是提供订单的查询。

![picture.png](http://wechatapppro-1252524126.file.myqcloud.com/apppuKyPtrl1086/image/ueditor/38181600_1575426436.png)

另外，当用户查询到一个订单列表之后，有时肯定会因为各种原因想要退货，这个是不可避免的。

因此在订单系统中也得提供退货功能，在下面的图中我们加入退货模块。

![picture.png](http://wechatapppro-1252524126.file.myqcloud.com/apppuKyPtrl1086/image/ueditor/55358100_1575426436.png)

此外，订单系统除了自己要提供的功能模块之外，还需要跟公司以外的第三方公司的一些系统进行对接。

比如你想要查看订单的配送状态，那么就需要订单系统从第三方物流公司的系统中进行查询，才能让你看到。

因此在下面的图中，我们还得加入订单系统跟第三方系统的对接。

![picture.png](http://wechatapppro-1252524126.file.myqcloud.com/apppuKyPtrl1086/image/ueditor/85515400_1575426436.png)

然后你应该知道，订单数据是一个公司的核心数据，很多时候公司内部的其他团队，比如大数据团队可能就需要获取订单数据进行分析，然后提供交易数据报表给公司的高层领导去看。

所以下面的图里，我画出来了订单的数据库以及第三方团队需要获取订单数据的一个业务场景。

![picture.png](http://wechatapppro-1252524126.file.myqcloud.com/apppuKyPtrl1086/image/ueditor/7543600_1575426437.png)

最后就是在类似双11、秒杀等大促场景下，可能大量的用户会蹲点守在手机前，等待一些特价促销的商品开卖之后进行抢购，此时可能会对订单系统会产生一个流量洪峰，甚至影响正常的一些下单功能。

因此对于订单系统，往往要提供一个专门用于抗双11、秒杀等活动的大促模块，专门用于处理特殊活动下的高并发下单场景，这个模块也得加上：

![picture.png](http://wechatapppro-1252524126.file.myqcloud.com/apppuKyPtrl1086/image/ueditor/31442300_1575426437.png)

讲到这里，明哥再次休息了一下，问道：

怎么样小猛，订单系统包含的一些功能模块，核心业务流程，以及一些非核心的业务流程和功能模块，大体都了解清楚了吗？

这些东西可是重中之重，因为后续我们要对订单系统进行架构改造，需要引入包括MQ、Elasticsearch、分库分表等大量的技术。

略微停顿了一下，明哥继续说道：当然，对你而言，我主要会安排你负责一部分基于MQ（消息中间件）技术的订单架构改造，暂时不会让你涉及其他的一些技术。

而对于MQ技术，几乎在上面这张图里所有的功能模块，都需要用MQ技术进行一定的架构改造。

**小猛**：明哥，你放心，听你讲完这套订单系统的业务流程和整体架构之后，我觉得非常的有意思，而且基本全部都听明白了，也一定会竭尽所能去学习MQ技术的相关知识，去做好我负责的那部分架构改造的！

**明哥**：好小伙子，态度很不错，但是可别高兴太早了，下面我来给你说说咱们的订单系统的线上环境的生产负载情况。要知道，我们公司可是有一定的业务量的，系统的整体负载和压力可不小，要做好这个事，还是有一定的难度的！

**4、订单系统的真实生产负载情况**

**明哥**：首先给你说一下，咱们公司是一个新兴的互联网公司，从创立到现在发展也没几年

但是在我们公司的这个垂直电商领域里，我们算是这个小领域的NO.1，做的非常不错。到目前为止，我们公司大概积累的注册用户有几千万的数量。

当然，不是每个注册用户都会天天来逛你的APP。真的天天逛你的APP的，基本上得是死忠粉丝了。大部分人也就是每隔几天会来APP里逛一逛，可能有时候会下一个订单。

所以现在根据统计来看，每天我们APP活跃的用户数量是一两百万的样子，这个其实也不算少了，虽说我们是创业公司，但是也达到百万日活的体量了。然后每天新增的订单数量，目前大概是几十万的样子。

我估计随着公司发展，可能很快就会达到每日百万量级的订单数量，当然，在一些双11、618等大促活动的时候，我们现在的订单系统就可以达到单日百万订单的量级了，所以我们的系统压力还是比较大的。

因此我们先在下面的图中加入订单系统当前每日的订单数量。

![picture.png](http://wechatapppro-1252524126.file.myqcloud.com/apppuKyPtrl1086/image/ueditor/51691600_1575426437.png)

再说说这个QPS，也就是**系统每秒的查询数量**，这个指标是说订单系统所有的核心以及非核心功能模块加起来，每秒钟有多少请求量。

对我们来说，在往常每天的高峰期，大概最多会达到每秒2000左右的访问量，不算太大。

但是如果要是有那种特价商品限时秒杀的活动，那可能就会达到每秒1万以上的访问压力了。

因此我们继续在下面的图中，加入系统每秒的请求压力。

![picture.png](http://wechatapppro-1252524126.file.myqcloud.com/apppuKyPtrl1086/image/ueditor/78883200_1575426437.png)

这就是我们这个订单系统的整体压力了，你可以看到，压力主要在两方面：

- 一方面是订单系统日益增长的数据量
- 一方面是在大促活动时每秒上万的访问压力

因此我们当前订单系统的整体架构是比较简单的，我们仅仅是让开发好的系统直接连接一台数据库服务器，所有的数据都是存储在里面的。

然后也是由这台数据库服务器去抗所有的访问压力，所以现在订单系统经常会在一些大促活动的时候出现不稳定的情况。

因为随着数据库中的订单数据越来越多，数据库的读写性能就会越来越差，尤其在大促活动高峰期的时候，数据库访问压力剧增，读写性能会进一步下降，经常出现请求过慢，请求超时等问题。

所以，咱们团队的任务，就是要尽快在订单系统的架构中引入更多的技术，进行大量的架构优化，让我们的订单系统逐步逐步的趋向于稳定。

小猛在听完明哥今天的讲解之后，认真的做了大量的笔记，打算今晚回家之后再反复消化，对系统的情况尽快熟悉了解。

一想到自己刚毕业就可以进入一个创业型互联网公司的核心技术团队，对有挑战的一个系统去做大量的优化工作，让系统变得越来越稳定，就觉得非常的兴奋和憧憬。

**小猛对明哥说**：放心吧老大，我一定会全力以赴的！

 **End**

### 02 授人以渔：能概括一下你们系统的架构设计、业务流程以及负载情况吗？

正文开始：

大家在看完了第一篇文章之后不知道有何感想？

相信不少朋友会觉得用这种案例代入的方式很新鲜，通过分析一个系统案例的各种技术难点，反向驱动去学习一个新技术，然后把新技术代入到系统里去解决问题。

其实我以及其他几个朋友一直有一个共同的观点：**技术的学习，一定要放在一个真实的环境中**

首先你得知道现在你的系统，或者行业里其他普遍的一些系统，都有哪些技术难点和痛点，面临哪些问题。

接着要针对这些问题，反过来去学习一个技术，学习完这个技术之后，一定要思考如何将技术代入到真实的环境中，去解决对应的问题。

这样学习技术，才是最高效正确的一种方法。而不是用非常传统的方式，按照一个技术的功能点去一个功能一个功能的学习。

那样学完了跟实战结合不起来，其实意义也不是非常大，也许过了一段时间你就忘记了。

因此我希望大家不光是学习我们的专栏的案例展示出来的系统技术难点，以及用MQ技术如何解决这些技术难点。

大家还应该同时认真学习我们的每个“**授人以渔**”的环节，去仔细思考自己负责的系统是否有一些技术难点，然后去思考学习到的MQ技术如何解决你的系统中的技术难点。

我知道这时很多朋友会说：**可是我自己负责的系统很low，没什么用户量，根本没什么技术难点。**

但是这种想法就完全错了。举个例子，你做一个OA系统、CRM系统、财务系统或者其他任何看起来很普通的系统，也许总共就几十个人用。

那你能不能思考一下，假设你的这个系统是一个SaaS云平台，要提供给几万个公司的百万用户去使用呢？

如果是这样，那你的系统必然会有很多的技术挑战，你可以去预估一下，当达到那个数量级之后，你的系统会有多大的数据量？多大的访问量？然后再去思考在这么大的数据量和访问量之下，现有的系统会有哪些技术难题？

接着你就可以思考，应该学习一些什么样的技术来解决这些问题？

所以今天第一个“**授人以渔**”的环节，我们希望大家可以跟第一篇文章的思路一样，自己梳理出来自己负责的系统的核心业务流程，核心功能模块，跟其他系统是如何额交互的，数据是如何存储，当前已经使用了哪些中间件技术。

你应该把自己的系统的业务流程以及技术架构都画出来，梳理出来。

然后你可以想一下，如果你的系统的用户量级增长百倍、千倍、甚至万倍呢？那么此时系统每天会增长多少数据量？每秒会有多少请求量？你的系统的生产负载会是一个什么样子？

希望大家好好的梳理这些东西，在思考的过程中如果有什么疑问，**不要藏着掖着**，欢迎在评论区提出来与我互动！

**End**

### 03 系统面临的现实问题：下订单的同时还要发券、发红包、Push推送，性能太差！

正文开始：

**1、明哥的突击考验：说说昨天讲的订单系统架构**

今天小猛来上班之后，明哥立马就把他叫到了一个小会议室里，打算给他讲讲订单系统当前面临的技术难点，这些技术难点就是订单系统当前最最亟需解决的一些问题

因此到会议室里以后，明哥首先把之前讲过的订单系统整体架构和流程快速的在小白板上重新画了出来。

明哥说：小猛，你看我下面画的这个图，先简单回顾一下，然后你来复述一遍订单系统的整体架构和流程，我看看你忘了没有。

​      ![img](http://wechatapppro-1252524126.file.myqcloud.com/image/ueditor/52606800_1578368503.cn/txdocpic/0/f8b64c3fb6110f688d4bccf417e29124/0)       

**2、一个认真总结做笔记的小猛**

小猛看着明哥画出来的这个图，非常有信心的开始复述，心想：我可是昨晚复习和总结了一晚上笔记，把老大昨天说的都给吸收了。

**小猛**：首先，订单系统必须得有一个下单模块负责让用户进行下订单

其次当订单创建好之后，就必须要跳转到第三方支付的界面上去，让用户尽快支付。如果用户支付成功了，然后就会回调订单系统的接口。

接着订单系统会去做一些事情，比如扣减商品的库存，更新订单的状态，给用户发券、发货红包或者积分，给用户发送Push去推送订单已经支付等待出库的通知。

接着用户就可以从订单系统的查询模块去检索自己的订单，此时可以做一些非核心的业务流程

比较常见的有：选择对商品进行退货、查询订单的物流状态、或者之前没来得及支付现在对订单进行支付，等等。

最后订单系统需要提供一个大促模块，专门去抗双11、双12、618、秒杀活动等特殊大促活动时的瞬时超高并发，这个必须跟正常的下单流程区分开来。

另外还可能有其他兄弟团队要来获取订单系统的数据，比如大数据团队。

而当前咱们的APP大致是千万注册用户，百万日活，每日几十万订单量，每天高峰期访问每秒两三千的QPS，大致整体负载压力是这样。

现在系统架构比较简单，主要是一套订单系统部署了多台机器，做了一个集群，然后底层就连一台数据库。

现在的问题就是，随着用户量越来越大，数据量会越来越大，高峰期并发量也会越来越高，系统的压力越来越大，光靠这个架构抗是很困难的，亟需对订单系统整体进行架构的升级和改造。

小猛行云流水般说完了订单系统的整体架构和核心的业务流程，还有当前面临的负载压力以及技术上的挑战，可见这孩子真是对项目下了功夫，用了心了。

明哥听了连连点头，非常满意，这小伙子是个好苗子，自己得好好带，尽快培养成骨干工程师。

**3、小猛的疑惑：系统压力越来越大到底指的是什么意思？**

但是虽然小猛快速解释清楚了明哥昨天灌输给他的这一套项目背景之后，小猛自己却有一个很大的疑惑，他有点不理解一个事情。

小猛问：明哥，你昨天最后老是不停的强调，我们的系统压力越来越大，但是我始终没搞明白，系统压力大到底是大在哪儿？这是什么意思啊？我昨晚想了半天也没搞明白。

明哥说：放心，这个系统压力大的概念，对很多初入职场的小伙子，或者是很多工作多年但是一直在做那种几十个人、几百个人用的内部系统的工程师，都是一个疑惑

因为没亲身经历过一些压力大的系统，是很难真正透彻的理解这个东西的。

于是明哥打算先给小猛从整体上解释一下这个问题。

**明哥**：昨天我们已经说过了，这个系统每天高峰期大概会有2000左右的QPS，也就是每秒会有2000左右的请求过来，这就是当前系统的一个最大压力。

在非高峰的时候，其实远远达不到这么高的并发，所以先考虑高峰期的压力就可以了。

说着，明哥在下面的图里画了一个红圈，“我们先讲讲这里的事儿，你得先搞明白系统的压力是从哪儿来的？”      ![img](http://wechatapppro-1252524126.file.myqcloud.com/image/ueditor/63336100_1578368503.cn/txdocpic/0/9976bfbf796fd2eb2bbcaa66e34b22fb/0)       

**4、明哥原来是个老司机：从早上的一个煎饼说起**

现在经过统计，我们这个电商APP大概是每天百万的用户在使用，但是你要知道一点，用户对任何一个APP的使用时间，都是根据APP的类型不同而有区别的。

比如你要用一个电商APP，那么本质是一种很放松的购物，可能是有什么东西需要买，立马掏出手机来买，也可能是没事儿干，跟逛街一样，就想逛一逛APP。

那么你作为一个正常的人思考一下，平时早上你刚起床，匆匆忙忙洗脸刷牙，然后出门在路上买个煎饼吃早饭，这个过程中你会逛一个电商APP吗？

恐怕不会！

接下来呢，你会健步如飞的去赶地铁，或者坐公交车，在这个过程中人挤人，你觉得你会玩儿电商APP吗？

恐怕也不会！

接着到了公司之后，就开始了一天的工作，在工作过程中如果你逛电商APP，那你可能是不打算继续干了。

所以为了保住你的饭碗，这个时候还是别逛了。

然后好不容易干到中午，大家吃完午饭开始午休，有的人刷抖音，有的人玩王者荣耀，你也许会打开手机逛一逛电商APP，这是有一定概率的。

但是如果你是一个合格的职场员工，上午干的很累，下午还有工作压力，中午也不敢放松太多，中午应该不会逛太多的时间。

下午继续工作，最后好不容易下班了，接着坐地铁或班车回家的时候，这个过程中往往是每个职场人一天最轻松的时刻

包括到家了以后，睡觉前，每个人都会适当放松一会儿，无论是玩游戏，还是逛电商APP，适当买点自己喜欢的东西给自己减减压。

明哥说到这里停顿了一下，问：小明，你觉得我说的这些是跟技术无关的东西吗？

小猛停顿了一下，说：明哥，一开始我很疑惑你为什么扯这么远，不过突然发现你说的这些好像对一个系统的工程师来说，确实是第一件应该了解的事情，也就是你的APP用户的生活习惯和APP的使用习惯。

这些用户的使用习惯直接决定了他们使用我们APP的频率、时间段和时长，一般每隔几天用一次我们的APP？每次使用一般在什么时间段？每次使用多长时间？

这些东西都要通过对用户的分析得出来。

明哥很满意的点点头：不错，你的反应真的很快，当时校招就觉得你比一般学生反应快很多，思维更加敏捷。一个工程师不能光是埋头于技术，视野要打开一些，思维要更加多元化，当时果然没选错你！

**5、根据线上统计数据推算出系统的负载**

喝了口水，明哥继续道：既然搞明白了用户的生活习惯，我们就可以结合线上的一些统计数据来推算一下系统的工作负载了。

通过线上一些数据的统计，我们大致知道，咱们这个APP，基本上80%的用户都习惯于在晚上六点过后到凌晨十一点这几个小时使用，这个刚好是大家下班的时间，便于大家购物。

所以在这几个小时内，可以认为有80万左右的用户会使用APP。

然后由于我们是一个电商的APP，需要用户大量的浏览商品，搜索商品，然后才会下订单和支付订单，所以用户一般会对APP的界面执行几十次到上百次的点击。

但是大部分点击都是跟一些商品系统、评论系统进行的交互，用户主要是查看商品，查看一些评价，还不是针对订单系统的。

因此对我们订单系统而言，主要的访问量就是下订单以及对订单的检索、查询，少量的退款等操作。

我们现在每天大概是三五十万个订单，也就对应了百万次下单操作和一些订单查询等操作

看着百万次针对订单系统的请求似乎很多，但是如果均摊到5个小时中呢？每秒钟大概只有几十次请求而已！

但是如果你要这么计算，那就大错特错了

因为我们的电商APP有两个特点，第一，真实的系统访问负载应该是一个半圆形的曲线，类似下面这样：

​      ![img](http://wechatapppro-1252524126.file.myqcloud.com/image/ueditor/72733700_1578368503.cn/txdocpic/0/24e7dd7037e4424bc5dc2aed05da6f80/0)     

比如从晚上6点开始访问量开始增加，一直到可能晚上八九点到一个顶点，访问是最大的，然后慢慢的开始下落，到晚上十一点就变得较低。

所以在看系统的访问压力的时候，是不能直接按平均值来计算的。

另外，这个电商APP有一个特点，每天都有一些限时限量售卖的特价商品，就是每天会有一批特价商品是限量的，而且限制在晚上某个时间点售卖

因此往往在这段时间里，会有很多用户在等着到了那个时间就一下子点击购买下单，此时订单系统的压力往往是最大的。

综合下来而言，根据线上系统的接口统计数据来看，晚上购物最活跃的时候，订单系统下单最顶点的高峰时段每秒会有超过2000的请求，这就是订单系统的最高负载。其他时候都比这个负载会低不少。

**6、明哥终极解惑：为什么系统的压力会越来越大？**

听到这里，小猛还是没有明白，那么为什么系统的压力会越来越大？

小猛说：我现在完全可以理解我们订单系统的高峰期的负载是怎么来的了，但是系统的压力到底是指的是什么？

小猛对明哥再次提出了疑问。

明哥说：别着急，因为你对互联网类的系统肯定有很多地方都不熟悉，对互联网系统的思考和一些类似OA、CRM之类的传统软件系统是完全不一样的，要习惯互联网系统的分析方式。

明哥继续道：你看，现在线上的订单系统一共部署了8台机器，每台机器的配置是4核8G，这是互联网公司的标准配置，当然也有不少系统是用2核4G的机器部署的，那也是标准配置。

因此高峰期每台机器的请求大概是每秒200~300之间。

明哥一边说着，一边画出了下面的图。



​      ![img](http://wechatapppro-1252524126.file.myqcloud.com/image/ueditor/86090500_1578368503.cn/txdocpic/0/1b12beb94d04b6fb1f5be794c6a64a4d/0)       

但是这8台订单系统部署的服务器都是连接一台数据库服务器的，数据库服务器的配置是16核32G，而且是SSD固态硬盘的，用的是比较高配置比较贵的机器，因此性能会更好一些。

这也是比较常规的数据库服务器的配置，但是一般也会用比如8核16G和机械硬盘等机器部署数据库。

说着，明哥又在下面的图中补充了一个数据库服务器进去。



​      ![img](http://wechatapppro-1252524126.file.myqcloud.com/image/ueditor/3103900_1578368504.cn/txdocpic/0/6501bf4529ea0fd3ec73ed3195ad6c13/0)       

现在线上这样的一个机器部署情况，在高峰期每秒2000以上请求的情况下是很轻松可以抗住的

因为4核8G的机器一般每秒钟抗几百请求都没问题，现在才每秒两三百请求，CPU资源使用率都不超过50%。

可以说8台4核8G的机器，每台机器每秒高峰期两三百请求是很轻松的。

然后数据库服务器因为用的是16核32G的配置，因此之前压测的时候知道他即使每秒上万请求也能做到，只不过那个已经是他的极限了，会导致数据库服务器的CPU、磁盘、网络、IO、内存的使用率几乎达到极限。

但是一般来说在每秒四五千的请求的话，这样的数据库服务器是没什么问题的，何况经过线上监控统计，现在数据库服务器在高峰期的每秒请求量也就是三四千的样子，因此基本上还没什么大问题。

所以明哥说到这里，顿了一顿，看着小猛说：要明白什么是系统压力，就得明白你的系统线上部署的机器情况和使用的数据库的机器情况

而且作为一个合格的互联网行业的Java工程师，要对各种机器配置大致能抗下的并发量有一个基本的了解。

小猛听到这里，简直是目瞪口呆，跟这种线上系统有真实负载和压力的情况想比，自己上大学的时候在实验室里做的那种Demo小项目，简直完全不是一个概念。

仿佛在他面前打开了一个新世界，真是太有意思了！

**7、如果系统压力越来越大会怎么样？**

这个时候小猛开始有点找到门道了，他问明哥：那么如果咱们的用户量越来越大，并发量越来越大，数据量越来越大，这个系统会有什么问题？

明哥笑笑说：那这里的问题就真的很多了，一旦系统压力越来越大，无论是并发量还是数据量，你会发现你的系统各个地方都要优化，都有问题，这不是一个人可以解决的，也不是一两天就可以解决的。

一个高并发、大数据量的系统架构迭代、演进和优化，需要一个精干的技术团队经年累月的不停的去做，期间要涉及到大量的技术方案、架构重构。

但是今天最后的最重要的一个主题，就是先给你讲一个**现在系统最明显的一个技术问题**，也是影响用户体验的一个问题。

现在我重新画出来我们的订单系统的一个业务流程图，你看下面。

​      ![img](http://wechatapppro-1252524126.file.myqcloud.com/image/ueditor/18489700_1578368504.cn/txdocpic/0/4ea8769cd855eb41cc09ade91e8d9b15/0)       

我们都知道，在用户下订单之后一般就是要支付，在支付成功之后我们要干很多的事情

在上面那个图的第8个步骤里，其实我们除了发优惠券、发红包、发送Push通知给用户之外，还要做很多其他的事情。

比如：对于一个电商APP而言，你卖掉了一个商品，就要扣减掉商品的库存，而且一旦用户成功支付了，你还得更新订单的状态变成待发货。

也就是说，在上图第8个步骤里，其实是有很多事情要做的，明哥说着在上图里的步骤8的地方补充进去了几个子步骤，看下图红圈中的部分：   ![img](http://wechatapppro-1252524126.file.myqcloud.com/image/ueditor/35902100_1578368504.cn/txdocpic/0/69595aa4d2c77240085da920c272279d/0)       

现在根据我们线上系统的统计，这个步骤8那里的多个子步骤全部执行完毕，加起来大概需要1秒~2秒的时间

有时候在高峰期负载压力很高的时候，如果数据库的负载较高，会导致数据库服务器的磁盘、IO、CPU的负载都很高，会导致数据库上执行的SQL语句性能有所下降。

因此在高峰期的时候，有的时候甚至需要几秒钟的时间完成上述几个步骤。

那么他的影响是什么呢？

想象一下，如果你是一个用户，结果你在支付完一个订单之后，界面上会有一个圈圈不停的旋转，让你等待好几秒之后才能提示支付成功。

对用户来说，几秒钟的时间，会让人非常不耐烦的！

所以，首先针对步骤8里的子步骤过多，速度过慢，让用户支付之后等待时间过长的问题，就是**订单系统第一个亟需解决的问题**！

小猛听完明哥的分析之后，呆了一会儿。显然刚刚毕业第一次接触互联网类的系统，需要一点时间给他去消化。

过了一会儿，他跟明哥说：明哥，今天的信息量真的很大，我今晚回去再好好捋捋，好好做一下总结和笔记。

明哥笑笑：好好加油，利用好你现在单身的优势，技术上迅速成长起来。你明哥是过来人，等你谈恋爱、结婚、有了小孩，就。。。 

**End**

### 04 授人以渔：你们系统的核心流程性能如何？有没有哪个环节拖慢了速度？

正文开始：

今天的授人以渔环节，要结合上一篇文章给大家提示一些需要每个人自己去分析的事情。

上一篇文章里，我们详细的给大家展示出来了对一个系统的用户使用习惯的分析，进而得出了用户对系统的使用频率、使用时间段以及使用时长。

然后就可以根据用户的使用情况，计算出来系统的负载，到底每秒钟会有多少请求去访问我们的这个系统。

再接着，根据系统的负载情况，我们要搞明白线上系统部署的机器情况和数据库的机器情况，每台机器的配置情况，然后想想到底每台机器可以抗多大的访问量。得出当前系统的整体压力。

接着我们要思考，在当前这样的系统压力下：

- 系统的核心业务流程性能如何？
- 核心流程的每个步骤要耗费多长时间？
- 现在核心流程的性能你满意吗？是否还有优化的空间？
- 在系统高峰期的时候，机器和数据库负载很高，是否对核心流程的性能有影响？
- 如果有影响的话，会有多大的影响？

希望大家根据上一篇文章的思路，自己对自己的系统做出如上的分析。

此时很多人一定会问了，我这里的系统实在是不行啊，因为我的系统可能根本就不是给人用的，也许是给其他的系统用的！

那此时，你就应该去分析使用你的系统的其他系统，他对你的系统调用时是什么样的习惯？为什么？是什么因素决定了他要那样去调用你的系统？

此时还有很多人会说，我的系统总共就几十个人用，根本没有压力可言，这怎么办？

那你就想，你的这个系统做一个SaaS云平台的模式，提供给几万个公司，百万用户使用，不就可以了？你要自己去模拟这个场景。

然后，你按照文中的思路去推算出系统高峰期的负载，以及你的线上系统的机器的压力，到底要部署多少机器去满足这个压力。

然后还有很多同学可能会问，我的核心流程的性能怎么看啊？我不知道啊。

那简单，自己偷偷摸摸在代码里加入一个日志打印，悄悄的把每个步骤的耗时打印出来，自己看一看，然后看看核心流程的时间耗时多长，有没有优化的空间。

记住，这个授人以渔的环节，你务必要去做，去思考，去梳理，去总结，没有这个过程，你还是没有把技术最终转化为自己的东西！ 

**End**

### 05 系统面临的现实问题：订单退款时经常流程失败，无法完成退款！

**1、想解决问题的小猛，大脑却一片空白**

昨天明哥给小猛讲了互联网系统的用户使用情况以及负载之间的关系，还有系统负载造成的压力都是指的什么，真是让小猛打开眼界。

小猛以前可从没考虑过，平时部署的系统、使用的数据库居然还有这些问题。

而且昨天明哥也给小猛指出了系统现在面临的第一个问题，就是支付成功之后的核心业务流程里混杂的子步骤太多了：

扣减库存、更新订单状态、更新积分、发优惠券、发红包、发送Push推送、通知仓储系统发货，等等一系列的事情要做。

这一连串的步骤有时候在系统高峰期压力大的时候，可能需要好几秒才能完成，让用户体验非常的不好。

小猛也回去想了很久，这个问题应该怎么解决呢？

暂时也没什么思路，毕竟自己经验还浅，大脑一片空白。算了，还是等着明哥给讲讲吧！

**2、再次回顾一个复杂的订单支付流程**

今天小猛刚一上班，厕所都来不及上，就被明哥给拽去了小会议室。接着明哥就要给小猛继续分析系统现在存在的一些问题。

小猛心想：必须得好好听啊！问题分析完之后，明哥就要给我派发开发任务了，到时候我做的事情都是用来解决这些技术问题的。

到了会议室，明哥立马就在小白板上唰唰的画出了订单支付过后的一系列流程，就在下面的图里

包含了扣减库存、更新订单状态、更新积分、发优惠券、发红包、发Push推送、通知仓储系统调度发货。

​      ![img](http://wechatapppro-1252524126.file.myqcloud.com/image/ueditor/53978600_1578368522.cn/txdocpic/0/3c8471116d955c5c60be82f57ead5ad1/0)       

小猛看着上面那个订单支付后的核心流程图，心里感叹道：真是复杂啊！

自己平时上网购物确实知道买东西付钱之后，电商平台上的商品库存会减少，而且还会给自己增加一些积分。积分多到一定程度，会员等级会升级。

而且一般每次都会发放一些优惠券、红包抵用券之类的东西，并且再查看订单的时候，状态已经变更为待发货。

但是真到了自己去思考一个订单系统设计的时候，才发现这个购物真是一个非常复杂的流程。

**3、对订单进行退款时需要干些什么？**

接着明哥说：之前我们讲过，订单系统的第一个问题，就是支付之后的流程过于复杂，导致耗时太长，用户体验太差，这个是我们后续一定会去优先解决的问题。

那么订购单系统的**第二个问题**，就是订单支付的反向过程，**退款**。

小猛这时很奇怪的问：订单退款的时候都要干些什么啊？有什么问题呢？

明哥说：你想想，用户下一个订单，把钱付给平台之后，平台会给用户一系列的利好，比如发券、发积分、发红包。

为什么要给用户这么多好处？还不是因为你付钱给人家了？

小猛说：是的是的，这个世界是现实的，没有平白无故的爱，也没有平白无故的恨。

明哥接着说：那么在你申请退款之后，平台就会把之前你付给他的钱还给你了。

既然钱退给你了，人家根本就没得到你什么好处，这个时候还不得把之前给你的一些利好都收回来？比如优惠券、积分、红包之类的东西。

所以，本质上订单退款应该是一个订单支付的逆向过程，也就是说他应该做如下一些事：

- 重新给商品增加库存
- 更新订单状态为“已完成”
- 减少你的积分
- 收回你的优惠券和红包
- 发送Push告诉你退款完成了
- 通知仓储系统取消发货

最重要的是，需要通过第三方支付系统把钱重新退还给你。

而且如果电商平台都已经给你发货了，你才申请退款，实际上你还得把收到的商品给人家快递回去，等他们收到了商品再把钱退还给你。

当然，这里我们简单起见，就说商品还没发货这种情况吧。

明哥说着，就唰唰的在小白板上又画了一个图，这是退款的流程图。      ![img](http://wechatapppro-1252524126.file.myqcloud.com/image/ueditor/65535500_1578368522.cn/txdocpic/0/d46f063d72c254e314dab55502f88a5b/0)       

小猛一看，倒吸了一口凉气，心想，做个电商系统还真不容易啊！买东西退东西原来都这么复杂，有这么多的讲究！

**4、小猛的灵光一闪：退款和支付不是有一样的问题吗？**

这个时候小猛大脑突然灵光一闪，他说：明哥，那这个退款和支付不是有一样的问题吗？都是流程太长，子步骤过多，如果用户点击退款之后要一下子执行这么多步骤，可能需要好几秒的时间，用户体验同样是很差的！

明哥用满意的眼神看着小猛：真是没看错人，你这脑子就是灵活！没错，实际上这个订单的退款也有同样的一个问题，就是步骤太多太耗时，一起执行的话，就会耗费很长时间，用户体验很不好。

但是，明哥话锋一转：不过订单的退款可不只是这一个问题，你再观察一下，这里还有什么问题？

小猛疑惑的盯着这个流程图10秒的时间，一时语塞，茫然的看着明哥，实在想不出这里还有什么问题。

**5、退款的最大问题：第三方支付系统如果退款失败怎么办？**

明哥这个时候说，其实在退款的时候，最大的问题还不是步骤太多执行太慢，最大的问题是假设你的库存增加完了，订单状态更新了，积分收回了，优惠券收回了，仓储系统中断发货了，然后Push推送告诉你说已经退款了，结果第三方支付系统退款失败了。

比如有可能是第三方支付系统自己的问题导致退款失败，也可能是你在调用第三方支付系统的时候，因为你自己的网络问题导致调用失败，就退款失败了。

总之，用户以为退款成功了，结果一查自己账户，钱就是没进来，这才是最要命的一个问题。

明哥说着，在下面的图里，画上了一个重重的红圈。

​      ![img](http://wechatapppro-1252524126.file.myqcloud.com/image/ueditor/77958800_1578368522.cn/txdocpic/0/bf7671e1f1f0818d58edc03eab4c1528/0)       

明哥指着上图中的红圈，严肃的说，你有没有想过如果调用第三方支付系统退款的时候万一失败了会怎么样？

小猛入职以后第一次看见明哥这么严肃的表情，有点吓到了，胆怯的问：是会把我拉出去祭天吗？顿时脑子里浮现出一个程序员在祭坛上被祭天的场景。

明哥哈哈大笑：那倒不至于，不过这种情况可能会导致用户再也不愿意来我们这里购物了，而且领导一定会狠批我们，年终奖就不用想了。

要是赶上公司年景不好，要优化几个人出去的时候，弄不好就轮到你了！

总而言之，这个问题，也是我们订单系统要解决的一个很重要的问题。远远比步骤太多耗时太长，用户体验不好这个问题要严肃的多。

**6、如果用户下单后一直不付款怎么办？**

明哥接着说，现在我们已经看完了用户支付和退款两个流程里的问题了，接着我们来看看第三个问题，就是用户在支付之前会干什么。

通常来说，用户在购物车里会加入很多的商品，然后选择下单跳转到一个订单确认界面，在这里确认收货地址、发票抬头、优惠券使用等一系列的问题，接着正式下这个订单。

明哥说着，在小白板上画出了一个流程图。

​      ![img](http://wechatapppro-1252524126.file.myqcloud.com/image/ueditor/86804100_1578368522.cn/txdocpic/0/cbc660b8bbd0095c52294a5cf5f044b9/0)      

接着用户对订单一旦确认完毕，就会提交订单，订单提交到订单系统之后，就会正式在数据库中创建一个订单出来

明哥说着在流程图里加了一点步骤      ![img](http://wechatapppro-1252524126.file.myqcloud.com/image/ueditor/99074200_1578368522.cn/txdocpic/0/1ac2c4ba97b7581c00870f52532b57c9/0)      

接着正常来说，就会跳转到支付界面让他进行付款了，但是万一这个人在付款界面犹豫了一下呢？结果自己把付款界面给关了，这不就是订单创建了，但是没支付么？

此时订单的状态“待支付”，而且只要你下了订单，你订单里涉及到的商品，都会有对应的锁定库存的一个工作，相当于给你预先保留好这些商品。

明哥说着在流程图里又加了几个步骤。

​      ![img](http://wechatapppro-1252524126.file.myqcloud.com/image/ueditor/14037000_1578368523.cn/txdocpic/0/7d593d46401db62e8895bfa784c9a9fe/0)       

明哥指着图里画红圈的地方说，你看订单系统在创建订单的时候已经调用库存系统锁定了你要买的商品的库存，结果明明给你跳转到支付界面了，你却放弃了支付，这不是在耍我们么？

要是订单一直不付款，一直这么放着，他对应的商品库存就会一直锁定，别人都没法买了。

这就好比你去商场买鞋子，看到一双球鞋要1500块，然后结果你就拿个铁盒子来放在商店里，把球鞋放进去锁上，然后告诉营业员说，我下个月发工资过来买这个鞋子，现在我把他锁起来，谁都不许买，给我留着！

难道你让人家球鞋店给你保留鞋子一个月？

听到明哥的这个比喻，小猛不禁哈哈大笑，比喻的很贴切，确实是这个道理。

明哥接着说道：所以一般来说，我们的订单系统会启动一个后台线程，这个后台线程就是专门扫描数据库里那些待付款的订单。

如果发现超过24小时还没付款，就直接把订单状态改成“已关闭”了，释放掉锁定的那些商品库存。

明哥在流程图里又加了一个步骤。      ![img](http://wechatapppro-1252524126.file.myqcloud.com/image/ueditor/24425200_1578368523.cn/txdocpic/0/6c78f7ab6f1e963282c4fdb57e3448d3/0)       

**7、如果有几十万订单没付款，难道要一直傻傻的扫描？**

明哥接着说，问题就出在了这个扫描待支付订单上了。

假设咱们现在数据库中积压了几十万笔待支付的订单，难道你要求一个后台线程不停的去扫描这几十万笔订单吗？这个效率明显是很低的啊！

万一以后有几百万笔未支付订单呢？难道要不停的扫描几百万笔待支付的订单？

**所以这个就是订单支付之前最大的一个技术问题。**

小猛听完之后，恍然大悟，现在订单支付之前，支付的时候，支付之后要退款的时候，居然都有各自的问题所在，看来后续要做的优化还真是不少！

今天小猛觉得自己对订单系统的业务和技术问题又理解的更加深刻了，他决定回家继续好好做笔记，务必让自己在一周以内对订单系统彻底熟悉起来！

**End**

### 06 授人以渔：你们系统出现过核心流程链路失败的情况吗？

今天的授人以渔环节，我希望大家可以去考虑一下，自己系统的核心流程里除了性能之外，是否有可能某个关键的步骤会失败？

因为不管是什么系统，无论是一些管理信息系统，还是互联网系统，或者大数据系统，一定有一个核心的链路。

比如管理系统，类似CRM什么的，可能需要对客户进行一些非常关键的核心操作，此时肯定会涉及多个业务功能多个步骤，这就是这类系统的核心链路。

如果是互联网系统，比如是电商系统，在交易的过程中，一定会涉及到复杂的链路。

除此之外，任何一个其他的系统都会有这种链路，比如一个体育运动APP，可能需要对一些场馆进行活动预约，那么预约的过程，是否也涉及到了场馆的剩余席位、预约记录、积分等核心步骤的执行？这就是这类APP的核心链路。

对一些大数据类的系统，比如一些数据报表系统，在数据进入系统的时候，是否需要经过清洗、计算、转换和存储？这就是数据报表系统的一个核心链路。

在报表查询的时候，是否需要涉及到SQL的查询，数据的处理和转换等过程？这也就是系统的核心链路。

所以很多朋友在后台提问，都很绝望的说，自己负责的系统太low太low了，实在想不出什么地方可以融入MQ技术。

其实各位大可不必这么想，因为再low的系统，他也有核心链路，哪怕是一个学校的政务系统，也是有核心的一些流程步骤的。

因此大家一定要在自己的核心链路里做文章，找机会。那么各位今天就看看，在你的核心链路里，有没有可能一个关键的步骤会失败？

如果这个关键步骤失败了，这个时候会怎么样？如果某个步骤没有成功，是不是需要启动后台线程定时扫描进行补偿？

希望大家结合上一篇文章的内容，深入的对自己系统进行思考。

### 07 系统面临的现实问题：第三方客户系统的对接耦合性太高，经常出问题！

**1、重新观察订单支付的核心流程**

经过了前几天的培训，小猛已经对目前订单系统的整体情况有了一个大致了解，而且也知道了系统目前面临的一些问题，包括一个订单在支付之前、支付过程中以及支付完成后退款时面临的一些技术隐患。

小猛心想，我这几天每天晚上整理笔记都到半夜，这些东西都理解的滚瓜烂熟了，应该没什么问题了。

没想到今天一早，小猛上班之后，又立马被明哥叫到了小会议室。

明哥进了会议室，二话不说，立马在小白板上画出了一个订单支付时的核心流程图。

​      ![img](http://wechatapppro-1252524126.file.myqcloud.com/image/ueditor/78099900_1578370736.cn/txdocpic/0/d30f82a61ce485a9f908689829d2a67a/0)       

小猛说：明哥，怎么又是这个图啊？这个流程我已经滚瓜烂熟了，问题不是很明显了么，就是支付之后流程里的步骤太多，耗时太长了，这样非常影响用户体验。

明哥微笑着对小猛说：那你觉得这个流程里真的就什么问题都没了吗？

小猛内心一阵紧张，赶紧又看了一遍，但是看来看去还是没发现什么问题。心虚的说道：我感觉没什么问题了啊。

**2、老司机设计系统的必备经验：跟第三方系统打交道**

明哥这个时候就开始给小猛解释起来了，毕竟也不能让这孩子太紧张了，一般很多年轻工程师，开发经验没那么丰富的，都不会意识到系统可能存在的一些技术隐患。

在订单支付的时候，大部分核心步骤，其实都是在自己公司的系统里完成的，比如你更新订单的状态，是在自己公司的订单系统内部完成的；你扣减库存，是找自己公司内部的库存系统完成的；你在增加积分的时候，是找自己公司内部的积分系统完成的；你在派发优惠券、红包的时候，是找自己公司内部的营销系统完成的。

但是这些都做完之后，最关键的一个环节呢？

**商品的出库发货，你找谁？**

一般电商公司内部都会有自己的仓储系统，管理各种仓库和商品的发货，通常来说会选择去找一个距离你用户最近的一个仓库，然后从里面调度一些商品进行发货，在发货的时候还需要调用第三方物流公司的系统，通知物流公司去仓库里取货发货。

对于物流公司而言，必然会由自己的物流系统收到货运通知之后，自动通知自己的快递员或者运输队到对方仓库里取货，然后去派发货物给购买商品的用户。

所以明哥在支付订单的核心流程图里又补充了几个步骤。

​      ![img](http://wechatapppro-1252524126.file.myqcloud.com/image/ueditor/96846500_1578370736.cn/txdocpic/0/ff707e43d09afc1d81bd5e05759480bf/0)       

明哥指着上图的右侧添加的部分说：以前你以为通知仓储系统发货只是一个非常简单的事情，但是你看看，现在如果一个用户购买了商品，要把商品送到他的手上，其实还有不少事要做吧？

小猛不好意思的点点头，心想自己还是经验太浅了，怎么就没有去多想想呢。

**3、到底什么叫做“系统之间的耦合”？**

明哥接着说：没关系，其实很多年轻工程师在做开发的时候，往往思维非常的简单，很多人主要是关注自己手头的一些CRUD的工作。但是在复杂的互联网系统里，往往不是CRUD那么简单。

接下来，我就给你解释一个在系统设计上的一个概念，叫做“**系统之间的耦合**”

很多人经常听到“耦合”这个词，一直搞不懂到底什么叫做耦合？

其实这个东西有非常学术的说法，但如果按照那个来解释，应该就没几个人能听懂了。所以我会用非常通俗的语言来给你解释。

举个例子，比如在我们的订单支付流程里，订单系统其实是要调用很多其他系统的，比如库存系统、积分系统、营销系统、仓储系统，等等。

明哥说着，在图里画了好几个系统之间调用的红圈。

​      ![img](http://wechatapppro-1252524126.file.myqcloud.com/image/ueditor/9024100_1578370737.cn/txdocpic/0/770057b581f8dd9abbe58eecfa3117d2/0)       

好，那么我们现在来思考一个问题，假设促销系统现在有一个接口，专门是让你调用了以后派发优惠券的，现在这个接口接收的参数有5个，你要是调用这个接口，就必须给他传递5个参数过去，这个是没的说的。

现在问题来了，负责促销系统的工程师某一天突然有一个新的想法，他希望改一改这个接口，在接口调用的时候需要传递7个参数！

一旦他的这个新接口上线了，你还是给他传5个参数，那么他那里就会报错，这个派发优惠券的行为就会失败！

那在这样的一个情况下应该怎么办？

很简单，你作为订单系统的负责人，必须要配合促销系统去修改代码，既然他要7个参数，那么你就必须得在代码里调用他的接口的时候传递7个参数。

并且你还得配合他的新接口去进行测试以及部署上线，你必须得围绕着他转，配合他。

明哥说着，在图里重新画了两个小红圈，代表订单系统和促销系统的接口调用的修改。      ![img](http://wechatapppro-1252524126.file.myqcloud.com/image/ueditor/25052200_1578370737.cn/txdocpic/0/f2b52406a44ba98a0805878e378af2fe/0)       

在这种情况下，就说明你的订单系统跟促销系统是强耦合的。因为促销系统任何一点接口修改，都会牵扯你围着他转，去配合他， 耗费你们订单团队的人力和时间，说明你们两个系统耦合在一起了。

要动一起动，要静一起静，这就是系统间的耦合。

明哥说到这里停顿了一下，看着小猛问：怎么样，理解了没有？

小猛若有所思的看着小白板上的两个红圈：有点懂了，又有点没懂，但是确实感觉对“耦合”这两个字的理解有那么点意思了。

明哥笑了笑：没关系，你之所以感觉没彻底懂，是因为你没配合其他团队的兄弟去干一些修改接口之类的破事儿，当你自己一边在重构订单系统，干的热火朝天，一边又被迫去花时间配合营销团队修改坑爹的接口的时候。。。

明哥停顿了一下，继续说：估计你心里一边在问候人家的直系亲属，一边狠狠的在你的笔记本上会写下几个字，“坑爹的耦合”！从此以后你对“耦合”就会理解深刻，并且深恶痛绝了。

小猛听完明哥自带画面感的一番描述，哈哈大笑，感觉自己对“耦合”的理解又更深了一点。

**4、订单系统有没有跟第三方物流系统耦合？**

接着明哥提出了一个问题：小猛，你现在思考一下，订单系统有没有跟第三方物流系统耦合呢？

小猛看着图，他发现按照明哥的说法，订单系统是跟仓储系统耦合，而仓储系统又跟第三方物流系统耦合，那么是不是说明，订单系统也间接的耦合了第三方物流系统？小猛提出了自己的思考。

明哥点点头说：非常正确，就是如此，你看图里我画的几个红圈的地方。

​      ![img](http://wechatapppro-1252524126.file.myqcloud.com/image/ueditor/39585200_1578370737.cn/txdocpic/0/fd0ea7b44de83cc94ec33d3cbf9fe173/0)       

订单系统要调用仓储系统的接口去发货，仓储系统在接到订单系统的调动之后，又要同时去调用第三方物流系统去生成物流单，通知人家去取货。

所以在上图的流程中，必须要等到第三方物流系统返回确认信息之后，仓储系统才能返回结果，订单系统才能结束对仓储系统的调用。

想想看，在这个情况下，订单系统不就跟仓储系统、第三方物流系统，全部耦合在一起了吗？

**5、跟第三方系统耦合的痛苦：性能差，不稳定**

接着明哥脸上突然出现了一种非常复杂的表情：痛苦！嫌弃！有厌恶！五味杂陈。。。

为什么这么复杂的情感？明哥接着说：对我们多年设计系统的人来说，跟第三方系统的交互往往是最麻烦的。

因为对于我们自己公司内的系统，即使他有问题，所有代码、数据库都在自己公司，你可以去优化，你知道他如何运行，你知道问题在哪里，也知道怎么解决。

但是对于第三方系统的调用，那就不是那么回事了。你不知道他是怎么写的，甚至他的系统是用Go、C++、PHP写的都有可能。

那么问题来了，假如你调用他的接口，结果他的接口有时候速度很快只要20ms，有时候速度很慢要200ms，有时候调用很正常，有时候偶尔会调用失败几次，你怎么办？

你不知道他是如何实现的，不知道他问题在哪里，你更不知道如何解决他的问题，你也没资格去改动他的代码。问他们的工程师，人家根本不理你，就说一句：我们系统大部分情况下不是挺好的么！

所以你要记住一点：**第三方系统，永远是不能完全信任的**，他随时有可能出现意料之外的性能变差、接口失败的问题。

这就是你的系统跟第三方系统耦合在一起的痛苦：对方不可控，导致你的系统的性能和稳定性也不可控。

**6、小猛的顿悟：第三方系统的耦合给订单系统带来了不确定性**

小明听到这里，立马脑子里有一种顿悟的感觉，他跟着说，那岂不是我们的订单系统调用仓储系统，接着调用第三方物流系统，很可能被第三方系统给拖累？

万一他的性能突然降低，我们的系统性能就降低了，万一他接口突然调用失败，我们的这次操作也会失败，后续还要考虑重试机制？

明哥点点头：说的没错，所以在我们订单支付的核心流程里，其实还有这么一个技术隐患，耦合第三方系统带来的不确定性，也是需要后续我们去解决的。

小猛今天感觉又是慢满满的收获，若有所思的走出了会议室，决定今晚好好的吸收和消化今天学到的东西。

### 08 授人以渔：你们有没有跟第三方系统对接过，有遇到什么问题吗？

今天的授人以渔的环节，我们希望引导大家去思考几个问题

第一个问题，大家结合在上一篇文章里学习到的知识，思考一下，自己对系统间的耦合，是否有了一个更加深入的理解？

然后再考虑一下，你手头负责的系统或者服务，都跟谁耦合了？

最重要的，你负责的系统是否跟某个第三方系统进行了耦合？如果有，**建议大家在评论区中分享交流**，这是一种非常好的经验积累和分享。

另外，各位再思考一个问题，你现在系统跟第三方系统耦合了，是否遇到了性能上的问题？

比如你自己系统就只要20ms，结果第三方系统要200ms。

是否有稳定性的问题？比如第三方系统的接口有时候会超时、失败。

如果你有类似的经验，**同样可以在评论区里分享交流。**而没有类似的经验的同学，也可以看看别的朋友的分享。

之前几篇文章的评论区中，就有好几个朋友对自己系统和第三方系统耦合进行了经验分享，非常精彩，大家可以去看一下。

### 09 系统面临的现实问题：大数据团队需要订单数据，该怎么办？

**1、高大上的大数据，不识庐山真面目**

小猛早早的就来上班了，昨天吸收了明哥讲的关于系统和第三方系统耦合的问题，感觉真是意犹未尽。

小猛心里默默的感叹，虽然自己没能直接进入BAT等大厂去工作，但是至少能一毕业就来一个快速发展的互联网公司，在里面可以接触到真实的互联网系统架构面临的问题，感觉自己很幸运。

跟前两天一样，明哥一看到小猛，立马又把他拉到小会议室里去了。

今天明哥并没有一进会议室就唰唰画出来一张流程图，而是问了小猛一个问题：你知道我们公司的大数据团队是干什么的吗？

小猛一听就来兴趣了，兴奋的说，大数据啊，前几年就在国内火起来了，听着特别的高大上，还有现在人工智能啊之类的。

但是。。。大数据到底是干什么的？这个问题我还真的没考虑过，就是听着特别高大上，新闻都老说高端大数据什么的，连老家村子里的一些亲戚都听说过这个高大上的字眼。

明哥哈哈的笑了起来：你连大数据都不知道是干嘛的，还这么兴奋干什么呢！我今天来给你讲讲，大数据具体是干什么的，因为今天我们要讲的订单系统问题，是跟大数据团队有关系的。

**2、大数据到底是干嘛的？**

举个例子，咱们公司是做电商业务的，说白了就跟以前你老家门口的商店是一个性质。要准备很多的货物，然后在架子上陈列出来，然后村子里的人没事儿了就来逛一逛，看到喜欢的就放到购物框里去，最后拿到收银台那儿去结账。

我们现在有一个电商APP，很高大上的样子，其实本质是不是跟村门口的商店是一样的？

我们要在仓库里准备商品，然后我们要在APP里陈列商品，接着还得打广告吸引很多人来APP里看看。

如果有人看到喜欢的，就加入自己的购物车，最后对购物车下订单，跳转到支付系统进行结账，然后我们就通过物流公司把货物发送给用户了。

所以现在我们考虑一下，假设你要是这个电商公司的老板，你每天会想些什么事情？

首先，我每天去公司第一眼，必须得知道昨天一共卖了多少营业额！这个是我们公司运营至关重要的问题，因为我们必须不停的卖货，卖很多很多的货出去，营业额做的很高，才能养活公司几百个人。

但是光有营业额还不够，我还想知道昨天一共有多少个用户在我们这里购买了商品？一共有多少笔订单？每个商品分别卖了多少件？哪商品是最火爆卖的最好的？我们的APP昨天有多少人打开了？打开APP的人里有多少人下订单购物了？

此外，我还想知道，我们昨天的毛利润一共有多少（就是营业额扣除掉商品本身的成本之后的毛利，如果你用毛利再减去公司运营的成本，比如300个员工的工资，公司房租、水电等等，再交完税，就是老板和股东的净利润了）？

还没完，我还得知道，昨天下订单购物的人里，老用户有多少人（就是以前在你这里注册过或者购物过的，这些算老用户）？新用户有多少人（就是第一次下载你的APP，注册之后立马就购物的用户）？

当老板知道这些数据之后，才能继续去考虑公司的运营策略。

比如老板拿到了用户量这个数据，觉得用户量还是太少了，要抓紧投放广告，多拉一些人来购物。

或者老板可能觉得爆款的商品太少了，大部分商品业绩平平，说明没有吸引消费者，那么就得多去选择一些符合用户喜好的爆款商品。

又可能老板发现很多人打开了APP，但是不知道为什么就是没下订单，那就得多放一些吸引人的商品在首页了。

因此，只要听明白了上面的这段描述，你一定就能理解什么是大数据，以及大数据团队是干什么的了。

很简单，上面说的老板要每天上班第一件事情要了解的那一大堆的数据，其实就是大数据，只不过互联网公司跟村门口的小卖铺有一点区别。村里的小卖铺只要服务好村里100多个人就可以了，但是我们作为一个面向互联网的电商APP，要服务的是100万用户。

**所以每天如果有100万用户来访问你的APP，积累下来的一些浏览行为、访问行为、交易行为都是各种数据，这个数据量很大，所以你可以称之为“大数据”**

反之，如果一个村口的小卖铺的老板，自己积累下来每天100个用户的行为和交易在一个笔记本上，其实那也是数据，但是那数据量很小，就是“小数据”。

接着再来说大数据团队是干什么的？

大数据团队每天要负责的事情，说白了就是去**尽可能的搜集每天100万用户在你的APP上的各种行为数据。**

比如用户搜索了什么东西，点击了什么东西，评论了什么东西。还有就是搜集用户在APP里的交易数据，比如最核心的一种，就是我们的订单数据。

订单数据就直观的代表了用户在APP里的所有的交易。

然后大数据团队搜集过来大量的数据之后，就形成了所谓的“大数据”。接着他用这些大数据可以计算出很多东西。

最常见的就是数据报表，比如说用户行为报表，订单分析报表，等等。这些数据报表都是提供给老板来看的。

这就是所谓的“大数据”和大数据团队干的事儿。

小猛听的目瞪口呆，他觉得明哥简直帅呆了，把大数据解释的如此直白，浅显易懂。

照这个理论来解释大数据，他下次过年回家都可以跟村口开小卖铺的老大爷解释什么是大数据了。

其实村口老大爷每天在自己的笔记本上记录的店铺的各种经营情况，也是数据，只不过量太小了，所以是“小数据”。高大上的大数据，本质上也是这个意思！

**3、大数据团队跟我们订单团队有什么关系？**

接着小猛突然一个机灵，从自己跟小卖铺大爷解释大数据的白日梦中惊醒了。

他问明哥：说了半天这个大数据，那他跟我们订单系统有啥关系啊？

明哥微微一笑：听到这里你还没反应过来吗？

小猛有点不好意思，稍微沉思了一下，瞬间脑子就明白过来了。对啊！大数据团队的职责不就是搜集各种各样的数据吗？那其中也包含我们的订单数据啊！他们需要分析每天几十万个订单，从中提取出老板最关系的APP交易数据报表！

明哥很高兴的说道：对了，你的反应很快，就是这个意思。

但是明哥叹了一口气，唉，不过现在这也就是我们订单系统面临的另外一个问题，大数据团队从我们这里提取数据，已经严重影响到我们订单系统的运行了。

**4、最low的做法：直接从订单库里select数据出来**

明哥接着说，现在大数据团队也是公司刚刚成立的，各种基础组件都没搭建好，但是老板要一些数据实在太着急了，所以现在你知道大数据团队在订单这块的一些交易报表，是怎么跑出来的吗？

小猛木然的看着明哥，摇摇头。

明哥继续说道：现在我们的订单数据库，是直接对外暴露的，大数据团队是直接可以访问我们的订单数据库的。

他们有一个数据报表系统，那个系统每次在老板查看交易报表的时候，就会直接用一个几百行的大SQL，从我们的订单数据库里查出来需要的数据！

明哥说着在小白板上画出了一个示意图。

![img](http://wechatapppro-1252524126.file.myqcloud.com/image/ueditor/15782700_1578370749.cn/txdocpic/0/a536211ec1232e41ac3f645f3c769384/0)       

你看这个示意图，很快就明白怎么回事了。

小猛这个时候还是木然的看着明哥，说道：那人家查就查吧，对我们能有什么影响？毕竟老板要看，我们也只能这样啊。

明哥惊讶的看着小猛：看来你还年轻，不知道这种几百行大SQL的恐怖威力啊！

**5、几百行的大SQL直接查线上库的危害**

明哥接着解释道：首先你要知道一点，我们的订单数据库里的数据量是很大的，最开始每天APP就几百个订单，到现在每天小几十万订单，我们每个月都新增千万级订单数据。

现在表里已经有的订单都有千万以上了，我们毕竟是最近几个月才发展起来的，所以历史数据没那么多。

但是每天新增几十万订单，数据增长是很快的，如果我们不对数据库架构做一些重构，很快单表上亿数据，基本系统运转就困难了。

其次，就以我们现在数据库里千万级数据来说，每次老板要看交易报表的时候，数据报表系统运行一个几百行的大SQL到我们库里，这种级别的SQL在这种量级下，快则三五秒，慢则几十秒！

明哥说到这里停顿了一下，看着小猛。

结果小猛还是没什么反应，他心想，几十秒的话，也最多就是报表查询速度慢点而已，跟我们有什么关系？

明哥接着解释，但是这种几百行的大SQL执行是非常消耗CPU的，对磁盘IO的负载也是很重的，尤其是每天不止老板一个人要看数据报表，这个报表系统是对公司开放的，包括副总，高管，中层经理，运营，产品经理，全公司几十个人都会看这些报表。

每次当有几十个几百行的大SQL同时运行在我们订单数据库里的时候，都会导致我们的数据库CPU负载很高，磁盘IO负载很高！

一旦我们的数据库负载很高，直接会导致我们的订单系统执行的一些增删改查的操作性能大幅度下降！

小猛这个时候才梦然醒悟，他看着明哥在图里又增加了几笔，瞬间就搞明白里面的厉害关系了。

​      ![img](http://wechatapppro-1252524126.file.myqcloud.com/image/ueditor/27878200_1578370749.cn/txdocpic/0/6cfb492b3ed92f86f778398705b5740e/0)       

搞了半天，昨天我在工位上做笔记的时候，听到旁边的师兄抱怨说，怎么订单系统的接口突然性能又下降了，原来就是因为有好多人在查看数据报表，结果几十个几百行的大SQL运行在我们订单数据库啊！

小猛同情的看着明哥，心想：唉，老大真是太不容易了，又不能不让老板看报表，但是最后数据的计算压力居然都落在订单系统身上了，真是不容易啊！

小猛跟明哥说：明哥，今晚我回去一定好好梳理这个大数据团队强加给我们的技术难题，好好思考一下该怎么解决！

### 10 授人以渔：你们有没有遇到过自己系统的数据，其他团队需要获取的？

今天的授人以渔环节，大家可以结合上一篇文章的知识来思考一个问题：大家负责的系统是否需要向一些其他团队提供数据出去？

不一定是像上一篇文章中那样是大数据团队到你这里来获取数据，但凡是其他系统要从你这里获取数据的，都是类似的情况。

给大家举一个例子，现在都流行微服务化，很多后台系统都是拆分为很多服务的，其实有的服务粒度比较粗，基本就是类似于一个子系统的概念。然后在服务之间可能都会互相进行数据的访问。

曾经我们见得比较多的一个情况是这样的，比如订单系统可能需要获取库存数据、价格数据、还有其他一些数据，此时可能就会直接从其他服务的数据库里查询数据出来。也就是订单系统可能会跨系统直接去访问库存系统的数据库。

这样的情况在很多公司的系统粗放发展的时候，是很常见的。

最后我们经常会在一些公司里看到这样的现象：订单系统胡乱查询库存系统的数据库，结果把库存系统的数据库搞挂了，也有这种可能。

还有比如很多公司的商品系统，即要对外提供商品数据访问的系统，需要大量的数据，也是需要库存数据、促销数据等等，此时也是需要进行跨系统的数据访问。

所以大家可以结合这种情况思考一下，在你们公司里，跨系统的数据访问是否存在？都是什么样的场景？

欢迎大家在评论区里给出自己的经验分享！

### 11 系统面临的现实问题：秒杀活动时数据库压力太大，该怎么缓解？

**1、愁眉苦脸的小猛：为啥订单系统有一大堆问题？**

小猛今天一早就到了公司，但是在工位上愁眉不展。因为他经过最近几天的学习，觉得自己所在的订单技术团队，这个订单系统面临的技术问题真是太多了。

他一边想，一边在自己的A4白纸上画图。

​      ![img](http://wechatapppro-1252524126.file.myqcloud.com/image/ueditor/32662400_1578370764.cn/txdocpic/0/6f30180335d4cdd314c0a5368bd12933/0)       

小猛一边画图，一边自言自语：首先是在一个订单支付之前，用户一旦下了订单，就会锁定对应的商品库存，别人就不能买了。然后万一用户一直没支付，还得一个后台线程不停的扫描数据库里的待支付订单，去自动取消长时间没支付的订单。

但是如果这种订单有几十万甚至几百万之多呢？不停的让后台线程扫描，性能很差，也非常的不方便。

接着小猛又在白纸上画了一个图出来。

​      ![img](http://wechatapppro-1252524126.file.myqcloud.com/image/ueditor/43643600_1578370764.cn/txdocpic/0/70e62e0f57020f2cb093d83979cbbe75/0)       



这个图就稍微复杂一点了。支付订单之后要经历更新订单状态、扣减库存、发送Push推送、增加积分、派发优惠券和红白、通知仓储系统发货，等等过程。

这一系列的过程要是都执行下来，那性能真是太差了！

而且不光是这样，在这个调用链路中，订单系统还跟仓储系统耦合在了一起，仓储系统是跟第三方物流系统耦合在一起的。

这种耦合，就导致了第三方物流系统如果性能出现抖动，会导致我们的核心链路的性能也会抖动，第三方物流系统的接口如果调用失败，会导致我们的核心链路也出现部分失败。

小猛一阵摇头，又接着画了一个图：

​      ![img](http://wechatapppro-1252524126.file.myqcloud.com/image/ueditor/57984100_1578370764.cn/txdocpic/0/71f73a31c2b905fc4a704ef1fba8018c/0)       

看上图，哪怕是订单支付过后，如果用户要退款，这个时候涉及到自己公司内部系统的一系列回滚，比如更新订单状态、增加库存、收回优惠券和红包、减少积分，通知取消发货，等等。

而且此时还得调用第三方支付系统进行退款，但是万一在这里退款失败了呢？那用户就拿不到自己的钱了，所以还得考虑这个问题。

接着小猛拍拍脑袋，又画了一个图。

​      ![img](http://wechatapppro-1252524126.file.myqcloud.com/image/ueditor/65676000_1578370764.cn/txdocpic/0/61c9846335e31e4031b7577949f66cfc/0)       

真是搞不懂这个大数据团队在搞什么，虽然是刚刚组建，来不及搭建自己的架构。但是就因为老板急着看数据报表，就直接跑几百行的大SQL从我们订单数据库里来拿数据，这个太不靠谱了。

如果有几十个人同时看报表，几十个几百行的大SQL运行在订单数据库里，瞬间会导致我们的CPU和磁盘IO负载过高，导致我们订单系统自己的CRUD操作的性能下降，真是想着都揪心！

小猛看着自己画的这四张图，感觉自己完全理解现在订单系统面临的困境了，但他觉得有心无力，因为问题很多，不知道如何去解决。

而且他觉得，这些还只是明哥给他讲的一些问题，包括数据库压力过高，数据量过大，搜索订单性能太差等很多这类问题，可能明哥都没给他讲，因为毕竟是团队其他兄弟在负责这类事情。

**2、明哥的赞赏：知耻而后勇，就成功了**

正当小猛出神的时候，明哥来到了他的身后，看着他手里画的4张图，很是欣慰。心想：真是没看错这个小伙子，悟性很高，聪明努力，几天功夫就把订单系统面临的技术问题都理解透彻了。

明哥拍拍小猛的肩膀说：怎么样，是不是感觉自己对这些技术问题有心无力？

小猛点点头：是的，我现在知道有这些问题了，但是不知道怎么去解决他们，明哥你让我来负责这些问题的技术方案的设计，我可能做不到啊。

明哥微笑着说：你不要过于担心了，你是应届生，我怎么会把担子都压在你身上呢。

其实最主要的，是我来一步步指导你去调研一些技术，然后给你一些思路，让你设计出解决这些问题的技术方案来，所以我会全程带着你的，放心。

小猛一听就乐了：原来有明哥这么粗的大腿抱，不是我一个人抗啊，那我就放心了。

明哥说：知耻而后勇，就成功了，现在你意识到了自己能力不足，以后一定要多加努力！

**3、双11对一个订单系统到底有多大压力？**

明哥接着带小猛到了会议室里，在会议室里明哥说：今天要告诉你这个订单系统未来需要你来解决的最后一个问题，就是抗双11大流量压力！这个也是需要你来搞定的，当然，我会带着你一起做，给你指导思路。

小猛一听就来兴趣了，因为平时常常在网上看到，12306售票网站的压力有多么的大，平时淘宝天猫的双11活动时系统压力有多么大，春晚时候的微信红包压力有多么大，但是自己一直不太理解这里面的问题所在。

明哥看出了小猛的疑惑，开始了讲解。

首先经过之前的讲解，我们已经知道了咱们的电商APP的用户使用习惯以及我们的订单系统面对的压力。

在平时晚上的高峰使用期，最顶峰的时候大概是每秒2000左右的请求压力到订单系统上来。

明哥说着，就在小白板上画了一个图出来。

​      ![img](http://wechatapppro-1252524126.file.myqcloud.com/image/ueditor/78767300_1578370764.cn/txdocpic/0/a70d66692a8fe6162d7547bc4a41ebe6/0)       

接着明哥问小猛一个问题：如果用户每秒会发起2000个请求到我们的订单系统的各类接口，包括下单接口、退款接口、查询接口等等，那么你觉得我们的订单系统每秒会执行多少条SQL在订单数据库上？

小猛被这么一问，一下子就呆住了，这个问题还从来没想过。

明哥接着解释，这个其实是一个有经验的工程师一般都会了解的一个估算方法，比如每秒订单系统的各类接口被调用2000次，平均每个接口会执行多少次数据库操作？

一般你可以认为平均每个接口会执行2~3次的数据库操作。

一般一个接口根据业务复杂度的不同，有的接口可能处理一个请求要执行五六次数据库操作，有的接口可能是1次数据库操作+两三个其他系统的接口调用（比如库存系统、营销系统）。

总之，一般来说，业务系统的接口处理逻辑，基本都集中在对自己的数据库的操作以及对其他系统的调用上。

所以大致在我们这里，结合线上数据库的可视化监控界面，基本可以知道，平均每次订单系统的接口调用，会执行2次数据库操作，我们观察数据库的监控界面，在最高峰的时候，每秒大概是有4000左右的请求。

说到这里，明哥继续在上图中补充了一点东西。



​      ![img](http://wechatapppro-1252524126.file.myqcloud.com/image/ueditor/87482600_1578370764.cn/txdocpic/0/2199adf6874590ccbbc3b5a5df0784d6/0)       



之前讲过，线上数据库是部署了一台服务器的，用的是高配置的16核32G以及SSD固态硬盘的机器，因此观察线上数据库的情况，在每秒4000请求的时候，虽然CPU、磁盘、IO等负载较高，但是基本还在承受范围内。

那么接着问题来了，如果在双11之类的超级大促活动中，我们的订单系统可能会面临多大的压力？以及订单数据库可能面临多大的压力？

**4、双11之类的大促活动有多恐怖**

明哥接着解释，双11之类的大促活动你知道有多恐怖吗？

明哥举了一个最直接的例子，明哥他媳妇儿。

明哥他媳妇儿每年最盼望的就是一年一度的双11，因为这个时候往往所有人购物成风，她也可以疯狂的购物，不用顾虑明哥痛苦的眼神。

为什么呢？因为明哥那个时候一定是坚守在公司里值班，保证公司的系统稳定性，不会在家里。当然只是个玩笑！

但是实际情况也差不多如此，在类似双11之类的活动时，基本上很多电商都会在双11零点之后突然开启一个特别大的折扣优惠，比如来一个全场3折大甩卖。

很多少男少女，中年妇女，都会等在手机前。

明哥的媳妇就会在双11之前几天，在购物车里加入大量的商品，然后在双11零点来临前盯着手机等待，等零点一过，双11全场大甩卖正式开始，此时大量的人在这个时候突然下单，抢购商品，仿佛商品都不要钱一样。

所以此时很多顶级大电商公司的系统，可能会在双11购物最高潮的时候，系统QPS达到百万级别，也就是每秒百万请求！

当然，明哥所在的公司还没那么恐怖，毕竟是一个创业型电商公司。

但情况也好不到哪儿去，明哥回忆道：去年双11的时候，公司也搞了一场活动，当时公司用户量很少，那年双11就几十万用户参与了，但是就这样，在双11购物最高峰的时候，也达到了每秒几千的QPS！

明哥说，当时我们那台16核32G的高配置机器部署的数据库，短时间内CPU、磁盘、IO的负载飙升到了最高，但是这种购物高潮往往不会持续太久，所以很短时间过后，负载就慢慢下来了，基本还能抗住！

**5、今年的双11活动对系统压力会有多大？**

明哥接着说，那么今年的双11活动对系统压力会有多大你知道吗？公司现在积累的注册用户已经千万级了，平时的日活用户都百万级，今年的双11参与活动的用户预计有可能会达到两三百万。

假设是这个量级的话，基本可以做一个设想，如果有200万用户参与双11活动，在双11购物最高峰的时候，肯定会比往年的高峰QPS高好几倍，预计有可能今年双11最高峰的时候，会达到每秒至少1万的QPS。

也就是说，光是系统被请求的QPS就会达到1万以上，那么系统请求数据库的QPS就会达到2万以上。仅仅凭借我们目前的数据库性能，是无论如何扛不住每秒2万请求的。

小猛听到这样的一番分析，从系统面临的实际场景，一直到系统的压力挑战，目瞪口呆。

他很惊讶，在一些大促活动的时候，数据库的访问压力完全有可能会超出他能承受的极限，那这个时候该怎么办呢？

明哥笑笑说：别着急，其实这个每秒2万QPS也不算太高，跟BAT比起来，就是小巫见大巫了，我们只要合理设计系统架构和技术方案，其实也是可以轻易的抗住这个压力的。

小猛听明哥如此的淡定，顿时像个小迷弟，一脸崇拜之情。通过技术解决现实生活中的挑战，真是太有意思了！

### 12 授人以渔：你们系统会不会遇到流量洪峰的场景，导致瞬时压力过大？

今天的授人以渔的环节，希望大家结合上一讲的大促秒杀一类的场景去思考一个问题：在你负责的系统中，是否存在一些比较特殊的场景，在某个特定的时间点，或者某个特定的节日，会出现一大波流量洪峰？

而且建议大家先思考一个问题，就是大家各自的系统平时的QPS有多高？

有些人会觉得，自己不知道怎么看这个QPS，那么大家完全可以自己写一个简单的QPS统计框架，在你的各个接口被调用的时候，先执行这个QPS统计框架的代码。

然后在QPS统计框架里计算各个接口每秒被访问的次数，然后输出到你的日志文件里去即可。

当然，更好的方式是采用一些可视化的监控系统去观察你的系统的QPS。

接着建议大家去观察一下自己线上数据库的QPS，一般也都是基于一些可视化监控系统去看的。

这里很多人估计又会说了，我的系统真的真的很low，没多少QPS。

没关系，你完全可以假设你的系统突然出现一阵流量洪峰，比如每秒QPS突然暴增100倍，甚至1000倍，此时你的系统能抗住吗？数据库能抗住吗？

希望大家去认真思考这些问题，并且欢迎把自己系统的情况分享到评论区里，跟其他朋友进行交流。

后续希望大家都像这样，带着自己的思考和问题去学习各种技术方案，最后解决这些问题。

通过这种方式，你一定可以把学到的东西都跟自己的系统结合起来，融为自己的东西。 

**End**

### 13 阶段性复习：一张思维导图给你梳理高并发订单系统面临的技术痛点！

今天是我们第一个阶段的复习环节，我们已经把一个订单系统面临的各种技术问题都给大家分析的比较清晰了，因此我们会在这里对目前的技术问题做一个总结和梳理。

同时也给大家解释一下，为什么我们要加入阶段性复习的环节。

大家应该都知道，一般学习一个专栏持续的周期都比较长，通常都在三个月左右。这里有很多的原因，其中有作者的原因，也有用户的原因。

对作者来说，每周要在繁忙的工作之余（大家都知道，国内的互联网公司基本都是996的节奏）写作出几篇高质量的、精心打磨和修改的文章，其实是很耗费时间的。我们的专栏每篇文章都在3000字以上，这样一个篇幅的文章，从构思、到写作、到反复修改，起码要几个小时的时间。

因此对于作者来说，每周输出几篇高质量的文章，是一个非常正常平稳的写作节奏。

而对于用户来说，在学习上讲究的短频持续的学习。也就是说，假设现在给你一本书，让你每天看3个小时，连续一个月把他看完，你觉得会怎么样？

说实话，很多程序员都会囤书，买了一大堆的书，但是你数一数，你真正把一本书完完整整看完的，又有几本？

这里当然有一个很重要的原因，就是很多技术书籍较为枯燥乏味，让你顺流而下，一章一章阅读是很难坚持的，可能每本书都是坚持看了头三章，就看不下去了。

另外一个原因，人很难每天耗费几个小时干一个事情，并且连续坚持好几周，除非是在我们上学的时候，有老师逼着，有升学毕业的压力在，才会反人性这么干，但是正常来说，大家都不愿意这样子。

因此对一个读者而言，学习一个技术，每天都学习一个知识点，不耗费太多精力，是较为容易长期坚持下来的。

最理想的情况是，三个月后，发现自己不知不觉啃完了一个几十篇文章的完整专栏，并且里面的知识居然都看懂了，还有点意犹未尽，这个是作为作者最希望看到的情况

这就是站在一个学习者的角度而言，为什么跟着一个专栏用三个月的周期长期持续坚持是更好的。

但是这里同样也引入了一个问题：如果学习一个东西的周期持续那么长时间，势必导致有些人学到后面忘了前面，这是人之常情。

因为每个人都有记忆曲线，你看了一个东西，可能一周内记得很清楚，一个月后基本很模糊，半年后就彻底遗忘了。

所以针对这个问题，我在这个专栏里加入了一个阶段性复习的环节，每当学习完一个阶段，我都会用思维导图的方式梳理出你学习过的核心知识点

这样让各位经常可以对照思维导图快速回忆，有针对性的复习一下，那么就会一直保持对自己学过的东西的记忆。

当最后专栏全部结束了，我还会出一个针对整个专栏的大思维导图，让大家能够随时回忆出来3个月学习的一个成果。这样你以后在工作中用到这个技术了，还可以随时回到专栏里，对照思维导图快速复习。

这个阶段性复习的过程，是跟之前解释过的“授人以渔”的环节相辅相成，同样重要的

“授人以渔”的环节是用来训练大家的主动思考能力，让大家真正主动思考知识，消化知识，把知识融入到自己的工作里去，让学到的东西真正转化为你自己的东西，而不仅仅是对一些知识点死记硬背。

而阶段性复习过程，就是帮助大家不断的回忆和梳理学习过的东西，不断的反复记忆，避免遗忘，把学过的东西强化到自己的大脑里去。

因此，上述就是我设计阶段性复习环节的初衷，那接下来我们就来看看，我给大家梳理出来的第一个阶段的思维导图。      ![img](http://wechatapppro-1252524126.file.myqcloud.com/image/ueditor/30464700_1578370778.cn/txdocpic/0/e0552686ea297fc01493dd4811d0007d/0)       

大家通过这个思维导图，立马就可以对学习过的知识一目了然，看到当前订单系统面临的一些核心的技术问题。

思维导图是一个非常好的工具，可以帮助你在大脑里存储一些知识的核心体系，让你记忆更加深刻。

**End**

### 14 阶段性复习：放大100倍压力，也要找出你系统的技术挑战！

本文也是我们阶段性复习的一个重要环节，因为我们的学习节奏是每次更新一篇技术文章+一篇授人以渔，目的是让大家学完一个知识之后，能够引导大家对自己的系统进行反思和主动思考。

因此对阶段性复习而言，我们也是每次都有两篇文章，一篇是用思维导图对学习过的知识体系的梳理，一篇是对过去一个阶段学习过的知识的授人以渔环节的梳理和总结，这也是非常重要的一个部分。

今天我就来带着大家梳理一下过去一个阶段的授人以渔环节，我们希望大家能够哪些问题进行深度的思考。

**第一**，大家先思考一下系统的核心业务流程，当然不是指那种查询之类的操作。所谓核心链路指的是对你的系统进行的数据更新的操作，这才是核心链路，因为查询操作一般来说不涉及复杂的业务逻辑，主要是对数据的展示。

对你的系统的核心链路分析一下，有哪些步骤，这些步骤各自的性能如何，综合起来让你的核心链路的性能如何？在这里是否有改进的空间？

**第二**，大家可以思考一下，在你的系统中，是否有类似后台线程定时补偿的逻辑？

比如订单长时间未支付就要自动关闭它，你们系统里有没有那种后台线程，会定时扫描你的数据，对异常数据进行补偿、自动修复等操作的？

如果有的话，这种数据一般量有多大？如果没有，你可以思考一下，你们系统的核心数据是否需要类似的后台自动扫描机制？

**第三**，大家可以思考一下，在你的系统里有没有跟第三方系统进行耦合？就是一些核心流程里需要同步调用第三方系统进行查询、更新等操作，第三方系统是否对你的核心链路有性能和稳定性上的影响？

**第四**，大家可以思考一下，在你的核心链路中，是否存在那种关键步骤可能会失败的情况？万一失败了该怎么办？

**第五**，大家可以思考一下，平时是否存在其他系统需要获取你们数据的情况？他们是如何获取你们数据的？

是直接跑SQL从你们数据库里查询？或者是调用你们的接口来获取数据？是否存在这种情况？如果有，对你们有什么影响吗？

**第六**，你们的系统是否存在流量洪峰的情况，有时候突然之间访问量增大好几倍，是否会对你们的系统产生无法承受的压力？

希望大家能好好思考这六个问题，同时思考后的结果，欢迎发送到评论区一起交流！

**End**

### 15 解决订单系统诸多问题的核心技术：消息中间件到底是什么？

**1、解决订单系统诸多问题的核心技术：消息中间件**

今天一上班，小猛非常期待的跑到了明哥的工位旁：明哥，现在订单系统的所有问题我们都搞清楚了，是不是可以开始研究对应的技术方案了啊？

明哥说：当然了，今天开始我们要慢慢调研和落地一些技术方案，去逐步解决订单系统面临的各种问题了。

首先第一步，我先给你介绍一个用来解决我们订单系统问题的核心技术，消息中间件。

明哥问：你对消息中间件有了解过吗？

小猛说：这个还真没有，因为平时在学校里都做一些CRUD的项目，像什么酒店管理系统啊，图书馆管理系统之类的。

明哥笑了笑：没关系，我先简单给你介绍一下消息中间件的概念，你肯定一听就懂，并不难。

**2、了解消息中间件之前，先认识一下什么是“同步”**

首先，我们想一下，通常而言，在公司里可能会存在多个业务系统，这些业务系统之间的通信都是进行接口调用的。明哥说着在纸上画出了一幅简易的示意图。

​      ![img](http://wechatapppro-1252524126.file.myqcloud.com/image/ueditor/56967300_1578370790.cn/txdocpic/0/c6939e22729a2f64a6d65f67751b8cdd/0)       

现在假设系统A收到了一个请求，可能是用户通过浏览器或者APP发起的，这个时候系统A收到请求之后就会立马去调用系统B，然后系统B返回结果给系统A之后，系统A才能返回结果给用户，是不是这样？

明哥接着在图里补充了一些东西。

​      ![img](http://wechatapppro-1252524126.file.myqcloud.com/image/ueditor/69143200_1578370790.cn/txdocpic/0/b8a78e40c615d18fcd7919c509c42b33/0)       

小猛点点头，确实是的，因为通过一个复杂的系统去实现各种复杂的功能，满足用户的需求，简化来说，大致确实如此。

明哥接着说，那么在这种情况下，用户发起一个请求，系统A收到请求，接着系统A必须立马去调用系统B，直到系统B返回了，系统A才能返回结果给用户，这种模式其实就是所谓的“同步调用”。

这个同步的意思，就是各个系统的联动都是同步依次进行的，一个系统先动，然后立马带动另外一个系统一起动，最后大家依次干完了以后，再返回结果。

这就是同步调用最通俗的解释了，不是那种学术型的解释。

**3、再来看看依托消息中间件如何实现异步？**

明哥接着说，现在假设我们在系统A和系统B之间加入了一个东西，这个东西就叫做“消息中间件”，但是这五个字念着太麻烦了，干脆就简单点，叫MQ就行了，英文全称就是“Message Queue”，也就是消息队列。

然后明哥在图里加入了消息中间件。     ![img](http://wechatapppro-1252524126.file.myqcloud.com/image/ueditor/80345500_1578370790.cn/txdocpic/0/13de6929108b5f667ba24db29ef9838f/0)    

加入了这个消息中间件以后，系统A和系统B之间是怎么通信的呢？

很简单，之所以叫这个东西 是“消息中间件”，说明他里面一个核心的概念就是“消息”。所以系统A一般会发送一个消息给MQ。

接着系统A就认为自己的工作干完了，然后就直接返回结果给用户了，明哥在图里加了点东西，而且还标号了各个步骤执行的顺序。    ![img](http://wechatapppro-1252524126.file.myqcloud.com/image/ueditor/92109600_1578370790.cn/txdocpic/0/6baa79232a5cca24787d75e4c191b321/0)    

此时小猛很疑惑，那系统B什么时候执行自己的任务呢？

明哥紧接着说：别着急，马上就到系统B了。你先思考一下，这个时候系统A跟系统B是不是看着就没什么关系了？因为系统A要做的事情只是接收请求，发送消息到MQ，然后就返回结果给用户，系统B他就不管了。

然后系统B根据自己的情况，可能会在系统A投递消息到MQ之后的1秒内，也可能是1分钟之后，也可能是1小时之后，多长时间都有可能，反正不管是多长时间后，系统B肯定会从MQ里获取到一条属于自己的消息。

然后获取到消息之后，根据消息的指示再完成自己的工作。

明哥说着继续在图里补充了一些东西。     ![img](http://wechatapppro-1252524126.file.myqcloud.com/image/ueditor/7919900_1578370791.cn/txdocpic/0/ce45ad158875a011ba168ac91914efdb/0)    

在这种情况下，系统A和系统B有没有实现通信？

有，因为系统A发了一个消息给MQ，系统B从MQ里获取了一个消息，干了自己该干的工作。

那么系统A跟系统B之间是不是同步调用？

不是，因为系统A仅仅是发个消息到MQ，至于系统B什么时候获取消息，有没有获取消息，他是不管的。

所以这种情况下，我们说系统A和系统B是**异步调用**。

所谓异步调用，意思就是系统A先干了自己的工作，然后想办法去通知了系统B。

但是系统B什么时候收到通知？什么时候去干自己的工作？这个系统A不管，不想管，也没法管，跟他就没关系了。

但是最终在正常下，系统B总会获取到这个通知，然后干自己该干的事儿。

这种情况下，并不是系统A动了，系统B就立马同步动，他们不是同步的。而是系统A动了，但是系统B可能过一会儿才动，他们的步调是不一样的，所以是异步的。

这就是所谓的“异步调用”最通俗的解释了，完全没任何的学术痕迹。

**4、消息中间件是用来干什么的？**

听到这里，小猛又觉得自己面前打开了一扇新的大门，以前自己就知道做CRUD之类的事儿，最多是用Spring Cloud、Dubbo之类的技术搭建过几个简单的Demo，让不同的系统实现同步调用。

但是自己从没想过系统之间还可以进行异步调用！

所以听到这里，小猛不禁脱口而出：所以消息中间件，其实就是一种系统，他自己也是独立部署的，然后让我们的两个系统之间通过发消息和收消息，来进行异步的调用，而不是仅仅局限于同步调用。

明哥大赞：精辟的总结！

**5、那么消息中间件到底有什么用呢？**

小猛接着提出了一个疑问：那让两个系统之间不是同步调用，而是异步调用，有什么用呢？换句话说，我们可以用消息中间件来干什么？

明哥说：这个用处可多了去了，主要的作用有这么几个，包括**异步化提升性能，降低系统耦合，流量削峰**，等等。

比如，现在假设系统A要调用系统B干一个事儿，然后系统A先执行一些操作，需要耗费20ms，接着系统B执行一些操作要耗费200ms，总共就要耗费220ms。明哥说着重新画了一个图做了一个示意。     ![img](http://wechatapppro-1252524126.file.myqcloud.com/image/ueditor/17452700_1578370791.cn/txdocpic/0/c50f75a6a4eecc6487989b19438780a4/0)    这个时候等系统A和系统B都干完活儿，才能返回结果给用户，要等待220ms。

那么如果在系统A和系统B之间加一个MQ呢？

系统A干完自己的事情，就20ms，然后发送一个消息到MQ，就5ms，然后就直接返回结果给用户了。

也就是说，用户仅仅等待25ms就收到了结果。

然后系统B从MQ里获取消息，接着花费200ms去执行，但是这个200ms就跟用户没关系了，用户早就收到结果了，他也不关心你花200ms还是2s去干自己的事。

明哥说着在这个图里补充了一些东西。     ![img](http://wechatapppro-1252524126.file.myqcloud.com/image/ueditor/30733700_1578370791.cn/txdocpic/0/e449b2c1e88fef487e4ec832a7dfd454/0)    

这样的话，对用户来说，是不是从原来等待220ms返回结果，变成现在只要25ms就可以返回结果了？

小猛听着都愣了，还有这套玩法？真是太棒了，消息中间件居然可以用来优化系统性能。

明哥接着说，现在我们说另外一个场景，还是上面那个图来举例。如果系统A同步调用系统B，那么按照我们说过的，是不是这属于系统间的耦合？因为系统A和系统B是耦合在一起的，互相之间会有影响。

那么如果系统B要是突然出现故障了，是不是会导致系统A调用系统B感知到这个故障？因为系统A调用系统B肯定是返回异常的，此时系统A是不是也得返回异常给用户？而且系统A是不是还要去处理这个异常？

明哥说着画了一个示意图：    ![img](http://wechatapppro-1252524126.file.myqcloud.com/image/ueditor/40614500_1578370791.cn/txdocpic/0/f8d3dfd6fa62879babbc2d38b1e617c4/0)    

这一切都是因为系统A和系统B通过同步调用的模式耦合在了一起，所以一旦系统B出现故障，很可能会影响系统A也有故障

而且系统A还得去关心系统B的故障，去处理对应的异常，这是很麻烦的。

那么假设我们在系统A和系统B之间加入一个消息中间件，在这种情况下，系统A对系统B的调用仅仅是发送一个消息到MQ，然后就直接返回给用户了，后面对系统B就不管了。

此时系统B如果出现了故障，对系统A根本没影响，系统A也感觉不到。

明哥说着画了一个图出来。      ![img](http://wechatapppro-1252524126.file.myqcloud.com/image/ueditor/50201400_1578370791.cn/txdocpic/0/8bc774431f645cc1d381cb6c7a573790/0)    系统B故障，就成了他自己的事了，他要自己等故障恢复了，继续去完成他要干的活儿，此时就对系统A没任何影响了。

为什么会有这样的效果呢？因为通过引入MQ，两个系统实现了异步化调用，也就实现了解耦，系统A并没有跟系统B耦合，所以互相之间并没有任何影响。

小猛听到这里，豁然开朗，消息中间件还能让两个系统解耦，让他们俩互相之间没有任何影响，太有意思了！

接着明哥说：消息中间件还有最后一个特别牛的功能，叫做流量削峰。

假设系统A是不操作数据库的，因此只要多部署几台机器，就可以抗下每秒1万的请求，比如部署个20台机器，就可以轻松抗下每秒上万请求。

然后系统B是要操作一台数据库服务器的，那台数据库的上限是接收每秒6000请求，那么系统B无论部署多少台机器都没用，因为他依赖的数据库最多只能接收每秒6000请求。

明哥说着画出了一幅图。

​      ![img](http://wechatapppro-1252524126.file.myqcloud.com/image/ueditor/63004600_1578370791.cn/txdocpic/0/418fca32cdd9c2c0688cd018a44ffcd2/0)       

现在假设大量用户同时发起访问，系统A就是收到了1万QPS怎么办？

这时候，系统A会瞬间把1万QPS转发给系统B，假设你系统B也部署20台机器，系统B自己可以抗住1万QPS，那么数据库呢？

数据库是抗不下来1万QPS的，此时系统B如果对数据库发起1万QPS的请求，一定会瞬间压垮数据库的。

所以这时如果引入MQ，就可以解决这个问题了。MQ这个技术抗高并发的能力远远高于数据库，同样的机器配置下，如果数据库可以抗每秒6000请求，MQ至少可以抗每秒几万请求。

为什么呢？因为数据库复杂啊，他要能够支持你执行复杂的SQL语句，支持事务等复杂的机制，支持你对数据进行增删改查，听着简单，其实是很复杂的！所以一般数据库单服务器也就支撑每秒几千的请求。

但是MQ就不一样了，他的核心功能就是让你发消息给他，再让别人从他这里获取消息，这个就简单的多了，所以同等机器配置下，MQ一般都能抗几万并发请求。

所以只要你引入一个MQ，那么就可以让系统A把每秒1万请求都作为消息直接发送到MQ里，MQ可以轻松抗下来这每秒1万请求

明哥说着画了一个图。     ![img](http://wechatapppro-1252524126.file.myqcloud.com/image/ueditor/73137500_1578370791.cn/txdocpic/0/fe09f5b474bc58175a8bcfb881e4687c/0)       

接着，系统b只要慢慢的从MQ里获取消息然后执行数据库读写操作即可，这个获取消息的速度是系统B自己可以控制的，所以系统B完全可以用一个比较低的速率获取消息然后写入数据库，保证对数据库的QPS不要超过他的极限值6000。

明哥说着对图补充了一下。    ![img](http://wechatapppro-1252524126.file.myqcloud.com/image/ueditor/83316000_1578370791.cn/txdocpic/0/b38a2f5d348417183fbf026922f20b3d/0)       

这个时候因为系统A发送消息到MQ很快，系统B从MQ消费消息很慢，所以MQ里自然会积压一些消息

不过不要紧，MQ一般都是基于磁盘来存储消息的，所以适当积压一些消息是可以的。

当系统A的高峰过去，每秒可能就恢复到1000 QPS了，此时系统b还是以每秒6000QPS的速度获取消息写入数据库，那么自然MQ里积压的消息就会慢慢被消化掉了。

所以这就是MQ进行流量削峰的效果，**系统A发送过来的每秒1万请求是一个流量洪峰，然后MQ直接给扛下来了，都存储自己本地磁盘，这个过程就是流量削峰的过程，瞬间把一个洪峰给削下来了，让系统B后续慢慢获取消息来处理。**

小猛听着都呆了，MQ还能这么玩儿？这简直是一个神功利器啊！看起来很棘手的系统性能差、耦合性高、流量洪峰等问题，只要引入MQ居然就可以搞定了，真是太好了！

明哥说：好了，今天就先讲到这里，你回去一定要好好的吸收MQ的这些知识，他到底是什么，用来干什么的，有哪些功能。

**End**

### 16 授人以渔：结合自己的系统问题思考一下，MQ有什么用处？

今天的授人以渔是跟之前让大家思考的自己系统面临的一些技术问题有直接关系的，今天给大家留一个小的思考题，权当我们后续内容的一个小预习。

之前大家或多或少都思考过自己系统可能面临的一些技术问题，那么现在学习了MQ的基本概念和他的一些使用场景和功能，大家可以思考一下，如果把MQ引入到你的系统里，能解决你系统的一些问题吗？

比如：能不能提升你的核心链路的性能？能不能降低你系统跟其他系统的耦合度？能不能让你的系统应对流量洪峰？

希望大家踊跃的思考，并在评论区里留下你的经验和分析思路，跟其他用户进行交流，大家一起进步。

**End**

### 17 领导的要求：你来对 Kafka、RabbitMQ 以及 RocketMQ 进行技术选型调研

**1、小猛的顿悟：订单系统的很多问题都可以用MQ来解决**

小猛昨天听了明哥对MQ这个东西的一番解释之后，已经有了一个基本的概念了，他回到家里仔细的想了想，发现似乎订单系统面临的很多问题都可以用MQ来解决！

举个例子，支付订单流程中步骤过多，导致性能很差。这个问题可以用MQ来解决，让订单系统仅仅完成最核心的一些步骤和调用，然后发送消息到MQ，比如仓储系统之类的就可以从MQ里获取消息，然后慢慢的执行一些很耗时的步骤。

还有比如订单系统在退款的时候，可能会遇到第三方支付系统退款失败的问题，从而影响整个退款流程的失败，这个问题也可以用MQ解决。可以让订单系统在退款的时候完成公司内部各个系统的流程，然后发送消息到MQ，由一个专门的服务去负责调用第三方支付系统，处理可能出现的失败。

在双11大促活动的时候，也可以让瞬间涌入的大量下单请求到MQ里去排队，然后让订单系统在后台慢慢的获取订单，以数据库可以接受的速率完成操作，避免瞬间请求量过大击垮数据库。

小猛想着觉得很兴奋，订单系统的诸多问题似乎都可以基于MQ来解决啊！

他一大早去公司上班之后，就把自己的那些想法告诉了明哥，明哥非常的高兴，他觉得小猛真是太棒了，自己就领悟出来了MQ在订单系统里的各种用法！

**2、万事开头难：要在订单系统里用MQ技术，从哪一步开始呢？**

听着明哥的表扬，小猛觉得特别的开心，但是另外一方面，他也有一个很大的疑问，虽然知道MQ是一个东西，可以解决订单系统的一些问题，但是万事开头难，到底应该从哪里入手呢？

他跟明哥提出了自己的疑惑，明哥笑着说，要做一些技术架构的升级，引入一些新的技术，当然要从技术调研开始了。

小猛很疑惑：技术调研应该怎么做？

明哥解释道：其实技术调研说白了，就是对一个技术去找到一些业内常用的开源实现，然后对各种不同的实现都进行一些调研，对比一下他们的优劣势，看看谁比较符合我们的需求，谁比较适合我们来使用。

具体来说，比如对于我们现在的情况，你只知道有一个MQ的概念，但是你要考虑一下：

- 业内常用的MQ有哪些？
- 每一种MQ各自的表现如何？
- 这些MQ在同等机器条件下，能抗多少QPS（每秒抗几千QPS还是几万QPS）？
- 性能有多高（发送一条消息给他要2ms还是20ms）？
- 可用性能不能得到保证（要是MQ部署的机器挂了怎么办）？

然后你还得考虑：

- 他们会不会丢失数据？
- 如果需要的话能否让他们进行线性的集群扩容（就是多加几台机器）？
- 消息中间件经常需要使用的一些功能他们都有吗（比如说延迟消息、事务消息、消息堆积、消息回溯、死信队列，等等）？

另外还得考虑这些MQ在文档是否齐全？社区是否活跃？在行业内是否广泛运用？是用什么语言编写的？

把这些事情都搞清楚了，那么你就完成了技术调研，可以全面的对比各种MQ的优劣势，然后从中选择一个最适合我们的来使用。

小猛都没反应过来呢，明哥接着说道，这个技术调研的任务，我就打算交给你了！正好让你借着这个机会对各种MQ有一个基本的了解。其实也没你想的那么难，对你来说要做调研的话，就是上网搜集资料，然后进行梳理对比就可以了。

小猛尴尬的说，好吧，那我尽力而为。

**3、Kafka、RabbitMQ以及RocketMQ的调研对比**

过了几天，小猛就完成了一份MQ技术调研报告，他找到了明哥，开始讲起了自己做这份调研报告的心得体会。

首先，小猛通过网上搜集资料，发现一般国内常用的MQ技术有四种实现，ActiveMQ、Kafka、RabbitMQ、RocketMQ，但是其中ActiveMQ主要是几年以前较多公司使用，现在几乎国内用的公司都很少了。

因此小猛搜集资料的时候主要是针对Kafka、RabbitMQ、RocketMQ三种技术做的调研。

**（1）Kafka的优势和劣势**

先来说Kafka，小猛通过查阅一些Kafka的基本资料发现，首先Kafka的吞吐量几乎是行业里最优秀的，在常规的机器配置下，一台机器可以达到每秒十几万的QPS，相当的强悍。

Kafka性能也很高，基本上发送消息给Kafka都是毫秒级的性能。可用性也很高，Kafka是可以支持集群部署的，其中部分机器宕机是可以继续运行的。

但是Kafka比较为人诟病的一点，似乎是丢数据方面的问题，因为Kafka收到消息之后会写入一个磁盘缓冲区里，并没有直接落地到物理磁盘上去，所以要是机器本身故障了，可能会导致磁盘缓冲区里的数据丢失。

而且Kafka另外一个比较大的缺点，就是功能非常的单一，主要是支持发送消息给他，然后从里面消费消息，其他就没有什么额外的高级功能了。所以基于Kafka有限的功能，可能适用的场景并不是很多。

因此综上所述，以及查阅了Kafka技术在各大公司里的使用，基本行业里的一个标准，是把Kafka用在用户行为日志的采集和传输上，比如大数据团队要收集APP上用户的一些行为日志，这种日志就是用Kafka来收集和传输的。

因为那种日志适当丢失数据是没有关系的，而且一般量特别大，要求吞吐量要高，一般就是收发消息，不需要太多的高级功能，所以Kafka是非常适合这种场景的。

**（2）RabbitMQ的优势和历史**

再说RabbitMQ，在RocketMQ出现之前，国内大部分公司都从ActiveMQ切换到RabbitMQ来使用，包括很多一线互联网大厂，而且直到现在都有很多中小型公司在使用RabbitMQ。

RabbitMQ的优势在于可以保证数据不丢失，也能保证高可用性，即集群部署的时候部分机器宕机可以继续运行，然后支持部分高级功能，比如说死信队列，消息重试之类的，这些是他的优点。

但是他也有一些缺点，最为人诟病的，就是RabbitMQ的吞吐量是比较低的，一般就是每秒几万的级别，所以如果遇到特别特别高并发的情况下，支撑起来是有点困难的。

而且他进行集群扩展的时候（也就是加机器部署），还比较麻烦。

另外还有一个较为致命的缺陷，就是他的开发语言是erlang，国内很少有精通erlang语言的工程师，因此也没办法去阅读他的源代码，甚至修改他的源代码。

所以现在行业里的一个情况是，很多BAT等一线互联网大厂都切换到使用更加优秀的RocketMQ了，但是很多中小型公司觉得RabbitMQ基本可以满足自己的需求还在继续使用中，因为中小型公司并不需要特别高的吞吐量，RabbitMQ已经足以满足他们的需求了，而且也不需要部署特别大规模的集群，也没必要去阅读和修改RabbitMQ的源码。

**（3）RocketMQ的优势和劣势**

RocketMQ是阿里开源的消息中间件，久经沙场，非常的靠谱。他几乎同时解决了Kafka和RabbitMQ的缺陷。

RocketMQ的吞吐量也同样很高，单机可以达到10万QPS以上，而且可以保证高可用性，性能很高，而且支持通过配置保证数据绝对不丢失，可以部署大规模的集群，还支持各种高级的功能，比如说延迟消息、事务消息、消息回溯、死信队列、消息积压，等等。

而且RocketMQ是基于Java开发的，符合国内大多数公司的技术栈，很容易就可以阅读他的源码，甚至是修改他的源码。

所以现在国内很多一线互联网大厂都切换为使用RocketMQ了，他们需要RocketMQ的高吞吐量，大规模集群部署能力，以及各种高阶的功能去支撑自己的各种业务场景，同时还可以根据自己的需求定制修改RocketMQ的源码。

RocketMQ是非常适合用在Java业务系统架构中的，因为他很高的性能表现，还有他的高阶功能的支持，可以让我们解决各种业务问题。

当然，RocketMQ也有一点美中不足的地方，就是经过我的调查发现，RocketMQ的官方文档相对简单一些，但是Kafka和RabbitMQ的官方文档就非常的全面和详细，这可能是RocketMQ目前唯一的缺点。

**（4）活跃的社区和广泛的运用**

最后一点，基本上Kafka、RabbitMQ和RocketMQ的社区都还算活跃，更新频率都还可以，而且基本运用都非常的广泛。

尤其是Kafka和RabbitMQ，目前Kafka几乎是国内大数据领域日志采集传输的标准，RabbitMQ在各种中小公司里运用极为广泛，RocketMQ也是开始在一些大公司和其他公司里快速推行中。

**4、经验老到的明哥：其实我早有准备**

当小猛把这一番调研结果结合自己写好的调研文档给明哥讲完之后，明哥哈哈的笑着说，不错不错，以一个新人的能力而言，做调研到这个程度基本上是差不多了。

不过其实几种MQ的技术对比和分析，我自己也早就做过了，让你去做这个调研，主要是锻炼一下你，让你多了解了解。

小猛有点不好意思的挠挠头说到：原来是这样，那我就不在关公面前耍大刀了，明哥，那你觉得我们该用哪个MQ呢？

似乎看起来RabbitMQ也能满足我们，毕竟我们现在也属于中小型互联网公司，并发量没那么大；但是RocketMQ似乎是更好的选择，他规避掉了RabbitMQ的全部缺点。

明哥说到，虽然我们现在是一个中小型互联网公司，看起来似乎RabbitMQ足以应对我们的需求，但是假设未来我们成长为一个大公司呢？也许我们也会有每秒几十万的QPS，也许我们以后也需要对MQ进行源码的二次开发，那此时RabbitMQ还合适吗？

所以，我的决定是，一步到位，直接用RocketMQ作为我们公司的技术选型。

小猛听完明哥的分析和决定之后，觉得老大霸气侧漏，那就啥也不说了，后面就跟着明哥用RocketMQ去重构订单系统吧！

**End**

### 18 授人以渔：你们公司主要使用的 MQ 是哪种？为什么要选用它？

今天的授人以渔环节，我希望大家能够去思考一些问题。首先是就你自己而言，在过往的工作中，了解过哪几种MQ？然后你过往的工作中使用过哪几种MQ？你对这些了解过的MQ有什么看法？你觉得他们的优劣势分别是什么？

如果你以前用过MQ，那么你用他解决了什么问题？当时解决的效果如何？

另外你在使用某个MQ的时候感受如何，觉得他好用吗？你是否觉得用过的MQ存在某些缺陷？

如果现在你们公司里就部署了MQ，是哪一种MQ？你的系统里使用到MQ了吗？用MQ来解决什么问题呢？解决的效果如何？是否遇到过什么问题？

另外，有没有思考过，为什么你们要选用这个MQ？当时选用他的理由是什么？

如果你从来没接触过MQ，那么给你留一个小的作业和思考题：

你去网上查一查，除了我们讲的ActiveMQ、RabbitMQ、Kafka、RocketMQ以外，还有哪些MQ？那些MQ的优劣势和特点是什么？

希望大家对这些思考题好好想一下，在评论区写下自己的思考，和我交流。我、救火队队长、石杉老哥都真心希望未来很多专栏，通过这种授人以渔的方式，不断的启发和鼓励国内的程序员建立起难能可贵的主动思考的能力来，提升程序员的软素质和能力，希望大家努力。

**End**

### 19 新技术引入：给团队分享 RocketMQ 的架构原理和使用方式

**1、来自leader的技术分享任务**

今天明哥上班之后，立马找到小猛，给他布置了一个任务。

明哥说，现在既然已经初步完成了MQ技术调研，确定了我们一步到位用阿里开源的RocketMQ，那么就可以进行下一步了，希望你能对RocketMQ技术做一些初步的研究。

第一步，可以看看RocketMQ大体上是如何运行的，也就是他的基本原理，希望你能通过查阅资料，研究一下RocketMQ技术，然后写一份PPT，给团队里的其他同学做一次技术分享。

这里我提几个要求，就是我们想要知道的关于RocketMQ的东西有哪些。比如：

- RocketMQ是如何集群化部署来承载高并发访问的？
- 如果RocketMQ中要存储海量消息，如何实现分布式存储架构？

我希望你能把这些问题搞清楚。

小猛听完明哥的要求之后，立马就开始查阅了大量资料，开始写他的第一份技术分享PPT了。

很快，小猛花了一整天的时间就完成了这次研究和分享PPT的编写，然后跟团队成员约了一个时间集中在一个会议室里为大家进行RocketMQ原理的分享。

**2、MQ如何集群化部署来支撑高并发访问？**

首先说第一个问题，MQ如何集群化部署来支撑高并发访问？

这里就先讲一个概念，假设RocketMQ部署在一台机器上，即使这台机器配置很高，但是一般来说一台机器也就是支撑10万+的并发访问。

小猛说着打开一张图。

​      ![img](http://wechatapppro-1252524126.file.myqcloud.com/image/ueditor/59175400_1578385784.cn/txdocpic/0/e13f1a54d66ffd8285aa3d7de5bb48bf/0)       

那么这个时候，假设有大量的系统都要往RocketMQ里高并发的写入消息，可能达到每秒有几十万请求，这个时候怎么办呢？

没关系，RocketMQ是可以集群化部署的，可以部署在多台机器上，假设每台机器都能抗10万并发，然后你只要让几十万请求分散到多台机器上就可以了，让每台机器承受的QPS不超过10万不就行了。

小猛说着打开了下一张图。

​      ![img](http://wechatapppro-1252524126.file.myqcloud.com/image/ueditor/72114000_1578385784.cn/txdocpic/0/6ef2a0e9f569966d45858e9f9f6f17df/0)       

这其实就是RocketMQ集群化部署抗下高并发的主要原理，当然，具体怎么做才能让系统的流量分散在RocketMQ部署的多台机器上，这个以后再找机会做一个比较详细的分享，今天主要先讲大体上的一个架构原理。

**3、MQ如果要存储海量消息应该怎么做？**

现在来说第二个问题，MQ会收到大量的消息，这些消息并不是立马就会被所有的消费方获取过去消费的，所以一般MQ都得把消息在自己本地磁盘存储起来，然后等待消费方获取消息去处理。

既然如此，MQ就得存储大量的消息，可能是几百万条，可能几亿条，甚至万亿条，这么多的消息在一台机器上肯定是没法存储的，RocketMQ是如何分布式存储海量消息的呢？

延续上面的图，其实发送消息到MQ的系统会把消息分散发送给多台不同的机器，假设一共有1万条消息，分散发送给10台机器，可能每台机器就是接收到1000条消息，如下图：

​      ![img](http://wechatapppro-1252524126.file.myqcloud.com/image/ueditor/90105800_1578385784.cn/txdocpic/0/88f9e690f0273731139551ff4743f364/0)       

其次，每台机器上部署的RocketMQ进程一般称之为Broker，每个Broker都会收到不同的消息，然后就会把这批消息存储在自己本地的磁盘文件里

这样的话，假设你有1亿条消息，然后有10台机器部署了RocketMQ的Broker，理论上不就可以让每台机器存储1000万条消息了吗？

小猛接着打开下一张图。

​      ![img](http://wechatapppro-1252524126.file.myqcloud.com/image/ueditor/5161500_1578385785.cn/txdocpic/0/0caf9182d53bd651e1ec7d30b4526a50/0)       

所以本质上RocketMQ存储海量消息的机制就是分布式的存储

所谓分布式存储，就是把数据分散在多台机器上来存储，每台机器存储一部分消息，这样多台机器加起来就可以存储海量消息了！

**4、高可用保障：万一Broker宕机了怎么办？**

小猛继续说下一个问题，要是任何一台Broker突然宕机了怎么办？那不就会导致RocketMQ里一部分的消息就没了吗？这就会导致MQ的不可靠和不可用，这个问题怎么解决？

RocketMQ的解决思路是Broker主从架构以及多副本策略。

简单来说，Broker是有Master和Slave两种角色的，小猛打开一张图。

​      ![img](http://wechatapppro-1252524126.file.myqcloud.com/image/ueditor/20442200_1578385785.cn/txdocpic/0/ad235c96602a681606e8d86b1767e6e9/0)       

Master Broker收到消息之后会同步给Slave Broker，这样Slave Broker上就能有一模一样的一份副本数据！

这样同一条消息在RocketMQ整个集群里不就有两个副本了，一个在Master Broker里，一个在Slave Broker里！

这个时候如果任何一个Master Broker出现故障，还有一个Slave Broker上有一份数据副本，可以保证数据不丢失，还能继续对外提供服务，保证了MQ的可靠性和高可用性

**5、数据路由：怎么知道访问哪个Broker？**

现在又有一个问题了，对于系统来说，要发送消息到MQ里去，还要从MQ里消费消息

那么大家怎么知道有哪些Broker？怎么知道要连接到哪一台Broker上去发送和接收消息？这是一个大问题！

所以RocketMQ为了解决这个问题，有一个NameServer的概念，他也是独立部署在几台机器上的，然后所有的Broker都会把自己注册到NameServer上去，NameServer不就知道集群里有哪些Broker了？

如下图所示：

​      ![img](http://wechatapppro-1252524126.file.myqcloud.com/image/ueditor/37465200_1578385785.cn/txdocpic/0/c769640bf5621cce9243f485c2e3cc6b/0)       

然后对于我们的系统而言，如果他要发送消息到Broker，会找NameServer去获取路由信息，就是集群里有哪些Broker等信息

如果系统要从Broker获取消息，也会找NameServer获取路由信息，去找到对应的Broker获取消息。

小猛说着打开了最后一张图。

​      ![img](http://wechatapppro-1252524126.file.myqcloud.com/image/ueditor/52793800_1578385785.cn/txdocpic/0/b2f9bda441a97ca7feb1a235279c2203/0)       

基本上这个就是RocketMQ最基本的一个架构原理图。

**6、后续的疑问。。。**

小猛分享完之后，满心欢喜的期望大家都给他一阵热烈的掌声，结果没想到的是其他的兄弟听完之后，每个人都有一种沉思的表情，似乎有很多的不解，突然大家开始七嘴八舌的问小猛很多的问题：

“小猛，大的架构原理是知道了，但是发送消息的时候面对N多台机器，到底应该向哪一台上面的Broker发送过去？”

“小猛，RocketMQ的数据模型是什么，我们发送消息过去的时候，是发送到什么里面去，队列还是什么？”

”小猛，RocketMQ接收到数据之后是直接写磁盘吗，那性能会不会太差了？”

”小猛，小猛，哎，你怎么不说话了。。。。”

小猛听着大家七嘴八舌的提问，真是汗颜，自己才刚刚了解了一些基本原理，还难以解答这么多的问题啊！

这时明哥出来打了圆场，大家稍安勿躁，稍安勿躁，我正式给小猛一个任务，让他来作为我们团队的RocketMQ技术先锋，大家的问题后续小猛慢慢研究清楚了，然后给大家多做分享，一定让大家对RocketMQ有一个透彻的了解，大家觉得怎么样？

大家一听，一起大喊：小猛，靠你了啊！

小猛瞬间脑门黑线，真是压力山大啊。。。。

**End**

### 20 授人以渔：结合你对其他 MQ 的了解，思考 RocketMQ 的设计有何特点？

今天的授人以渔环节，希望大家去做一个调研和技术对比，对MQ做一些深度的思考。

希望大家可以去查阅资料了解一下Kafka和RabbitMQ两种技术的架构原理，尤其关注以下几点：

1. 他们都是如何集群化部署抗高并发的？
2. 他们对海量消息是如何分布式存储的？
3. 他们是如何实现主从多备份的高可用架构的？
4. 他们是如何实现集群路由让别人找到对应的机器发送消息和接收消息的？

希望大家搞明白这几个问题，从架构原理上自己对比一下Kafka、RabbitMQ、RocketMQ。

同时把自己的调研心得分享到评论区跟其他同学一起交流和分享，加油，培养自己主动思考的能力！

**End**

### 21 设计生产架构之前的功课：消息中间件路由中心的架构原理是什么？

**1、小猛的RocketMQ研究之路**

上回给同事们分享了RocketMQ的基本架构后，大家都希望小猛多研究研究RocketMQ的原理，因为上次仅仅了解了一些基本原理，还远远不能让大家满足，很多细节都存在各种各样的疑问。

所以小猛发现，自己真是被明哥推到了一个坑里，这哪是简单的做一下调研和分享，明明就是让他来负责团队里至关重要的RocketMQ技术啊！

不仅要研究透彻一个技术，还要给大家做大量分享，保证团队能够成功的将MQ技术运用到订单系统架构里去，这真是一个长期而且艰巨的任务！

不过小猛转念一想，其实这也是明哥给自己的一个机会，毕竟不是每个新人都能这么好运，一进公司就担负起这种核心技术任务的。那既然如此，干脆就借着这个机会深入的研究一下RocketMQ，边研究边想办法把技术落地去实践。

初生牛犊不怕虎，说干就干，小猛的RocketMQ研究之路就这样开始了。。。

**2、研究RocketMQ的一个切入点**

首先，小猛思考了一下，研究RocketMQ应该从哪个点来切入呢？

他回忆了一下之前自己PPT里做的一个RocketMQ整体架构图。

​      ![img](http://wechatapppro-1252524126.file.myqcloud.com/image/ueditor/73563600_1578385791.cn/txdocpic/0/4760317cad965593b982b35d7cc42f18/0)       

他仔细想了一下，其实RocketMQ这个技术一共是包含了四个核心的部分：

**第一块**就是他的NameServer，这个东西很重要，他要负责去管理集群里所有Broker的信息，让使用MQ的系统可以通过他感知到集群里有哪些Broker。

**第二块**就是Broker集群本身了，必须得在多台机器上部署这么一个集群，而且还得用主从架构实现数据多副本存储和高可用。

**第三块**就是向MQ发送消息的那些系统了，这些系统一般称之为生产者，这里也有很多细节是值得深究的，因为这些生产者到底是如何从NameServer拉取路由信息的？如何选择Broker机器建立连接以及发送消息的？

**第四块**就是从MQ获取消息的那些系统，这些系统一般称之为消费者。

仔细想想消费者里其实也隐藏了很多的技术细节，比如到底是Broker主动推送消息给消费者？还是消费者自己从Broke里拉取消息？这些也都很值得深究。

那么到底从哪儿入手开始呢？因为自己的思路是边研究边落地，最好是初步搞清楚一些RocketMQ的架构设计细节，然后就申请一些机器开始落地部署了，可以测试测试，然后尝试让一些生产系统开始使用他。

此时小猛的目光放到了NameServer上，他觉得NameServer正是研究RocketMQ必须优先选择的一个切入点，因为没有NameServer，一切都无从谈起，可以说这是RocketMQ运行的起点。

好，那么就从NameServer开始研究，然后再给大家做一次分享！

**3、一次关于RocketMQ NameServer设计原理的技术分享**

小猛花了几天的时间对RocketMQ的NameServer进行了一些研究，得出了很多的心得，对NameServer的设计理念和一些细节真的有了更深一步的认识。

因此他用心做了一份技术分享PPT，然后召集了团队里的小伙伴，又做了一次**关于NameServer的技术分享**。

会议室里，大家伙刚坐下，就有不少人对小猛有点意见了。有人说，小猛，你怎么搞的，分享也不搞点干货，我们都想看看Broker的一些底层原理，比如数据是怎么存储的，怎么写入磁盘的 ，中间有没有缓冲层的设计之类的。

小猛尴尬的说，大家别着急啊，我其实也想到了RocketMQ底层那些特别牛X的技术实现细节，但是想来想去，还是觉得应该从NameServer先开始，因为这个是RocketMQ的起点啊，没有他，RocketMQ怎么运行呢？

大家伙一听，觉得还挺对的，那好，耐心听小猛来讲吧。

**4、NameServer到底可以部署几台机器？**

小猛此时先切入了第一个问题，大家想想，要部署RocketMQ，就得先部署NameServer，那么这个NameServer到底可以部署几台机器呢？

是一台机器？还是可以部署多台机器？如果部署多台机器，他们之间是怎么协同工作的？

大家面面相觑，没人说出个所以然来，都催促小猛别卖关子，赶紧继续讲，尽量30分钟内搞定分享，大家还得各回各工位，各找各自的产品经理继续撕需求和写代码呢！

小猛脑门黑线了一下，心想自己本来还想跟大家互动一下，结果大家这么猴急，那好，别啰嗦了，直接一鼓作气讲完吧！

NameServer，首先是支持部署多台机器的。也就是说，NameServer是可以集群化部署的，大家回头看看我之前做的PPT里的图，小猛打开一张图，里面画了一个红圈。

​      ![img](http://wechatapppro-1252524126.file.myqcloud.com/image/ueditor/87032600_1578385791.cn/txdocpic/0/8a7894b45b45c1e7d9e4174d4ab83ad0/0)       

在当时的图里就是画了多台NameServer机器的，只不过上次分享没提到了NameServer集群部署这个话题。

那为什么NameServer要集群化部署？

最主要的一个原因，就是**高可用性**。

因为大家都知道，NameServer是集群里非常关键的一个角色，他要管理Broker信息，别人都要通过他才知道跟哪个Broker通信，所以没了他就会很麻烦！

那么如果NameServer就部署一台机器的话，一旦NameServer宕机了，岂不是会导致RocketMQ集群出现故障？

所以通常来说，NameServer一定会多机器部署，实现一个集群，起到高可用的效果，保证任何一台机器宕机，其他机器上的NameServer可以继续对外提供服务！

**5、Broker是把自己的信息注册到哪个NameServer上去？**

下一个问题：Broker在启动的时候是把自己的信息注册到哪个NameServer上去的？

有的人可能会猜测，是不是这样，比如一共有10台Broker机器，2个NameServer机器，然后其中5台Broker会把自己的信息注册到1个NameServer上去，另外5台Broker会把自己的信息注册到另外1个NameServer上去。

小猛这时打开了一个这种猜想的示意图，在这个图里，两个Master Broker分别注册到了不同的NameServer上去。如下图所示：      ![img](http://wechatapppro-1252524126.file.myqcloud.com/image/ueditor/2124900_1578385792.cn/txdocpic/0/001c603aae0a99ee76fb50aef335b8be/0)       

那么到底是不是这样呢？

答案是：**不对**

这样搞有一个最大的问题，如果1台NameServer上有5个Broker的信息，另外1个NameServer上有另外5个Broker的信息，那么此时任何一个NameServer宕机了，不就导致5个Broker的信息就没了吗？

所以这种做法是不靠谱的，会导致数据丢失，系统不可用。

因此正确答案是：每个Broker启动都得向所有的NameServer进行注册

也就是说，每个NameServer都会有一份集群中所有Broker的信息。

小猛接着打开了下一张图。      ![img](http://wechatapppro-1252524126.file.myqcloud.com/image/ueditor/21894900_1578385792.cn/txdocpic/0/3c2e1c0a693589cfc77474310f8da045/0)       

在这个图里就示范了一个Master Broker得向两台NameServer都进行注册的情况，这才是真正的情况。

**6、系统如何从NameServer获取Broker信息？**

下一个问题：扮演生产者和消费者的系统们，如何从NameServer那儿获取到集群的Broker信息呢？

他们需要知道集群里有哪些Broker，才能根据一定的算法挑选一个Broker去发送消息或者获取消息。

有两种办法：

第一种办法是这样，NameServer那儿会主动发送请求给所有的系统，告诉他们Broker信息。

这种办法靠谱吗？明显不靠谱，因为NameServer怎么知道要推送Broker信息给哪些系统？未卜先知吗？

第二种办法是这样的，每个系统自己每隔一段时间，定时发送请求到NameServer去拉取最新的集群Broker信息。

这个办法是靠谱的，没有什么明显的缺陷，所以RocketMQ中的生产者和消费者就是这样，**自己主动去NameServer拉取Broker信息的**。

小猛接着打开了一张图。

​      ![img](http://wechatapppro-1252524126.file.myqcloud.com/image/ueditor/36243200_1578385792.cn/txdocpic/0/0b1f8b0d908cd78a805acf4853343948/0)       

顺便在这里解释一下，图里的路由信息，大致可以理解为集群里的Broker信息以及其他相关的数据信息

通过这些路由信息，每个系统就知道发送消息或者获取消息去哪台Broker上去进行了，这起到一个把消息路由到一个Broker上的效果，所以一般我们把这种信息叫做路由信息。

**7、如果Broker挂了，NameServer是怎么感知到的？**

下一个问题，现在一个Broker启动之后向NameServer注册了，每个NameServer都知道集群里有这么一台Broker的存在了，然后各个系统从NameServer那儿也拉取到了Broker信息，也知道集群里有这么一台Broker

但是如果之后这台Broker挂了呢？

要解决这个问题，靠的是Broker跟NameServer之间的心跳机制，Broker会每隔30s给所有的NameServer发送心跳，告诉每个NameServer自己目前还活着。

小猛说着，打开了一个图，在里面有一个心跳的概念。

​      ![img](http://wechatapppro-1252524126.file.myqcloud.com/image/ueditor/47597000_1578385792.cn/txdocpic/0/9f97342e69127636a55e68e36f230875/0)       

每次NameServer收到一个Broker的心跳，就可以更新一下他的最近一次心跳的时间

然后NameServer会每隔10s运行一个任务，去检查一下各个Broker的最近一次心跳时间，如果某个Broker超过120s都没发送心跳了，那么就认为这个Broker已经挂掉了。

小猛说着又打开了一张图。

​      ![img](http://wechatapppro-1252524126.file.myqcloud.com/image/ueditor/63190100_1578385792.cn/txdocpic/0/e20020536a6aadd0d184b2b8e15a889f/0)       

**8、Broker挂了，系统是怎么感知到的？**

下一个问题，如果Broker挂掉了，那么作为生产者和消费者的系统是怎么感知到的呢？难道必须得NameServer发送请求给所有的系统通知他们吗？

这个是不现实的，之前已经说过了，NameServer去发送这个东西非常的不靠谱。

但是如果NameServer没有及时通知给那些系统，那么有没有可能出现这样一种情况，刚开始集群里有10个Broker，各个系统从NameServer那里得知，都以为有10个Broker。

结果此时突然挂了一个Broker，120s没发心跳给NameServer，NameServer是知道现在只有9个Broker了。

但是此时其他系统是不知道只有9个Broker的，还以为有10个Broker，此时可能某个系统就会发送消息到那个已经挂掉的Broker上去，此时是绝对不可能成功发送消息的

小猛说着打开了一张图。

​      ![img](http://wechatapppro-1252524126.file.myqcloud.com/image/ueditor/79832600_1578385792.cn/txdocpic/0/e30e275919425a3ad8553090b0696414/0)       

针对这个情况怎么办？这个问题要我们以后去分析生产者原理的时候才会具体说他的细节，现在简单先提一下思路。

大家可以想一下，如果确实是那个情况，可以有两种解决办法。

首先，你可以考虑不发送消息到那台Broker，改成发到其他Broker上去。

其次，假设你必须要发送消息给那台Broker，那么他挂了，他的Slave机器是一个备份，可以继续使用，你是不是可以考虑等一会儿去跟他的Slave进行通信？

总之，这些都是思路，但是现在我们先知道，对于生产者而言，他是有一套容错机制的，即使一下子没感知到某个Broker挂了，他可以有别的方案去应对。

而且过一会儿，系统又会重新从NameServer拉取最新的路由信息了，此时就会知道有一个Broker已经宕机了。

OK！今天的技术分享就到这里了，这就是NameServer的核心工作原理。

大家最主要是知道他的集群化部署、Broker会注册到所有NameServer去、30s心跳机制和120s故障感知机制、生产者和消费者的客户端容错机制，这些是最核心的。

大家听完了小猛的分享之后，不禁一起鼓掌，都觉得小猛研究的确实不错，说的通俗易懂，而且让每个人对NameServer的理解都更深入了。

**End**

### 22 授人以渔：要是没有这个路由中心，消息中间件可以正常运作么？

今天的授人以渔，希望能让大家对消息中间件技术的路由中心有一个深度思考。

大家如果认真完成了之前一个授人以渔，对Kafka、RabbitMQ、RocketMQ的架构原理都有了一个认知之后，就会发现，不同的MQ技术总得有一个**路由中心**的角色。

这个路由中心的角色需要去感知集群里所有的Broker节点，然后需要去配合生产者和消费者，让人家都能感知到集群里有哪些Broker，才能让各个系统跟MQ进行通信。

如果大家之前都对Kafka和RabbitMQ自行查阅资料有了一个基本的了解之后，就会发现Kafka的路由中心实际上是一个非常复杂、混乱的存在。他是由ZooKeeper以及某个作为Controller的Broker共同完成的。

如果你没自行查阅kafka资料，对这句话会不理解，但还是希望大家积极完成每次布置的授人以渔的环节。

RabbitMQ的话自己本身就是由集群每个节点同时扮演了路由中心的角色。

而RocketMQ是把路由中心抽离出来作为一个独立的NameServer角色运行的，因此可以说在路由中心这块，他的架构设计是最清晰明了的。

那么请大家在这里思考一个问题，RocketMQ把NameServer独立抽取出来运行，那么假设这个NameServer集群整体都故障了，失去了这个NameServer集群之后：

- RocketMQ还能正常运行吗？
- 生产者还能发送消息到Broker吗？
- 消费者还能从Broker拉取消息吗？

**End**

### 23 设计生产架构之前的功课：Broker的主从架构原理是什么？

**1、将目光从 NameServer 转移到 Broker**

小猛上次的NameServer技术分享做的非常成功，大家都通过分享学到了更多的东西，尤其对RocketMQ集群运作的原理，有了更进一步的认识

不过好多人都想对Broker的原理有更多的了解，毕竟最终实现MQ功能的就是Broker。

因此小猛也将自己研究RocketMQ的目光从NameServer转移到了Broker上，他花了一些时间对Broker的原理做了研究，也积累了一些心得体会，接着他又做了一份PPT，打算给大家再做一次Broker原理的分享。

这一天，小猛再次把大家都叫到了会议室，开始了他的第三次技术分享：RocketMQ Broker原理分析

**2、Master Broker是如何将消息同步给Slave Broker的？**

先来看第一个问题，我们都知道，为了保证MQ的数据不丢失而且具备一定的高可用性，所以一般都是得将Broker部署成Master-Slave模式的，也就是一个Master Broker对应一个Slave Broker

然后Master需要在接收到消息之后，将数据同步给Slave，这样一旦Master Broker挂了，还有Slave上有一份数据。

小猛说着打开了一张图：

​      ![img](http://wechatapppro-1252524126.file.myqcloud.com/image/ueditor/71107400_1578385799.cn/txdocpic/0/f1bd96d191e2dc825baa0d9800bab2e0/0)       

**说明**：

- Slave Broker也会向所有的NameServer进行注册，图中没有画出！
- Slave Broker也会向所有的NameServer每30s发送心跳，图中没有画出！

在这里，我们先考虑一个问题，Master Broker是如何将消息同步给Slave Broker的？

是Master Broker主动推送给Slave Broker？还是Slave Broker发送请求到Master Broker去拉取？

**答案是第二种**，RocketMQ的Master-Slave模式采取的是Slave Broker不停的发送请求到Master Broker去拉取消息。

所以首先要明白这一点，就是RocketMQ自身的Master-Slave模式采取的是**Pull模式**拉取消息。

小猛说着又打开了一个图，在图里他标识出来了Slave拉取消息的示意：

​      ![img](http://wechatapppro-1252524126.file.myqcloud.com/image/ueditor/87847900_1578385799.cn/txdocpic/0/22ca0793ec8ecb8ac4e7f9aac3dd3c87/0)       

**3、RocketMQ 实现读写分离了吗？**

下一个问题，既然Master Broker主要是接收系统的消息写入，然后会同步给Slave Broker，那么其实本质上Slave Broker也应该有一份一样的数据。

所以这里提出一个疑问，作为消费者的系统在获取消息的时候，是从Master Broker获取的？还是从Slave Broker获取的？

其实都不是。答案是：**有可能从Master Broker获取消息，也有可能从Slave Broker获取消息**

作为消费者的系统在获取消息的时候会先发送请求到Master Broker上去，请求获取一批消息，此时Master Broker是会返回一批消息给消费者系统的

小猛说着打开了一张图，里面有这个示意。

​      ![img](http://wechatapppro-1252524126.file.myqcloud.com/image/ueditor/4510100_1578385800.cn/txdocpic/0/6d30755fe3151925891481b0c7f17483/0)       

然后Master Broker在返回消息给消费者系统的时候，会根据当时Master Broker的负载情况和Slave Broker的同步情况，向消费者系统建议下一次拉取消息的时候是从Master Broker拉取还是从Slave Broker拉取。

举个例子，要是这个时候Master Broker负载很重，本身要抗10万写并发了，你还要从他这里拉取消息，给他加重负担，那肯定是不合适的。

所以此时Master Broker就会建议你从Slave Broker去拉取消息。

或者举另外一个例子，本身这个时候Master Broker上都已经写入了100万条数据了，结果Slave Broke不知道啥原因，同步的特别慢，才同步了96万条数据，落后了整整4万条消息的同步，这个时候你作为消费者系统可能都获取到96万条数据了，那么下次还是只能从Master Broker去拉取消息。

因为Slave Broker同步太慢了，导致你没法从他那里获取更新的消息了。

所以这一切都会由Master Broker根据情况来决定，小猛说着打开了一个图，里面有示意。

​      ![img](http://wechatapppro-1252524126.file.myqcloud.com/image/ueditor/28276500_1578385800.cn/txdocpic/0/f23452fa313cc80951e169e069e5997c/0)       

所以在写入消息的时候，通常来说肯定是选择Master Broker去写入的

但是在拉取消息的时候，有可能从Master Broker获取，也可能从Slave Broker去获取，一切都根据当时的情况来定。

**4、如果Slave Broke挂掉了有什么影响？**

下一个问题：如果Slave Broker挂掉了，会对整个系统有影响吗？

答案是：**有一点影响，但是影响不太大**

因为消息写入全部是发送到Master Broker的，然后消息获取也可以走Master Broker，只不过有一些消息获取可能是从Slave Broker去走的。

所以如果Slave Broker挂了，那么此时无论消息写入还是消息拉取，还是可以继续从Master Broke去走，对整体运行不影响。

只不过少了Slave Broker，会导致所有读写压力都集中在Master Broker上。

**5、如果Master Broker挂掉了该怎么办？**

现在假设出现了一个故障，Master Broker突然挂了，这样会怎么样？

这个时候就对消息的写入和获取都有一定的影响了。但是其实本质上而言，Slave Broker也是跟Master Broker一样有一份数据在的，只不过Slave Broker上的数据可能有部分没来得及从Master Broker同步。

但是此时RocketMQ可以实现直接自动将Slave Broker切换为Master Broker吗？

答案是：**不能**

在RocketMQ 4.5版本之前，都是用Slave Broker同步数据，尽量保证数据不丢失，但是一旦Master故障了，Slave是没法自动切换成Master的。

所以在这种情况下，如果Master Broker宕机了，这时就得手动做一些运维操作，把Slave Broker重新修改一些配置，重启机器给调整为Master Broker，这是有点麻烦的，而且会导致中间一段时间不可用。

小猛说着打开了一张图，在图里他标识出来了Master故障情况下的手工运维的情况。

​      ![img](http://wechatapppro-1252524126.file.myqcloud.com/image/ueditor/44693700_1578385800.cn/txdocpic/0/cb2e13e4c9c26482d2229c4c0b443b06/0)       

所以这种Master-Slave模式**不是彻底的高可用模式，他没法实现自动把Slave切换为Master**

**6、基于Dledger实现RocketMQ高可用自动切换**

在RocketMQ 4.5之后，这种情况得到了改变，因为RocketMQ支持了一种新的机制，叫做Dledger

本身这个东西是基于Raft协议实现的一个机制，实现原理和算法思想是有点复杂的，我们在这里先不细说。

因为。。。小猛说到这里，挠了挠头，有点不好意思的说到，我也是最近明哥给了任务之后才开始研究RocketMQ的，一些东西还没研究那么深。不过等我们后面一边在实践RocketMQ技术的时候，我会一边继续深入研究的，以后如果有机会再给大家再做技术分享，专门分析这个Dledger底层的原理。

今天我先讲讲基于Dledger可以实现RocketMQ的高可用自动切换的效果。

简单来说，把Dledger融入RocketMQ之后，就可以让一个Master Broker对应多个Slave Broker，也就是说一份数据可以有多份副本，比如一个Master Broker对应两个Slave Broker。

然后依然会在Master和Slave之间进行数据同步，小猛说着打开了一张图。

​      ![img](http://wechatapppro-1252524126.file.myqcloud.com/image/ueditor/56251000_1578385800.cn/txdocpic/0/bd7d56f2bbbfd5024bd97e78088ec4b1/0)       

此时一旦Master Broker宕机了，就可以在多个副本，也就是多个Slave中，通过Dledger技术和Raft协议算法进行leader选举，直接将一个Slave Broker选举为新的Master Broker，然后这个新的Master Broker就可以对外提供服务了。

整个过程也许只要10秒或者几十秒的时间就可以完成，这样的话，就可以实现Master Broker挂掉之后，自动从多个Slave Broker中选举出来一个新的Master Broker，继续对外服务，一切都是自动的。

小猛说着就打开了另外一张图，在图里就有Slave自动选举，以及Slave切换为新的Master的过程。

​      ![img](http://wechatapppro-1252524126.file.myqcloud.com/image/ueditor/70982400_1578385800.cn/txdocpic/0/435e36c3422df24bc19bf8ba0c2c7e8a/0)       

所以。。。说到这里，小猛对下面一直沉默听分享的明哥说，我觉得我们在设计RocketMQ生产部署架构的时候，完全可以采用基于Dledger的部署方式，这样可以让RocketMQ做到自动故障切换了！

明哥听到这里，对小猛非常的赞赏。小猛非常靠谱，把一些关键的问题都梳理的很清晰，包括Broker主从同步原理、故障时的自动切换缺点、最新版本的Dledger自动切换改进，这些问题都已经考虑到了。

大家听到这里，也是一阵热烈的掌声，因为随着分享的推进，每个人都觉得RocketMQ这个技术到落地实践的距离更近了。

**End**

### 24 授人以渔：Broker主从同步有没有数据不一致问题？

希望大家今天在学习完RocketMQ的主从同步架构以及高可用切换机制之后，思考以下一些问题：

- 假设如果没有RocketMQ 4.5新版本引入的Dledger技术，仅仅是靠之前的Master-Slave主从同步机制，那么在Master崩溃的时候，可能会造成多长时间的系统不可用？这个时候如何能够尽快的恢复集群运行？依赖手工运维的话，如何能尽快的去完成这个运维操作？

- 在RocketMQ 4.5之后引入了Dledger技术可以做到自动选举新的Master，那么在Master崩溃一直到新的Master被选举出来的这个过程中，你觉得对于使用MQ的系统而言，会处于一个什么样的状态呢？

- 希望大家去研究一下Kafka和RabbitMQ的多副本和高可用机制，Kafka是如何在集群里维护多个副本的？出现故障的时候能否实现自动切换？RabbitMQ是如何在集群里维护多个数据副本的？出现故障的时候能否实现自动切换？

- 既然有主从同步机制，那么有没有主从数据不一致的问题？Slave永远落后Master一些数据，这就是主从不一致。那么这种不一致有没有什么问题？有办法保证主从数据强制一致吗？这样做又会有什么缺点呢？

其实大家在学习了之前的知识之后，对上述问题已经完全有足够的基础知识去思考了，你只要开动脑筋，稍微查阅一些资料，主动往前迈一步去思考一下，就会得到这些问题的答案。

另外，你会发现在持续的主动思考过程中，你的技术思维和技术思考能力得到了锻炼，这个能力是非常有用的软素质，可以帮助你在工作中有更开阔的技术思维解决问题，让你在面试的时候可以举一反三，现场快速思考一些你从没接触过的问题。

希望你可以把对这些问题的思考写在评论区里，跟其他同学一起交流。

**End**

### 25 落地第一步：设计一套高可用的消息中间件生产部署架构

**1、MQ生产部署架构的设计任务**

经过上一次的技术分享，小猛基本上把RocketMQ的核心工作原理都搞明白了，接着下一步明哥给他的任务就是基于RocketMQ的核心原理，去设计一套RocketMQ的生产部署架构出来。

在这套生产部署架构中，需要着重考虑到高可用的问题，要保证整个系统运行过程中任何一个环节宕机都不能影响系统的整体运行。

小猛在接受了这个任务之后，就开始埋头设计起了MQ的生产部署架构，几天之后就搞定了这套架构设计，然后他找明哥单独到一个小会议室里，开始给明哥讲他构思的这套MQ的生产部署架构。

**2、NameServer集群化部署，保证高可用性**

首先第一步，我们要让NameServer集群化部署，我建议可以部署在三台机器上，这样可以充分保证NameServer作为路由中心的可用性，哪怕是挂掉两台机器，只要有一个NameServer还在运行，就能保证MQ系统的稳定性。

小猛说着，打开了架构方案里的第一张图。

​      ![img](http://wechatapppro-1252524126.file.myqcloud.com/image/ueditor/39194900_1578385808.cn/txdocpic/0/74c0de67e6bc447499df8c769e002c5f/0)       

因为我上次分享的时候也说了，NameServer的设计是采用的Peer-to-Peer的模式来做的，也就是可以集群化部署，但是里面任何一台机器都是独立运行的，跟其他的机器没有任何通信。

每台NameServer实际上都会有完整的集群路由信息，包括所有的Broker节点信息，我们的数据信息，等等。所以只要任何一台NameServer存活下来，就可以保证MQ系统正常运行，不会出现故障。

因此NameServer的集群化部署是必须的第一步。

**3、基于Dledger的Broker主从架构部署**

其次，就是要考虑我们的Broker集群应该如何部署，采用什么方式来部署。

经过上次的分享我们已经知道，如果采用RocketMQ 4.5以前的那种普通的Master-Slave架构来部署，能在一定程度上保证数据不丢失，也能保证一定的可用性。

但是那种方式的缺陷是很明显的，最大的问题就是当Master Broker挂了之后，没办法让Slave Broker自动切换为新的Master Broker，需要手工做一些运维操作，修改配置以及重启机器才行，这个非常麻烦。

在手工运维的期间，可能就会导致系统的不可用。

所以既然现在RocketMQ 4.5之后已经基于Dledger技术实现了可以自动让Slave切换为Master的功能，那么我们肯定是选择基于Dledger的主备自动切换的功能来进行生产架构的部署。

而且Dledger技术是要求至少得是一个Master带两个Slave，这样有三个Broke组成一个Group，也就是作为一个分组来运行。一旦Master宕机，他就可以从剩余的两个Slave中选举出来一个新的Master对外提供服务。

此时小猛又打开了一个图。

​      ![img](http://wechatapppro-1252524126.file.myqcloud.com/image/ueditor/49362300_1578385808.cn/txdocpic/0/3897eb522dc3aa0b6e37cc9e51ac12c1/0)       

**每个Broker（不论是Master和Slave）都会把自己注册到所有的NameServer上去。**

**注：图中没有画出Slave Broker注册到NameServer。**

然后Master Broker还会把数据同步给两个Slave Broker，保证一份数据在不同机器上有多份副本。

**4、Broker是如何跟NameServer进行通信的？**

小猛说到这里停顿了一下，想了想然后继续说到，之前我们分享的时候就说过，这个Broker会每隔30秒发送心跳到所有的NameServer上去，然后每个NameServer都会每隔10s检查一次有没有哪个Broker超过120s没发送心跳的，如果有，就认为那个Broker已经宕机了，从路由信息里要摘除这个Broker。

但是当时没有讲Broker和NameServer进行通信的细节，这里在我们的生产架构方案里补充进去一些细节。

首先，Broker跟NameServer之间的通信是基于什么协议来进行的？

HTTP协议？RPC调用？还是TCP长连接？首先我们要搞明白这个。

在RocketMQ的实现中，采用的是**TCP长连接**进行通信。

也就是说，Broker会跟每个NameServer都建立一个TCP长连接，然后定时通过TCP长连接发送心跳请求过去

小猛说着打开下一张图，在这个图里完善了一些Broker跟NameServer通信的细节。    ![img](http://wechatapppro-1252524126.file.myqcloud.com/image/ueditor/65723900_1578385808.cn/txdocpic/0/0e4954466a0eb9301c8d28b9a086ddf6/0)      

所以各个NameServer就是通过跟Broker建立好的长连接不断收到心跳包，然后定时检查Broker有没有120s都没发送心跳包，来判定集群里各个Broker到底挂掉了没有。

**5、使用MQ的系统都要多机器集群部署**

下一步，我们一定会有很多的系统使用RocketMQ，有些系统是作为生产者往MQ发送消息，有些系统是作为消费者从MQ获取消息，当然还有的系统是既作为生产者，又作为消费者，所以我们要考虑这些系统的部署。

对于这些系统的部署本身不应该在MQ的考虑范围内，但是我们还是应该给出一个建议，就是无论作为生产者还是消费者的系统，都应该多机器集群化部署，保证他自己本身作为生产者或者消费者的高可用性。

因为一个系统如果就部署在一台机器上，然后作为生产者向MQ发送消息，那么一旦哪天机器上的生产者系统挂了，整个流程就断开了，不能保证高可用性。

但是如果在多台机器上部署生产者系统，任何一台机器上的生产者挂了，其他机器上的生产者系统可以继续运行。

小猛此时打开了下一张图，里面有生产者系统和消费者系统集群化部署的示意。      ![img](http://wechatapppro-1252524126.file.myqcloud.com/image/ueditor/73950200_1578385808.cn/txdocpic/0/de7502617930cc9fda67ff2f8ea324a5/0)       

上述所说在图里可以清晰看到，同理消费者系统也是集群化部署的，如果一台机器上的消费者系统挂了，其他机器上的消费者系统应该是可以继续运行的。

**6、MQ的核心数据模型：Topic到底是什么？**

下一步，生产者和消费者都会往MQ里写入消息和获取消息了，但是有一个问题：

MQ中的数据模型是什么？你投递出去的消息在逻辑上到底是放到哪里去的？是队列吗？还是别的什么呢？

小猛在这里补充了一个很关键的概念，这个就是MQ中的核心数据模型，Topic。

这个Topic如果直接翻译为中文，大概就是主题的意思，但是你要是听到主题两个字瞬间会觉得很蒙圈，因为感觉上主题似乎是手机上选择的各种壁纸主题这种概念，比如换一个壁纸主题，手机背景就变了。

所以对Topic还是不能直译，其实他表达的意思就是一个**数据集合**的意思。

举个例子，现在你的订单系统需要往MQ里发送订单消息，那么此时你就应该建一个Topic，他的名字可以叫做：topic_order_info，也就是一个包含了订单信息的数据集合。

然后你的订单系统投递的订单消息都是进入到这个“topic_order_info”里面去的，如果你的仓储系统要获取订单消息，那么他可以指定从“topic_order_info”这里面去获取消息，获取出来的都是他想要的订单消息了。

一句话：Topic其实就是一个数据集合的意思，不同类型的数据你得放不同的Topic里去。

要是你有一些商品数据要发送消息到MQ里，你就应该创建一个Topic叫做“topic_product_info”，代表里面都是商品数据，那些想要从MQ里获取商品数据的系统就可以从“topic_product_info”里获取了。

所以简单来说，你的系统如果要往MQ里写入消息或者获取消息，首先得创建一些Topic，作为数据集合存放不同类型的消息，比如说订单Topic，商品Topic，等等。

**7、Topic作为一个数据集合是怎么在Broker集群里存储的？**

下一个问题：我们创建的那些Topic是怎么存储在Broker集群里的呢？

这里就体现出来一个分布式存储的概念了。

首先我们来想一下，比如我们有一个订单Topic，可能订单系统每天都会往里面投递几百万条数据，然后这些数据在MQ集群上还得保留好多天，那么最终可能会有几千万的数据量，这还只是一个Topic。

那么如果有很多的Topic，并且里面都有大量的数据，最终加起来的总和也许是一个惊人的数字，此时这么大量的数据本身是不太可能存放在一台机器上的。

如果一台机器没法放下那么多的数据，应该怎么办呢？

很简单，分布式存储。

我们可以在创建Topic的时候指定让他里面的数据分散存储在多台Broker机器上，比如一个Topic里有1000万条数据，此时有2台Broker，那么就可以让每台Broker上都放500万条数据。

这样就可以把一个Topic代表的数据集合分布式存储在多台机器上了。

小猛说着，打开了一个图，在这个图里，新画出来了一个Master Broker和两个Slave Broker，因为Dledger技术要求每个Master都得带两个Slave来进行选举。然后示意出来了一个订单Topic的数据分布式存储在两个Master Broker上了。



​      ![img](http://wechatapppro-1252524126.file.myqcloud.com/image/ueditor/86380600_1578385808.cn/txdocpic/0/521ef1437b77fba5929f4e17af9ec853/0)       

而且另外很重要的一件事是，每个Broke在进行定时的心跳汇报给NameServer的时候，都会告诉NameServer自己当前的数据情况，比如有哪些Topic的哪些数据在自己这里，这些信息都是属于路由信息的一部分。

小猛说着在上面的图里画了一个红圈，示意了Broker心跳的时候会汇报给NameServer自己的数据情况，这样每个NameServer都知道集群里有哪些Broker，每个Broker存放了哪些Topic的数据。



​      ![img](http://wechatapppro-1252524126.file.myqcloud.com/image/ueditor/96749200_1578385808.cn/txdocpic/0/50c548f74e7db23132cee7ddef15c2ef/0)       

**8、生产者系统是如何将消息发送给Broker的？**

接着是下一个问题：生产者系统是如何将消息发送到Broker的呢？

首先我们之前说过，在发送消息之前，得先有一个Topic，然后在发送消息的时候你得指定你要发送到哪个Topic里面去。

接着既然你知道你要发送的Topic，那么就可以跟NameServer建立一个TCP长连接，然后定时从他那里拉取到最新的路由信息，包括集群里有哪些Broker，集群里有哪些Topic，每个Topic都存储在哪些Broker上。

小猛说着打开了一张示意图，在里面用红圈示意了拉取路由信息。

​      ![img](http://wechatapppro-1252524126.file.myqcloud.com/image/ueditor/11857900_1578385809.cn/txdocpic/0/2a3ec3768a23cc24f12c58bbd56116b9/0)       

然后生产者系统自然就可以通过路由信息找到自己要投递消息的Topic分布在哪几台Broker上，此时可以根据负载均衡算法，从里面选择一台Broke机器出来，比如round robine轮询算法，或者是hash算法，都可以。

这个具体的选择Broker的算法，后面我们在讲RocketMQ技术落地到项目的时候再来细说就可以。

总之，选择一台Broker之后，就可以跟那个Broker也建立一个TCP长连接，然后通过长连接向Broker发送消息即可.

Broker收到消息之后就会存储在自己本地磁盘里去。小猛说着又打开了一个图，在图里用红圈圈出了发送消息的地方。

​      ![img](http://wechatapppro-1252524126.file.myqcloud.com/image/ueditor/24683100_1578385809.cn/txdocpic/0/780eb4c89f0fb7e6b23ae54fb2ad1bd5/0)       

这里唯一要注意的一点，就是生产者一定是投递消息到Master Broker的，然后Master Broker会同步数据给他的Slave Brokers，实现一份数据多份副本，保证Master故障的时候数据不丢失，而且可以自动把Slave切换为Master提供服务。

**9、消费者是如何从Broker上拉取消息的？**

消费者系统其实跟生产者系统原理是类似的，他们也会跟NameServer建立长连接，然后拉取路由信息，接着找到自己要获取消息的Topic在哪几台Broker上，就可以跟Broker建立长连接，从里面拉取消息了。

小猛说着打开了最后一张图，也就是最终的MQ生产部署架构图。

​      ![img](http://wechatapppro-1252524126.file.myqcloud.com/image/ueditor/37912500_1578385809.cn/txdocpic/0/3e1f50b27bb1c50000d59cc6dd8b8772/0)       

这里唯一要注意的一点是，消费者系统可能会从Master Broker拉取消息，也可能从Slave Broker拉取消息，都有可能，一切都看具体情况。

**10、整体架构：高可用、高并发、海量消息、可伸缩**

小猛指着最终的架构图说，整个这套生产架构是实现完全高可用的，因为NameServer随便一台机器挂了都不怕，他是集群化部署的，每台机器都有完整的路由信息；

Broker随便挂了一台机器也不怕，挂了Slave对集群没太大影响，挂了Master也会基于Dledger技术实现自动Slave切换为Master；

生产者系统和消费者系统随便挂了一台都不怕，因为他们都是集群化部署的，其他机器会接管工作。

而且这个架构可以抗下高并发，因为假设订单系统对订单Topic要发起每秒10万QPS的写入，那么只要订单Topic分散在比如5台Broker上，实际上每个Broker会承载2万QPS写入，也就是说高并发场景下的10万QPS可以分散到多台Broker上抗下来。

然后集群足以存储海量消息，因为所有数据都是分布式存储的，每个Topic的数据都是存储在多台Broker机器上的，用集群里多台Master Broker就足以存储海量的消息。

所以，用多个Master Broker部署的方式，加上Topic分散在多台Broker上的机制，可以抗下高并发访问以及海量消息的分布式存储。

然后每个Master Broker有两个Slave Broker结合Dledger技术可以实现故障时的自动Slave-Master切换，实现高可用性。

最后，这套架构还具备伸缩性，就是说如果要抗更高的并发，存储跟多的数据，完全可以在集群里加入更多的Broker机器，这样就可以线性扩展集群了。

明哥听完这套生产部署架构的设计，对小猛真是由衷的赞赏，感觉这个小伙子虽然才刚毕业，但是考虑问题真的很周全，很多细节都考虑到了，而且除了细节还能进行整体架构的考虑，真的很不错。

明哥说：小伙子太棒了，我相信你只要有这个劲头，后续一定可以帮助咱们团队用MQ技术改造好系统架构的。

**End**

### 26 授人以渔：你们公司的消息中间件生产环境如何部署的？

今天的授人以渔环节，希望大家能够结合学习到的MQ生产部署架构的知识来思考下面问题：

- 在你们公司里有用MQ吗？
- 如果有的话是什么MQ？
- 你们的MQ在生产环境的部署架构是怎么做的？
- 路由中心、MQ集群、生产者和消费者分别是怎么部署的？为什么要那样部署？
- 那样部署可以实现高并发、海量消息、高可用和线性可伸缩吗？

希望大家可以结合自己之前查阅资料了解到的知识思考下，RabbitMQ和Kafka他们两个是如何实现生产架构部署，来支撑高并发、海量消息、高可用和可伸缩的呢？他们能实现这些吗？

希望大家好好思考这两个授人以渔的问题，然后再评论区里给出你的回答，分享给大家，一起共同进步。

**End**

### 27 部署一个小规模的 RocketMQ 集群，为压测做好准备

**1、小猛的第一个实战任务：部署一个小规模的RocketMQ集群**

既然已经完成了RocketMQ生产架构的设计了，接着就得一步一步完成真正的生产集群的部署了，明哥这个时候给小猛布置了第一个实战任务，就是先分配几台机器给小猛，让他完成一个小规模的RocketMQ集群的部署。

这个小规模的RocketMQ集群部署好了之后，还需要对这个集群进行压测，看一看在公司的机器配置下，可以抗下多高的QPS。

小猛接下了这个任务，同时又看了看他之前设计出来的最终生产部署架构图，他知道这个图仅仅是一个逻辑架构图，不是物理部署架构图，但是物理部署架构图得参照这个逻辑架构图才能部署出来。

​      ![img](http://wechatapppro-1252524126.file.myqcloud.com/image/ueditor/6387900_1578388980.cn/txdocpic/0/154e39c083ddbb75f0ccd9d516b5b67a/0)       

**2、公司给小猛分配的第一批机器**

小猛先看了看公司给他分配的第一批机器的各项配置，然后迅速基于这批机器制定了RocketMQ集群部署的规划。

1. NameServer：3台机器，每台机器都是8核CPU + 16G内存 + 500G磁盘 + 千兆网卡
2. Broker：3台机器，每台机器都是24核CPU（两颗x86_64 cpu，每颗cpu是12核） + 48G内存 + 1TB磁盘 + 千兆网卡
3. 生产者：2台机器，每台机器都是4核CPU + 8G内存 + 500GB磁盘 + 千兆网卡
4. 消费者：2台机器，每台机器都是4核CPU + 8G内存 + 500GB磁盘 + 千兆网卡

NameServer是核心的路由服务，所以给8核16G的较高配置的机器，但是他一般就是承载Broker注册和心跳、系统的路由表拉取等请求，负载其实很低，因此不需要特别高的机器配置，部署三台也可以实现高可用的效果了。

Broker是最负载最高的，未来要承载高并发写入和海量数据存储，所以把最高配置的机器都会留给他，这里用3台机器组成一个“单Master + 双Slave”的集群。

生产者和消费者机器都是临时用来测试的，而且一般他们都是业务系统，只会部署在标准的4核8G的机器配置下。

所有机器都是千兆网卡，足够他们使用了。

小猛看着自己手头的机器，点点头，可以开始部署了。

**3、选择一台机器快速部署RocketMQ尝试一下**

首先，小猛的第一步不是一下子就把整个集群部署好，而是先找一台机器准备在上面先快速部署一个RocketMQ尝试一下。

在机器上部署RocketMQ之前，先安装一下JDK，同时要在环境变量中设置Java_HOME，这个小猛很熟练就搞定了。（画外音，如果有不会的同学，可以自己查阅资料）

接着在一台机器上执行了下面的命令来构建Dledger：

git clone https://github.com/openmessaging/openmessaging-storage-dledger.git

cd openmessaging-storage-dledger

mvn clean install -DskipTests

接着小猛在机器上个执行了下面的命令来构建RocketMQ：

git clone https://github.com/apache/rocketmq.git

cd rocketmq

git checkout -b store_with_dledger origin/store_with_dledger

mvn -Prelease-all -DskipTests clean install -U

接着进入一个目录中：

cd distribution/target/apache-rocketmq

在这个目录中，需要编辑三个文件，一个是bin/runserver.sh，一个是bin/runbroker.sh，另外一个是bin/tools.sh

在里面找到如下三行，然后将第二行和第三行都删了，同时将第一行的值修改为你自己的JDK的主目录

[ ! -e "$JAVA_HOME/bin/java" ] && JAVA_HOME=$HOME/jdk/java

[ ! -e "$JAVA_HOME/bin/java" ] && JAVA_HOME=/usr/java

[ ! -e "$JAVA_HOME/bin/java" ] && error_exit "Please set the JAVA_HOME variable in your environment, We need java(x64)!"

**注**：如果要查看你的JDK装哪儿了，可以用命令：/usr/libexec/java_home -V，修改为你的Java主目录即可

接着执行下面的命令进行快速RocketMQ集群启动：

sh bin/dledger/fast-try.sh start

这个命令会在当前这台机器上启动一个NameServer和三个Broker，三个Broker其中一个是Master，另外两个是Slave，瞬间就可以组成一个最小可用的RocketMQ集群。

接着使用下面的命令检查一下RocketMQ集群的状态：

sh bin/mqadmin clusterList -n 127.0.0.1:9876

此时你需要等待一会儿，这个命令执行的过程会有点缓慢，大概可能几秒到几十秒过后，你会看到三行记录，说是一个RaftCluster，Broker名称叫做RaftNode00，然后BID是0、1、2，也有可能是0、1、3

这就说明的RocketMQ集群启动成功了，BID为0的就是Master，BID大于0的就都是Slave，其实在这里也可以叫做Leader和Follower

接着就可以尝试一下Slave是如何自动切换为Master的了。

我们看到三台机器的地址分别为：

1. 192.168.31.153:30921
2. 192.168.31.153:30911
3. 192.168.31.153:30931

我们发现30921端口的Broker的BID是0，说明他是Master

此时我们可以用命令（lsof -i:30921）找出来占用30921端口的进程PID，接着就用kill -9的命令给他杀了，比如我这里占用30921端口的进程PID是4344，那么就执行命令：kill -9 4344

接着等待个10s，再次执行命令查看集群状态：

sh bin/mqadmin clusterList -n 127.0.0.1:9876

此时就会发现作为Leader的BID为0的节点，变成另外一个Broker了，这就是说Slave切换为Master了。

**4、完成正式三台NameServer的部署**

其实RocketMQ集群部署并不难，主要就是在几台机器上做好相应的配置，然后执行一些命令启动NameServer和Broker就可以了。

首先是在三台NameServer的机器上，大家就按照上面的步骤安装好Java，构建好Dledger和RocketMQ，然后编辑对应的文件，设置好JAVA_HOME就可以了。

此时可以执行如下的一行命令就可以启动NameServer：

nohup sh mqnamesrv &

这个NameServer监听的接口默认就是9876，所以如果你在三台机器上都启动了NameServer，那么他们的端口都是9876，此时我们就成功的启动了三个NameServer了

**5、完成一组Broker集群的部署**

接着需要启动一个Master Broker和两个Slave Broker，这个启动也很简单，分别在上述三台为Broker准备的高配置机器上，安装好Java，构建好Dledger和RocketMQ，然后编辑好对应的文件。

接着就可以执行如下的命令：

nohup sh bin/mqbroker -c conf/dledger/broker-n0.conf &

这里要给大家说一下，第一个Broker的配置文件是broker-n0.conf，第二个broker的配置文件可以是broker-n1.conf，第三个broker的配置文件可以是broker-n2.conf。

对于这个配置文件里的东西要给大家说明一下，自己要做对应的修改。

我们用**broker-n0.conf**举例子，然后在每个配置项上加入注释，告诉大家应该如何修改每台机器的配置：

\# 这个是集群的名称，你整个broker集群都可以用这个名称

brokerClusterName = RaftCluster

\# 这是Broker的名称，比如你有一个Master和两个Slave，那么他们的Broker名称必须是一样的，因为他们三个是一个分组，如果你有另外一组Master和两个Slave，你可以给他们起个别的名字，比如说RaftNode01

brokerName=RaftNode00

\# 这个就是你的Broker监听的端口号，如果每台机器上就部署一个Broker，可以考虑就用这个端口号，不用修改

listenPort=30911

\# 这里是配置NameServer的地址，如果你有很多个NameServer的话，可以在这里写入多个NameServer的地址

namesrvAddr=127.0.0.1:9876

\# 下面两个目录是存放Broker数据的地方，你可以换成别的目录，类似于是/usr/local/rocketmq/node00之类的

storePathRootDir=/tmp/rmqstore/node00

storePathCommitLog=/tmp/rmqstore/node00/commitlog

\# 这个是非常关键的一个配置，就是是否启用DLeger技术，这个必须是true

enableDLegerCommitLog=true

\# 这个一般建议和Broker名字保持一致，一个Master加两个Slave会组成一个Group

dLegerGroup=RaftNode00

\# 这个很关键，对于每一组Broker，你得保证他们的这个配置是一样的，在这里要写出来一个组里有哪几个Broker，比如在这里假设有三台机器部署了Broker，要让他们作为一个组，那么在这里就得写入他们三个的ip地址和监听的端口号

dLegerPeers=n0-127.0.0.1:40911;n1-127.0.0.1:40912;n2-127.0.0.1:40913

\# 这个是代表了一个Broker在组里的id，一般就是n0、n1、n2之类的，这个你得跟上面的dLegerPeers中的n0、n1、n2相匹配

dLegerSelfId=n0

\# 这个是发送消息的线程数量，一般建议你配置成跟你的CPU核数一样，比如我们的机器假设是24核的，那么这里就修改成24核

sendMessageThreadPoolNums=24

上面说完了这个配置文件在各个Broker上应该如何修改，其实你结合之前学习过的Broker的工作原理，就应该理解这些配置的含义了。

其实最关键的是，你的Broker是分为多组的，每一组是三个Broker，一个Master和两个Slave。

对每一组Broker，他们的Broker名称、Group名称都是一样的，然后你得给他们配置好一样的dLegerPeers（里面是组内三台Broker的地址）

然后他们得配置好对应的NameServer的地址，最后还有就是每个Broker有自己的ID，在组内是唯一的就可以了，比如说不同的组里都有一个ID为n0的broker，这个是可以的。

所以按照这个思路就可以轻松的配置好一组Broker，在三台机器上分别用命令启动Broker即可。启动完成过后，可以跟NameServer进行通信，检查Broker集群的状态，就是如下命令：

sh bin/mqadmin clusterList -n 127.0.0.1:9876。

**6、编写最基本的生产者和消费者代码准备压测**

接着就可以编写最基本的生产者和消费者代码，准备执行压测了。

可以新建两个工程，一个是生产者，一个是消费者，两个工程都需要加入下面的依赖：

![image.png](http://wechatapppro-1252524126.file.myqcloud.com/image/ueditor/18566900_1578388980.png)



然后生产者的示例代码如下，大家现在不需要知道里面的含义，只要知道他可以发送消息即可，基本的代码说明都写在下面的注释里了

简单来说，就是只要一运行，就立马不停的在while死循环里去发送消息，根据需要可以设置为多个线程：

![image.png](http://wechatapppro-1252524126.file.myqcloud.com/image/ueditor/29069300_1578388980.png)

接着是示例用的消费者代码，如下所示，关键的注释都写在里面了，消费者就是不停的去获取消息然后打印出来即可：



![image.png](http://wechatapppro-1252524126.file.myqcloud.com/image/ueditor/42508100_1578388980.png)



小猛忙活了几天总算弄完了一个小集群，由三个NameServer、三个Broker以及四个业务系统机器组成，他试了一下，Broker都正常运行，请求NameServer可以看到集群信息，而且测试了一下，能够正常的发送消息和接收消息。

一切万事俱备，只欠东风，接下来就要调整Broker的OS内核参数、JVM参数然后重新启动Broker，接着就可以启动生产者和消费者去发送消息和获取消息，然后去观察RocketMQ能承载的QPS，CPU、IO、磁盘、网络等负载。

**End**

### 28 授人以渔：动手完成一个小规模的RocketMQ集群的部署进行练习

今天的授人以渔任务非常简单明了，希望大家动手去做一做今天讲的RocketMQ集群部署的练习

大家可以自己在windows上安装一个linux虚拟机，然后用一台虚拟机先跟着文章里的步骤，去尝试在单机上快速部署一个小规模集群。

接着可以在windows上安装多个linux虚拟机，比如用一个虚拟机部署NameServer，然后用三个虚拟机部署Broker。部署Broker集群的时候，可以参照文章里对配置修改的说明，自行修改配置，然后启动Broker即可。

如果通过命令验证集群部署成功了，接着就可以按照文章里的步骤去测试一下Slave-Master的自动切换能力，可以杀掉Master进程，然后等一会看看Slave是否会切换为Master。

接着大家可以用文章里的生产者和消费者的代码，去尝试一下发送消息和消费消息，如果都跑通的话，那么就成功了。

文章里讲的机器配置，都是从真实生产环境得来的，因为这里没有条件去演示真实生产环境的部署和测试，但是我们会用真实的机器配置去讲解。到底如何部署，如何调整os内核参数、jvm参数，如何压测，压测效果一般是什么样的，然后就是按照一个公司的真实负载，集群到底应该如何规划。相信大家跟着学习下来，也会掌握这些实践经验的。

好了，今天的授人以渔环节的练习如果完成的朋友，可以到评论区里进行分享，如果遇到问题也可以去提问，如果成功了也可以去分享一下。

**End**

### 29 生产运维：如何对RocketMQ集群进行可视化的监控和管理？

**1、小猛在压测前突然有一个困惑**

现在RocketMQ集群如何部署都已经知道了，小猛原计划就应该要开始着手优化生产机器上的os内核参数和RocketMQ的jvm参数了，这些参数优化好了，才能正式在高配置机器上启动RocketMQ，让他把性能发挥到最高，接着压测才有意义。

但是小猛在做这些事儿之前突然产生了一个困惑，他在想一个事，如果RocketMQ集群参数正式优化好了然后启动了集群，接着用几台机器跑生产者和消费者去压测，那么压测完了到底要看什么呢？

他想了想，觉得既然是压测，那么必然是要看RocketMQ集群能承载的最高QPS，同时在承载这个QPS的同时，各个机器的CPU、IO、磁盘、网络、内存的负载情况，要看机器资源的使用率，还要看JVM的GC情况，等等。

但是现在有一个问题来了，到底怎么看这些东西呢？

小猛突然发现自己在压测之前还少了一个步骤，那就是应该研究一下RocketMQ集群的监控、管理和运维

比如有什么办法可以看到RocketMQ集群的一些性能指标，有什么办法可以对RocketMQ进行一些运维操作，比如说在集群里加入一台Broker之类的。

好吧，看来自己还有点操之过急了。

小猛赶紧去找了明哥，跟他说了这个情况，跟明哥多申请了一点时间去让他研究RocketMQ集群的监控和运维管理。

**2、RocketMQ的大优势：可视化的管理界面**

其实大家可以思考一个问题，整个RocketMQ集群的元数据都集中在了NameServer里，包括有多少Broker，有哪些Topic，有哪些Producer，有哪些Consumer，目前集群里有多少消息，等等。

所以如果我们能想办法跑到NameServer里去，自然就可以知道很多东西

但是那不行，因为NameServer并没有对我们打开一扇门让我们进去知道这些东西。

但是RocketMQ里既然有大量的信息可以让我们进行监控和查看，他自然会提供一些办法来让我们看到，这就是他最大的优势之一，一个可视化的管理界面。

我们可以随便找一台机器，用NameServer的三台机器中的任意一台机器就可以，在里面执行如下命令拉取RocketMQ运维工作台的源码：

git clone https://github.com/apache/rocketmq-externals.git

然后进入rocketmq-console的目录：

cd rocketmq-externals/rocketmq-console

执行以下命令对rocketmq-cosole进行打包，把他做成一个jar包：

mvn package -DskipTests

然后进入target目录下，可以看到一个jar包，接着执行下面的命令启动工作台：

java -jar rocketmq-console-ng-1.0.1.jar --server.port=8080 --rocketmq.config.namesrvAddr=127.0.0.1:9876

这里务必要在启动的时候设置好NameServer的地址，如果有多个地址可以用分号隔开，接着就会看到工作台启动了，然后就通过浏览器访问那台机器的8080端口就可以了，就可以看到精美的工作台界面。

**3、如何通过工作台进行集群监控**

这个可视化的工作台可以说是非常强大的，他几乎满足了我们大部分对RocketMQ集群监控的需求，我们一步一步看看他都有哪些功能。

首先刚进入界面，会看到类似下面的东西：

​      ![img](http://wechatapppro-1252524126.file.myqcloud.com/image/ueditor/42908800_1578389078.cn/txdocpic/0/bb33ec2a8e72d7302a6ad2672c5ce01d/0)       

这个时候大家可能有点懵，其实看看右上角有一个按钮是“ChangeLanguage”，可以支持切换语言的，大家就切换成简体中文就行了。

在这个界面里可以让你看到Broker的大体消息负载，还有各个Topic的消息负载，另外还可以选择日期要看哪一天的监控数据，都可以看到。

接着大家点击上边导航栏里的“集群”，就会进入集群的一个监控界面。

​      ![img](http://wechatapppro-1252524126.file.myqcloud.com/image/ueditor/64928800_1578389078.cn/txdocpic/0/689f2969cbb2e1222361fd25047ae53d/0)       



在这个图里可以看到非常有用的一些信息，你可以看到各个Broker的分组，哪些是Master，哪些是Slave，他们各自的机器地址和端口号，还有版本号

包括最重要的，就是他们每台机器的生产消息TPS和消费消息TPS，还有消息总数。

这是非常重要的，通过这个TPS统计，就是每秒写入或者被消费的消息数量，就可以看出RocketMQ集群的TPS和并发访问量。

另外在界面右侧有两个按钮，一个是“状态”，一个是“配置”。其中点击状态可以看到这个Broker更加细节和具体的一些统计项，点击配置可以看到这个Broker具体的一些配置参数的值。

点击上边导航栏的“主题”，可以看到下面的界面，通过这个界面就可以对Topic进行管理了，比如你可以在这里创建、删除和管理Topic，查看Topic的一些装填、配置，等等，可以对Topic做各种管理。

​      ![img](http://wechatapppro-1252524126.file.myqcloud.com/image/ueditor/80026200_1578389078.cn/txdocpic/0/44bbcf865342d8a84f295e65dd37981d/0)       



接着点击上边导航栏里的“消费者”和“生产者”，就可以看到访问MQ集群的消费者和生产者了，还可以做对应的一些管理。

​      ![img](http://wechatapppro-1252524126.file.myqcloud.com/image/ueditor/92549100_1578389078.cn/txdocpic/0/59cc8304b9457d528f9c2fb278daa175/0)       



​      ![img](http://wechatapppro-1252524126.file.myqcloud.com/image/ueditor/3670400_1578389079.cn/txdocpic/0/91a740382a8e0bb3c9b6542a313d1711/0)       



接着点击导航栏里的“消息”和“消息轨迹”，又可以对消息进行查询和管理。

​      ![img](http://wechatapppro-1252524126.file.myqcloud.com/image/ueditor/14292700_1578389079.cn/txdocpic/0/2ed97fa3f29bf7520220c057156328bf/0)       



​      ![img](http://wechatapppro-1252524126.file.myqcloud.com/image/ueditor/33517800_1578389079.cn/txdocpic/0/4f6831190a70bcd5ac8411e7dbc66300/0)       



大体上这个工作台的监控和管理功能就是这些了，所以大家可以在这里看到，我们这个工作台，就可以对集群整体的消息数量以及消息TPS，还有各个Broker的消息数量和消息TPS进行监控。

同时我们还可以对Broker、Topic、消费者、生产者、消息这些东西进行对应的查询和管理，非常的便捷。

**4、机器本身的监控应该如何做？**

这里小猛又想到了一个问题：现在有了这个东西，我们是可以在压测的时候看到整个RocketMQ的TPS了，也就是Transaction Per Second，就是每秒事务的意思，在这里就是每秒消息数量的意思。

但是我们要同时看到集群每台机器的CPU、IO、磁盘、内存、JVM GC的负载和情况怎么办呢？

其实这些东西都有很好的监控系统可以去看了，比如说Zabbix、Open-Falcon等等，一般公司都会用这些东西来监控机器的性能和资源使用率。

如果没有这些东西的话，也没关系，在压测的时候完全可以登录到各个Broker机器上去，直接用linux命令行的一些命令来检查这些东西的资源使用率，其实都是可以看到的，包括JVM GC的情况，都是可以通过命令行工具来查看的。

**End**

### 30 授人以渔：你们公司的MQ集群是如何进行监控和管理的？

今天的授人以渔想要大家思考几个问题：

1. 你们公司的MQ集群是如何进行监控和管理的？有可视化的界面吗？你可以跟你们公司负责MQ集群运维的同事沟通一下，看看他平时监控主要看哪些东西？管理主要做哪些操作？为什么要做这些？
2. 你思考一下，假设让你来负责运维管理一个MQ集群，平时你要关注哪些监控指标，为什么？在什么情况下需要来进行一些运维管理，一般都要做哪些运维的操作？

记住我之前一直强调的，主动思考，主动思考，这个可以帮你大幅度提升你的技术软思维能力，而不是简单的理解+记忆，那是普通程序员要干的事儿。

如果你提希望提升自己的能力，那么这种主动思考，多角度探索的思维能力，是一个优秀程序员必备的！

**End**

### 31 RocketMQ生产集群准备：进行OS内核参数和JVM参数的调整

**1、压测前的准备工作**

小猛在折腾了几天，用公司分配的几台机器部署好一个小规模的RocketMQ集群之后，终于开始思考如何进行压测的问题了。小猛盯着下面的架构图，陷入了一阵沉思，像RocketMQ这种中间件集群，应该如何进行压测，要准备哪些东西呢？

​      ![img](http://wechatapppro-1252524126.file.myqcloud.com/image/ueditor/14462000_1578388338.cn/txdocpic/0/6c1704c8907ab8e635e671b3dca3c3c8/0)       

如果是一些经验不丰富的平时主要是做CRUD类的增删改查工作的Java工程师，可能此时就会直接尝试运行几个生产者和消费者的程序，然后多开一些线程写数据到RocketMQ，同时从RocketMQ消费数据

接着从RocketMQ的管理工作台中看一下TPS，每秒可以处理多少条消息，此时就算是完成压测了。

但是小猛并没有这样轻举妄动，他还是选择去咨询了一下明哥，提出了这个疑问，压测一个中间件真的就如此简单吗？

明哥听到小猛这个疑问后，就给小猛解释起了这种中间件集群的压测准备工作了。对于生产环境的中间件集群，不能直接用各种默认参数启动，因为那样可能有很多问题，或者没法把中间件的性能发挥出来。

对于一个中间件而言，第一步，你需要对他部署的机器的OS内核参数进行一定的调整（也就是linux操作系统的一些内核参数）

因为OS内核参数很多默认值未必适合生产环境的系统运行，有些参数的值需要调整大一些，才能让中间件发挥出来性能，我们看下面的的图。

​    ![img](http://wechatapppro-1252524126.file.myqcloud.com/image/ueditor/22699200_1578388338.cn/txdocpic/0/ef8ce067be3e419e6d7ea0c65048767c/0)   

接着下一步需要思考的一个问题，就是一般中间件，比如RocketMQ、MyCat、Elasticsearch、Kafka之类的东西，很多都是Java开发的，或者是基于JVM的Scala开发的（比如Kafka）

所以你可以认为在一台机器上部署和启动一个中间件系统，说白了就是启动一个JVM进程，由这个JVM进程来运行中间件系统内的所有代码，然后实现中间件系统的各种功能。

我们看下面的图，这里清晰的展示出了一台机器上部署了一个中间件系统，就是启动了一个JVM进程的概念。

这里如果有朋友对JVM这块知识不太了解，给大家推荐一下狸猫技术窝上的《从0开始带你成为JVM实战高手》这个专栏，是我的好朋友救火队队长写的，已经更新完毕。

​      ![img](http://wechatapppro-1252524126.file.myqcloud.com/image/ueditor/34981400_1578388338.cn/txdocpic/0/25c77725852562f722244a7a0ae19d75/0)       

所以其实对于一个生产环境的中间件系统而言，在部署和启动之前，需要关注的第二个东西就是JVM的各种参数

比如内存区域的大小分配，垃圾回收器以及对应的行为参数，GC日志存放地址，OOM自动导出内存快照的配置，等等。

所以你就需要对JVM进行合理的优化配置，比如最简单的一点，明明你部署了一个几十GB内存的高配置物理机，结果你就给中间件系统的JVM分配了1GB的内存，你觉得这是不是在开玩笑？

相当于你机器配置很高，结果你的中间件系统就用了里面的几十分之一的内存，根本没用上那么多的资源！

我们看下面的图画圈的地方，这里就引申出了要配置JVM参数的概念，这是很多人都会忽略的一点。

​      ![img](http://wechatapppro-1252524126.file.myqcloud.com/image/ueditor/47988200_1578388338.cn/txdocpic/0/4a602e847673f45519dfd9c578c30b50/0)       

最后第三件事情，就是中间件系统自己本身的一些核心参数的设置，比如你的中间件系统会开启很多线程处理请求和工作负载，然后还会进行大量的网络通信，同时会进行大量的磁盘IO类的操作。

这个时候你就需要依据你的机器配置，合理的对中间件系统的核心参数进行调整

比如你的机器配置很高，是24核CPU，结果你的中间件系统默认就开启了4个工作线程去处理请求，这不是在开玩笑么！相当于24核CPU里很多都是空闲状态，是没有任何事情可以干的。

要是不进行合理的参数设置，几乎可以认为就是在浪费高配置的机器资源！

所以以上三点，就是对任何一个中间件系统，在进行压力测试以及生产环境部署之前，都必须要进行调整的！

当然如果是普通的那种Java Web业务系统，通常而言上线之前主要关注的就是JVM的参数而已，对os内核参数以及业务系统自身参数大多数情况下都没有太多的要求

但是中间件系统而言，往往必须要对**os内核参数、jvm参数以及自身核心参数**都做出相对应的合理的调整，再进行压测和上线。

**2、对RocketMQ集群进行OS内核参数的调整**

接着明哥就开始为小猛讲解RocketMQ集群部署的机器需要调整的一些os内核参数的含义，并且给小猛说了一些他建议的调整值。

（1）vm.overcommit_memory

“vm.overcommit_memory”这个参数有三个值可以选择，0、1、2。

如果值是0的话，在你的中间件系统申请内存的时候，os内核会检查可用内存是否足够，如果足够的话就分配内存给你，如果感觉剩余内存不是太够了，干脆就拒绝你的申请，导致你申请内存失败，进而导致中间件系统异常出错。

因此一般需要将这个参数的值调整为1，意思是把所有可用的物理内存都允许分配给你，只要有内存就给你来用，这样可以避免申请内存失败的问题。

比如我们曾经线上环境部署的Redis就因为这个参数是0，导致在save数据快照到磁盘文件的时候，需要申请大内存的时候被拒绝了，进而导致了异常报错。

可以用如下命令修改：echo 'vm.overcommit_memory=1' >> /etc/sysctl.conf。

（2）vm.max_map_count

这个参数的值会影响中间件系统可以开启的线程的数量，同样也是非常重要的

如果这个参数过小，有的时候可能会导致有些中间件无法开启足够的线程，进而导致报错，甚至中间件系统挂掉。

他的默认值是65536，但是这个值有时候是不够的，比如我们大数据团队的生产环境部署的Kafka集群曾经有一次就报出过这个异常，说无法开启足够多的线程，直接导致Kafka宕机了。

因此建议可以把这个参数调大10倍，比如655360这样的值，保证中间件可以开启足够多的线程。

可以用如下命令修改：echo 'vm.max_map_count=655360' >> /etc/sysctl.conf。

（3）vm.swappiness

这个参数是用来控制进程的swap行为的，这个简单来说就是os会把一部分磁盘空间作为swap区域，然后如果有的进程现在可能不是太活跃，就会被操作系统把进程调整为睡眠状态，把进程中的数据放入磁盘上的swap区域，然后让这个进程把原来占用的内存空间腾出来，交给其他活跃运行的进程来使用。

如果这个参数的值设置为0，意思就是尽量别把任何一个进程放到磁盘swap区域去，尽量大家都用物理内存。

如果这个参数的值是100，那么意思就是尽量把一些进程给放到磁盘swap区域去，内存腾出来给活跃的进程使用。

默认这个参数的值是60，有点偏高了，可能会导致我们的中间件运行不活跃的时候被迫腾出内存空间然后放磁盘swap区域去。

因此通常在生产环境建议把这个参数调整小一些，比如设置为10，尽量用物理内存，别放磁盘swap区域去。

可以用如下命令修改：echo 'vm.swappiness=10' >> /etc/sysctl.conf。

（4）ulimit

这个是用来控制linux上的最大文件链接数的，默认值可能是1024，一般肯定是不够的，因为你在大量频繁的读写磁盘文件的时候，或者是进行网络通信的时候，都会跟这个参数有关系

对于一个中间件系统而言肯定是不能使用默认值的，如果你采用默认值，很可能在线上会出现如下错误：error: too many open files。

因此通常建议用如下命令修改这个值：echo 'ulimit -n 1000000' >> /etc/profile。

（5）一点小小的总结

其实大家综合思考一下这几个参数，会发现到最后要调整的东西，无非都是跟磁盘文件IO、网络通信、内存管理、线程数量有关系的，因为我们的中间件系统在运行的时候无非就是跟这些打交道。

- 中间件系统肯定要开启大量的线程**（跟vm.max_map_count有关）**
- 而且要进行大量的网络通信和磁盘IO**（跟ulimit有关）**
- 然后大量的使用内存**（跟vm.swappiness和vm.overcommit_memory有关）**

所以对OS内核参数的调整，往往也就是围绕跟中间件系统运行最相关的一些东西。

**3、对JVM参数进行调整**

接着明哥开始给小猛讲解起了RocketMQ的JVM参数如何调整，首先得先找到RocketMQ启动脚本中是如何设置JVM参数的，并且明白默认JVM参数的含义，同时再有针对性的做出适当的调整和修改。

我们回顾一下之前讲部署RocketMQ集群的时候，给大家介绍过几个启动脚本

在rocketmq/distribution/target/apache-rocketmq/bin目录下，就有对应的启动脚本，比如mqbroker是用来启动Broker的，mqnamesvr是用来启动NameServer的。

用mqbroker来举例，我们查看这个脚本里的内容，最后有如下一行：

sh ${ROCKETMQ_HOME}/bin/runbroker.sh org.apache.rocketmq.broker.BrokerStartup $@

这一行内容就是用runbroker.sh脚本来启动一个JVM进程，JVM进程刚开始执行的main类就是org.apache.rocketmq.broker.BrokerStartup

我们接着看runbroker.sh脚本，在里面可以看到如下内容：

JAVA_OPT="${JAVA_OPT} -server -Xms8g -Xmx8g -Xmn4g"

JAVA_OPT="${JAVA_OPT} -XX:+UseG1GC -XX:G1HeapRegionSize=16m -XX:G1ReservePercent=25 -XX:InitiatingHeapOccupancyPercent=30 -XX:SoftRefLRUPolicyMSPerMB=0"

JAVA_OPT="${JAVA_OPT} -verbose:gc -Xloggc:/dev/shm/mq_gc_%p.log -XX:+PrintGCDetails -XX:+PrintGCDateStamps -XX:+PrintGCApplicationStoppedTime -XX:+PrintAdaptiveSizePolicy"

JAVA_OPT="${JAVA_OPT} -XX:+UseGCLogFileRotation -XX:NumberOfGCLogFiles=5 -XX:GCLogFileSize=30m"

JAVA_OPT="${JAVA_OPT} -XX:-OmitStackTraceInFastThrow"

JAVA_OPT="${JAVA_OPT} -XX:+AlwaysPreTouch"

JAVA_OPT="${JAVA_OPT} -XX:MaxDirectMemorySize=15g"

JAVA_OPT="${JAVA_OPT} -XX:-UseLargePages -XX:-UseBiasedLocking"

JAVA_OPT="${JAVA_OPT} -Djava.ext.dirs=${JAVA_HOME}/jre/lib/ext:${BASE_DIR}/lib"

\#JAVA_OPT="${JAVA_OPT} -Xdebug -Xrunjdwp:transport=dt_socket,address=9555,server=y,suspend=n"

JAVA_OPT="${JAVA_OPT} ${JAVA_OPT_EXT}"

JAVA_OPT="${JAVA_OPT} -cp ${CLASSPATH}"

在上面的内容中，其实就是在为启动Broker设置对应的JVM参数和其他一些参数，我们可以把其中JVM相关的参数抽取出来给大家解释一下：

“-server -Xms8g -Xmx8g -Xmn4g -XX:+UseG1GC -XX:G1HeapRegionSize=16m -XX:G1ReservePercent=25 -XX:InitiatingHeapOccupancyPercent=30 -XX:SoftRefLRUPolicyMSPerMB=0 -verbose:gc -Xloggc:/dev/shm/mq_gc_%p.log -XX:+PrintGCDetails -XX:+PrintGCDateStamps -XX:+PrintGCApplicationStoppedTime -XX:+PrintAdaptiveSizePolicy -XX:+UseGCLogFileRotation -XX:NumberOfGCLogFiles=5 -XX:GCLogFileSize=30m -XX:-OmitStackTraceInFastThrow -XX:+AlwaysPreTouch -XX:MaxDirectMemorySize=15g -XX:-UseLargePages -XX:-UseBiasedLocking”

我们来分门别类解释一下这些参数，当然解释这些参数是建立在大家要对JVM有一定的了解基础之上，因此还是建议大家先看一下狸猫技术窝的《从0开始带你成为JVM实战高手》这个专栏。

**-server**：这个参数就是说用服务器模式启动，这个没什么可说的，现在一般都是如此

**-Xms8g -Xmx8g -Xmn4g**：这个就是很关键的一块参数了，也是重点需要调整的，就是默认的堆大小是8g内存，新生代是4g内存，但是我们的高配物理机是48g内存的

所以这里完全可以给他们翻几倍，比如给堆内存20g，其中新生代给10g，甚至可以更多一些，当然要留一些内存给操作系统来用

**-XX:+UseG1GC -XX:G1HeapRegionSize=16m**：这几个参数也是至关重要的，这是选用了G1垃圾回收器来做分代回收，对新生代和老年代都是用G1来回收

这里把G1的region大小设置为了16m，这个因为机器内存比较多，所以region大小可以调大一些给到16m，不然用2m的region，会导致region数量过多的

**-XX:G1ReservePercent=25**：这个参数是说，在G1管理的老年代里预留25%的空闲内存，保证新生代对象晋升到老年代的时候有足够空间，避免老年代内存都满了，新生代有对象要进入老年代没有充足内存了

默认值是10%，略微偏少，这里RocketMQ给调大了一些

**-XX:InitiatingHeapOccupancyPercent=30**：这个参数是说，当堆内存的使用率达到30%之后就会自动启动G1的并发垃圾回收，开始尝试回收一些垃圾对象

默认值是45%，这里调低了一些，也就是提高了GC的频率，但是避免了垃圾对象过多，一次垃圾回收耗时过长的问题

**-XX:SoftRefLRUPolicyMSPerMB=0**：这个参数默认设置为0了，在JVM优化专栏中，救火队队长讲过这个参数引发的案例，其实建议这个参数不要设置为0，避免频繁回收一些软引用的Class对象，这里可以调整为比如1000

**-verbose:gc -Xloggc:/dev/shm/mq_gc_%p.log -XX:+PrintGCDetails -XX:+PrintGCDateStamps -XX:+PrintGCApplicationStoppedTime -XX:+PrintAdaptiveSizePolicy -XX:+UseGCLogFileRotation -XX:NumberOfGCLogFiles=5 -XX:GCLogFileSize=30m**：这一堆参数都是控制GC日志打印输出的，确定了gc日志文件的地址，要打印哪些详细信息，然后控制每个gc日志文件的大小是30m，最多保留5个gc日志文件。

**-XX:-OmitStackTraceInFastThrow**：这个参数是说，有时候JVM会抛弃一些异常堆栈信息，因此这个参数设置之后，就是禁用这个特性，要把完整的异常堆栈信息打印出来

**-XX:+AlwaysPreTouch**：这个参数的意思是我们刚开始指定JVM用多少内存，不会真正分配给他，会在实际需要使用的时候再分配给他

所以使用这个参数之后，就是强制让JVM启动的时候直接分配我们指定的内存，不要等到使用内存的时候再分配

**-XX:MaxDirectMemorySize=15g**：这是说RocketMQ里大量用了NIO中的direct buffer，这里限定了direct buffer最多申请多少，如果你机器内存比较大，可以适当调大这个值，如果有朋友不了解direct buffer是什么，可以自己查阅一些资料。

**-XX:-UseLargePages -XX:-UseBiasedLocking**：这两个参数的意思是禁用大内存页和偏向锁，这两个参数对应的概念每个要说清楚都得一篇文章，所以这里大家直接知道人家禁用了两个特性即可。

最后我们做一点小的总结，RocketMQ默认的JVM参数是采用了**G1垃圾回收器****，默认堆内存大小是8G**

这个其实完全可以根据大家的机器内存来调整，你可以增大一些也是没有问题的，然后就是一些G1的垃圾回收的行为参数做了调整，这个一般我们不用去动，然后就是对GC日志打印做了设置，这个一般也不用动。

其余的就是禁用一些特性，开启一些特性，这些都直接维持RocketMQ的默认值即可。

**4、对RocketMQ核心参数进行调整**

明哥讲完RocketMQ默认的JVM参数以及我们要做的一些微调之后，就继续讲RocketMQ自身的一些核心参数的调整了。

之前讲解集群部署的时候给大家提过，在下面的目录里有dledger的示例配置文件：rocketmq/distribution/target/apache-rocketmq/conf/dledger

在这里主要是有一个较为核心的参数：**sendMessageThreadPoolNums=16**

这个参数的意思就是RocketMQ内部用来发送消息的线程池的线程数量，默认是16

其实这个参数可以根据你的机器的CPU核数进行适当增加，比如机器CPU是24核的，可以增加这个线程数量到24或者30，都是可以的。

RocketMQ还有一些其他的核心参数，在后续专栏讲解的过程中，咱们再继续来分析如何优化和调整。

**5、今日内容总结**

我们最后来简单对今天讲解的内容作一下总结：

**（1）**中间件系统在压测或者上生产之前，需要对三大块参数进行调整：**OS内核参数、JVM参数以及中间件核心参数**

**（2）**OS内核参数主要调整的地方都是跟磁盘IO、网络通信、内存管理以及线程管理有关的，需要适当调节大小

**（3）**JVM参数需要我们去中间件系统的启动脚本中寻找他的默认JVM参数，然后根据机器的情况，对JVM的堆内存大小，新生代大小，Direct Buffer大小，等等，做出一些调整，发挥机器的资源

**（4）**中间件核心参数主要也是关注其中跟网络通信、磁盘IO、线程数量、内存 管理相关的，根据机器资源，适当可以增加网络通信线程，控制同步刷磁盘或者异步刷磁盘，线程数量有多少，内存中一些队列的大小

**End**

### 32 授人以渔：你们公司的MQ集群是如何配置生产参数的？

今天的技术文章里的内容量是非常大的，差不多5000字的内容，需要大家好好的吸收和消化，里面涉及很多的技术内容。因此，今天给大家的授人以渔的环节就相对轻松简单一些了。

其实大家看完今天的内容，完全可以去看看自己公司里的MQ集群是如何配置生产参数的

比如os内核参数做了哪些调整和优化？JVM参数做了哪些调整和优化？MQ自身核心参数做了哪些调整和优化？

大家完全可以在公司内部找到MQ的负责人，虚心请教一下，必要的时候完全可以请人家吃个饭，因为实际上对于一个中间件系统而言，这些生产集群里的参数调整，是最核心的一块经验。

希望大家去好好探索一下，然后有心得体会的话，可以在评论区里留言，给大家分享你的探索所得，同时有什么疑问，也可以在评论区和我交流。

**End**

### 33 对小规模RocketMQ集群进行压测，同时为生产集群进行规划

**1、压测就是拼命往死了压吗？**

上次听明哥讲了一套完整的生产级中间件参数调整的方案，包含了OS内核参数调整，JVM参数调整以及中间件核心参数调整

小猛在消化理解之后，很快就在已经部署好的一个小规模的RocketMQ集群上对上述几块参数都根据明哥的建议进行了调节，完事儿之后小猛再一次盯着自己的RocketMQ部署图进入了思考。

​      ![img](http://wechatapppro-1252524126.file.myqcloud.com/image/ueditor/256500_1578388350.cn/txdocpic/0/94cb72db12d859b2a6ea0604b392dde7/0)       

所谓的压测到底是如何压测？难道就是简单的启动几台机器上的生产者和消费者，然后每台机器都开启大量线程模拟并发写入RocketMQ以及并发从RocketMQ上读取消息吗

难道就是不停的增加压测用的生产者和消费者的机器，同时不停的增加他们的线程，然后去看RocketMQ集群的极限在哪里吗？

不，小猛觉得压测这个事情并没有那么简单。于是他再一次去请教了明哥，在压测的时候到底要关注哪些指标？采用什么样的压测方式才是正确的的？

明哥听完小猛的疑问之后，再一次耐心的给小猛做出了详细的解释。

其实如果对一个小规模的RocketMQ集群进行疯狂的压测，最后压测出来一个最大的极限TPS值，那只是压测中我们想要的一个结果而已，并不是实际中的最理想结果。

什么意思呢？

假设我们现在对部署好的RocketMQ集群拼命进行压测，不停的增加生产者和消费者的机器以及线程数量，不停的增加RocketMQ集群的并发写入量和并发消费量，发现RocketMQ集群似乎可以抗下每秒10万+的消息量

那么你觉得在生产环境上，我们可以放心的让RocketMQ集群来抗这么高的TPS吗？

显然不是，因为我们在压测的时候一方面要关注RocketMQ能抗下多少TPS，一方面还要关注RocketMQ部署的几台机器的资源使用率和负载情况。

比如RocketMQ集群在抗下10万TPS（可以理解为每秒处理10万条消息）的同时，结果机器的CPU负载达到100%，内存几乎消耗殆尽，IO负载极高，网卡流量打满甚至快要打爆，此时你觉得这个10万TPS的成本是不是太高了？

因为眼看着你抗下了超高的TPS，结果自己机器资源消耗殆尽，几乎机器都快挂了，那么你在真正的生产环境能放心的允许RocketMQ集群抗到10万TPS吗？

显然是不行的，因为在机器快挂掉的情况下让中间件抗超高的负载是绝对不行的。

所以这种压测方法，仅仅能压测出来一个极限值而已。实际上我们平时做压测，主要关注的还是要压测出来一个最合适的最高负载。

什么叫最合适的最高负载呢？

意思就是**在RocketMQ的TPS和机器的资源使用率和负载之间取得一个平衡。**

比如RocketMQ集群在机器资源使用率极高的极端情况下可以扛到10万TPS，但是当他仅仅抗下8万TPS的时候，你会发现cpu负载、内存使用率、IO负载和网卡流量，都负载较高，但是可以接受，机器比较安全，不至于宕机。

那么这个8万TPS实际上就是最合适的一个最高负载，也就是说，哪怕生产环境中极端情况下，RocketMQ的TPS飙升到8万TPS，你知道机器资源也是大致可以抗下来的，不至于出现机器宕机的情况。

所以我们做压测，其实最主要的是综合TPS以及机器负载，尽量找到一个最高的TPS同时机器的各项负载在可承受范围之内，这才是压测的目的。

**2、一次RocketMQ小规模集群的压测**

（备注：以下压测过程以及压测结果，都是根据我们之前真实的RocketMQ压测报告总结而来，非常的有代表性，大家完全可以结合我们之前说的机器配置来参考一下）

（1）RocketMQ的TPS和消息延时

我们让两个Producer不停的往RocketMQ集群发送消息，每个Producer所在机器启动了80个线程，相当于每台机器有80个线程并发的往RocketMQ集群写入消息。

而RocketMQ集群是1主2从组成的一个dledger模式的高可用集群，只有一个Master Broker会接收消息的写入。

然后有2个Cosumer不停的从RocketMQ集群消费数据。

每条数据的大小是500个字节，**这个非常关键**，大家一定要牢记这个数字，因为这个数字是跟后续的网卡流量有关的。

我们发现，一条消息从Producer生产出来到经过RocketMQ的Broker存储下来，再到被Consumer消费，基本上这个时间跨度不会超过1秒钟，这些这个性能是正常而且可以接受的。

同时在RocketMQ的管理工作台中可以看到，Master Broker的TPS（也就是每秒处理消息的数量），可以稳定的达到7万左右，也就是每秒可以稳定处理7万消息。

（2）cpu负载情况

其次我们检查了一下Broker机器上的CPU负载，可以通过top、uptime等命令来查看

比如执行top命令就可以看到cpu load和cpu使用率，这就代表了cpu的负载情况。

在你执行了top命令之后，往往可以看到如下一行信息：

load average：12.03，12.05，12.08

类似上面那行信息代表的是cpu在1分钟、5分钟和15分钟内的cpu负载情况

比如我们一台机器是24核的，那么上面的12意思就是有12个核在使用中。换言之就是还有12个核其实还没使用，cpu还是有很大余力的。

这个cpu负载其实是比较好的，因为并没有让cpu负载达到极限。

（3）内存使用率

使用free命令就可以查看到内存的使用率，根据当时的测试结果，机器上48G的内存，仅仅使用了一部分，还剩下很大一部分内存都是空闲可用的，或者是被RocketMQ用来进行磁盘数据缓存了。

所以内存负载是很低的。

（4）JVM GC频率

使用jstat命令就可以查看RocketMQ的JVM的GC频率，基本上新生代每隔几十秒会垃圾回收一次，每次回收过后存活的对象很少，几乎不进入老年代

因此测试过程中，Full GC几乎一次都没有。（友情提示，如果不了解jstat命令如何分析JVM GC的，还是建议看一下《从0开始带你成为JVM实战高手》专栏）

（5）磁盘IO负载

接着可以检查一下磁盘IO的负载情况。

首先可以用top命令查看一下IO等待占用CPU时间的百分比，你执行top命令之后，会看到一行类似下面的东西：

Cpu(s): 0.3% us, 0.3% sy, 0.0% ni, 76.7% id, 13.2% wa, 0.0% hi, 0.0% si。

在这里的13.2% wa，说的就是磁盘IO等待在CPU执行时间中的百分比

如果这个比例太高，说明CPU执行的时候大部分时间都在等待执行IO，也就说明IO负载很高，导致大量的IO等待。

这个当时我们压测的时候，是在40%左右，说明IO等待时间占用CPU执行时间的比例在40%左右，这是相对高一些，但还是可以接受的，只不过如果继续让这个比例提高上去，就很不靠谱了，因为说明磁盘IO负载可能过高了。

（6）网卡流量

使用如下命令可以查看服务器的网卡流量：

sar -n DEV 1 2

通过这个命令就可以看到每秒钟网卡读写数据量了。当时我们的服务器使用的是千兆网卡，千兆网卡的理论上限是每秒传输128M数据，但是一般实际最大值是每秒传输100M数据。

因此当时我们发现的一个问题就是，在RocketMQ处理到每秒7万消息的时候，每条消息500字节左右的大小的情况下，每秒网卡传输数据量已经达到100M了，就是已经达到了网卡的一个极限值了。

因为一个Master Broker服务器，每秒不光是通过网络接收你写入的数据，还要把数据同步给两个Slave Broker，还有别的一些网络通信开销。

因此实际压测发现，每条消息500字节，每秒7万消息的时候，服务器的网卡就几乎打满了，无法承载更多的消息了。

（7）针对压测的一点小总结

最后针对本次压测做一点小的总结，实际上经过压测，最终发现我们的服务器的性能瓶颈在网卡上，因为网卡每秒能传输的数据是有限的

因此当我们使用平均大小为500字节的消息时，最多就是做到RocketMQ单台服务器每秒7万的TPS，而且这个时候cpu负载、内存负载、jvm gc负载、磁盘io负载，基本都还在正常范围内。

只不过这个时候网卡流量基本已经打满了，无法再提升TPS了。

因此在这样的一个机器配置下，RocketMQ一个比较靠谱的TPS就是7万左右。

**3、基于公司业务情况规划生产集群**

在经过了一轮完善的压测之后，小猛提交了一份压测报告给明哥，里面写清楚了压测的过程，在压测时候的机器各项指标的表现。接着小猛同时对生产集群的部署做了一些简单的规划。

这个RocketMQ集群实际上未来不光是服务于订单团队，还要服务于全公司，只不过现在因为公司规模很小，暂时先由订单团队来负责集群部署而已，所以在做集群规划的时候还是要考虑到全公司的情况。

就全公司的情况而言，实际上现在还处于创业成长期，即使在搞双11活动高峰的时候，公司后台系统的并发访问量也就是每秒上万，即使你多考虑一些，每秒几万的并发量也就最多了。

因此在部署的时候，小猛建议是对NameServer采用3台机器部署就足够了，而对于Broker而言采用6台机器来部署，2个Master Broker和4个Slave Broker，这样2个Master Broker每秒最多可以处理十几万消息，4个Slave Broker同时也能每秒提供高吞吐的数据消费，而且全面保证高可用性。

这样的一个生产部署架构，绝对是可以满足公司现在的消息吞吐量的

因此，实际上最终的部署方案还是如下图所示。      ![img](http://wechatapppro-1252524126.file.myqcloud.com/image/ueditor/12067800_1578388350.cn/txdocpic/0/94cb72db12d859b2a6ea0604b392dde7/0)       

**4、今日内容总结**

现在我们来总结一下今天学习到的内容：

1. 到底应该如何压测：应该在TPS和机器的cpu负载、内存使用率、jvm gc频率、磁盘io负载、网络流量负载之间取得一个平衡，尽量让TPS尽可能的提高，同时让机器的各项资源负载不要太高。
2. 实际压测过程：采用几台机器开启大量线程并发读写消息，然后观察TPS、cpu load（使用top命令）、内存使用率（使用free命令）、jvm gc频率（使用jstat命令）、磁盘io负载（使用top命令）、网卡流量负载（使用sar命令），不断增加机器和线程，让TPS不断提升上去，同时观察各项资源负载是否过高。
3. 生产集群规划：根据公司的后台整体QPS来定，稍微多冗余部署一些机器即可，实际部署生产环境的集群时，使用高配置物理机，同时合理调整os内核参数、jvm参数、中间件核心参数，如此即可

**End**

### 34 授人以渔：你们公司的MQ集群做过压测吗？生产集群是如何规划的？

今天的授人以渔也给大家一个任务，同样还是去找你们公司的MQ集群负责人了解一下：

- 他们对MQ集群做过压测吗？
- 使用什么样的机器配置做的压测？
- 使用多大规模的集群做的压测？如何压测的？
- 在压测的过程中发现单Broker的TPS最高有多少？
- 在压测过程中，cpu负载、内存使用率、jvm gc频率、磁盘io负载、网卡流量负载，这些值都是如何变化的？
- 在压测过后，是如何规划生产集群的？
- 目前公司线上MQ集群的TPS多高？机器资源的负载情况如何？能否抗住？

希望大家去了解这些问题，这对大家深入理解MQ技术有很大的好处，如果有什么探索心得体会，随时在评论区分享出来。同样如果在探索的时候遇到什么问题，也请在评论区提出来和我交流。

**End**

### 35 阶段性复习：一张思维导图给你梳理消息中间件集群生产部署架构规划

今天是一个思维导图进行阶段性梳理和复习的环节，我们还是按照之前的规矩，把最近这一个阶段学习到的知识体系通过思维导图的方式展现给大家

希望大家能对照这个思维导图进行阶段性复习，避免总是着急想要学习新的东西，应该及时把每个阶段学习到的内容进行巩固和消化。

同时要频繁的复习，对抗自己的记忆曲线，避免遗忘，把学习到的技术刻入你的脑海中，转化为你自己的东西。

​      ![img](http://wechatapppro-1252524126.file.myqcloud.com/image/ueditor/43149000_1578389169.cn/txdocpic/0/815783acea0449998d1740610b4f5d8b/0)       

我们可以参考上面的思维导图去一步一步梳理和复习学习到的知识体系

从消息中间件到底是个什么东西开始，然后考虑如何对MQ进行技术选型？

接着了解RocketMQ的核心技术原理，然后是RocketMQ的生产部署方案如何制定？

然后开始上手部署一个小规模的RocketMQ集群，同时做好集群的可视化监控，并且对小规模的RocketMQ集群进行生产级的参数调整，然后对RocketMQ集群进行压测，最后根据压测结果规划一个生产集群进行最终部署。

当这个阶段的内容都做完之后，你会发现下个阶段我们就可以正式进入基于RocketMQ集群完成系统架构改造的环节了。

**End**

### 36 阶段性复习：按照你们公司的真实负载，设计消息中间件集群生产架构

希望大家在梳理和复习完我们教给你的知识体系之后，同时去结合自己公司的情况做一下系统性的思考，包括如下的一些问题：

- 你们系统有没有使用MQ技术的业务场景？
- 你们公司是如何进行技术选型的？
- 你能对RocketMQ、Kafka、RabbitMQ三种技术的架构原理都进行一个思考和横向对比吗？
- 如果RocketMQ没有路由中心了能正常运转吗？
- 主从同步是否有数据一致性问题？
- 你们公司的MQ集群是采用什么样的部署架构？
- 你有没有动手完成一个小规模RocketMQ集群的部署？
- 你们公司都是如何对MQ集群进行可视化监控的？
- 你们公司的MQ集群是如何调整生产参数的？公司的MQ集群做过压测吗？你们公司的MQ集群生产环境是如何部署的？

希望大家重新复习和梳理这些问题，将学习到的知识深度和自己所在的公司业务、环境去结合，去思考，去找对应的MQ负责人请教，让自己对MQ技术的掌握深入到生产环境，深入到一线落地实践里去。

**End**

### 37 基于MQ实现订单系统的核心流程异步化改造，性能优化完成！

**1、万事俱备只欠东风：开始做项目！**

经过之前一段时间的学习、忙活以及折腾，小猛终于把RocketMQ的核心架构原理，还有小规模集群的部署和压测，以及最终生产环境的集群部署，全部都搞定了

目前小猛手头已经有了一套3台NameServer机器+6台Broker机器的生产集群，而且对集群的生产参数都进行了适当优化，足以抗下每秒十多万消息的处理。

小猛满意的盯着自己电脑屏幕上的一个生产部署架构图，回顾了一下自己的RocketMQ集群部署情况。

​      ![img](http://wechatapppro-1252524126.file.myqcloud.com/image/ueditor/28337900_1578389189.cn/txdocpic/0/20c18d97b7c4e9e7ed0851a5d4709569/0)       

现在既然已经有了一套MQ生产集群了，那下一步当然是基于MQ开始改造订单系统架构了！

应该全面在订单系统的各个环节引入MQ技术，来解决订单系统目前面临的各种技术问题，全面优化订单系统的各项指标！

**2、从哪里开始入手改造订单系统？**

小猛接着就开始思考了，之前跟明哥已经分析了很多订单系统目前面临的技术问题，到底应该从哪个点入手开始引入MQ技术进行架构改造呢？

针对这个问题，小猛再一次请教了一下明哥。

明哥听到这个问题之后，给小猛分析了一下自己的看法。目前订单系统面临的技术问题包括以下一些环节：

1. 下单核心流程环节太多，性能较差
2. 订单退款的流程可能面临退款失败的风险
3. 关闭过期订单的时候，存在扫描大量订单数据的问题
4. 跟第三方物流系统耦合在一起，性能存在抖动的风险
5. 大数据团队要获取订单数据，存在不规范直接查询订单数据库的问题
6. 做秒杀活动时订单数据库压力过大

针对这些问题，实际上比较合适的就是从第一个问题开始解决，因为下单流程性能较差是目前比较明显的问题，而且是比较严重影响用户体验的。而订单退款失败这种是属于小概率出现的问题，即使出现也可以通过人工处理给解决。

至于关闭过期订单存在大量订单数据扫描的问题，这个问题目前凸显还不严重，因为目前订单数据量还没有那么大。跟第三方物流系统的耦合导致系统性能抖动，也是小概率出现的，并不是经常出现的。

而大数据团队直接查订单数据库跑报表出来，目前压力有点大，但是还不会对订单库造成过大的影响。

至于秒杀时订单数据库压力过大，也不是目前的主要问题，因为秒杀活动不是经常有，而且目前即使压力过大，但是MySQL部署在高配置物理机上，基本上也能抗住的。

所以经过上述分析过后，明哥的建议是，从下单核心流程开始引入MQ技术进行改造，然后逐步解决订单退款失败问题、跟第三方物流系统耦合导致的性能抖动问题、大数据团队直接查询订单库的问题、秒杀活动时订单库压力过大的问题、关闭订单时扫描大量订单数据的问题。

**3、技术方案：通过引入MQ实现订单核心流程的异步化改造**

听完明哥的分析之后，小猛接下来就开始进入第一步，尝试在订单系统中引入MQ技术来实现订单核心流程中的部分环节的异步化改造了。

首先小猛先回顾了一下支付订单的核心流程，如下图所示。

​      ![img](http://wechatapppro-1252524126.file.myqcloud.com/image/ueditor/44611700_1578389189.cn/txdocpic/0/20747f27cf1ca2d78d3fd23cad7a8445/0)       

现在每次支付完一个订单后，都需要执行一系列的动作，包括：

- 更新订单状态
- 扣减库存
- 增加积分
- 发优惠券
- 发短信
- 通知发货

这会导致一次核心链路执行时间过长，可能长达好几秒种。

不知道大家是否遇到过一些APP，有时候你下单过后跳转到第三方支付的界面（比如支付宝或者微信），然后等你成功支付过后，退回到APP自己的界面上

此时APP上会显示一个圆圈不停的旋转，提醒你等待几秒钟让后台确认订单处理成功，这个等待的过程如果时间较长，往往对用户体验是很不好的。

所以实际上我们需要的一个效果是：在用户支付完毕后，只要执行最核心的更新订单状态以及扣减库存就可以了，保证速度足够快。

然后诸如增加积分、发送优惠券、发送短信、通知发货的操作，都可以通过MQ实现异步化执行。

因此在这个思路指导下，小猛画出了一个订单核心流程的改造图。

​      ![img](http://wechatapppro-1252524126.file.myqcloud.com/image/ueditor/57049000_1578389189.cn/txdocpic/0/de2bf8f5af78bc81d3b1aee447c84074/0)       

在上面的图里，订单系统仅仅会同步执行更新订单状态和扣减库存两个最关键的操作，因为一旦你支付成功，只要保证订单状态变为“已支付”，库存扣减掉，就可以保证核心数据不错乱。

然后订单系统接着会发送一个订单支付的消息到RocketMQ中去，然后积分系统会从RocketMQ里获取到消息，然后根据消息去累加积分

营销系统会从RocketMQ里获取到消息然后发送优惠券，推送系统会从RocketMQ里获取到消息然后推送短信，仓储系统会从RocketMQ里获取到消息然后生产物流单核和发货单，去通知仓库管理员打包商品，准备交接给物流公司去发货。

在上面的改造后的架构中，我们可以举个例子来计算一下引入MQ对订单核心流程的性能优化的效果。

比如更新订单状态需要耗费30ms，调用库存服务的接口进行库存扣减需要耗费80ms，增加积分需要耗费50ms，派发优惠券需要耗费60ms，发送短信需要耗费100ms（涉及与第三方短信系统交互，可能性能抖动会达到1秒+），通知发货需要耗费500ms（因为涉及到跟第三方物流系统交互以及与仓库管理系统交互，比较耗费时间，而且可能会性能抖动达到1秒+）。

如果没有进行架构改造，每次支付成功后都需要由订单系统调用大量的其他系统进行各种操作，可能一次订单核心链路的执行需要接近秒钟

而且如果第三方短信系统以及第三方物流系统出现性能抖动，那么可能一次核心流程就要几秒钟。

但是现在经过上述改造过后，一旦你支付成功，实际上订单系统只需要更新订单状态（30ms）+扣减库存（80ms）+发送订单消息到RocketMQ（10ms），一共120ms就可以了

对于终端用户而言，一旦支付成功退回到APP界面，还没等你反应过来，可能就显示给你订单支付成功的界面了，不会出现一个圆圈不停的旋转提醒你等待后台检查订单是否支付成功。

而积分系统、营销系统、推送系统、仓储系统都会自己从RocketMQ里去获取订单支付消息执行自己要处理的业务逻辑，不会再影响订单核心链路的性能。

**4、在订单系统中如何发送消息到RocketMQ？**

在小猛设计完上述方案之后，就要开始落地实施这个技术方案了，这里就涉及到了两个部分

一个是订单系统自身的改造，他需要去除掉调用积分系统、营销系统、推送系统以及仓储系统的逻辑，而改成发送一个订单支付消息到RocketMQ里去；

另外一个是积分系统、营销系统、推送系统以及仓储系统的改造，需要从RocketMQ里获取消息，然后根据消息执行自己的业务逻辑。

因此首先我们给大家看一个代码示例，比如原来的订单支付成功的接口如下所示：



![image.png](http://wechatapppro-1252524126.file.myqcloud.com/image/ueditor/68688900_1578389189.png)

现在的话，则需要对上述代码做一个改造，去除掉一些代码逻辑，然后增加一个发送消息到RocketMQ的代码逻辑。

如果要发送消息到RocketMQ，则首先需要在项目里引入下面的依赖：



![image.png](http://wechatapppro-1252524126.file.myqcloud.com/image/ueditor/80636800_1578389189.png)



接着我们需要封装如下的一个RocketMQ生产者的类，类很简单，具体类的注释都写在下面了，大家看一下类的注释就知道是怎么用的。



![image.png](http://wechatapppro-1252524126.file.myqcloud.com/image/ueditor/91801200_1578389189.png)



通过上述代码就可以让订单系统把订单消息发送到RocketMQ的一个Topic里去了。

**5、订单消息会进入哪个Broker里去呢？**

那么大家肯定会疑惑了，按照我们部署的MQ集群而言，Master Broker有两台，那么此时消息会进入哪个Master Broker里去呢？

实际上我们之前说过，Topic是一个逻辑上的概念，实际上他的数据是分布式存储在多个Master Broker中的

如下图所示

​    ![img](http://wechatapppro-1252524126.file.myqcloud.com/image/ueditor/6572200_1578389190.cn/txdocpic/0/e66bc683fb9e9a9fb153d1a43077a8dc/0)       

我们可以看到图里两个红圈，意思就是“TopicOrderPaySuccess”这个Topic的数据会分散在两个Broker中。

因此当你发送一个订单消息过去的时候，会根据一定的负载均衡算法和容错算法把消息发送到一个Broker中去。

当然肯定很多朋友会问了，那么Topic的数据到底是分散在哪几个Broker上？可以分散在多少个Broker上？Producer到底是如何选择Broker发送消息过去的？

这些问题大家别着急，现阶段先了解到这个程度就行，后面专栏里有很多RocketMQ底层实现机制的分析，到时候这些问题都会迎刃而解的。

**6、其他系统改造为从RocketMQ中获取订单消息**

接着下一步就要推动积分系统、营销系统、推送系统、仓储系统的负责人在自己的系统里改造为从RocketMQ中去获取订单消息，然后根据获取到的消息执行对应的业务逻辑

因此小猛给出了一段示例性的从RocketMQ中消费消息的代码。



![image.png](http://wechatapppro-1252524126.file.myqcloud.com/image/ueditor/15311700_1578389190.png)![img](blob:https://admin.xiaoe-tech.com/435f2cbd-3114-417b-8d12-002902f108c3)

![image.png](http://wechatapppro-1252524126.file.myqcloud.com/image/ueditor/29757100_1578389190.png)![img](blob:https://admin.xiaoe-tech.com/94846495-3c42-4274-b092-47b37c94fedd)

![image.png](http://wechatapppro-1252524126.file.myqcloud.com/image/ueditor/43154700_1578389190.png)![img](blob:https://admin.xiaoe-tech.com/45cbf839-b08c-462b-8c1a-219213d34c86)

通过上述代码，积分系统、营销系统、推送系统、仓储系统，就可以从RocketMQ里消费“TopicOrderPaySuccess”中的订单消息，然后根据订单消息执行增加积分、发送优惠券、发送短信、通知发货之类的业务逻辑了。

这些系统在RocketMQ部署图中对应的实际上就是下图中画圈的消费者部分。

​      ![img](http://wechatapppro-1252524126.file.myqcloud.com/image/ueditor/55549300_1578389190.cn/txdocpic/0/8f0b26a73bdf6f62f1d826b93efb6130/0)       

**7、订单核心流程改造的流程梳理**

接着我们来做一个小小的总结，当各个系统都落地该方案之后，并且部署上线之后，订单系统就会如下图红圈所示，每次支付成功后仅仅更新自己的订单状态，同步扣减库存，接着就会发送消息到RocketMQ里去。

​      ![img](http://wechatapppro-1252524126.file.myqcloud.com/image/ueditor/75036300_1578389190.cn/txdocpic/0/9b06855eebebb2c44f3b1ced57151ea7/0)       

然后推送系统、营销系统、积分系统、仓储系统一旦部署了改造后的代码，就会如下图红圈所示，从RocketMQ里不停的获取订单消息并且执行对应的业务逻辑。



​      ![img](http://wechatapppro-1252524126.file.myqcloud.com/image/ueditor/89299900_1578389190.cn/txdocpic/0/9c7659176143f0f77eb4acf5e8d48cd7/0)       

通过上述改造，可以将订单核心流程的性能从1秒~几秒的情况优化到100ms+，可以实现10倍性能提升的效果。

**End**

### 38 授人以渔：如果在你们系统的核心流程引入MQ，应该如何改造系统？

今天的授人以渔环节，希望大家可以结合学习到的订单系统核心流程改造的思路，去思考一下，你们系统里的核心链路有没有类似的环节过多性能较差的问题？

我这里所谓的核心链路，不是说查询链路，即并不是一次请求全部是查询。而是说的是数据更新链路，即一次请求过后会对你的各种核心数据进行更新，同时还会调用其他服务或者系统进行数据更新或者查询，这样的一个链路叫做系统的核心链路。

针对这样的系统核心数据链路，你考虑一下有没有哪些环节拖累了性能？

你能否通过在系统里打印日志的方式，排查出来核心数据链路中的每个环节的耗时是多长？哪些环节是最耗时的？

有没有可能引入MQ技术把一些耗时的步骤做成异步化的方式，来优化核心数据链路的性能？

如果可以的话，你应该如何设计这个技术方案？哪些环节同步执行？哪些环节要异步执行？

希望大家深度结合自己的项目思考一下，有什么心得体会可以在评论区分享出来。

大家记住一点，努力将学到的知识消化掉并且结合自己的项目去思考如何落地实践，这样你出去面试的时候才能很好的结合自己的项目聊技术。

否则仅仅只是吸收和输入知识，最后出去面试还是只能背出来我们教给你的知识体系，但是并没有完全转化为你的东西。

**End**

### 39 基于MQ实现订单系统的第三方系统异步对接改造，解耦架构完成！

**1、下一步要解决订单系统哪个问题？**

小猛在推动完成了订单系统的核心流程的异步化改造后，让核心流程的性能一下子提升了10倍以上，从原来需要1秒甚至几秒才能完成，到现在核心流程只需要执行订单状态更新以及库存扣减两个步骤，以及发送一个消息到RocketMQ里去，仅仅需要耗时100ms。

这个优化的效果让所有人都很满意，因此明哥继续支持小猛对下一个问题引入MQ进行改造

那么接着应该解决订单系统哪个问题呢？小猛这个时候回顾了一下之前明哥列出来的问题列表：

1. 下单核心流程环节太多，性能较差
2. 订单退款的流程可能面临退款失败的风险
3. 关闭过期订单的时候，存在扫描大量订单数据的问题
4. 跟第三方物流系统耦合在一起，性能存在抖动的风险
5. 大数据团队要获取订单数据，存在不规范直接查询订单数据库的问题
6. 做秒杀活动时订单数据库压力过大

此时小猛已经在上面的列表中划掉了第一项，还剩下5个问题。

这个时候他将目光移动到了第四条，也就是“跟第三方系统耦合在一起，性能存在抖动的风险”。

这个时候他仔细思考了一下，将目光转移到了目前的订单核心流程图上去。

他发现在这个订单核心流程图里，可以非常清晰的看到，订单系统间接耦合的第三方系统有两个：

一个是第三方短信系统，是用来推送短信给用户的，一个是第三方物流系统，用生成物流单通知物流公司来收货和配送的。

我们看下面的图画圈的地方，就标识出来了这两个东西。

​      ![img](http://wechatapppro-1252524126.file.myqcloud.com/image/ueditor/30989500_1578389206.cn/txdocpic/0/d058b394a5b22633d73a2d34fa423793/0)       

实际上如果按照以前最早的订单核心流程，订单系统会同步调用推送系统，然后推送系统调用第三方短信系统去发送短信给用户，接着订单系统会同步调用仓储系统，然后仓储系统调用第三方物流系统去生成物流单以及通知发货。

因此在最早的流程中，其实订单系统是间接性的跟第三方短信系统和第三方物流系统耦合在一起的，这样的话，一旦第三方系统出现了性能抖动就会影响到订单系统的性能。

比如正常第三方短信系统发送一个短信，只需要100ms，结果某一天突然性能下降变成发送短信需要1s了，此时会连带导致订单系统的性能也急剧下降。

但是似乎小猛仔细凝视上面的架构图，他发现现在引入了MQ之后，似乎订单核心流程已经变化了，然后对两个第三方系统的耦合问题似乎也有所改变了

既然如此，不如下一个问题就看看这个第三方系统的耦合问题如何解决吧！

**2、现在订单系统还跟第三方系统耦合吗？**

小猛盯着上面的架构图，开始思考一个问题，现在订单系统还跟两个第三方系统耦合在一起吗？

因为实际上订单系统现在已经不需要直接调用推送系统和仓储系统了，仅仅只是发送一个消息到RocketMQ而已

所以小猛突然灵光一闪发现了一个问题，那就是订单系统跟第三方系统耦合导致性能抖动的问题，其实已经解决了！

因为通过引入MQ到架构里，现在订单系统已经成功的跟推送系统以及仓储系统解耦了，如下面图里的红圈所示。

​      ![img](http://wechatapppro-1252524126.file.myqcloud.com/image/ueditor/51112800_1578389206.cn/txdocpic/0/8972b5661d7f10f0c0f44efe856c4de1/0)       

所以现在订单系统已经跟仓储系统和推送系统没关系了，只不过是仓储系统自己跟第三方物流系统耦合，推送系统自己跟第三方短信系统耦合而已！

此时即使第三方系统出现了严重的性能抖动，甚至是接口故障无法访问，也跟订单系统没任何关系！

因此比如第三方物流系统出现了性能抖动，此时只会影响到仓储系统而已，仓储系统调用第三方物流系统的接口时会出现短暂性的速度较慢的问题，如下图中红圈所示。

​      ![img](http://wechatapppro-1252524126.file.myqcloud.com/image/ueditor/66773100_1578389206.cn/txdocpic/0/80835393ceffd743479d191b98bf11be/0)       

所以实际上在订单系统问题列表中的与第三方系统耦合的问题，已经被解决掉了，小猛想到这里，又把下面的第4项给划掉了。

1. 下单核心流程环节太多，性能较差
2. 订单退款的流程可能面临退款失败的风险
3. 关闭过期订单的时候，存在扫描大量订单数据的问题
4. 跟第三方系统耦合在一起，性能存在抖动的风险
5. 大数据团队要获取订单数据，存在不规范直接查询订单数据库的问题
6. 做秒杀活动时订单数据库压力过大

**3、对RocketMQ的使用做一点进一步的探索？**

如此轻松就解决了一个订单系统的耦合问题，小猛觉得真是太愉快了，但是另外一方面小猛觉得既然这个任务如此轻松就完成了，那么不如抽时间对RocketMQ的使用做一点进一步的探索，然后给各个团队的兄弟做一次技术分享

这样可以让其他团队的兄弟都了解一下RocketMQ的使用方式都有哪几种，相信对各个团队初步使用RocketMQ是比较有意义的。

说到做到，小猛很快就对RocketMQ的使用方式做了进一步的探索，并且梳理出来了一份技术分享PPT，然后约了各个部门的同事，做了一次技术分享。

**4、什么叫做同步发送消息到RocketMQ？**

今天分享的第一个点：什么叫做同步发送消息到RocketMQ？

小猛打开了一个代码片段如下所示：



![image.png](http://wechatapppro-1252524126.file.myqcloud.com/image/ueditor/79548300_1578389206.png)



大家可以看到上面的代码片段就是我们目前发送消息到RocketMQ里去的代码，实际上这种方式就是所谓的同步发送消息到MQ

那么什么叫同步发送消息到MQ里去？

所谓同步，意思就是你通过这行代码发送消息到MQ去，SendResult sendResult = producer.send(msg)，然后你会卡在这里，代码不能往下走了

你要一直等待MQ返回一个结果给你，你拿到了SendResult之后，接着你的代码才会继续往下走。

这个就是所谓的同步发送模式。

**5、什么叫做异步发送消息到RocketMQ？**

接着我们看一下所谓的异步发送消息到MQ的代码是什么样的

首先在构造Producer的时候加入下面红框中的代码：

![image.png](http://wechatapppro-1252524126.file.myqcloud.com/image/ueditor/89978500_1578389206.png)

接着把发送消息的代码改成如下所示：



![image.png](http://wechatapppro-1252524126.file.myqcloud.com/image/ueditor/2413600_1578389207.png)

这个意思就是说，你把消息发送出去，然后上面的代码就直接往下走了，不会卡在这里等待MQ返回结果给你！

然后当MQ返回结果给你的时候，Producer会回调你的SendCallback里的函数，如果发送成功了就回调onSuccess函数，如果发送失败了就回调onExceptino函数。

这个就是所谓的异步发送，异步的意思就是你发送消息的时候不会卡在上面那行代码等待MQ返回结果给你，会继续执行下面的别的代码，当MQ返回结果给你的时候，会回调你的函数！

**6、什么叫做发送单向消息到RocketMQ？**

还有一种发送消息的方法，叫做发送单向消息，就是用下面的代码来发送消息：



![image.png](http://wechatapppro-1252524126.file.myqcloud.com/image/ueditor/12610700_1578389207.png)



这个sendOneway的意思，就是你发送一个消息给MQ，然后代码就往下走了，根本不会关注MQ有没有返回结果给你，你也不需要MQ返回的结果，无论发送的消息是成功还是失败，都不关你的事。

**7、这几种发送消息的方式到底该用哪一种？**

此时肯定会有很多人有疑问了，你告诉了我三种消息发送的模式，那么这个时候到底应该要用哪一种呢？

大家别着急针对这个问题，后续我们要结合消息不丢失、消息顺序性等案例场景来分析，你到底是适合同步消息？异步消息？还是单向消息？这个问题需要在后续的讲解中逐步展开。

目前大家只要知道，发送消息给MQ有这几种方式就可以了。

**8、什么叫做Push消费模式？**

小猛说完了发送消息给MQ的几种模式，接着讲到了消费消息的问题，首先他先打开了下面的代码片段，也就是目前各个系统从RocketMQ中消费消息的代码片段：

![image.png](http://wechatapppro-1252524126.file.myqcloud.com/image/ueditor/28492000_1578389207.png)

大家注意里面Consumer的类名：DefaultMQPushConsumer。

从类名中我们可以提取出来一个关键的信息：Push。其实从这里我们就能看出来，当前我们使用的消息消费实际上是Push模式。

那么什么是Push消费模式呢？

其实很简单，就是Broker会主动把消息发送给你的消费者，你的消费者是被动的接收Broker推送给过来的消息，然后进行处理。

这个就是所谓的Push模式，意思就是Broker主动推送消息给消费者。

**9、什么叫做Pull消费模式？**

小猛接着打开了下面的代码片段，这是RocketMQ官方提供的Pull消费模式的代码片段：

![image.png](http://wechatapppro-1252524126.file.myqcloud.com/image/ueditor/45319000_1578389207.png)



在上述代码中，我们可以看到使用的Consumer类是DefaultMQPullConsumer，从名字里就可以看到使用了Pull消费模式。

也就是说，Broker不会主动推送消息给Consumer，而是消费者主动发送请求到Broker去拉取消息过来。

**10、到底该使用Push模式还是Pull模式来消费？**

看到这里又有很多朋友要问了，那么我们到底应该使用Push模式还是Pull模式来消费？

其实这个要看具体的场景了，我们现在暂时先不要做太多的深究，只要先知道有两种消费模式就可以了。

后面我们会通过更多的案例分析来思考在什么场景下应该使用哪种消费模式，所以大家不用太心急。

**11、一点小小的总结**

到目前为止，我们发现通过引入MQ到订单核心流程中，已经解决了两个问题：

1. 核心流程环节过多性能较差的问题
2. 跟第三方系统耦合导致性能容易抖动的问题

另外我们还探索了RocketMQ使用的几种方式，包括同步发送消息、异步发送消息、单向发送消息，Push消费模式以及Pull消费模式。

**End**

### 40 授人以渔：如果你们系统要对接第三方系统，应该如何设计？

今天授人以渔的环节，希望大家思考三个问题。

**第一个问题**，思考一下你们的系统是否跟第三方系统存在耦合的问题？尤其是在核心数据链路中，是否存在因为耦合了第三方系统导致性能经常出现抖动的问题？

如果有类似的问题，能否在核心链路中引入MQ来跟第三方系统进行解耦？如果解耦之后能对你们核心链路的性能有多高的提升？

**另外一个问题**，大家去调研思考一下Kafka和RabbitMQ在使用的时候，有几种消息发送模式？有几种消息消费模式？

你们系统如果使用了MQ技术的话，那么你们平时使用的哪种消息发送模式？你们平时使用的是哪种消息消费模式？为什么？

**第三个问题**，大家先提前自己思考一下，几种消息发送模式下，在什么场景应该选用什么消息发送模式？几种消息消费模式下，在什么场景下应该选用什么消息消费模式？

思考能力极为重要，可以提升你在公司里解决技术问题的能力，也可以让你在面试的时候针对自己不熟悉的问题也可以瞬间给出靠谱的答案，有随机应变的本事。

主动思考能力也是目前国内程序员最缺乏的一个能力。希望大家积极思考，在评论区给出上面几个问题的思考结果。

**End**

### 41 基于MQ实现订单数据同步给大数据团队，应该如何设计？

**1、下面应该解决哪个问题？**

小猛已经成功解决了订单系统的两个问题，接着开始思考下一个应该解决的问题。小猛对着订单系统的问题列表陷入了思考：

1. 下单核心流程环节太多，性能较差
2. 订单退款的流程可能面临退款失败的风险
3. 关闭过期订单的时候，存在扫描大量订单数据的问题
4. 跟第三方系统耦合在一起，性能存在抖动的风险
5. 大数据团队要获取订单数据，存在不规范直接查询订单数据库的问题
6. 做秒杀活动时订单数据库压力过大

目前第一个和第四个问题都已经解决掉了，接下来哪个问题是比较紧急需要解决的呢？

小猛想了一下，觉得订单退款失败并不是太紧急的问题，因为这个问题偶然才会出现

另外订单数据量也不是特别大，因此关闭订单时扫描过多订单的问题也不是特别紧急。

这个时候，小猛认为大数据团队每天都要在订单数据库上执行上百次几百行的复杂大SQL，有时候会导致订单数据库性能抖动这个问题，是当前应该要解决的。

**2、大数据团队的几百行大SQL是如何影响订单数据库的？**

小猛想到这里，先回忆了一下大数据团队的几百行大SQL是如何影响订单数据库的

小猛在纸上迅速的画出了下面的一幅图。      ![img](http://wechatapppro-1252524126.file.myqcloud.com/image/ueditor/58601900_1578389220.cn/txdocpic/0/178b1ff9548d1c9b60a104aae11a32ab/0)       

在图里很清晰地看到，大数据团队的BI系统每天都会直接在订单数据库里执行上百次几百行的大SQL，而每次一个几百行大SQL的执行需要耗时几秒到十几秒不等

每次这样一个几百行的大SQL执行，都会导致MySQL数据库服务器的资源负载急剧抖动，会让CPU、内存、磁盘IO的负载都瞬间升高。

而一旦MySQL数据库的资源负载瞬间升高，会导致订单系统在MySQL数据库上执行的SQL语句性能出现急剧下降，因此会导致订单系统的性能也出现抖动。

这其实就是大数据团队目前对订单系统的影响。

**3、如何避免大数据团队直接查询订单数据库？**

小猛接着继续思考，如何解决这个问题呢？

实际上要解决这个问题，就必须要避免大数据团队直接查询订单数据库

那么又如何避免大数据团队直接查询订单数据库呢？这是一个最关键的问题。

其实很简单，完全可以由订单系统将订单数据推送到一个MQ里，然后大数据团队从MQ里获取订单数据，接着将订单数据落地到自己的存储中去

比如最简单的办法，就是将订单数据落地到大数据团队自己的一个MySQL数据库中，然后从自己的MySQL数据库里统计报表。

小猛一边思考，一边在纸上刷刷的画出了下面这个草图。

​      ![img](http://wechatapppro-1252524126.file.myqcloud.com/image/ueditor/69595100_1578389220.cn/txdocpic/0/529615575b5575cfae51bfe48029c8ff/0)      

如果能够采用这样的一个架构，那么大数据团队的几百行的大SQL就不会对订单数据库造成任何影响了。

**4、TopicOrderPaySuccess里的订单支付成功消息可以使用吗？**

下一个问题，订单系统应该如何将订单数据发送到RocketMQ里去呢？

之前我们讲过，已经让订单系统在支付成功的时候，将订单支付成功的消息发送到了RocketMQ里去了，然后其他系统会订阅这个订单支付成功的消息去进行对应的业务处理。

但是这个订单支付成功的消息，足够让大数据团队使用吗？

显然是不行的，因为大数据团队需要的是跟订单数据库一模一样的一份完整的数据，而不仅仅是订单支付成功的消息，所以不能直接使用之前“TopicOrderPaySuccess”这个Topic里的消息。

因此，我们还是需要想办法将完整的订单数据都发送到RocketMQ里去，然后让大数据团队去获取。

**5、如何将完整的订单数据发送到RocketMQ里去？**

这时小猛开始思考如何将完整的订单数据发送到RocketMQ里去

实际上一个比较简单的办法，就是在订单系统中但凡对订单执行增删改类的操作，就把这种对订单增删改的操作发送到RocketMQ里去。

然后大数据团队的数据同步系统从RocketMQ里获取到订单增删改的操作，就会在自己的数据库里执行一样的增删改操作。

通过还原执行一样的insert、update和delete语句，就可以在自己的数据库里还原出来一样的订单数据。

小猛边想边画出了下面的草图。

​      ![img](http://wechatapppro-1252524126.file.myqcloud.com/image/ueditor/83129600_1578389220.cn/txdocpic/0/a76535a5774569e3281f2cebefc88822/0)       

但是这种方案的一个问题就是订单系统为了将数据同步给大数据团队，必须在自己的代码里耦合大量的代码去发送增删改操作到RocketMQ，这会导致订单系统的代码出现严重的污染，因为这些发送增删改操作到RocketMQ里的代码是跟订单业务没关系的。

小猛灵机一动，想到了另外一个好办法。前段时间他听了其他团队的一个技术分享，目前公司已经部署了一种MySQL Binlog同步系统

这种系统会监听MySQL数据库的Binlog，所谓Binlog大致可以理解为MySQL的增删改操作日志。

然后MySQL Binlog同步系统会将监听到的MySQL Binlog（也就是增删改操作日志）发送给你的系统，让你来处理这些增删改操作日志。

这种MySQL Binlog系统现在是有不少成熟的开源技术方案的，比如阿里开源的Canal，以及Linkedin开源的Databus，都可以监听MySQL Binlog，然后将MySQL Binlog发送给你的系统，交给你去处理。

因此完全可以将数据同步方案修改为如下所示，采用Canal监听MySQL Binlog，然后直接发送到RocketMQ里

然后大数据团队的数据同步系统从RocketMQ中获取到MySQL Binlog，也就获取到了订单数据库的增删改操作，接着把增删改操作还原到自己的数据库中去就可以。

小猛想着就画出了下面的草图。

​      ![img](http://wechatapppro-1252524126.file.myqcloud.com/image/ueditor/2686800_1578389221.cn/txdocpic/0/23463fb5f946ebd35eb12f6b4ca3f9f2/0)       

而且这样的一套方案还有一个额外的好处，就是由订单技术团队将完整的订单数据库的MySQL Binlog推送到RocketMQ里

无论是大数据团队，还是未来公司的其他技术团队，比如说开放平台团队，人工智能团队，等等，只要想要订单数据，都可以直接从这个RocketMQ里去获取完整的订单数据。

小猛想着想着，在草图中继续加入了下面的一些东西。

   ![img](http://wechatapppro-1252524126.file.myqcloud.com/image/ueditor/21567100_1578389221.cn/txdocpic/0/1b0598483a2eb267980e622c833cc439/0)       

说到这里，我们要给大家解释一下，实际上大数据团队并没有必要仅仅只通过MySQL来出数据报表，完全可以采用Hadoop、Spark、Flink等大数据技术来出数据报表。

因此实际上看起来大数据团队那部分的图应该是如下图所示的。

​      ![img](http://wechatapppro-1252524126.file.myqcloud.com/image/ueditor/38530800_1578389221.cn/txdocpic/0/b820bf2d91eed17a27ec35e87c55efd4/0)       

**6、一点小小的总结**

今天的内容讲完了，我们来做一点小小的总结，我们今天分析了目前大数据团队对订单数据库造成的压力以及原因，接着分析了解决这个问题的方案，就是将订单数据同步给大数据团队，让他们自己处理。

然后我们一步步分析了如何将数据同步给大数据团队，先是考虑在订单系统代码内部嵌入一些额外的代码，将订单的增删改操作发送到RocketMQ里，但是后来发现这样会导致污染订单系统的代码。

所以后来我们提出了一个完美的解决方案，就是用Canal、Databus这样的MySQL Binlog同步系统，监听订单数据库的binlog发送到RocketMQ里

然后大数据团队的数据同步系统从RocketMQ里获取订单数据的增删改binlog日志，还原到自己的数据存储中去，可以是自己的数据库，或者是Hadoop之类的大数据生态技术。

然后大数据团队将完整的订单数据还原到自己的数据存储中，就可以根据自己的技术能力去出数据报表了，不会再影响订单系统的数据库了。

到这里为止，小猛发现自己通过MQ技术又解决掉了订单系统的一个问题，他列出了下面的问题列表：

1. 下单核心流程环节太多，性能较差
2. 订单退款的流程可能面临退款失败的风险
3. 关闭过期订单的时候，存在扫描大量订单数据的问题
4. 跟第三方系统耦合在一起，性能存在抖动的风险
5. 大数据团队要获取订单数据，存在不规范直接查询订单数据库的问题
6. 做秒杀活动时订单数据库压力过大

**End**

### 42 授人以渔：对其他团队要获取你们核心数据的问题，应该如何解决？

今天的授人以渔环节，我们希望大家思考以下一些问题，你们公司里有没有那种其他团队要获取你们的核心数据的情况？

是直接从你们数据库里查询？还是用了其他的什么数据同步方案？

如果你们已经有数据同步方案了，那么目前的方案是否有什么问题？其他团队从你们这里获取数据是否造成了什么压力？如果目前的方案有问题的话，应该如何改进？

即使目前没有人从你这里获取数据，那么你觉得你这里有什么核心数据是最有价值的？

希望大家结合自己公司的业务思考一下，是否有可能有其他团队需要从你这里获取数据？如果要从你这里获取数据，你又应该如何设计数据同步方案？

希望大家对上述问题进行深度的思考，然后在评论区给出你们的思考结果。

**End**

### 43 秒杀系统的技术难点以及秒杀商品详情页系统的架构设计

**1、下一个要解决的问题是什么？**

小猛在最近一段时间研究了MQ技术，并且合理的为公司搭建了一套RocketMQ集群之后，立马就将MQ技术引入到了订单系统里，解决掉了好几个之前比较棘手的问题

小猛看了一下问题清单：

（1）下单核心流程环节太多，性能较差

（2）订单退款的流程可能面临退款失败的风险

（3）关闭过期订单的时候，存在扫描大量订单数据的问题

（4）跟第三方系统耦合在一起，性能存在抖动的风险

（5）大数据团队要获取订单数据，存在不规范直接查询订单数据库的问题

（6）做秒杀活动时订单数据库压力过大

目前已经解决了3个技术问题了，还剩下的有订单退款失败、扫描大量订单、秒杀活动压力过大这3个问题了

这个时候小猛开始思索了，下一个应该解决哪个问题呢？正想着这个事儿呢，明哥来找他了。

明哥告诉了小猛一个消息，最近公司的运营花了很多钱做活动拉新用户，公司APP的日活用户一直在增长

现在已经明显发现每天高峰时间公司搞秒杀活动的时候，比以前有更多的用户在某个时间点蹲守在手机APP前。特价秒杀商品时间一到，就有大量的并发请求过来，系统压力非常大

我们看下面的图：

​      ![img](http://wechatapppro-1252524126.file.myqcloud.com/image/ueditor/63564500_1578389233.cn/txdocpic/0/3b9dfec0a9dc6ce969171d6fba153be4/0)    

如果仅仅是订单系统自己本身压力过大，还不是太大的问题。因为订单系统目前部署了20台4核8G的机器，整个集群抗每秒上万请求压力是可以的，即使后续用户量越来越大，大不了就是给订单系统加更多的机器就可以了。

但是这里有一个问题，20台订单系统的机器都是访问同一台机器上部署的MySQL数据库的，那一台数据库服务器目前经常在晚上秒杀活动的时候，瞬时并发量达到上万。

所以最近几天明显发现数据库的负载越来越高，比如CPU、IO、内存、磁盘的负载几乎都快要到极限了，看下面的图。      ![img](http://wechatapppro-1252524126.file.myqcloud.com/image/ueditor/78475200_1578389233.cn/txdocpic/0/37f563d0d26028bbe389e2740f3d168e/0)       

所以明哥说，整个公司各个技术团队都将要为秒杀活动进行系统优化，务必让各个系统可以用合理的架构、有限的机器资源去抗下来未来越来越多用户参与的秒杀活动，订单系统作为公司核心的交易系统，也必然要参与到本次优化中去。

而且这次架构优化，将会由各个技术团队的leader直接带队负责，小猛要全程参与到里面。

小猛一听，内心兴奋极了，因为终于有机会参与到公司的高并发系统架构优化里来了。

**2、秒杀活动压力过大怎么办？难道是加机器吗？**

今天明哥召开了一个订单技术团队内部的会议，给大家来介绍目前面临公司系统的整体情况，以及兄弟团队的秒杀架构优化方案。

首先明哥向订单团队的弟兄们抛出了**第一个问题**，秒杀活动目前压力过大，应该如何解决？是不是简单的堆机器或者加机器就可以解决的？

比如给订单系统部署更多的机器，是不是可以抗下更高的并发？

这个是没问题的，订单系统自己是可以通过部署更多的机器进行线性扩展的。

但是第二个问题来了，那么数据库呢？是不是也要部署更多的服务器，进行分库分表，然后让更多的数据库服务器来抗超高的数据库高并发访问？

这个思路是这样的，所谓分库分表，就是把目前的一台数据库服务器变成多台数据库服务器，然后把一张订单表变成多张订单表。

举个例子，目前假设订单表里有1200万条数据，然后有一台数据库服务器，如果我们现在变成3台数据库服务器，那么可以在每台数据库服务器里放400万订单数据，这就是所谓的分库分表

我们看下面的图      ![img](http://wechatapppro-1252524126.file.myqcloud.com/image/ueditor/93304500_1578389233.cn/txdocpic/0/b45b9f657fb74c4ebac3adba7f63452b/0)    

这种做法的好处是什么呢？

比如未来订单系统的整体访问压力达到了每秒3万请求了，此时订单系统通过扩容可以部署很多机器，然后其中1万请求写入到一台数据库服务器，1万请求写入到另一台数据库服务器，另外1万请求写入最后一台数据库服务器，就好像下面的图这样子。      ![img](http://wechatapppro-1252524126.file.myqcloud.com/image/ueditor/4285800_1578389234.cn/txdocpic/0/2d287062b191736c6c512a58d45b4ba7/0)       

这样不就可以通过增加更多的数据库服务器轻松的抗下更高的并发请求了吗？但是事实上这个方案大家觉得靠谱吗？

答案是**不太靠谱**的，除非是技术能力比较弱的公司，没有厉害的架构师去利用已有的技术合理设计优秀的架构，才会用这种堆机器的方法简单的来抗下超高的并发。

因为如果用堆机器的方法来解决这个问题，必然存在一个问题，就是随着你的用户量越来越大，你的并发请求越来越多，会导致你要不停的增加更多的机器

如果现在你每秒的并发请求量是1万，可能你就需要20台4核8G的订单服务器+1台高配置的数据库服务器，就可以扛下来了。

但是如果你未来用户量增长10倍，每秒有10万并发请求呢？难道你就直接让订单系统部署200台机器？然后将数据库服务器增加到10台？这样会导致你公司的服务器成本急剧飙升！

所以解决问题往往不能用这种简单粗暴堆机器的方案！

**3、巧妙的架构设计帮公司节省巨大成本**

会议进行到这里，明哥直接代表公司的技术高层做了一个总结：为了应对秒杀活动这种特殊场景，不能采取无限制的扩容服务器的方案，而应该是利用各种技术去合理设计更加优秀的架构，在有限的机器资源条件下，去抗下更高的并发！

因此我们不能仅仅依赖于最简单粗暴的堆机器的策略，而是要仔细的分析秒杀活动进行时的核心请求链路，然后精心设计架构，优雅的抗下越来越高的并发量。

**4、不归订单管的部分：高并发的商品详情页请求**

明哥接着介绍，其实秒杀活动主要涉及到的并发压力就是两块，**一个是高并发的读，一个是高并发的写。**

我们还是从用户参与秒杀活动的实际场景入手，一点一点从业务到技术的来进行分析。

首先大家可以思考一下，平时大量的用户是怎么参与到秒杀活动里来的？

往往是这样，很多人都知道我们的APP每天晚上比如8:30会有一波秒杀商品开始售卖，因此每次到了晚上8:30之前，就有很多用户会登录我们的APP，然后在APP前坐等秒杀特价商品。

所以这个时候，必然出现一种场景，就是首先大量用户会拿着APP不停的刷新一个秒杀商品的页面

我们看下面的图

​      ![img](http://wechatapppro-1252524126.file.myqcloud.com/image/ueditor/21132700_1578389234.cn/txdocpic/0/b9bbadfe1aab1b5e90f58fef637417da/0)       

那么这些秒杀商品页面是从哪儿加载出来的呢？

本质上来说是从商品技术团队负责的商品详情页系统中加载出来的，我们看下面的图，图中引入了一个商品详情页系统的概念，他负责提供我们看到的各种秒杀商品页面。

​      ![img](http://wechatapppro-1252524126.file.myqcloud.com/image/ueditor/38003700_1578389234.cn/txdocpic/0/1f0f7e5483812e243d748b662aaee268/0)       

所以首先这个商品详情页系统就是在秒杀活动开始之前最先被大量用户高并发访问的一个系统了！

大家可以思考一个问题，如果没有秒杀活动的时候，其实大量的用户是分散在不同的时间段里来逛我们的APP的，而且逛的是不同的人会看不同的商品的页面。

但是在秒杀活动的时候，他面临的第一个问题就是，可能几十万人，甚至百万级的用户，会同一时间频繁的访问**同一个秒杀商品的页面**

比如“3折抢购原价6888的手机，限售100台”这样的活动，可能有几十万人在8:30之前会集中访问这个秒杀商品的活动页面，对商品详情页系统造成过巨大的访问压力。

**5、商品团队的秒杀架构优化：页面数据静态化**

因此明哥接着开始讲解，商品技术团队是如何解决秒杀商品活动页面被同一个时间点的大量用户频繁访问，造成商品详情页系统压力过大的问题。

实际上商品技术团队针对这个问题，采取的是**页面数据静态化+多级缓存**的方案。

首先第一步，秒杀商品页面必须是将其数据做到静态化，这是什么意思呢？

简单来说是这样，如果让秒杀商品页面是动态化的，那么每次一个用户只要访问这个商品详情页，就必须发送一次请求到后端的商品详情页系统来获取数据。

比如商品的标题、副标题、价格、优惠策略、库存、大量的图片、商品详情说明、售后政策等等，这一大堆的东西都是商品详情页的数据。

那么你可以选择让用户浏览这个秒杀商品的时候，每次都发送请求到后台去加载这些数据过来，然后渲染出来给用户看这个商品页面，这就是所谓的动态模式。

我们看下面的图里画圈的地方，很明显就是这种方式。

​      ![img](http://wechatapppro-1252524126.file.myqcloud.com/image/ueditor/50120800_1578389234.cn/txdocpic/0/bea107e618a7ffc0fbf36b3266829a55/0)       

如果这商品详情页里的大量数据都是存储在商品团队的数据库里的，那么岂不是大量的用户同时频繁访问这个商品详情页，会直接导致商品详情页系统承受高并发的访问？同时导致商品数据库承受高并发的访问？

所以首先需要将这个秒杀活动的商品详情页里的数据做成静态化的，也就是说提前就从数据库里把这个页面需要的数据都提取出来组装成一份静态数据放在别的地方，避免每次访问这个页面都要访问后端数据库。

**6、商品团队的秒杀架构优化：多级缓存**

接着就是多级缓存的架构，我们会使用**CDN + Nginx + Redis**的多级缓存架构

什么意思呢？就是说秒杀商品详情页的数据，首先会放一份在离用户地理位置比较近的CDN上

CDN你大致可以这么理解。比如我们公司的机房在上海，系统也部署在上海，那么对于陕西的用户，难道每次都要发送请求到我们的上海机房里来获取数据吗？

不是，我们完全可以将一些静态化好的数据放在陕西的一个CDN上。同样对于广州的用户，可以把这些静态化好的数据放在广州的CDN上，这个CDN现在都是各种云厂商提供的服务，我们先看下面的图。

​      ![img](http://wechatapppro-1252524126.file.myqcloud.com/image/ueditor/69899000_1578389234.cn/txdocpic/0/076110c6d13e1fbd0c0304b54e13986b/0)       

然后不同地方的用户在加载这个秒杀商品的详情页数据时，都是从就近的CDN上加载的，不需要每次请求都发送到我们公司在上海的机房去。

这个CDN缓存就是我们多级缓存架构里的第一级缓存。

那如果因为缓存过期之类的问题，CDN上没有用户要加载的商品详情页数据怎么办呢？

此时用户就会发送请求到我们公司的机房里的机器上去请求加载这个商品的数据了，这个时候我们需要在Nginx这样的服务器里做一级缓存。

在Nginx中是可以基于Lua脚本实现本地缓存的，我们可以提前把秒杀商品详情页的数据放到Nginx中进行缓存，如果请求发送过来，可以从Nginx中直接加载缓存数据，不需要把请求转发到我们商品系统上去，看下面的图。

​      ![img](http://wechatapppro-1252524126.file.myqcloud.com/image/ueditor/82179300_1578389234.cn/txdocpic/0/45ed5ab14b729bb14bca62e929fd91bf/0)       

这个时候如果在Nginx服务器上也没加载到秒杀商品的数据呢？

比如同样因为Nginx上的缓存数据过期之类的问题，导致没找到我们需要的数据。

此时就可以由Nginx中的Lua脚本发送请求到Redis集群中去加载我们提前放进去的秒杀商品数据，如下面的图。

​    ![img](http://wechatapppro-1252524126.file.myqcloud.com/image/ueditor/4609800_1578389235.cn/txdocpic/0/08410646238653b924aa47042d357a33/0)       

如果在Redis中还是没有找到呢？

那么就由Nginx中的Lua脚本直接把请求转发到商品详情页系统里去加载就可以了，此时就会直接从数据库中加载数据出来，如下图所示

但是一般来说数据一般是可以从CDN、Nginx、Redis中加载到的，可能只有极少的请求会直接访问到商品系统去从数据库里加载商品页数据。      ![img](http://wechatapppro-1252524126.file.myqcloud.com/image/ueditor/24752300_1578389235.cn/txdocpic/0/e11a806c5c0153125fa261dca9d45188/0)       

通过这样的一套方案，我们就可以把用于秒杀活动的商品详情页数据进行静态化，然后把静态化以后的一串商品数据（比如可能就是一个大的JSON串）放到CDN、Ngxin、Redis组成的多级缓存里去，这样大量的用户同时访问这个秒杀商品页面就对我们的商品系统本身没什么压力了。

因为分布在全国各地的用户的大量请求都是分散发送给各个地方的CDN的，所以CDN就分摊掉了大量的请求。而即使请求到达了我们的后台系统，都是由轻松单机抗10万+并发的Nginx和Redis来返回商品数据的。

**7、今天内容的一点小总结**

今天我们借着明哥的视角给大家分析了一下秒杀场景下的堆机器方案的弊端，同时从秒杀活动发生的场景入手，分析了一下在秒杀活动发生的某个时间点前后，大量的用户会集中的去访问这个秒杀商品的页面。

因此为了针对这个问题进行优化，我们讲了商品技术团队需要做的数据静态化以及多级缓存的架构。

实际上秒杀系统是一个非常复杂的系统，里面涉及的细节是很多的，如果真的要从0开始带着大家讲清楚一个秒杀系统涉及到的方方面面和所有细节，至少需要一个专栏几十篇文章的内容才能说清楚。

因此在这个专栏里，我们主要是要借着秒杀场景去讲一下RocketMQ的限流削峰的功效，所以对秒杀系统本身的很多细节我们并没有涉及，主要是从整体角度讲一下秒杀系统的架构设计和思路，还望很多对秒杀系统的实现细节有兴趣的朋友理解。

**End**

### 44 授人以渔：你们有没有类似秒杀的业务场景？如果没有，自己想一个出来！

今天给大家留的授人以渔的环节，是希望大家思考一下，自己公司里有没有类似秒杀的业务场景？

也就是说在某个特殊的时间点，你大量的用户都登录到你的系统里来，然后进行某种特殊的操作，从而导致你的业务瞬时并发压力过大。

给大家举一些例子，比如说一个考勤系统，可能每天就是早上上班时间并发访问量特别的大，或者是工资系统，每个月到发工资的时候公司发短信提醒了员工，马上大量的人登录上来进行查询。

希望大家打开脑洞去思考有没有类似的场景，哪怕你平时系统的并发访问最多是每秒10个请求，高并发的时候也就每秒100个请求也是可以的。

**因为只要有这样的场景，你可以假设，现在你的系统在这个场景下的并发请求不是100，而是1000，甚至1万，10万，然后基于这个假设倒推去思考你的系统设计。**

如果你们实在没有这样的场景，那么你能不能去假想一个出来？

比如你做的就是最普通的财务系统，几乎没什么高并发，但是你可以假象一下，假设你们公司的财务系统要对接大量的供应商，也许在某个特殊的时间点，比如每个月提现结算的时候，会有大量的请求到你的财务系统里来？

这个凭空想象有点难，需要你结合自己的业务去思考，但还是希望大家，结合自己公司的业务思考，因为你绞尽脑汁想了，才能把专栏里学到的技术融入到你公司的系统里去，出去面试的时候才能把这些东西消化成你的经验去说，而不是干巴巴的背诵专栏里给你讲解的这些知识。

**End**

### 45 基于MQ实现秒杀订单系统的异步化架构以及精准扣减库存的技术方案

**1、秒杀场景下的抢购流程分析**

上次我们讲到，明哥召开了一个团队内部的会议，先介绍了一下在秒杀场景下使用堆机器方案的弊端，接着讲了一下兄弟团队，也就是商品技术团队为了应对秒杀场景下的秒杀商品页面的高并发读取，做的大量的架构优化方案。

接着明哥就要继续讲订单技术团队为了应对秒杀的问题，需要进行哪些架构的优化。

首先从秒杀活动的场景入手来分析，假设我们每天在晚上8:30都有一个秒杀活动，都会主推一个特别好的商品进行3折限量秒杀抢购，比如一个价值6888的手机就3折出售，而且限量每天100个。

那么在这个8:30的时间点之前，实际上大量的用户（可能多达几十万甚至上百万）会集中登录到APP上，然后同时访问这个秒杀活动的商品页面，这个频繁访问商品页面的问题已经被商品技术团队解决掉了。

接着就是到8:30之后，一到时间，页面上会让一个立即抢购的按钮变成可以点击的状态，在那之前这个按钮是灰色的，不能点击。然后瞬间可能几十万甚至上百万人会同时点击这个按钮，尝试对后台发起请求去抢购这个商品。

在这个过程中，实际上大量的人要做的事情，就是跟之前正常购买商品一样的事情，比如下订单、支付、扣减库存以及后续一系列事情。所以在这个过程中，如果按照之前的策略，让所有请求都访问到订单系统以及订单数据库，那么不可避免的是导致订单系统和数据库压力过大。

如果为了每天一个秒杀活动就加10倍，20倍的机器，那么公司的成本就太高了。因此明哥带领的订单技术团队，就是对这个问题进行优化。

**2、用答题的方法避免作弊抢购以及延缓下单**

首先我们考虑第一个问题，有没有可能会有人自己写一个抢购的脚本或者作弊软件，疯狂的发送请求去抢商品

答案是肯定的，肯定是有人会写作弊的脚本或者软件。

所以一般来说，现在你要参与抢购，都会让你点击按钮之后先进行答题，就是说先弹出来一个框，让你回答一个问题，回答正确了你才能发起抢购的请求。

这个办法是非常有效的，因为首先他避免了一些作弊软件去发送抢购请求，另外就是不同的人答题的速度是不一样的，所以可以通过这个答题让不同的人发送请求的时间错开，不会在一个时间点发起请求。

所以首先就需要在客户端增加一个秒杀答题的功能，如下图所示。

​      ![img](http://wechatapppro-1252524126.file.myqcloud.com/image/ueditor/23207100_1578389431.cn/txdocpic/0/3769257f93e08fb3bb26903b171138c0/0)       

**3、为秒杀独立出来一套订单系统**

接着用户的下单抢购的请求发送出去之后，会达到我们的后台系统，对于后台系统而言，我们需要思考一下，是否直接使用我们目前已有的订单系统去抗所有的请求？

答案是否定的，这么做会有问题。

假设你有100万用户在这个时间段很活跃都会来购买商品，但是可能只有其中50万用户在参与秒杀活动，同一时间发送了大量的抢购请求到后台系统，但是同时还有很多其他的用户这个时候并不在参与秒杀系统，他们在进行其他商品的常规性浏览和下单。

因此这个时候如果你让秒杀下单请求和普通下单请求都由一套订单系统来承载，那么可能会导致秒杀下单请求耗尽了订单系统的资源，或者导致系统不稳定，然后导致其他普通下单请求也出现问题，没有办法完成的下单。

所以一般我们会对订单系统部署两个集群，一个集群是秒杀订单系统集群，一个集群是普通订单系统集群

我们看下面的图。当我们为两套系统独立部署之后，甚至可以为秒杀场景下的订单系统做很多特殊的优化。

​      ![img](http://wechatapppro-1252524126.file.myqcloud.com/image/ueditor/36980300_1578389431.cn/txdocpic/0/ea7e7c55d83c6f9be73b07db6ddf12c0/0)       



**4、基于Redis实现下单时精准扣减库存**

然后在后台系统中我们首先需要做的一个事情，就是扣减库存。

因为大家都知道，秒杀商品一般是有数量的限制的，比如几十万人可能就抢购1万个特价商品。

所以当大量的请求到达后台系统之后，首先第一步，就可以先去扣减库存。

扣减库存应该怎么来扣呢？如果还是直接由订单系统调用库存系统的接口，然后访问库存数据库去扣减，那么势必导致瞬时压力过大，可能让库存系统的压力很大。

因此在秒杀场景下，一般会采用另外一个思路。

通常在秒杀场景下，**一般会将****每个秒杀商品的库存提前写入Redis中**，然后当请求到来之后，就直接对Redis中的库存进行扣减

Redis是可以轻松用单机抗每秒几万高并发的，因此这里就可以抗下高并发的库存扣减

我们看下面的图：

​      ![img](http://wechatapppro-1252524126.file.myqcloud.com/image/ueditor/54457100_1578389431.cn/txdocpic/0/44f971b70d950cbad4810b4dfa6452e7/0)       

比如我们可能总共就1万件秒杀商品，那么其实最多就是前1万个到达的请求可以成功从Redis中扣减库存，抢购到这个商品

接着后续的请求在从Redis里扣减库存的时候，都会发现库存已经没了，就无法抢购到商品了。

**5、抢购完毕之后提前过滤无效请求**

其实在Redis中的库存被扣减完之后，就说明后续其他的请求都没有必要发送到秒杀系统中了，因为商品已经被抢购完毕了

此时我们可以让Nginx在接收到后续请求的时候，直接就把后续请求过滤掉。

比如一旦商品抢购完毕，可以在ZooKeeper中写入一个秒杀完毕的标志位，然后ZK会反向通知Nginx中我们自己写的Lua脚本，通过Lua脚本后续在请求过来的时候直接过滤掉，不要向后转发了。

​      ![img](http://wechatapppro-1252524126.file.myqcloud.com/image/ueditor/68414000_1578389431.cn/txdocpic/0/ed86d51d13f7c8966f424f86ba5f2eaf/0)       

这样的话，如果有50万人同时抢购1万件商品，其实最多就前面1万人发送的请求会抢购到商品，之后的49万请求都会在Nginx层面直接被拦截掉，过滤掉这些无效请求，返回响应告诉他们商品库存已经没了。

这样可以最大幅度削减对后端秒杀系统的请求压力。

**6、瞬时高并发下单请求进入RocketMQ进行削峰**

接着我们来考虑下，哪怕是有1万件商品同时被1万人秒杀成功了，那么可能瞬间会有1万请求涌入正常的订单系统进行后续的处理，此时可能还是会有瞬间上万请求访问到订单数据库中创建订单。

所以这个时候，完全可以引入RocketMQ进行削峰处理

也就是说，对于秒杀系统而言，如果判断发现通过Redis完成了库存扣减，此时库存还大于0，就说明秒杀成功了需要生成订单，此时就直接发送一个消息到RocketMQ中即可。

然后让普通订单系统从RocketMQ中消费秒杀成功的消息进行常规性的流程处理即可，比如创建订单，等等。

这样的话，瞬间上万并发的压力会被RocketMQ轻松抗下来，然后普通的订单系统可以根据自己的工作负载慢慢的从RocketMQ中拉取秒杀成功的消息，然后进行后续操作就可以了，不会对订单数据库造成过大的压力。

否则如果你让瞬间产生的一万或者几万的订单请求直接访问订单数据库，必然还是会让他压力过大，需要额外增加机器，那是没有必要的。

因此在这里利用RocketMQ抗下每秒几万并发的下单请求，然后让订单系统以每秒几千的速率慢慢处理就可以了，也就是延迟个可能几十秒，这些下单请求就会处理完毕。

我们看下面的图，就是这样的一个思路。

​      ![img](http://wechatapppro-1252524126.file.myqcloud.com/image/ueditor/88308000_1578389431.cn/txdocpic/0/ac55c0fe48a608cf28047cc54293d0e3/0)       

**7、秒杀架构的核心要点**

其实大家通过这篇文章的思路分析，就会清晰的看到，对于一个秒杀系统而言，比较重要的有以下几点：

1. 在前端/客户端设置秒杀答题，错开大量人下单的时间，阻止作弊器刷单
2. 独立出来一套秒杀系统，专门负责处理秒杀请求
3. 优先基于Redis进行高并发的库存扣减，一旦库存扣完则秒杀结束
4. 秒杀结束之后，Nginx层过滤掉无效的请求，大幅度削减转发到后端的流量
5. 瞬时生成的大量下单请求直接进入RocketMQ进行削峰，订单系统慢慢拉取消息完成下单操作

对于瞬时超高并发抢购商品的场景，**首先必须要避免直接基于数据库进行高并发的库存扣减**，因为那样会对库存数据库造成过大的压力

因为数据库单机可能每秒只能抗几千请求，但是改成直接基于Redis进行高并发扣减库存，每秒可以轻松抗几万请求。

我们看下面图的画圈的地方，这就是针对高并发的第一处优化，将瞬时高并发请求转发到Redis而不是MySQL，轻松抗下高并发。

​      ![img](http://wechatapppro-1252524126.file.myqcloud.com/image/ueditor/5367100_1578389432.cn/txdocpic/0/af32974aed171b13f11595f9bb1d24d8/0)       

一旦库存扣减为0之后，秒杀结束，因此实际上可能只有前面少量请求可以进入后台系统，**后续占据99%的请求，都可以直接在Nginx层面被拦截掉**，不会转发到后台系统造成任何压力

我们看下图中的画圈处。

​      ![img](http://wechatapppro-1252524126.file.myqcloud.com/image/ueditor/20206800_1578389432.cn/txdocpic/0/99886b50e92ff587cd1814e451fad06b/0)       

接着瞬时生成的大量秒杀成功后的订单请求，不会直接交给订单系统去处理，否则也可能会对订单数据库瞬时造成过大压力

**此时会直接写入RocketMQ中进行削峰，让RocketMQ轻松抗下高并发压力，让订单系统慢慢消费和处理下单操作**

看下面图的画圈的地方。

​      ![img](http://wechatapppro-1252524126.file.myqcloud.com/image/ueditor/31184100_1578389432.cn/txdocpic/0/86f1ea2a43eca25c5fe3bb52dac5e86b/0)       

所以通过上述分析，我们发现，像秒杀这种瞬时超高并发的场景，我们**架构优化的核心**就是独立出来一套系统专门处理，**避免高并发请求落在MySQL上**

因为MySQL天生不擅长抗高并发，我们需要通过Redis、Nginx、RocketMQ这些天生轻松可以单机抗几万甚至十万并发的系统来优化架构。

**8、一点小小的总结**

我们来对今天的文章做一点小小的总结

首先，我们利用两篇文章从一个比较高的角度给大家分析了秒杀场景下的各种问题，以及商品系统和订单系统需要进行如何的优化。

其次，大家要明白的一点是，我们在这个案例中，其实核心不是要给大家讲一个完整的秒杀架构的细节，而是让大家感受**在一个复杂系统架构中，RocketMQ是如何扮演削峰的角色的**

另外我们再次强调一下，一个秒杀系统的方方面面是很复杂的，我们不可能通过两篇文章把各种细节都讲清楚，至少需要一个完整专栏，用几十篇文章才能把一个秒杀系统落地的方方面面和细节都说清楚。

在我们的专栏里，核心还是利用这个案例给大家演示一下RocketMQ在高并发场景下削峰的使用，让大家明白RocketMQ在项目中是怎么来使用的。 

**End**

### 46 授人以渔：如果你们有类似秒杀的瞬时高并发场景，应该如何改造？

今天的授人以渔环节，我们希望大家可以结合近期分析的这个秒杀系统的案例来思考一下，如果在上一次授人以渔环节中，大家绞尽脑汁给自己的系统也想了一个类似秒杀的场景，那么在你的系统中如果要应对瞬时超高并发，应该怎么处理？应该如何设计架构来抗下瞬时超高的并发？

希望大家能够仔细去思考这个问题，因为还是要将学习到的架构设计思路融入到自己负责的系统里去，融合到自己负责的业务场景里去，这样大家出去面试的时候，才能真正将RocketMQ这个技术结合自己的项目说好。

如果大家在分析自己的业务场景时以及想办法将RocketMQ技术融入自己的业务场景时，有任何问题，可以在评论区提问，我们会及时回复大家的问题。

**End**

### 47 阶段性复习：一张思维导图给你梳理全面引入MQ的订单系统架构

在这个阶段里，我们初步的把RocketMQ技术融入到了一些订单系统的场景案例中，让大家感受到了如何用MQ技术来解决链路过长导致的性能较差的问题，以及耦合第三方系统导致的性能不稳定的问题，还有耦合其他团队导致自己数据存储被不规范访问的问题，包括瞬时高并发下的过高压力问题。

而且初步带大家认识了一下RocketMQ的消息生产和消费的最基本的使用例子，其实学完这个阶段之后，大家如果在自己的系统中发现一些技术问题是需要用MQ来解决的，已经可以初步的去进行业务分析、引入MQ技术、落地MQ技术来解决自己的问题了。

但是这个阶段相对而言也是一个比较初级的阶段，因为仅仅是简单的将MQ技术应用到系统里解决一些业务问题而已，没涉及到任何MQ相关的高阶功能和更加复杂的业务问题

其实很多朋友或多或少在公司里都用过MQ，但是很多人对MQ的掌握就停留在这个阶段，而且很多人往往就是简单使用MQ，对MQ集群部署、集群运维、TPS压测以及生产集群规划这些东西都没什么概念。

所以我们今天简单的对这个阶段做一个复习，然后接下来我们继续**深入研究RocketMQ技术的底层原理**，在了解了MQ技术的底层后，接下来我们才能更好的利用MQ的高阶功能去解决更加复杂的业务问题。

因此今天我们给出一张思维导图，带着大家梳理和复习我们教给大家的一套用MQ解决业务问题的思路。

​      ![img](http://wechatapppro-1252524126.file.myqcloud.com/image/ueditor/62081400_1578389446.cn/txdocpic/0/ba57d0feabd4cca6160d7797515eefa5/0)      

**End**

### 48 阶段性复习：思考一下，如果你们系统全面接入MQ，架构该如何设计？

今天的阶段性复习环节，我希望大家可以针对自己的系统思考以下几个问题：

1. 你们的系统中是否存在核心链路环节过多导致性能较差的问题？如果有的话，是否可以引入MQ进行适当异步化提升链路性能？
2. 你们的系统是否存在核心链路耦合了第三方系统，进而导致链路性能不稳定的问题？如果有，是否可以引入MQ进行第三方系统的解耦，避免核心链路的性能受到影响？
3. 你们的系统是否存在有其他团队直接耦合访问你们数据库的情况，进而导致你们的数据库性能不稳定？如果有的话，是否可以引入MQ来推送你们的核心数据出去，跟其他团队进行解耦？
4. 你们的系统是否存在瞬时超高并发的场景？如果有的话，是否可以引入MQ来进行瞬时流量削峰，避免为了应对瞬时超高并发从而不停的增加机器？

**End**

### 49 精益求精：深入研究一下生产者到底如何发送消息的？

**1、为了随时准备应对线上系统的问题，要深入研究MQ**

最近一段时间加班加点的工作，小猛和整个订单技术团队终于搞定了公司的RocketMQ集群，而且还对订单系统架构做了初步的改造，解决了系统面临的很多技术问题

小猛看着自己手上的一个清单：

（1）下单核心流程环节太多，性能较差

（2）订单退款的流程可能面临退款失败的风险

（3）关闭过期订单的时候，存在扫描大量订单数据的问题

（4）跟第三方系统耦合在一起，性能存在抖动的风险

（5）大数据团队要获取订单数据，存在不规范直接查询订单数据库的问题

（6）做秒杀活动时订单数据库压力过大

现在这个清单里剩下的就是订单退款偶尔会失败，以及关闭过期订单时扫描大量数据的问题了

接下来应该解决哪个问题呢？

小猛正在思考的时候，明哥过来告诉了他一个消息，现在公司的核心系统都已经接入了RocketMQ，而且核心链路的运转整个就是基于RocketMQ的，一旦在RocketMQ的使用过程中出了一点问题，那么公司的核心业务就会出问题。

所以技术高层的意思是让我们必须要对RocketMQ进行一定深度的技术研究，保证万一线上系统出现一些问题，可以有足够的底层技术积累去分析和解决线上问题，万万不能对RocketMQ仅仅停留在简单使用的层次上。

因此明哥交给了小猛一个任务，趁着现在线上系统压力不大，出问题概率不高，而且系统刚刚接入RocketMQ不久，抓住这个时间窗口，赶紧去研究一下RocketMQ的底层运行原理，同时对团队输出技术分享，提升整个团队对MQ技术的掌控能力！

**2、研究RocketMQ底层原理的顺序和思路**

接着小猛就开始思考，到底应该采用一个什么样的顺序和思路去研究RocketMQ的底层原理呢？

小猛盯着自己手头的线上生产环境部署架构图。      ![img](http://wechatapppro-1252524126.file.myqcloud.com/image/ueditor/40386500_1578389457.cn/txdocpic/0/f142a9472ed3b5fe4925dc7d4dae8c12/0)       

目前公司生产环境的情况，就是部署了一个小规模的RocketMQ生产集群，基本都是在稳定运行中，可以支撑公司的核心链路以及秒杀业务，然后有订单系统、大数据系统、库存系统、积分系统等各种公司核心系统都接入了RocketMQ的生产和消费。

所以公司技术高层可能担心的是如果在RocketMQ生产消息或者消费消息的过程中出现了什么问题，就会直接导致核心链路出问题。

因此对照上面的部署架构图，小猛决定按照如下的思路来研究RocketMQ：

1. 对生产者往Broker集群发送消息的底层原理做一个研究
2. 看看Broker对于接收到的消息，到底是如何存储到磁盘上去的？
3. 基于DLedger技术部署的Broker高可用集群，到底如何进行数据同步的？
4. 消费者到底是基于什么策略选择Master或Slave拉取数据的？
5. 消费者是如何从Broker拉取消息回来，进行处理以及ACK的？如果消费者故障了会如何处理？

按照这个思路就涵盖了RocketMQ的整个使用流程，如果把这些问题都研究一下，那么对RocketMQ的运行流程就比较了解了。

小猛接着就按照上面的思路开始一步一步的进行研究，在花了几天时间研究完RocketMQ的生产者的工作原理之后，他就对团队内部进行了一次技术分享。

下面就是小猛分析RocketMQ生产者工作原理的过程。

**3、创建Topic的时候为何要指定MessageQueue数量？**

首先如果要搞明白生产者的工作原理，那么就必须先明白一个概念：MessageQueue是什么？

而要明白MessageQueue是什么，就必须把他跟Topic以及Broker综合起来看，才能搞明白。

如果我们要使用RocketMQ，你先部署出来一套RocketMQ集群这个肯定是必须的，在有了集群之后，就必须根据你的业务需要去创建一些Topic。

比如之前我们看到，我们需要一个“TopicOrderPaySuccess”的Topic去存放订单支付成功的消息。

像这些Topic就可以在之前我们讲过的RocketMQ可视化工作台里去创建，在里面就可以创建一个Topic出来，**在创建Topic的时候需要指定一个很关键的参数，就是MessageQueue**。

简单来说，就是你要指定你的这个Topic对应了多少个队列，也就是多少个MessageQueue。

那么这个MessageQueue是用来干嘛的？大家是不是觉得很奇怪？因为此时看不出来他是干嘛用的！

**4、Topic、MessageQueue以及Broker之间到底是什么关系？**

其实Topic、MessageQueue以及Broker之间是有关系的，咱们来举一个例子

比如你现在有一个Topic，我们为他指定创建了4个MessageQueue，那么我们接着来思考一下，这个Topic的数据在Broker集群中是如何分布的？

之前最早我们给大家讲过，每个Topic的数据都是分布式存储在多个Broker中的，比如下面的图里我们会看到这个示意。

​      ![img](http://wechatapppro-1252524126.file.myqcloud.com/image/ueditor/49964600_1578389457.cn/txdocpic/0/8442e4964d4d0795e99164e87946362d/0)       

但是我们如何决定这个Topic的哪些数据放这个Broker上，哪些数据放那个Broker上？这是一个问题

所以在这里RocketMQ引入了MessageQueue的概念，本质上就是一个数据分片的机制。

在这个机制中，假设你的Topic有1万条数据，然后你的Topic有4个MessageQueue，那么大致可以认为会在每个MessageQueue中放入2500条数据

当然，这个不是绝对的，有可能有的MessageQueue的数据多，有的数据少，这个要根据你的消息写入MessageQueue的策略来定。

但是我们这里先假定在每个MessageQueue中会平均分配Topic的数据吧，那么下一个问题来了，我们有4个MessageQueue平均分配了Topic的数据，这些MessageQueue放在哪里？

当然是放在Broker上了！

也就是说，很有可能就是在2个Broker上，每个Broker放两个MessageQueue，我们看下面的图就是这个示意。

​      ![img](http://wechatapppro-1252524126.file.myqcloud.com/image/ueditor/58816800_1578389457.cn/txdocpic/0/62b585951d7950003f01667f7c2dd81a/0)       

所以其实MessageQueue就是RocketMQ中非常关键的一个数据分片机制，他通过MessageQueue将一个Topic的数据拆分为了很多个数据分片，然后在每个Broker机器上都存储一些MessageQueue。

通过这个方法，就可以实现Topic数据的分布式存储！

**5、生产者发送消息的时候写入哪个MessageQueue？**

接着我们要考虑一个问题，生产者在发送消息的时候，会写入到哪个MessageQueue中？

要解决这个问题，大家首先就要记得之前我们讲解过的一个重要的点，生产者会跟NameServer进行通信获取Topic的路由数据。

所以生产者从NameServer中就会知道，一个Topic有几个MessageQueue，哪些MessageQueue在哪台Broker机器上，哪些MesssageQueue在另外一台Broker机器上，这些都会知道

我们看下面的图。

​      ![img](http://wechatapppro-1252524126.file.myqcloud.com/image/ueditor/67867100_1578389457.cn/txdocpic/0/972b6a29069c74e0378eb5974135efbf/0)       

然后呢，现在我们暂时先认为生产者会均匀的把消息写入各个MessageQueue，就是比如这个生产者发送出去了20条数据，那么4个MessageQueue就是每个都会写入5条数据。

至于其他的写入MessageQueue的策略，我们后续会结合其他的高阶功能和业务场景来讲解，现在大家先不要去纠结这个问题。

所以我们看一下下面的图，在图里就有生产者把数据均匀写入MessageQueue的示意。

​      ![img](http://wechatapppro-1252524126.file.myqcloud.com/image/ueditor/80050700_1578389457.cn/txdocpic/0/6c4d4ec6e6f854bc41c5efb683880281/0)       

通过这个方法，是不是就可以让生产者把写入请求分散给多个Broker？是不是也可以让每个Broker都均匀分摊到一定的写入请求压力？

这样假设单个Broker可以抗每秒7万并发，那么两个Broker就可以抗每秒14万并发！这样就可以实现RocketMQ集群抗下每秒10万+超高并发的场景了！

另外通过这个方法，是不是就可以让一个Topic中的数据分散在多个MessageQueue中，进而分散在多个Broker机器上？这样就可以实现RocketMQ集群分布式存储海量的消息数据了！

**6、如果某个Broker出现故障该怎么办？**

接下来我们分析一下，如果某个Broker临时出现故障了，比如Master Broker挂了，此时正在等待的其他Slave Broker自动热切换为Master Broker，那么这个时候对这一组Broker就没有Master Broker可以写入了

大家看下面的图。

​      ![img](http://wechatapppro-1252524126.file.myqcloud.com/image/ueditor/90965100_1578389457.cn/txdocpic/0/455984656c2adeb5209cdf272600da9d/0)       

如果你还是按照之前的策略来均匀把数据写入各个Broker上的MessageQueue，那么会导致你在一段时间内，每次访问到这个挂掉的Master Broker都会访问失败，这个似乎不是我们想要的样子。

对于这个问题，通常来说建议大家在Producer中开启一个开关，就是sendLatencyFaultEnable

一旦打开了这个开关，那么他会有一个自动容错机制，比如如果某次访问一个Broker发现网络延迟有500ms，然后还无法访问，那么就会自动回避访问这个Broker一段时间，比如接下来3000ms内，就不会访问这个Broker了。

这样的话，就可以避免一个Broker故障之后，短时间内生产者频繁的发送消息到这个故障的Broker上去，出现较多次数的异常。而是在一个Broker故障之后，自动回避一段时间不要访问这个Broker，过段时间再去访问他。

那么这样过一段时间之后，可能这个Master Broker就已经恢复好了，比如他的Slave Broker切换为了Master可以让别人访问了。

**7、对今天的内容做一点小小的总结**

最后，我们来对今天的文章做一点小小的总结，今天我们讲了以下几个内容：

1. 为了解决线上系统使用RocketMQ过程中可能遇到的问题，我们需要对RocketMQ底层运行原理做一定深入的研究
2. 对RocketMQ底层原理的研究顺序
3. 创建Topic的时候需要指定关键的MessageQueue
4. Topic、MessageQueue和Broker之间的关系是什么？
5. 生产者是如何将消息写入MessageQueue的？
6. 如果Broker故障的时候，生产者如何让他自动启动容错处理？

**End**

### 50 授人以渔：Kafka、RabbitMQ有类似MessageQueue的数据分片机制吗

今天要留给大家的一个授人以渔的作业，是希望大家去查阅资料，调研思考一下：

- Kafka、RabbitMQ他们有类似的数据分片机制吗？
- 他们是如何把一个逻辑上的数据集合概念（比如一个Topic）给在物理上拆分为多个数据分片的？
- 拆分后的多个数据分片又是如何在物理的多台机器上分布式存储的？
- 为什么一定要让MQ实现数据分片的机制？
- 如果不实现数据分片机制，让你来设计MQ中一个数据集合的分布式存储，你觉得好设计吗？

**End**

### 51 精益求精：深入研究一下Broker是如何持久化存储消息的？

**1、为什么Broker数据存储是最重要的一个环节？**

小猛上次给大家分享完Producer的工作原理之后，团队整体都对RocketMQ的数据分片机制以及发送消息的时候如何写入各个Broker机器有了一定的了解。接着小猛就开始来给大家分享最为重要的Broker数据存储的环节。

首先我们得明确一点，为什么Broker数据存储是最重要的一个环节？

很简单，实际上类似RocketMQ、Kafka、RabbitMQ的消息中间件系统，他们不只是让你写入消息和获取消息那么简单，他们本身最重要的就是提供强大的数据存储能力，可以把亿万级的海量消息存储在自己的服务器的磁盘上。

这样的话，各种不同的系统从MQ中消费消息的时候，才可以从MQ服务器的磁盘中读取到自己需要的消息。

否则如果MQ不在机器磁盘上存储大量的消息，如果消息都放在自己的内存里，一个是内存很可能放不下，另外一个是可能你机器重启，内存里的消息就会全部丢失了。

所以大家首先要明确一点，**Broker数据存储实际上才是一个MQ最核心的环节**，他决定了生产者消息写入的吞吐量，决定了消息不能丢失，决定了消费者获取消息的吞吐量，这些都是由他决定的。

所以今天我们来深入的探索一下Broker的数据存储机制。

**2、CommitLog消息顺序写入机制**

首先我们来思考一下，当生产者的消息发送到一个Broker上的时候，他接收到了一条消息，接着他会对这个消息做什么事情？

首先第一步，他会把这个消息直接写入磁盘上的一个日志文件，叫做CommitLog，直接顺序写入这个文件，如下图。

​      ![img](http://wechatapppro-1252524126.file.myqcloud.com/image/ueditor/78658400_1578389464.cn/txdocpic/0/620f7f2dbe682824f99c854e60adc341/0)     

这个CommitLog是很多磁盘文件，每个文件限定最多1GB，Broker收到消息之后就直接追加写入这个文件的末尾，就跟上面的图里一样。如果一个CommitLog写满了1GB，就会创建一个新的CommitLog文件。

**3、MessageQueue在数据存储中是体现在哪里呢？**

接着我们会发现一个问题，如果写入这个Broker的消息都是进入到CommitLog中去存储的，那么上次我们提到的MessageQueue是体现在哪里的呢？

其实在Broker中，对Topic下的每个MessageQueue都会有一系列的ConsumeQueue文件。

这是什么意思呢？

就是在Broker的磁盘上，会有下面这种格式的一系列文件：

$HOME/store/consumequeue/{topic}/{queueId}/{fileName}

上面那一串东西是什么意思？

我们之前说过，对每个Topic你不是在这台Broker上都会有一些MessageQueue吗？所以你会看到，{topic}指代的就是某个Topic，{queueId}指代的就是某个MessageQueue。

然后对存储在这台Broker机器上的Topic下的一个MessageQueue，他有很多的ConsumeQueue文件，这个ConsumeQueue文件里存储的是一条消息对应在CommitLog文件中的offset偏移量。

很多人可能看到这里就直接看晕了，没明白这个是什么意思。。。

没关系，我们一步一图来给大家说明一下这是怎么回事。

首先我们假设有一个Topic，他有4个MessageQueue，然后在两台Broker机器上，每台Broker机器会存储两个MessageQueue。

那么此时假设生产者选择对其中一个MessageQueue写入了一条消息，此时消息会发送到Broker上。

然后Broker必然会把这个消息写入自己的CommitLog文件中，是不是？

好，我们看下面的图里，我用红圈画出来了一个消息，我们假设就是刚刚写入的消息。

​      ![img](http://wechatapppro-1252524126.file.myqcloud.com/image/ueditor/87387800_1578389464.cn/txdocpic/0/7da975588283004f42bdb536ec176c8a/0)       

我们继续看下面的图，我在图里加入了两个ConsumeQueue，分别叫做ConsumeQueue0和ConsumeQueue1，他们分别对应着Topic里的MessageQueue0和MessageQueue1。      ![img](http://wechatapppro-1252524126.file.myqcloud.com/image/ueditor/95815000_1578389464.cn/txdocpic/0/6351c3f96588ec995000990e95f76d52/0)       

也就是说，Topic下的MessageQueue0和MessageQueue1就放在这个Broker机器上，而且他们每个MessageQueue目前在磁盘上就对应了一个ConsumeQueue，所以就是MessageQueue0对应着Broker磁盘上的ConsumeQueue0，MessageQueue1对应着磁盘上的ConsumeQueue1。

接着假设Queue的名字叫做：TopicOrderPaySuccess，那么此时在Broker磁盘上应该有如下两个路径的文件：

$HOME/store/consumequeue/TopicOrderPaySuccess/MessageQueue0/ConsumeQueue0磁盘文件

$HOME/store/consumequeue/TopicOrderPaySuccess/MessageQueue1/ConsumeQueue1磁盘文件

然后呢，当你的Broker收到一条消息写入了CommitLog之后，其实他同时会将这条消息在CommitLog中的物理位置，也就是一个文件偏移量，就是一个offset，写入到这条消息所属的MessageQueue对应的ConsumeQueue文件中去。

比如现在这条消息在生产者发送的时候是发送给MessageQueue0的，那么此时Broker就会将这条消息在CommitLog中的offset偏移量，写入到MessageQueue0对应的ConsumeQueue0中去，如下图所示。

​      ![img](http://wechatapppro-1252524126.file.myqcloud.com/image/ueditor/3779100_1578389465.cn/txdocpic/0/0a2d5297109a5a43c89b0fa03ea715b7/0)       

所以实际上，ConsumeQueue0中存储的是一个一个消息在CommitLog文件中的物理位置，也就是offset

所以其实大家看下面的图，图里展示出来的是ConsumeQueue中的一个物理位置其实是对CommitLog文件中一个消息的引用。

​      ![img](http://wechatapppro-1252524126.file.myqcloud.com/image/ueditor/10728400_1578389465.cn/txdocpic/0/0ecd1480d96de8f31b7a0d115d338435/0)       

实际上在ConsumeQueue中存储的每条数据不只是消息在CommitLog中的offset偏移量，还包含了消息的长度，以及tag hashcode，一条数据是20个字节，每个ConsumeQueue文件保存30万条数据，大概每个文件是5.72MB。

所以实际上Topic的每个MessageQueue都对应了Broker机器上的多个ConsumeQueue文件，保存了这个MessageQueue的所有消息在CommitLog文件中的物理位置，也就是offset偏移量。

**4、如何让消息写入CommitLog文件近乎内存写性能的？**

接着我们给大家讲一个比较关键的概念：对于生产者把消息写入到Broker时，Broker会直接把消息写入磁盘上的CommitLog文件，那么Broker是如何提升整个过程的性能的呢？

因为这个部分的性能提升会直接提升Broker处理消息写入的吞吐量，比如你写入一条消息到CommitLog磁盘文件假设需要10ms，那么每个线程每秒可以处理100个写入消息，假设有100个线程，每秒只能处理1万个写入消息请求。

但是如果你把消息写入CommitLog磁盘文件的性能优化为只需要1ms，那么每个线程每秒可以处理1000个消息写入，此时100个线程每秒可以处理10万个写入消息请求。所以大家可以明显看到，Broker把接收到的消息写入CommitLog磁盘文件的性能，对他的TPS有很大的影响。

所以在这里，Broker是基于OS操作系统的**PageCache**和**顺序写**两个机制，来提升写入CommitLog文件的性能的。

首先Broker是以顺序的方式将消息写入CommitLog磁盘文件的，也就是每次写入就是在文件末尾追加一条数据就可以了，对文件进行顺序写的性能要比对文件随机写的性能提升很多

我们看下面图里的红圈，就是示意数据是顺序写入的。      ![img](http://wechatapppro-1252524126.file.myqcloud.com/image/ueditor/20828200_1578389465.cn/txdocpic/0/cab3decc001ef7aee92f7373aa15ab1c/0)       

另外，数据写入CommitLog文件的时候，其实不是直接写入底层的物理磁盘文件的，而是先进入OS的PageCache内存缓存中，然后后续由OS的后台线程选一个时间，异步化的将OS PageCache内存缓冲中的数据刷入底层的磁盘文件。

我们看下面的图，图里示意出了，数据先写入OS的PageCache缓存中，然后后续由OS自己的线程将缓存里的数据刷入磁盘中。



​      ![img](http://wechatapppro-1252524126.file.myqcloud.com/image/ueditor/32856400_1578389465.cn/txdocpic/0/becb592cf51039ebdcfd330b58983323/0)       

所以在这样的优化之下，采用**磁盘文件顺序写+OS PageCache写入+OS异步刷盘的策略**，基本上可以让消息写入CommitLog的性能跟你直接写入内存里是差不多的，所以正是如此，才可以让Broker高吞吐的处理每秒大量的消息写入。

**5、同步刷盘与异步刷盘**

想必很多朋友此时可能意识到一个问题了，那么如果采用上述的模式，不就是异步刷盘的模式吗？

对的，在上述的异步刷盘模式下，生产者把消息发送给Broker，Broker将消息写入OS PageCache中，就直接返回ACK给生产者了。

此时生产者就认为消息写入成功了，那么会有什么问题吗？

问题肯定是有的，如果生产者认为消息写入成功了，但是实际上那条消息此时是在Broker机器上的os cache中的，如果此时Broker直接宕机，那么是不是os cache中的这条数据就会丢失了？

我们看下面的图，红圈圈出来了数据早os cache里的情况，如果此时broker宕机，那么必然导致这里的数据丢失，而producer还以为数据已经写入成功了，以为不会丢失，所以肯定是有问题的。

所以异步刷盘的的策略下，可以让消息写入吞吐量非常高，但是可能会有数据丢失的风险，这个是大家需要清除的。

​      ![img](http://wechatapppro-1252524126.file.myqcloud.com/image/ueditor/44354000_1578389465.cn/txdocpic/0/2f066d46298dfea2cdc67ed7d917e15b/0)       

另外一种模式叫做同步刷盘，如果你使用同步刷盘模式的话，那么生产者发送一条消息出去，broker收到了消息，必须直接强制把这个消息刷入底层的物理磁盘文件中，然后才会返回ack给producer，此时你才知道消息写入成功了。

只要消息进入了物理磁盘上，那么除非是你的物理磁盘坏了导致数据丢失，否则正常来说数据就不会丢失了，我们看下面的图，就是示意了同步刷盘的效果。

​      ![img](http://wechatapppro-1252524126.file.myqcloud.com/image/ueditor/55330600_1578389465.cn/txdocpic/0/39ac43e5fd325b0ec602d9b6b013e7ca/0)       

如果broker还没有来得及把数据同步刷入磁盘，然后他自己挂了，那么此时对producer来说会感知到消息发送失败了，然后你只要不停的重试发送就可以了，直到有slave broker切换成master broker重新让你可以写入消息，此时可以保证数据是不会丢的。

但是如果你强制每次消息写入都要直接进入磁盘中，必然导致每条消息写入性能急剧下降，导致消息写入吞吐量急剧下降，但是可以保证数据不会丢失。

好了，今天主要是分析一下broker对数据是如何存储的，从原理角度带着大家一步一图来分析一下，只有具体如何切换异步刷盘和同步刷盘的一些配置，后续我们会结合业务场景下的数据0丢失方案来讲解的。

**6、对今天内容的一点小小总结**

今天我们讲了broker最为核心的数据存储机制，包括如下一些知识点：

1. 为什么Broker数据存储机制是一个MQ最为核心的环节？
2. CommitLog数据存储机制
3. MessageQueue对应的ConsumeQueue物理位置存储机制
4. 基于CommitLog顺序写+OS Cache+异步刷盘的高吞吐消息写入的机制
5. 同步刷盘和异步刷盘各自的优缺点：高吞吐写入+丢失数据风险，写入吞吐量下降+数据不丢失

**End**

### 52 授人以渔：同步刷盘和异步刷盘分别适用于什么场景呢？

今天的内容比较硬干一些，所以给大家留的授人以渔的思考作业会相对简单一些，希望大家思考一下，**同步刷盘和异步刷盘两种策略，分别适用于什么不同的场景呢？**

异步刷盘可以提供超高的写入吞吐量，但是有丢失数据的风险，这个适用于什么业务场景？在你所知道的业务场景，或者工作接触过的业务场景中，有哪些场景需要超高的写入吞吐量，但是可以适度接受数据丢失？

同步刷盘会大幅度降低写入吞吐量，但是可以让你的数据不丢失，你接触哪些场景，是严格要求数据务必不能丢失任何一条，但是吞吐量并没有那么高的呢？

另外，大家可以去结合本节的内容，去查找资料看看，Kafka、RabbitMQ他们的broker收到消息之后是如何写入磁盘的？采用的是同步刷盘还是异步刷盘的策略？为什么？

希望大家好好思考这些问题，在评论区给出你的见解。

**End**

### 53 精益求精：基于DLedger技术的Broker主从同步原理到底是什么？

**1、Broker高可用架构原理回顾**

今天小猛打算跟团队里的其他兄弟分享一下基于DLedger的Broker高可用架构的一些实现原理，因为在上次分析完了Broker的数据存储原理之后，接下来需要了解的，实际上就是Broker接收到数据写入之后，是如何同步给其他的Broker做多副本冗余的。

说到这个，那么就必然牵扯到DLedger是个什么东西，如果直接给大家讲DLedger，估计很多又会看不懂了，所以我们还是秉持一步一图的风格，慢慢给大家一点点来讲，基于DLedger是如何实现Broker多副本高可用的。

首先，我们回顾一下，上一次已经讲到，producer写入消息到broker之后，broker会将消息写入本地CommitLog磁盘文件里去，然后还有一些ConsumeQueue会存储Topic下各个MessageQueue的消息的物理位置。      ![img](http://wechatapppro-1252524126.file.myqcloud.com/image/ueditor/71625200_1578389483.cn/txdocpic/0/60ce78feb37ffcc9b2682750fc7bb271/0)    

而且我们给大家说过，如果要让Broker实现高可用，那么必须有一个Broker组，里面有一个是Leader Broker可以写入数据，然后让Leader Broker接收到数据之后，直接把数据同步给其他的Follower Broker

我们看下面的图

​      ![img](http://wechatapppro-1252524126.file.myqcloud.com/image/ueditor/83637900_1578389483.cn/txdocpic/0/39fe558a508550a0d5dd5bfac7571b98/0)       

这样的话，一条数据就会在三个Broker上有三份副本，此时如果Leader Broker宕机，那么就直接让其他的Follower Broker自动切换为新的Leader Broker，继续接受客户端的数据写入就可以了。

**2、基于DLedger技术替换Broker的CommitLog**

接着很多人肯定特别好奇这里的一些实现细节，那么这些细节就是我们今天要讲的内容了。

首先大家要知道，Broker上述高可用架构就是基于DLedger技术来实现的，所以首先第一步，我们先要知道DLedger技术可以干什么。

DLedger技术实际上首先他自己就有一个CommitLog机制，你把数据交给他，他会写入CommitLog磁盘文件里去，这是他能干的第一件事情。

所以首先我们在下面的图里可以看到，如果基于DLedger技术来实现Broker高可用架构，实际上就是用DLedger先替换掉原来Broker自己管理的CommitLog，由DLedger来管理CommitLog

我们看下图：

​      ![img](http://wechatapppro-1252524126.file.myqcloud.com/image/ueditor/94642000_1578389483.cn/txdocpic/0/d903030f32d9abf7c6f56f21c899069f/0)       

所以首先第一步大家要知道的是，我们需要使用DLedger来管理CommitLog，然后Broker还是可以基于DLedger管理的CommitLog去构建出来机器上的各个ConsumeQueue磁盘文件。

**3、DLedger是如何基于Raft协议选举Leader Broker的？**

既然我们现在知道首先基于DLedger替换各个Broker上的CommitLog管理组件了，那么就是每个Broker上都有一个DLedger组件了

接着我们思考一下，如果我们配置了一组Broker，比如有3台机器，DLedger是如何从3台机器里选举出来一个Leader的？

实际上DLedger是**基于Raft协议来进行Leader Broker选举的**，那么Raft协议中是如何进行多台机器的Leader选举的呢？

这需要发起一轮一轮的投票，通过三台机器互相投票选出来一个人作为Leader。

简单来说，三台Broker机器启动的时候，他们都会投票自己作为Leader，然后把这个投票发送给其他Broker。

我们举一个例子，Broker01是投票给自己的，Broker02是投票给自己的，Broker03是投票给自己的，他们都把自己的投票发送给了别人。

此时在第一轮选举中，Broker01会收到别人的投票，他发现自己是投票给自己，但是Broker02投票给Broker02自己，Broker03投票给Broker03自己，似乎每个人都很自私，都在投票给自己，所以第一轮选举是失败的。

因为大家都投票给自己，怎么选举出来一个Leader呢？

接着每个人会进入一个随机时间的休眠，比如说Broker01休眠3秒，Broker02休眠5秒，Broker03休眠4秒。

此时Broker01必然是先苏醒过来的，他苏醒过来之后，直接会继续尝试投票给自己，并且发送自己的选票给别人。

接着Broker03休眠4秒后苏醒过来，他发现Broker01已经发送来了一个选票是投给Broker01自己的，此时他自己因为没投票，所以会尊重别人的选择，就直接把票投给Broker01了，同时把自己的投票发送给别人。

接着Broker02苏醒了，他收到了Broker01投票给Broker01自己，收到了Broker03也投票给了Broker01，那么他此时自己是没投票的，直接就会尊重别人的选择，直接就投票给Broker01，并且把自己的投票发送给别人。

此时所有人都会收到三张投票，都是投给Broker01的，那么Broker01就会当选为Leader。

其实只要有（3台机器 / 2） + 1个人投票给某个人，就会选举他当Leader，这个（机器数量 / 2） + 1就是大多数的意思。

这就是Raft协议中选举leader算法的简单描述，简单来说，他确保有人可以成为Leader的核心机制就是一轮选举不出来Leader的话，就让大家随机休眠一下，先苏醒过来的人会投票给自己，其他人苏醒过后发现自己收到选票了，就会直接投票给那个人。

依靠这个随机休眠的机制，基本上几轮投票过后，一般都是可以快速选举出来一个Leader。

因此我们看下图，在三台Broker机器刚刚启动的时候，就是靠这个DLedger基于Raft协议实现的leader选举机制，互相投票选举出来一个Leader，其他人就是Follower，然后只有Leader可以接收数据写入，Follower只能接收Leader同步过来的数据。

​      ![img](http://wechatapppro-1252524126.file.myqcloud.com/image/ueditor/8199600_1578389484.cn/txdocpic/0/af8e0940977c070f2c597fa89c55bbcd/0)       

**4、DLedger是如何基于Raft协议进行多副本同步的？**

接着我们来说一下，Leader Broker收到消息之后，是如何基于DLedger把数据同步给其他Broker的。

DLedger在进行同步的时候是采用Raft协议进行多副本同步的，我们接下来聊一下Raft协议中的多副本同步机制。

简单来说，**数据同步会分为两个阶段，一个是uncommitted阶段，一个是commited阶段**

首先Leader Broker上的DLedger收到一条数据之后，会标记为uncommitted状态，然后他会通过自己的DLedgerServer组件把这个uncommitted数据发送给Follower Broker的DLedgerServer。

我们看下面的图，就显示了这个过程。

​      ![img](http://wechatapppro-1252524126.file.myqcloud.com/image/ueditor/20914000_1578389484.cn/txdocpic/0/49d801f2c1de43f07b26713f89851ac3/0)      

接着Follower Broker的DLedgerServer收到uncommitted消息之后，必须返回一个ack给Leader Broker的DLedgerServer，然后如果Leader Broker收到超过半数的Follower Broker返回ack之后，就会将消息标记为committed状态。

然后Leader Broker上的DLedgerServer就会发送commited消息给Follower Broker机器的DLedgerServer，让他们也把消息标记为comitted状态。

这个就是基于Raft协议实现的两阶段完成的数据同步机制。

**5、如果Leader Broker崩溃了怎么办？**

通过上面的分析我们就知道了，对于高可用Broker架构而言，无论是CommitLog写入，还是多副本同步，都是基于DLedger来实现的。那么最后一个问题就是，如果Leader Broker挂了怎么办？

如果Leader Broker挂了，此时剩下的两个Follower Broker就会重新发起选举，他们会基于DLedger还是采用Raft协议的算法，去选举出来一个新的Leader Broker继续对外提供服务，而且会对没有完成的数据同步进行一些恢复性的操作，保证数据不会丢失。

我们看下面的图，就是示意了Leader Broker挂了之后，Follower Broker成为了新的Leader Broker，然后生产者写入新的Leader Broker的一个过程。

新选举出来的Leader会把数据通过DLedger同步给剩下的一个Follower Broker。

​      ![img](http://wechatapppro-1252524126.file.myqcloud.com/image/ueditor/35864900_1578389484.cn/txdocpic/0/3910723dbb4e6fa9b7d1cd48d0c65db0/0)      

**6、对今天内容的一点小小总结**

今天我们着重讲解了基于DLedger技术的高可用Broker集群是如何运行的，包含了以下的一些内容：

1. Broker高可用架构原理回顾：多副本同步+Leader自动切换
2. 基于DLedger技术管理CommitLog
3. Broker集群启动时，基于DLedger技术和Raft协议完成Leader选举
4. Leader Broker写入之后，基于DLedger技术和Raft协议同步给Follower Broker
5. 如果Leader Broker崩溃，则基于DLedger和Raft协议重新选举Leader 

**End**

### 54 授人以渔：采用Raft协议进行主从数据同步，会影响TPS吗？

今天我们想让大家思考一个问题，基于DLedger技术管理CommitLog之后，可以自动在一组Broker中选举出来一个Leader

然后在Leader接收消息写入的时候，基于DLedger技术写入本地CommitLog中，这个其实跟之前让Broker自己直接写入CommitLog是没什么区别的。

但是有区别的一点在于，Leader Broker上的DLedger在收到一个消息，将uncommitted消息写入自己本地存储之后，还需要基于Raft协议的算法，去采用两阶段的方式把uncommitted消息同步给其他Follower Broker

必须要超过一半的Follower Broker的DLedger对uncommitted消息返回ack，此时Leader Broker才能返回ACK给生产者，说这次写入成功了。

当然很多人会有疑问，那么不需要等他们执行了commit操作之后再返回给生产者吗？

实际上在这里只要有超过半数的Follower Broker都写入uncommitted消息之后，就可以返回给生产者了。

因此哪怕此时Leader Broker宕机了，超过半数的Follower Broker上也是有这个消息的，只不过是uncommitted状态，但是新选举的Leader Broker可以根据剩余Follower Broker上这个消息的状态去进行数据恢复，比如把消息状态调整为committed。

也就是说，这样的一个架构对每次写入都平添了一个成本，每次写入都必须有超过半数的Follower Broker都写入消息才可以算做一次写入成功

那么大家思考一个问题，这样做是不是会对Leader Broker的写入性能产生影响？是不是会降低TPS？

那么大家思考一下，是不是必须要在所有的场景都这么做？为什么？

**End**

### 55 精益求精：深入研究一下消费者是如何获取消息处理以及进行ACK的？

**1、消费组到底是个什么概念？**

在理解了Broker数据存储机制以及Broker高可用主从同步机制之后，我们就可以来看一下消费者是如何从Broker获取消息，并且进行处理以及维护消费进度的。

首先，我们需要了解的第一个概念，就是消费者组

消费者组的意思，就是让你给一组消费者起一个名字。比如我们有一个Topic叫“TopicOrderPaySuccess”，然后假设有库存系统、积分系统、营销系统、仓储系统他们都要去消费这个Topic中的数据。

此时我们应该给那四个系统分别起一个消费组的名字，比如说：stock_consumer_group，marketing_consumer_group，credie_consumer_group，wms_consumer_group。

设置消费组的方式是在代码里进行的，类似下面这样：



![image.png](http://wechatapppro-1252524126.file.myqcloud.com/image/ueditor/98080000_1578390161.png)



然后比如库存系统部署了4台机器，每台机器上的消费者组的名字都是“stock_consumer_group”，那么这4台机器就同属于一个消费者组，以此类推，每个系统的几台机器都是属于各自的消费者组的。

我们看一下下面的图，里面示意了两个系统，每个系统都有2台机器，每个系统都有一个自己的消费组。

​      ![img](http://wechatapppro-1252524126.file.myqcloud.com/image/ueditor/8551000_1578390162.cn/txdocpic/0/8f8fb0089617a7e084cb44d14014aa0a/0)       

然后给大家先解释一下不同消费者之间的关系，假设库存系统和营销系统作为两个消费者组，都订阅了“TopicOrderPaySuccess”这个订单支付成功消息的Topic，此时假设订单系统作为生产者发送了一条消息到这个Topic，如下图所示。

​      ![img](http://wechatapppro-1252524126.file.myqcloud.com/image/ueditor/18687800_1578390162.cn/txdocpic/0/3903ce914e7d2388c00b5b40dcb89ea8/0)     此时这条消息是怎么被消费的呢？

正常情况下来说，这条消息进入Broker之后，库存系统和营销系统作为两个消费组，每个组都会拉取到这条消息。

也就是说这个订单支付成功的消息，库存系统会获取到一条，营销系统也会获取到一条，他们俩都会获取到这条消息。

但是下一个问题来了，库存系统这个消费组里有两台机器，是两台机器都获取到这条消息？还是说只有一台机器会获取到这条消息？

答案是，正常情况下来说，库存系统的两台机器中只有一台机器会获取到这条消息，营销系统也是同理。

我们看下面的图，示意了对于一条订单支付成功的消息，库存系统的一台机器获取到了，营销系统的一台机器也获取到了。

当然为了画图方便，图里是让营销系统从Master Broker拉取的，库存系统从Slave Broker拉取的。     ![img](http://wechatapppro-1252524126.file.myqcloud.com/image/ueditor/29050600_1578390162.cn/txdocpic/0/424dfa84995dc934fb34946b9eaecf2b/0)    这就是在消费的时候我们要给大家介绍的第一个知识点，不同的系统应该设置不同的消费组，如果不同的消费组订阅了同一个Topic，对Topic里的一条消息，每个消费组都会获取到这条消息。

**2、集群模式消费 vs 广播模式消费**

接着我们给大家介绍下一个概念，就是对于一个消费组而言，他获取到一条消息之后，如果消费组内部有多台机器，到底是只有一台机器可以获取到这个消息，还是每台机器都可以获取到这个消息？

这个就是集群模式和广播模式的区别。

默认情况下我们都是集群模式，也就是说，一个消费组获取到一条消息，只会交给组内的一台机器去处理，不是每台机器都可以获取到这条消息的。

但是我们可以通过如下设置来改变为广播模式：

consumer.setMessageModel(MessageModel.BROADCASTING);

如果修改为广播模式，那么对于消费组获取到的一条消息，组内每台机器都可以获取到这条消息。但是相对而言广播模式其实用的很少，常见基本上都是使用集群模式来进行消费的。

**3、重温MessageQueue、CommitLog、ConsumeQueue之间的关系**

接着我们来研究一下MessageQueue与消费者的关系，通过之前的学习我们都已经知道了，一个Topic在创建的时候我们是要设置他有多少个MessageQueue的，而且我们也知道了，在Broker上MessageQueue是如何跟ConsumeQueue对应起来的。

我们先在图中展示出这些概念，在Broker上我们会看到CommitLog文件，还有对应的多个ConsumeQueue文件。      ![img](http://wechatapppro-1252524126.file.myqcloud.com/image/ueditor/41441200_1578390162.cn/txdocpic/0/09c4dd5821ce1ebf8d673e96c6282d62/0)       

根据之前学习到的知识，我们大致可以如此理解，Topic中的多个MessageQueue会分散在多个Broker上，在每个Broker机器上，一个MessageQueue就对应了一个ConsumeQueue，当然在物理磁盘上其实是对应了多个ConsumeQueue文件的，但是我们大致也理解为一 一对应关系。

我们看下图中，我圈出来了ConsumeQueue，就代表了一个Topic的多个MessageQueue在物理磁盘上分别对应一个ConsumeQueue的意思。      ![img](http://wechatapppro-1252524126.file.myqcloud.com/image/ueditor/52592500_1578390162.cn/txdocpic/0/71f133d6dbbe499b09200e5febd66d2b/0)       

但是对于一个Broker机器而言，存储在他上面的所有Topic以及MessageQueue的消息数据都是写入一个统一的CommitLog的

我们看下面的图，我圈出来了CommitLog，代表的是Broker上所有消息都是往里面写的。     ![img](http://wechatapppro-1252524126.file.myqcloud.com/image/ueditor/61808300_1578390162.cn/txdocpic/0/63f544c96f6eb6482310790b9d74147a/0)       

然后对于Topic的各个MessageQueue而言，就是通过各个ConsumeQueue文件来存储属于MessageQueue的消息在CommitLog文件中的物理地址，就是一个offset偏移量，我在下面的图中标识出来了这个地址应用的关系。

​      ![img](http://wechatapppro-1252524126.file.myqcloud.com/image/ueditor/74887800_1578390162.cn/txdocpic/0/4d6cd5b18e59e295851350a353f980fc/0)       

**4、MessageQueue与消费者的关系**

接着我们来想一个问题，对于一个Topic上的多个MessageQueue，是如何由一个消费组中的多台机器来进行消费的呢？

其实这里的源码实现细节是较为复杂的，但我们可以简单的理解为，他会均匀的将MessageQueue分配给消费组的多台机器来消费。

举个例子，假设我们的“TopicOrderPaySuccess”有4个MessageQueue，这4个MessageQueue分布在两个Master Broker上，每个Master Broker上有2个MessageQueue。

然后库存系统作为一个消费组里有两台机器，那么正常情况下，当然最好的就是让这两台机器每个都负责2个MessageQueue的消费了

比如库存系统的机器01从Master Broker01上消费2个MessageQueue，然后库存系统的机器02从Master Broker02上消费2个MessageQueue，这样不就把消费的负载均摊到两台Master Broker上去了？

我们在下面的图里画出了这个示意。

​      ![img](http://wechatapppro-1252524126.file.myqcloud.com/image/ueditor/84743000_1578390162.cn/txdocpic/0/ca8d43cc604ecd40a9a672f6cdbaa0e6/0)       

所以你大致可以认为一个Topic的多个MessageQueue会均匀分摊给消费组内的多个机器去消费，这里的一个原则就是，一个MessageQueue只能被一个消费机器去处理，但是一台消费者机器可以负责多个MessageQueue的消息处理。

**5、Push模式 vs Pull模式**

现在我们已经知道了一个消费组内的多台机器是分别负责一部分MessageQueue的消费的，那么既然如此，每台机器都必须去连接到对应的Broker，尝试消费里面的MessageQueue对应的消息了。

此时就要涉及到两种消费模式了，之前我们也提到过，一个是Push，一个是Pull。

实际上，这两个消费模式本质是一样的，都是消费者机器主动发送请求到Broker机器去拉取一批消息下来。

Push消费模式本质底层也是基于这种消费者主动拉取的模式来实现的，只不过他的名字叫做Push而已，意思是Broker会尽可能实时的把新消息交给消费者机器来进行处理，他的消息时效性会更好。

一般我们使用RocketMQ的时候，消费模式通常都是基于他的Push模式来做的，因为Pull模式的代码写起来更加的复杂和繁琐，而且Push模式底层本身就是基于消息拉取的方式来做的，只不过时效性更好而已。

Push模式的实现思路我这里简单说一下：当消费者发送请求到Broker去拉取消息的时候，如果有新的消息可以消费那么就会立马返回一批消息到消费机器去处理，处理完之后会接着立刻发送请求到Broker机器去拉取下一批消息。

所以消费机器在Push模式下会处理完一批消息，立马发起请求拉取下一批消息，消息处理的时效性非常好，看起来就跟Broker一直不停的推送消息到消费机器一样。

另外Push模式下有一个请求挂起和长轮询的机制，也要给大家简单介绍一下。

当你的请求发送到Broker，结果他发现没有新的消息给你处理的时候，就会让请求线程挂起，默认是挂起15秒，然后这个期间他会有后台线程每隔一会儿就去检查一下是否有的新的消息给你，另外如果在这个挂起过程中，如果有新的消息到达了会主动唤醒挂起的线程，然后把消息返回给你。

当然其实消费者进行消息拉取的底层源码是非常复杂的，涉及到大量的细节，但是他的核心思路大致就是如此，我们只要知道，哪怕是用常见的Push模式消费，本质也是消费者不停的发送请求到broker去拉取一批一批的消息就行了。

**6、Broker是如何将消息读取出来返回给消费机器的？**

接着我们思考一个小问题，Broker在收到消费机器的拉取请求之后，是如何将消息读取出来返回给消费机器的？

其实这里要涉及到两个概念，分别是ConsumeQueue和CommitLog。

假设一个消费者机器发送了拉取请求到Broker了，他说我这次要拉取MessageQueue0中的消息，然后我之前都没拉取过消息，所以就从这个MessageQueue0中的第一条消息开始拉取好了。

于是，Broker就会找到MessageQueue0对应的ConsumeQueue0，从里面找到第一条消息的offset，如下图所示。

​      ![img](http://wechatapppro-1252524126.file.myqcloud.com/image/ueditor/94787300_1578390162.cn/txdocpic/0/f94f6f0021f7df0f46a1caef824aac5c/0)       

接着Broker就需要根据ConsumeQueue0中找到的第一条消息的地址，去CommitLog中根据这个offset地址去读取出来这条消息的数据，然后把这条消息的数据返回给消费者机器，如下图所示。

​      ![img](http://wechatapppro-1252524126.file.myqcloud.com/image/ueditor/8575700_1578390163.cn/txdocpic/0/322bfa8a824798ec707c552d44a0399e/0)       

所以其实消费消息的时候，本质就是根据你要消费的MessageQueue以及开始消费的位置，去找到对应的ConsumeQueue读取里面对应位置的消息在CommitLog中的物理offset偏移量，然后到CommitLog中根据offset读取消息数据，返回给消费者机器。

**7、消费者机器如何处理消息、进行ACK以及提交消费进度？**

接着消费者机器拉取到一批消息之后，就会将这批消息回调我们注册的一个函数，如下面这样子：



![image.png](http://wechatapppro-1252524126.file.myqcloud.com/image/ueditor/19830900_1578390163.png)



当我们处理完这批消息之后，消费者机器就会提交我们目前的一个消费进度到Broker上去，然后Broker就会存储我们的消费进度

比如我们现在对ConsumeQueue0的消费进度假设就是在offset=1的位置，那么他会记录下来一个ConsumeOffset的东西去标记我们的消费进度，如下图。

​      ![img](http://wechatapppro-1252524126.file.myqcloud.com/image/ueditor/32801100_1578390163.cn/txdocpic/0/6f847a84251dc15b71590298496f6b44/0)       

那么下次这个消费组只要再次拉取这个ConsumeQueue的消息，就可以从Broker记录的消费位置开始继续拉取，不用重头开始拉取了。

**8、如果消费组中出现机器宕机或者扩容加机器，会怎么处理？**

最后我们来看一下，如果消费组中出现机器宕机或者扩容加机器的情况，他会怎么处理？

这个时候其实会进入一个rabalance的环节，也就是说重新给各个消费机器分配他们要处理的MessageQueue。

给大家举个例子，比如现在机器01负责MessageQueue0和Message1，机器02负责MessageQueue2和MessageQueue3，现在机器02宕机了，那么机器01就会接管机器02之前负责的MessageQueue2和MessageQueue3。

或者如果此时消费组加入了一台机器03，此时就可以把机器02之前负责的MessageQueue3转移给机器03，然后机器01就仅仅负责一个MessageQueue2的消费了，这就是负载重平衡的概念。

**9、对今天的内容做一点小的总结**

今天给大家整体分析了一下消费者进行消息拉取和消费的过程，包含以下的要点：

1. 消费组是个什么概念？一条消息在多个消费组中是如何分配的？
2. 在一个消费组内部的消费模式，集群模式 vs 广播模式
3. 重温Topic、MessageQueue、CommitLog、ConsumeQueue之间的关系
4. 一个消费组内的多台机器是如何分配MessageQueue的？
5. 消费者机器是如何从broker拉取消息的，push模式与pull模式
6. broker是如何基于ConsumeQueue和CommitLog，读取消息返回给消费者机器的？
7. 消费者机器是如何处理消息，以及提交消费进度的？
8. 消费组内出现机器宕机，或者是机器扩容的时候，会如何对MessageQueue进行重平衡？

**End**

### 56 授人以渔：消费者到底什么时候可以认为是处理完消息了？

今天结合这个消息消费的过程，想留给大家一些思考题去考虑一下：

1. 一般我们获取到一批消息之后，什么时候才可以认为是处理完这批消息了？是刚拿到这批消息就算处理完吗？还是说要对这批消息执行完一大堆的数据库之类的操作，才算是处理完了？
2. 如果获取到了一批消息，还没处理完呢，结果机器就宕机了，此时会怎么样？这些消息会丢失，再也无法处理了吗？
3. 如果获取到了一批消息，已经处理完了，还没来得及提交消费进度，此时机器宕机了，会怎么样呢？

希望大家好好思考这些问题，把自己的想法提交到评论区里跟大家一起分享。

**End**

### 57 精益求精：消费者到底是根据什么策略从Master或Slave上拉取消息的？

**1、Broker读写分离架构的回顾**

上一次我们已经分析了消息消费的整个流程和原理，这次我们来看一个比较关键的问题，也是很多人都关注的问题，就是Broker实现高可用架构的时候是有主从之分的

之前我们提到过，消息消费，可以从Master Broker拉取，也可以从Slave Broker拉取，具体是要看机器负载来定。

所以很多人都会有一个疑问，那到底什么时候从Master Broker拉取，什么时候从Slave Broker拉取。

所以我们先来简单回顾一下，之前我们对Broker的读写分离架构是怎么描述的。

之前我们说过，刚开始消费者都是连接到Master Broker机器去拉取消息的，然后如果Master Broker机器觉得自己负载比较高，就会告诉消费者机器，下次可以从Slave Broker机器去拉取。

我们看下面的图，图里示意是说Master Broker和Slave Broker都可以拉取消息。

​      ![img](http://wechatapppro-1252524126.file.myqcloud.com/image/ueditor/40209900_1578390189.cn/txdocpic/0/3abc1f231012d51d4d49ae76e63ca776/0)      

**2、CommitLog基于os cache提升写性能的回顾**

接着如果大家要搞明白到底什么时候从Master Broker拉取消息，什么时候从Slave Broker拉取消息，首先得搞明白一个很关键的问题，那就是拉取消息的时候必然会先读取ConsumeQueue文件，这个ConsumeQueue文件的读取是如何优化的？

要搞明白这个ConsumeQueue文件的读取是如何进行性能优化的，我们又得先回顾一下之前讲过的CommitLog文件写入的优化原理，其实他本质就是基于os cache来进行优化的

也就是说，broker收到一条消息，会写入CommitLog文件，但是会先把CommitLog文件中的数据写入os cache(操作系统管理的缓存)中去，如下图。

​      ![img](http://wechatapppro-1252524126.file.myqcloud.com/image/ueditor/51710300_1578390189.cn/txdocpic/0/88855d8f1e5ed0f6bf7dc08318f4a4f3/0)      

然后os自己有后台线程，过一段时间后会异步把os cache缓存中的CommitLog文件的数据刷入磁盘中去，如下图。

​      ![img](http://wechatapppro-1252524126.file.myqcloud.com/image/ueditor/63018900_1578390189.cn/txdocpic/0/7fc487d3a9bba8a44b04d1ae89f61486/0)      

就是依靠这个写入CommitLog时先进入os cache缓存，而不是直接进入磁盘的机制，就可以实现broker写CommitLog文件的性能是内存写级别的，这才能实现broker超高的消息接入吞吐量。

**3、一个很关键的问题：ConsumeQueue文件也是基于os cache的**

所以接下来我们就可以看一个很关键的问题了，那就是ConsumeQueue会被大量的消费者发送的请求给高并发的读取，所以ConsumeQueue文件的读操作是非常频繁的，而且同时会极大的影响到消费者进行消息拉取的性能和消费吞吐量。

所以实际上broker对ConsumeQueue文件同样也是基于os cache来进行优化的

也就是说，对于Broker机器的磁盘上的大量的ConsumeQueue文件，在写入的时候也都是优先进入os cache中的

而且os自己有一个优化机制，就是读取一个磁盘文件的时候，他会自动把磁盘文件的一些数据缓存到os cache中。

而且大家之前知道ConsumeQueue文件主要是存放消息的offset，所以每个文件很小，30万条消息的offset就只有5.72MB而已。所以实际上ConsumeQueue文件们是不占用多少磁盘空间的，他们整体数据量很小，几乎可以完全被os缓存在内存cache里。

大家看下面的图，我们示意了ConsumeQueue文件几乎都是放在os cache里的。

​      ![img](http://wechatapppro-1252524126.file.myqcloud.com/image/ueditor/73970100_1578390189.cn/txdocpic/0/d3d5c6756481e3b941b75e0034202411/0)      

所以实际上在消费者机器拉取消息的时候，第一步大量的频繁读取ConsumeQueue文件，几乎可以说就是跟读内存里的数据的性能是一样的，通过这个就可以保证数据消费的高性能以及高吞吐

下面的图示意了消息拉取的时候，都是从os cache里读取ConsumeQueue的数据的。

​      ![img](http://wechatapppro-1252524126.file.myqcloud.com/image/ueditor/86765400_1578390189.cn/txdocpic/0/38011a391834250a1c289eee1ef42521/0)       



**4、第二个关键问题：CommitLog是基于os cache+磁盘一起读取的**

接着我们来看第二个比较关键的问题，在进行消息拉取的时候，先读os cache里的少量ConsumeQueue的数据，这个性能是极高的，然后第二步就是要根据你读取到的offset去CommitLog里读取消息的完整数据了。

那么大家可以思考一下，这个从CommitLog里读取消息完整数据是如何读取的？是从os cache里读取？还是从磁盘里读取？

**答案是：两者都有**

因为CommitLog是用来存放消息的完整数据的，所以内容量是很大的，毕竟他一个文件就要1GB，所以整体完全有可能多达几个TB。

所以你思考一下，这么多的数据，可能都放在os cache里吗？

明显是不可能的，因为os cache用的也是机器的内存，一般多也就几十个GB而已，何况Broker自身的JVM也要用一些内存，留个os cache的内存只是一部分罢了，比如10GB~20GB的内存，所以os cache对于CommitLog而言，是无法把他全部数据都放在里面给你读取的！

也就是说，os cache对于CommitLog而言，主要是提升文件写入性能，当你不停的写入的时候，很多最新写入的数据都会先停留在os cache里，比如这可能有10GB~20GB的数据。

之后os会自动把cache里的比较旧的一些数据刷入磁盘里，腾出来空间给更新写入的数据放在os cache里，所以大部分数据可能多达几个TB都是在磁盘上的

我们看下面图里的示意，就是这个意思。

​      ![img](http://wechatapppro-1252524126.file.myqcloud.com/image/ueditor/99960100_1578390189.cn/txdocpic/0/7d448c095f380f6deab2979f809c1aa3/0)      

所以最终结论来了，当你拉取消息的时候，可以轻松从os cache里读取少量的ConsumeQueue文件里的offset，这个性能是极高的，但是当你去CommitLog文件里读取完整消息数据的时候，会有两种可能。

**第一种可能**，如果你读取的是那种刚刚写入CommitLog的数据，那么大概率他们还停留在os cache中，此时你可以顺利的直接从os cache里读取CommitLog中的数据，这个就是内存读取，性能是很高的。

**第二种可能**，你也许读取的是比较早之前写入CommitLog的数据，那些数据早就被刷入磁盘了，已经不在os cache里了，那么此时你就只能从磁盘上的文件里读取了，这个性能是比较差一些的。

**5、什么时候会从os cache读？什么时候会从磁盘读？**

接着我们看下面一个问题，那么什么时候会从os cache读？什么时候会从磁盘读呢？

其实这个问题很简单了，如果你的消费者机器一直快速的在拉取和消费处理，紧紧的跟上了生产者写入broker的消息速率，那么你每次拉取几乎都是在拉取最近人家刚写入CommitLog的数据，那几乎都在os cache里。

但是如果broker的负载很高，导致你拉取消息的速度很慢，或者是你自己的消费者机器拉取到一批消息之后处理的时候性能很低，处理速度很慢，这都会导致你跟不上生产者写入的速率。

比如人家都写入10万条数据了，结果你才拉取了2万条数据，此时有5万条最新的数据是在os cache里，有3万条你还没拉取的数据是在磁盘里，那么当后续你再拉取的时候，必然很大概率是从磁盘里读取早就刷入磁盘的3万条数据。

接着之前在os cache里的5万条数据可能又被刷入磁盘了，取而代之的是更新的几万条数据在os cache里，然后你再次拉取的时候，又会从磁盘里读取刷入磁盘里的5万条数据，相当于你每次都在从磁盘里读取数据了！

**6、Master Broker什么时候会让你从Slave Broker拉取数据？**

经过了上述大量的铺垫之后，我们终于可以解释这个关键性的问题了，到底什么时候Master Broker会让你从Slave Broker拉取数据？

其实这个问题我们上一个小节已经解释了一部分了，假设此时你的broker里已经写入了10万条数据，但是你仅仅拉取了2万条数据，下次你拉取的时候，是从第2万零1条数据开始继续往后拉取的，是不是？

也就是说，此时你有8万条数据是没有拉取的！

然后broker自己是知道机器上当前的整体物理内存有多大的，而且他也知道自己可用的最大空间占里面的比例，他是知道自己的消息最多可以在内存里放多少的！比如他心知肚明，他最多也就在内存里放5万条消息而已！

因为他知道，他最多只能利用10GB的os cache去放消息，这么多内存最多也就放5万左右的消息。

然后这个时候你过来拉取消息，他发现你还有8万条消息没有拉取，这个8万条消息他发现是大于10GB内存最多存放的5万条消息的，那么此时就说明，肯定有3万条消息目前是在磁盘上的，不在os cache内存里！

我们看下面的图，就分别示意了os cache里和磁盘上你没拉取的消息数量。

​      ![img](http://wechatapppro-1252524126.file.myqcloud.com/image/ueditor/13755100_1578390190.cn/txdocpic/0/8277fbb3c8f1a8af4d830382737fe9f9/0)      

所以他经过上述判断，会发现此时你很大概率会从磁盘里加载3万条消息出来！他会认为，出现这种情况，很可能是因为自己作为master broker负载太高了，导致没法及时的把消息给你，所以你落后的进度比较多。

这个时候，他就会告诉你，我这次给你从磁盘里读取3万条消息，但是下次你还是从slave broker去拉取吧！

以上就是这个关键问题的解答，本质是对比你当前没有拉取消息的数量和大小，以及最多可以存放在os cache内存里的消息的大小，如果你没拉取的消息超过了最大能使用的内存的量，那么说明你后续会频繁从磁盘加载数据，此时就让你从slave broker去加载数据了！

**7、对今日内容的一点总结**

今天我们给大家分析了一下消费者在拉取消息的时候到底是怎么选择Broker的，是从Master Broker还是Slave Broker去拉取，这里牵扯到了os cache，内存读，磁盘读，内存数据刷入磁盘等一系列的问题，包括了以下一些点：

1. Broker读写分离架构的回顾
2. CommitLog基于os cache实现写入性能优化的回顾
3. ConsumeQueue基于os cache实现读取性能优化的原理
4. CommitLog是基于os cache+磁盘一起进行读取的原理
5. 到底什么时候从os cache里读取CommitLog？什么时候从磁盘里读取？
6. Master Broker什么时候回让你去Slave Broker读取？

**End**

### 58 授人以渔：消费者是跟所有Broker建立连接，还是跟部分Broker建立连接？

今天的授人以渔环节，我们想让大家思考以下几个问题，相信每个人结合我们教给大家的知识，都能思考出来答案的：

**（1）**消费者机器到底是跟少数几台Broker建立连接，还是跟所有Broker都建立连接？这是不少朋友之前在评论区提出的问题，但是我想这里大家肯定都有自己的答案了。

**（2）**RocketMQ是支持主从架构下的读写分离的，而且什么时候找Slave Broker读取大家也都了解的很清楚了，那么大家思考一下，Kafka、RabbitMQ他们支持主从架构下的读写分离吗？支持Slave Broker的读取吗？为什么呢？

**（3）**如果支持读写分离的话，有没有一种可能，就是出现主从数据不一致的问题？比如有的数据刚刚到Master Broker和部分Slave Broker，但是你刚好是从那个没有写入数据的Slave Broker去读取了？

**（4）**消费吞吐量似乎是跟你的处理速度有很大关系，如果你消费到一批数据，处理太慢了，会导致你严重跟不上数据写入的速度，这会导致你后续几乎每次拉取数据都会从磁盘上读取，而不是os cache里读取，所以你觉得你在拉取到一批消息处理的时候，应该有哪些要点需要注意的？

欢迎大家将自己思考的结果发到评论区与我交流 

**End**

### 59 探秘黑科技：RocketMQ 是如何基于Netty扩展出高性能网络通信架构的？

**1、额外的加餐：探秘RocketMQ的一些黑科技**

目前咱们的专栏行进到这里为止，已经借着小猛的视角给大家分了一下RocketMQ运行的底层原理，本来应该到上一讲就结束这个阶段了

但是后来我们考虑了一下，还希望给大家再额外做一点加餐，单独加出来3讲RocketMQ黑科技探秘的内容，让大家能够对RocketMQ一些底层的比较关键的实现原理有一定的了解。

我们将会额外给大家讲解以下RocketMQ的核心底层原理：

1. RocketMQ是如何基于Netty扩展出高性能网络通信架构的？
2. 基于mmap内存映射实现CommitLog磁盘文件的高性能读写

今天这一讲，我们会给大家介绍一下RocketMQ中的Broker的网络通信的架构是如何基于Netty进行扩展的。

即使有些朋友对Netty没什么了解也是不要紧的，因为我们会站在线程和网络等较为基础的角度，给大家一步一图去分析。

**2、Reactor主线程与长短连接**

首先，作为Broker而言，他会有一个Reactor主线程。大家是不是对这个“Reactor主线程”这个称呼感觉有点恐惧？感觉出来一些特别厉害的不明所以的名词，让人有点胆怯，不敢继续往下看

没关系，你先别管“Reactor”是个什么东西，总之就先知道有这么个名字就行了，我们看下面的图里，你会发现Broker里有这么一个名字的线程，而且这个线程是负责监听一个网络端口的，比如监听个2888，39150这样的端口。

​      ![img](http://wechatapppro-1252524126.file.myqcloud.com/image/ueditor/43108900_1578390202.cn/txdocpic/0/be1a7a6219b6568f86538b229dbd7a96/0)    接着假设我们有一个Producer他现在想要跟Broker建立一个TCP长连接，可能有的朋友对这个长连接、短连接，也有点不明所以

没关系，一句话解释一下短连接：如果你要给别人发送一个请求，必须要建立连接 -> 发送请求 -> 接收响应 -> 断开连接，下一次你要发送请求的时候，这个过程得重新来一遍

每次建立一个连接之后，使用这个连接发送请求的时间是很短的，很快就会断开这个连接，所以他存在时间太短了，就是短连接。

长连接的话，就是反过来的意思，你建立一个连接 -> 发送请求 -> 接收响应 -> 发送请求 -> 接收响应 -> 发送请求 -> 接收响应

大家会发现，当你建立好一个长连接之后，可以不停的发送请求和接收响应，连接不会断开，等你不需要的时候再断开就行了，这个连接会存在很长时间，所以是长连接。

那么TCP长连接是什么意思呢？

如果你对网络没太多的了解，简单理解为TCP就是一个协议，所谓协议的意思就是，按照TCP这个协议规定好的步骤建立连接，按照他规定好的步骤发送请求。

比如你要建立一个TCP连接，必须先给对方发送他规定好的几个数据，然后人家按照规定返回给你几个数据，你再给人家发送几个数据，一切都按TCP的规定来。按照规定来，大家就可以建立一个TCP连接。

所以TCP长连接，就是按照这个TCP协议建立的长连接。

**3、Producer和Broker建立一个长连接**

接着比如有一个Producer他就要跟Broker建立一个TCP长连接了，此时Broker上的这个Reactor主线程，他会在端口上监听到这个Producer建立连接的请求

我们看下面的图，我示意了这个过程。      ![img](http://wechatapppro-1252524126.file.myqcloud.com/image/ueditor/51145400_1578390202.cn/txdocpic/0/18a359f563da2923b75381dd48634f79/0)       

接着这个Reactor主线程就专门会负责跟这个Producer按照TCP协议规定的一系列步骤和规范，建立好一个长连接。

但是现在问题来了，在Broker里用什么东西代表跟Producer之间建立的这个长连接呢？

**答案是：SocketChannel**

Producer里面会有一个SocketChannel，Broker里也会有一个SocketChannel，这两个SocketChannel就代表了他们俩建立好的这个长连接。

可能有人又会对这个SocketChannel名词感到很恐惧了，但是大家先别管这个SocketChannel，你只要知道他们俩建立好连接之后，就各自会有一个SocketChannel，俩SocketChannel配对起来就代表了一个连接

我们看下面的图     ![img](http://wechatapppro-1252524126.file.myqcloud.com/image/ueditor/58655600_1578390202.cn/txdocpic/0/617fc4f6253cd8020927af7f64dcc3b8/0)   接着下一个问题来了，既然Producer和Broker之间已经通过SocketChannel维持了一个长连接了，接着Producer是不是应该会通过这个SocketChannel去发送消息给Broker？

没错，就是这么做的，我们看下面的图。

​      ![img](http://wechatapppro-1252524126.file.myqcloud.com/image/ueditor/66628600_1578390202.cn/txdocpic/0/05a7317e742e13d81863c2c7386353ad/0)       

**4、基于Reactor线程池监听连接中的请求**

但是这个时候别急！我们还不能让Producer发送消息给Broker，因为虽然我们有一个SocketChannel组成的长连接，但是他仅仅是一个长连接而已！

假设Producer此时通过SocketChannel发送消息给到Broker那边的SocketChannel了，但是Broker里是哪个线程来负责从SocketChannel里获取这个消息呢？这是一个很大的问题！

所以我们接着要引入一个概念，就是Reactor线程池，你也先别管这里的“Reactor”是什么意思，你只要知道有一个这个名字的线程池就可以了，这个线程池里默认是3个线程！

然后Reactor主线程建立好的每个连接SocketChannel，都会交给这个Reactor线程池里的其中一个线程去监听请求。

​      ![img](http://wechatapppro-1252524126.file.myqcloud.com/image/ueditor/76302900_1578390202.cn/txdocpic/0/c895b4a0f99c9a71f8effd53d7e8bb65/0)    好，现在有了Reactor线程池这个概念，我们总算是可以让Producer发送请求过来了，他发送一个消息过来到达Broker里的SocketChannel，此时Reactor线程池里的一个线程会监听到这个SocketChannel中有请求到达了！

**5、基于Worker线程池完成一系列准备工作**

接着Reactor线程从SocketChannel中读取出来一个请求，这个请求在正式进行处理之前，必须就先要进行一些准备工作和预处理，比如SSL加密验证、编码解码、连接空闲检查、网络连接管理，诸如此类的一些事

那么问题又来了，这些事让谁来干呢？

这个时候需要引入一个新的概念，叫做Worker线程池，他默认有8个线程，此时Reactor线程收到的这个请求会交给Worker线程池中的一个线程进行处理，会完成上述一系列的准备工作

我们看下面的图

​      ![img](http://wechatapppro-1252524126.file.myqcloud.com/image/ueditor/88186400_1578390202.cn/txdocpic/0/90553a1438c20b77ab4f129ff992ae60/0)       

**6、基于业务线程池完成请求的处理**

那么现在如果Worker线程完成了一系列的预处理之后，比如SSL加密验证、编码解码、连接空闲检查、网络连接管理，等等，接着就需要对这个请求进行正式的业务处理了！我们来给大家举个例子。

比如对于你发送过来的消息，大家还记得我们之前讲解的Broker数据存储机制吗？

你接收到了消息，肯定是要写入CommitLog文件的，后续还有一些ConsumeQueue之类的事情需要处理，类似这种操作，就是业务处理逻辑。

这个时候，就得继续把经过一系列预处理之后的请求转交给业务线程池

比如对于处理发送消息请求而言，就会把请求转交给SendMessage线程池，而且如果大家还有一点点印象的话，其实在之前讲集群部署的时候，我们讲到过这个SendMessage线程是可以配置的，你配置的越多，自然处理消息的吞吐量越高。

我们看下面的图，就是引入了一个业务线程池的概念。

​      ![img](http://wechatapppro-1252524126.file.myqcloud.com/image/ueditor/98331200_1578390202.cn/txdocpic/0/d37d07f58327fcc1292c2e17b33e0fe9/0)       

**7、为什么这套网络通信框架会是高性能以及高并发的？**

最后我们来思考一下，为什么这套网络通信框架会是高性能以及高并发的呢？

原因很简单，假设我们只有一个线程来处理所有的网络连接的请求，包括读写磁盘文件之类的业务操作，那么会导致我们的并发能力必然很低。

一个线程每秒能处理多少个请求啊？是不是。

所以必须专门分配一个Reactor主线程出来，就是专门负责跟各种Producer、Consumer之类的建立长连接。

一旦连接建立好之后，大量的长连接均匀的分配给Reactor线程池里的多个线程。

每个Reactor线程负责监听一部分连接的请求，这个也是一个优化点，通过多线程并发的监听不同连接的请求，可以有效的提升大量并发请求过来时候的处理能力，可以提升网络框架的并发能力。

接着后续对大量并发过来的请求都是基于Worker线程池进行预处理的，当Worker线程池预处理多个请求的时候，Reactor线程还是可以有条不紊的继续监听和接收大量连接的请求是否到达。

而且最终的读写磁盘文件之类的操作都是交给业务线程池来处理的，当他并发执行多个请求的磁盘读写操作的时候，不影响其他线程池同时接收请求、预处理请求，没任何的影响。

所以最终的效果就是：

- Reactor主线程在端口上监听Producer建立连接的请求，建立长连接
- Reactor线程池并发的监听多个连接的请求是否到达
- Worker请求并发的对多个请求进行预处理
- 业务线程池并发的对多个请求进行磁盘读写业务操作

这些事情全部是利用不同的线程池并发执行的！任何一个环节在执行的时候，都不会影响其他线程池在其他环节进行请求的处理！

这样的一套网络通信架构，最终实现的效果就是可以高并发、高吞吐的对大量网络连接发送过来的大量请求进行处理，这是保证Broker实现高吞吐的一个非常关键的环节，就是这套网络通信架构。

因此对于这类中间件，如果你给他部署在高配置的物理机上，有几十个CPU核，那么此时你可以增加他的各种线程池的线程数量，这样就可以让各个环节同时高并发的处理大量的请求，由大量的CPU核来支持大量线程的并发工作。

**8、对今日内容做一点小的总结**

今天我们给大家讲解了一下RocketMQ中的网络通信架构，我们考虑很多朋友不一定会对TCP、NIO、TCP、BIO、Netty这些技术有了解，所以本文采取的是基于线程和网络这两个最基本的概念进行讲解的思路。

因为只要你是懂Java语言的，一定知道最基本的线程和网络这两个概念有一定的了解，顺着本文的思路看下来，相信大家一定可以对Broker的网络通信架构有一定的理解，核心的思路和架构应该是明白了。

**End**

### 60 授人以渔：BIO、NIO、AIO以及Netty之间的关系是什么？

今天的授人以渔环节给大家布置的任务会有点多，如果有朋友是对BIO、NIO、AIO以及Netty，SocketChannel，Selector，TCP这些网络和IO相关的基础知识都有比较扎实的了解，那么相信大家其实对今天文章里讲解的网络通信架构的实现思路，应该自己都能猜出来了。

实际上RocketMQ的网络通信架构就是基于Netty扩展实现的，包括Reactor主线程和Reactor线程池，这两个本质都是Netty封装好的概念，Netty自己就是基于Reactor模型去实现的。

因此希望如果有朋友对这些概念比较熟悉的，可以在评论区里分享出来自己的见解，即如何基于Netty、线程池去实现今天讲解的网络通信架构。

如果有朋友对这些技术都不太了解，建议大家自己查阅一些资料，搞明白TCP、BIO、NIO、AIO以及Netty这些都是什么东西，然后把自己的心得分享到评论区里去。

**End**

